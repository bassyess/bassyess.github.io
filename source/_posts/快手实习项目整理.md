# 快手实习项目整理
## 论文阅读
首先，是图像修复领域的调研和复现，主要是《Image Inpainting with Learnable Bidirectional Attention Maps》、《EdgeConnect: Structure Guided Image Inpainting using Edge Prediction》以及《Free-Form Image Inpainting with Gated Convolution》。
《Free-Form Image Inpainting with Gated Convolution》
## 图像修复
1、使用低阶图像特征的块（patch）匹配：生成看似合理的平稳纹理，但在处理复杂的场景，例如人脸和物体的时候，常出现严重的错误。
2、使用卷积神经网络推理生成模型： 从大规模数据集中学习到的语义，以端到端的方式合成非平稳图像中的内容。但是普通卷积的深度生成模型，在图像填充上存在严重的问题，因为普通卷积识所有输入的像素和特征，均为有效像素。对于图像填充来说，每一层的输入时由确实外的有效像素/特征和缺失区域（掩码区域）的无效像素组成。普通卷积使用相同的卷积核，适用于所有有效、无效和混合（例如那些空洞边界）的像素/特征，在自由形状上的掩码做测试时，导致视觉上的伪影（如颜色差异，模糊和孔周围明显的边缘响应）。
### 部分卷积
为了解决这一局限性，部分卷积（PartialConv），其中卷积被遮掩（masked）和归一化，仅以有效像素为条件。基于规则的掩码更新策略，用于更新下一层的有效位置。部分卷积将所有位置视为无效或有效，并用0或1掩码乘以所有层的输入，该掩码可以看做是一个单一的不可学习的特征门（gate）通道。
然而，这种假设是有几个局限性：
（1）考虑跨网络不同层的输入空间位置，他们可能包括：a)输入图像中有有效像素；b)输入图像中有掩蔽mask像素；c)感受野的神经元没有覆盖到输入图像的有效像素；d)感受野的神经元覆盖了不同数量的输入图像的有效像素，这些有效地图像像素也可能有不同的相对位置；e)深层合成的像素；f)启发式的将所有的位置归类为无效或有效，会忽略以上这些重要信息。
（2）如果我们扩展到用户知道的图像修复，用户在掩码内提供的稀疏草图（sparse sketch），这些像素位置应该被视为有效地还是无效的？如何正确地更新下一层的掩码？
（3）对于部分卷积，无效的像素将逐层逐渐消失，基于规则的掩码将在深层全部消失。然而，为了合成孔内的像素，这些深层可能还需要知道当前位置是在孔内还是孔外？全1掩码的部分卷积不能提供这样的信息。
### 门控卷积
因此提出了门控卷积的概念，门控卷积掩码更新过程，输入特征首先用于计算门控值$g=\theta(w_gx)$，$\theta$是激活函数，$w_g$是可学习参数。最终的输出是学习到的特征和门控值$y=\fi(wx)\bigdot g$的乘积。
由于普通卷积是将每一个像素都当成有效值去计算的，这个特性适用于分类和检测任务，但是不适用于inpainting任务，因为inpainting任务中hole里面的像素是无效值，因此对空洞hole里面的内容和外面的内容要加以区分，部分卷积虽然将里面和外面的内容加以区分，但是它将含有1个有效值像素的区域与含有9个有效值像素的区域同等对待，这明显不合理，gated conv则是使用卷积核sigmoid函数使得网络去学习这种区分。
### 光谱归一化马尔科夫判别器（SNPatchGAN）
之前的修复网络，为了修复带有矩形确实部分的图片，提出 local GAN 来提升实验结果；然而，我们要研究的是对任意形状缺失的形状，借鉴 global and GANs、MarkovianGANs、perpetual loss、spectral-normalized GANs，作者提出一个有效地GAN loss，即为 SN-PatchGAN。
SN-PatchGAN的组成，是由卷积网络构成，输入为image、mask、guidance channel，输出是一个形状为h×w×c的3维特征，h、w、c分别代表高、宽和通道数。SN-PatchGAN由6个卷积层（卷积核大小为2，步幅为2）堆叠来获得Markovian Patches特征的统计信息。然后直接将SN-PatchGAN应用到特征图的每一个特征元素，以输入图像的不同位置和不同语义（在不同的通道中表示）的形式表示GAN的$h\times w\times c$个。
值得注意的是，在训练的环境中，输出图中每个神经元的感受野可以覆盖整个输入图像，因此不需要全局判别器。
作者也采用了最近提出的Spectral normalization来进一步稳定GANs的训练。我们采用SN-GANs中描述的默认Spectral normalization的fast approximation算法。
为了判别输入的真假，作者也采用了hings loss来作为目标函数，未采用Perceptual loss的原因是相似的patch-level information已经被编码在SN-PatchGAN中。
### 网络结构
作者定制了一个带有Gated convolution layer和SN-PatchGan loss的generative inpainting network。网络结构由粗修复和细修复两个网络构成，采用了encoder-decoder network（PartialConv采用的是类似U-net的结构）。网络为全卷积神经网络，支持不同分辨率图片的输入。训练是一个端到端的过程。

## “蝴蝶消失”特效算法
快手的“蝴蝶消失”特效算法，主要是在用户上传的图片中，在蝴蝶飞舞的特效下，图片中的人像逐渐消失，还原完整的背景图像信息。算法的实现，是通过人像分割算法，检测图片中人体的位置并去除人体图像信息，然后采用图像修复算法还原人像区域可能存在的背景内容，实现蝴蝶飞舞下人像消失的特效。在这项工作中，我主要负责的是图像修复算法的研究以及后期的模型压缩等工作。
对于图像修复算法，我们使用卷积神经网络推理生成模型，从大规模数据集中学习到的语义，以端到端的方式合成非平稳图像中的内容。但是普通卷积的深度生成模型，在图像填充上存在严重的问题，因为普通卷积识所有输入的像素和特征，均为有效像素。但是对于图像填充来说，每一层的输入是由图像的有效像素和缺失区域的无效像素组成。普通卷积使用相同的卷积核，在人像这种自由形状上进行修复时，会导致视觉上的伪影（如颜色差异，模糊和孔周围明显的边缘响应）。
因此，我们采用门控卷积用于不规则的图像修复，它会为每个通道和每个空间位置（例如内部和外部掩码，RGB通道和用户知道通道）学习动态特征门控机制，使得最终的输出是学习到的特征与门控值g的乘积，门控卷积可以学会在单独的通道中突出掩码区域的信息，提高了不规则掩码输入的图像修复质量。我们通过堆叠门控卷积形成编码器和解码器网络，并将上下文注意模块集成到网络中，来更好的捕获远距离的依赖关系。
![网络结构](https://upload-images.jianshu.io/upload_images/13278405-ec200149adb2f468.png?imageMogr2/auto-orient/strip|imageView2/2/w/852/format/webp)
由于网络采用的是生成对抗网络，处理像素级的l1重建损失函数和GAN loss(生成器和判别器都使用hinge loss)外，我们还尝试添加其他的损失函数优化图像修复效果。 我们发现不同的损失函数对图像的修复结果有很大的影响，添加log-loss以及ls-loss生成的纹理信息相对来说比较差，但可以避免斑块状伪影的问题，而relgan-loss生成的纹理信息比较好，但会出现斑块状的纹理。添加感知损失perceptual loss，通过VGG16计算全图区域的影响能有效平滑修复区域的斑块信息，减少伪影现象，而添加风格损失style loss计算图像的风格变化，并没有带来明显的效果提升，因此模型最终选择添加感知损失来优化模型修复效果。（感知损失将真实图片卷积得到的feature与生产图片卷积得到的feature进行对比，是高层的内容和全局信息接近，也就是感知的含义）。
由于图像修复是基于人像分割算法得到的人像区域上进行修复的，在真实场景中，可能由于人像手持物体或者头发等导致人像分割的区域不准确，有残留的边缘区域会导致修复的结果出现斑块状的伪影现象。针对这种现象，我们在模型训练的时候添加了攻击噪声，使得模型更加的稳定和鲁棒。考虑到人像分割的不准确性多是发生于边缘区域，因此我们训练的时候对人像的mask轮廓上随机添加块状的缺口，模拟分割不准确问题。在验证集的添加30%的边界攻击数据集上进行验证，模型修复的SSIM相较于原始模型降低0.04，但相较于原始模型在攻击数据集的表降低0.1现，添加边界噪声的模型具有更加鲁棒的结果，模型最终的修复指标SSIM为0.737。
### 图像修复的评价指标
计算图像修复的质量，最直接的思路即比较修复后的图片与真实图像之间的可视误差，通过visibility of errors评价图像的质量。
#### PSNR
PSNR(Peak Signal to nise Ratio)，峰值信噪比，即峰值信号的能量与噪声的平均能量之比，通常表示时取log变成db计算，由于MSE为真实图片与含噪图像之差的能量均值，而两者的差即为噪声，因此PSNR即峰值信号能量与MSE之比。
优点：算法简单，计算的速度快。
缺点：基于对应像素点间的误差，呈现的差异值与人的主观感受不成比例，不符合人类视觉系统（HVS）的评价结果。
#### SSIM
SSIM(Structural Similarity)，结构相似性，也就是一种全参考的图像质量评价指标，它分别从亮度、对比度、结构三方面度量图像相似性。SSIM取值范围[0, 1]，值越大，表示图像失真越小，SSIM在图像去噪、图像相似度评价上是由于PSNR的。
$$SSIM = \frac{(2\mu_x\mu_y+c_1)(\sigma_{xy}+c_2}{(\mu_x^2+\mu_y^2+c_1)(\sigma_x^2+\sigma_y^2+c_2)}$$
我们每次计算都是从图片上取一个NxN的窗口，然后不断滑动窗口进行计算，最后取平均值作为全局的SSIM。
优点：改进了PSNR的缺点，比较符合人体视觉系统的评估。
缺点：结构相似性指标对于图像出现位移、缩放、旋转等非结构性的失真无法有效的运作。

## 模型压缩算法
### 分组卷积
分组卷积（Group convolution）：将多个卷积核拆分为分组，每个分组单独执行一系列运算之后，最终在全连接层再拼接在一起。分组卷积的重点不在于卷积，而在于分组：在执行卷积之后，将输出的feature map 执行分组。然后在每个组的数据会在各个GPU 上单独训练。
分组卷积在网络的全连接层才进行融合，这使得每个GPU 中只能看到部分通道的数据，这降低了模型的泛化能力。但是分组卷积降低了模型的参数数量以及计算量。
假设输入feature map具有$C_I$的输入通道，宽/高分别为$W_I, H_I$，假设卷积核的宽/高分别为$W_K, H_K$，有$C_O$个卷积核，则卷积的参数量为:$W_K\times H_K\times C_I\times C_O$，计算量为：$W_K\times H_K\times C_I\times W_O\times H_O\times C_O$。假设采用分组卷积，将输入通道分成G组，则分组后：参数量为$W_K\times H_K\times \frac{C_I}{G}\times \frac{C_O}{G}$，分组卷积的参数量、计算量均为标准卷积计算的$\frac{1}{G}$。
### 可分离卷积DepthWise
标准的卷积会考虑所有的输入通道，而DepthWise 卷积会针对每一个输入通道进行卷积操作，然后接一个1x1 的跨通道卷积操作。
DepthWise 卷积与分组卷积的区别在于：
1）分组卷积是一种通道分组的方式，它改变的是对输入的feature map 处理的方式。Depthwise 卷积是一种卷积的方式，它改变的是卷积的形式。
2）Depthwise 分组卷积结合了两者：首先沿着通道进行分组，然后每个分组执行DepthWise 卷积。
假设使用标准卷积，输入通道的数量为$C_I$，输出通道的数量为$C_O$，卷积核的尺寸为$W_K\times H_K$。则需要的参数数量为$C_I\times W_K\times H_K\times C_O$。使用Depthwise卷积时，图像的每个通道先通过一个$W_K\times H_K$的depthwise卷积层，再经过一个1x1、输出为$C_O$的卷积层。参数量为：
$$C_I\times W_K\times H_K+C_I\times 1\times 1\times C_O=W_K\times H_K\times C_I+C_IC_O$$
其参数数量是标准卷积的$\frac{1}{C_O}+\frac{1}{W_KH_K}$。
### 知识蒸馏
知识蒸馏的本质是让大的teacher model来协助线上的student model进行训练。因为模型训练时，我们通常采用复杂模型或Ensemble方式来获取最好的结果，从而导致参数冗余验证，在前向推理的时候，需要对模型进行复杂的计算。而知识蒸馏是把复杂模型或多个模型Ensemble（Teacher）学到的知识迁移到另一个轻量级模型上（Student）叫知识蒸馏，使得模型变轻量的同时（方便部署），尽量不损失性能。
知识蒸馏主要分成三个大类：
（1）输出迁移（output transfer），将网络的输出（soft-target）作为知识；
（2）特征迁移（feature transfer），将网络学习的特征作为知识；
（3）关系迁移（relation transfer），将网络或样本的关系作为知识。
在输出迁移中，我们对一些术语进行定义：
* Teacher：原始较大的模型或模型Ensemble，用于获取知识；
* Student：新的较小模型，接收teacher的知识，训练后用于前向预测；
* Hard target：样本原本的标签，Onehot
* Soft target：Teacher输出的预测结果（一般是softmax之后的概率）

这里的软目标的优势在于：
（1）弥补了简单分类中监督信号不足（信息熵比较少）的问题，增加了信息量；
（2）提供了训练数据中类别的关系（数据增强）；
（3）可能增强了模型泛化的能力。
而特征迁移Feature Transfer——将网络学习的特征作为知识，对卷积网络隐藏层输出的特征图——feature map（特征 & 知识）进行迁移（Attention transfer），让学生网络的feature map与教师网络的feature map尽可能相似。
关系迁移Relation Transfer——将网络或者样本的关系作为知识，让学生网络学习教师网络层与层之间的关系（特征关系）。
### 模型压缩过程
在原始的图像修复模型中，输入的图像大小为256x256，卷积的第一层通道数为48，模型的参数量接近25G，模型修复指标SSIM为0.7273。首先，们将输出图像的大小resize到128x128大小，模型的参数量降低为6G，但是模型的修复指标SSIM降低为0.6918，然后我们采用mobile_v2中的可分离卷积的思想，替换模型中的卷积方式，模型的参数量减少为1G，此时模型的SSIM指标为0.6486；接着我们进一步将卷积层的通道数减少为24，模型的参数量为300M，修复指标为0.6276。我们采用压缩的方式，很好的降低了模型的参数量，但由于模型压缩过程导致有用的参数的丢失，使得模型修复指标出现严重的下降，图像修复结果也出现严重的斑块状的伪影。为此，我们采用知识蒸馏的思想，将未压缩的模型作为教师网络，利用教师网络中生成的粗糙和中间特征图和输出的精细修复图，对学生网络的粗糙特征图和输出进行是修复图进行监督，在损失函数中计算二者的重建损失l1-loss，使得学生网络在训练过程中保留更多有用的信息。采用知识蒸馏的做法后，在参数量为1G的压缩模型中，SSIM指标提升为0.6661，在300M的蒸馏版本中模型的SSIM指标提升为0.6500，相较于未蒸馏前的效果有了明显的改进，而且修复的图片的斑块状伪影减少，修复区域更加的平滑。但在一些颜色变化复杂的区域，修复效果和原始相比还是会呈现明显的亮斑，因此我们添加感知损失计算teacher模型输出图像和学生网络输出图像的差值来平滑图像学生网络图像修复的结果。