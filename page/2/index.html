<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"bassyess.github.io","root":"/","scheme":"Pisces","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="千里之行，始于足下">
<meta property="og:type" content="website">
<meta property="og:title" content="Home">
<meta property="og:url" content="https://bassyess.github.io/page/2/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="千里之行，始于足下">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Kay">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://bassyess.github.io/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Home</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Home</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/03/03/%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(CNN)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/03/%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(CNN)/" class="post-title-link" itemprop="url">第五章 卷积神经网络(CNN)</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-03 12:24:30 / 修改时间：12:24:49" itemprop="dateCreated datePublished" datetime="2020-03-03T12:24:30+08:00">2020-03-03</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h1 id="第五章-卷积神经网络（CNN）"><a href="#第五章-卷积神经网络（CNN）" class="headerlink" title="第五章 卷积神经网络（CNN）"></a>第五章 卷积神经网络（CNN）</h1><p>​    卷积神经网络是一种用来处理局部和整体相关性的计算网络结构，被应用在图像识别、自然语言处理甚至是语音识别领域，因为图像数据具有显著的局部与整体关系，其在图像识别领域的应用获得了巨大的成功。</p>
<h2 id="5-1-卷积神经网络的组成层"><a href="#5-1-卷积神经网络的组成层" class="headerlink" title="5.1 卷积神经网络的组成层"></a>5.1 卷积神经网络的组成层</h2><p>​    以图像分类任务为例，在表5.1所示卷积神经网络中，一般包含5种类型的网络层次结构：</p>
<p>​                                                                 表5.1 卷积神经网络的组成</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">CNN层次结构</th>
<th style="text-align:center">输出尺寸</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">输入层</td>
<td style="text-align:center">$W_1\times H_1\times 3$</td>
<td style="text-align:left">卷积网络的原始输入，可以是原始或预处理后的像素矩阵</td>
</tr>
<tr>
<td style="text-align:center">卷积层</td>
<td style="text-align:center">$W_1\times H_1\times K$</td>
<td style="text-align:left">参数共享、局部连接，利用平移不变性从全局特征图提取局部特征</td>
</tr>
<tr>
<td style="text-align:center">激活层</td>
<td style="text-align:center">$W_1\times H_1\times K$</td>
<td style="text-align:left">将卷积层的输出结果进行非线性映射</td>
</tr>
<tr>
<td style="text-align:center">池化层</td>
<td style="text-align:center">$W_2\times H_2\times K$</td>
<td style="text-align:left">进一步筛选特征，可以有效减少后续网络层次所需的参数量</td>
</tr>
<tr>
<td style="text-align:center">全连接层</td>
<td style="text-align:center">$(W_2 \cdot H_2 \cdot K)\times C$</td>
<td style="text-align:left">将多维特征展平为2维特征，通常低维度特征对应任务的学习目标（类别或回归值）</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>$W_1\times H_1\times 3$对应原始图像或经过预处理的像素值矩阵，3对应RGB图像的通道;$K$表示卷积层中卷积核（滤波器）的个数;$W_2\times H_2$ 为池化后特征图的尺度，在全局池化中尺度对应$1\times 1$;$(W_2 \cdot H_2 \cdot K)$是将多维特征压缩到1维之后的大小，$C$对应的则是图像类别个数。</p>
</blockquote>
<h3 id="5-1-1-输入层"><a href="#5-1-1-输入层" class="headerlink" title="5.1.1 输入层"></a>5.1.1 输入层</h3><p>​    输入层(Input Layer)通常是输入卷积神经网络的原始数据或经过预处理的数据，可以是图像识别领域中原始三维的多彩图像，也可以是音频识别领域中经过傅利叶变换的二维波形数据，甚至是自然语言处理中一维表示的句子向量。以图像分类任务为例，输入层输入的图像一般包含RGB三个通道，是一个由长宽分别为$H$和$W$组成的3维像素值矩阵$H\times W \times 3$，卷积网络会将输入层的数据传递到一系列卷积、池化等操作进行特征提取和转化，最终由全连接层对特征进行汇总和结果输出。根据计算能力、存储大小和模型结构的不同，卷积神经网络每次可以批量处理的图像个数不尽相同，若指定输入层接收到的图像个数为$N$，则输入层的输出数据为$N\times H\times W\times 3$。</p>
<h3 id="5-1-2-卷积层"><a href="#5-1-2-卷积层" class="headerlink" title="5.1.2 卷积层"></a>5.1.2 卷积层</h3><p>​    卷积层(Convolution Layer)通常用作对输入层输入数据进行特征提取，通过卷积核矩阵对原始数据中隐含关联性的一种抽象。卷积操作原理上其实是对两张像素矩阵进行点乘求和的数学操作，其中一个矩阵为输入的数据矩阵，另一个矩阵则为卷积核（滤波器或特征矩阵），求得的结果表示为原始图像中提取的特定局部特征。图5.1表示卷积操作过程中的不同填充策略，上半部分采用零填充，下半部分采用有效卷积（舍弃不能完整运算的边缘部分）。<br>​                                                    <img src="img/ch5/convolution.png" alt="conv-same"><br>​                                                        图5.1 卷积操作示意图</p>
<h3 id="5-1-3-激活层"><a href="#5-1-3-激活层" class="headerlink" title="5.1.3 激活层"></a>5.1.3 激活层</h3><p>​    激活层(Activation Layer)负责对卷积层抽取的特征进行激活，由于卷积操作是由输入矩阵与卷积核矩阵进行相差的线性变化关系，需要激活层对其进行非线性的映射。激活层主要由激活函数组成，即在卷积层输出结果的基础上嵌套一个非线性函数，让输出的特征图具有非线性关系。卷积网络中通常采用ReLU来充当激活函数（还包括tanh和sigmoid等）ReLU的函数形式如公式（5-1）所示，能够限制小于0的值为0,同时大于等于0的值保持不变。</p>
<script type="math/tex; mode=display">
f(x)=\begin{cases}
   0 &\text{if } x<0 \\
   x &\text{if } x\ge 0
\end{cases}
\tag{5-1}</script><h3 id="5-1-4-池化层"><a href="#5-1-4-池化层" class="headerlink" title="5.1.4 池化层"></a>5.1.4 池化层</h3><p>​    池化层又称为降采样层(Downsampling Layer)，作用是对感受域内的特征进行筛选，提取区域内最具代表性的特征，能够有效地降低输出特征尺度，进而减少模型所需要的参数量。按操作类型通常分为最大池化(Max Pooling)、平均池化(Average Pooling)和求和池化(Sum Pooling)，它们分别提取感受域内最大、平均与总和的特征值作为输出，最常用的是最大池化。</p>
<h3 id="5-1-5-全连接层"><a href="#5-1-5-全连接层" class="headerlink" title="5.1.5 全连接层"></a>5.1.5 全连接层</h3><p>​    全连接层(Full Connected Layer)负责对卷积神经网络学习提取到的特征进行汇总，将多维的特征输入映射为二维的特征输出，高维表示样本批次，低位常常对应任务目标。</p>
<h2 id="5-2-卷积在图像中有什么直观作用"><a href="#5-2-卷积在图像中有什么直观作用" class="headerlink" title="5.2 卷积在图像中有什么直观作用"></a>5.2 卷积在图像中有什么直观作用</h2><p>​    在卷积神经网络中，卷积常用来提取图像的特征，但不同层次的卷积操作提取到的特征类型是不相同的，特征类型粗分如表5.2所示。<br>​                                                                 表5.2 卷积提取的特征类型</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">卷积层次</th>
<th style="text-align:center">特征类型</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">浅层卷积</td>
<td style="text-align:center">边缘特征</td>
</tr>
<tr>
<td style="text-align:center">中层卷积</td>
<td style="text-align:center">局部特征</td>
</tr>
<tr>
<td style="text-align:center">深层卷积</td>
<td style="text-align:center">全局特征</td>
</tr>
</tbody>
</table>
</div>
<p>图像与不同卷积核的卷积可以用来执行边缘检测、锐化和模糊等操作。表5.3显示了应用不同类型的卷积核（滤波器）后的各种卷积图像。<br>​                                                                 表5.3 一些常见卷积核的作用</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">卷积作用</th>
<th style="text-align:center">卷积核</th>
<th style="text-align:center">卷积后图像</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">输出原图</td>
<td style="text-align:center">$\begin{bmatrix} 0 &amp; 0 &amp; 0 \ 0 &amp; 1 &amp; 0 \ 0 &amp; 0 &amp; 0 \end{bmatrix}$</td>
<td style="text-align:center"><img src="/img/ch5/cat.jpg" alt="origin_img"></td>
</tr>
<tr>
<td style="text-align:center">边缘检测（突出边缘差异）</td>
<td style="text-align:center">$\begin{bmatrix} 1 &amp; 0 &amp; -1 \ 0 &amp; 0 &amp; 0 \ -1 &amp; 0 &amp; 1 \end{bmatrix}$</td>
<td style="text-align:center"><img src="/img/ch5/cat-edgeDetect.jpg" alt="edgeDetect-1"></td>
</tr>
<tr>
<td style="text-align:center">边缘检测（突出中间值）</td>
<td style="text-align:center">$\begin{bmatrix} -1 &amp; -1 &amp; -1 \ -1 &amp; 8 &amp; -1 \ -1 &amp; -1 &amp; -1 \end{bmatrix}$</td>
<td style="text-align:center"><img src="/img/ch5/cat-edgeDetect-2.jpg" alt="edgeDetect-2"></td>
</tr>
<tr>
<td style="text-align:center">图像锐化</td>
<td style="text-align:center">$\begin{bmatrix} 0 &amp; -1 &amp; 0 \ -1 &amp; 5 &amp; -1 \ 0 &amp; -1 &amp; 0 \end{bmatrix}$</td>
<td style="text-align:center"><img src="/img/ch5/cat-sharpen.jpg" alt="sharpen_img"></td>
</tr>
<tr>
<td style="text-align:center">方块模糊</td>
<td style="text-align:center">$\begin{bmatrix} 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 \end{bmatrix} \times \frac{1}{9}$</td>
<td style="text-align:center"><img src="/img/ch5/cat-boxblur.jpg" alt="box_blur"></td>
</tr>
<tr>
<td style="text-align:center">高斯模糊</td>
<td style="text-align:center">$\begin{bmatrix} 1 &amp; 2 &amp; 1 \ 2 &amp; 4 &amp; 2 \ 1 &amp; 2 &amp; 1 \end{bmatrix} \times \frac{1}{16}$</td>
<td style="text-align:center"><img src="/img/ch5/cat-blur-gaussian.jpg" alt="gaussian_blur"></td>
</tr>
</tbody>
</table>
</div>
<h2 id="5-3-卷积层有哪些基本参数？"><a href="#5-3-卷积层有哪些基本参数？" class="headerlink" title="5.3 卷积层有哪些基本参数？"></a>5.3 卷积层有哪些基本参数？</h2><p>​    卷积层中需要用到卷积核（滤波器或特征检测器）与图像特征矩阵进行点乘运算，利用卷积核与对应的特征感受域进行划窗式运算时，需要设定卷积核对应的大小、步长、个数以及填充的方式，如表5.4所示。</p>
<p>​                                                                         表5.4 卷积层的基本参数</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">参数名</th>
<th style="text-align:left">作用</th>
<th style="text-align:left">常见设置</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">卷积核大小 (Kernel Size)</td>
<td style="text-align:left">卷积核的大小定义了卷积的感受野</td>
<td style="text-align:left">在过去常设为5，如LeNet-5；现在多设为3，通过堆叠$3\times3$的卷积核来达到更大的感受域</td>
</tr>
<tr>
<td style="text-align:center">卷积核步长 (Stride)</td>
<td style="text-align:left">定义了卷积核在卷积过程中的步长</td>
<td style="text-align:left">常见设置为1，表示滑窗距离为1，可以覆盖所有相邻位置特征的组合；当设置为更大值时相当于对特征组合降采样</td>
</tr>
<tr>
<td style="text-align:center">填充方式 (Padding)</td>
<td style="text-align:left">在卷积核尺寸不能完美匹配输入的图像矩阵时需要进行一定的填充策略</td>
<td style="text-align:left">设置为’SAME’表示对不足卷积核大小的边界位置进行某种填充（通常零填充）以保证卷积输出维度与与输入维度一致；当设置为’VALID’时则对不足卷积尺寸的部分进行舍弃，输出维度就无法保证与输入维度一致</td>
</tr>
<tr>
<td style="text-align:center">输入通道数 (In Channels)</td>
<td style="text-align:left">指定卷积操作时卷积核的深度</td>
<td style="text-align:left">默认与输入的特征矩阵通道数（深度）一致；在某些压缩模型中会采用通道分离的卷积方式</td>
</tr>
<tr>
<td style="text-align:center">输出通道数 (Out Channels)</td>
<td style="text-align:left">指定卷积核的个数</td>
<td style="text-align:left">若设置为与输入通道数一样的大小，可以保持输入输出维度的一致性；若采用比输入通道数更小的值，则可以减少整体网络的参数量</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>卷积操作维度变换公式：</p>
<p>$O_d =\begin{cases} \lceil \frac{(I_d - k_{size})+ 1)}{s}\rceil ,&amp; \text{padding=VALID}\ \lceil \frac{I_d}{s}\rceil,&amp;\text{padding=SAME} \end{cases}$</p>
<p>其中，$I_d$为输入维度，$O_d$为输出维度，$k_{size}$为卷积核大小，$s$为步长</p>
</blockquote>
<h2 id="5-4-卷积核有什么类型？"><a href="#5-4-卷积核有什么类型？" class="headerlink" title="5.4 卷积核有什么类型？"></a>5.4 卷积核有什么类型？</h2><p>​    常见的卷积主要是由连续紧密的卷积核对输入的图像特征进行滑窗式点乘求和操作，除此之外还有其他类型的卷积核在不同的任务中会用到，具体分类如表5.5所示。<br>​                                                                     表5.5 卷积核分类</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">卷积类别</th>
<th style="text-align:center">示意图</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">标准卷积</td>
<td style="text-align:center"><img src="/img/ch5/img7.png" alt="image"></td>
<td style="text-align:left">最常用的卷积核，连续紧密的矩阵形式可以提取图像区域中的相邻像素之间的关联关系，$3\times3$的卷积核可以获得$3\times3$像素范围的感受视野</td>
</tr>
<tr>
<td style="text-align:center">扩张卷积（带孔卷积或空洞卷积）</td>
<td style="text-align:center"><img src="/img/ch5/img8.png" alt="image"></td>
<td style="text-align:left">引入一个称作扩张率（Dilation Rate）的参数，使同样尺寸的卷积核可以获得更大的感受视野，相应的在相同感受视野的前提下比普通卷积采用更少的参数。同样是$3\times3$的卷积核尺寸，扩张卷积可以提取$5\times5$范围的区域特征，在实时图像分割领域广泛应用</td>
</tr>
<tr>
<td style="text-align:center">转置卷积</td>
<td style="text-align:center"><img src="/img/ch5/img10.png" alt="image"></td>
<td style="text-align:left">先对原始特征矩阵进行填充使其维度扩大到适配卷积目标输出维度，然后进行普通的卷积操作的一个过程，其输入到输出的维度变换关系恰好与普通卷积的变换关系相反，但这个变换并不是真正的逆变换操作，通常称为转置卷积(Transpose Convolution)而不是反卷积(Deconvolution)。转置卷积常见于目标检测领域中对小目标的检测和图像分割领域还原输入图像尺度。</td>
</tr>
<tr>
<td style="text-align:center">可分离卷积</td>
<td style="text-align:center"><img src="/img/ch5/img11.png" alt="image"></td>
<td style="text-align:left">标准的卷积操作是同时对原始图像$H\times W\times C$三个方向的卷积运算，假设有$K$个相同尺寸的卷积核，这样的卷积操作需要用到的参数为$H\times W\times C\times K$个；若将长宽与深度方向的卷积操作分离出变为$H\times W$与$C$的两步卷积操作，则同样的卷积核个数$K$，只需要$(H\times W + C)\times K$个参数，便可得到同样的输出尺度。可分离卷积(Seperable Convolution)通常应用在模型压缩或一些轻量的卷积神经网络中，如MobileNet$^{[1]}$、Xception$^{[2]}$等</td>
</tr>
</tbody>
</table>
</div>
<h2 id="5-5-二维卷积与三维卷积有什么区别？"><a href="#5-5-二维卷积与三维卷积有什么区别？" class="headerlink" title="5.5 二维卷积与三维卷积有什么区别？"></a>5.5 二维卷积与三维卷积有什么区别？</h2><ul>
<li><strong>二维卷积</strong><br>二维卷积操作如图5.3所示，为了更直观的说明，分别展示在单通道和多通道输入中，对单个通道输出的卷积操作。在单通道输入的情况下，若输入卷积核尺寸为 $(k_h, k_w, 1)​$，卷积核在输入图像的空间维度上进行滑窗操作，每次滑窗和 $(k_h, k_w)​$窗口内的值进行卷积操作，得到输出图像中的一个值。在多通道输入的情况下，假定输入图像特征通道数为3，卷积核尺寸则为$(k_h, k_w, 3)​$，每次滑窗与3个通道上的$(k_h, k_w)​$窗口内的所有值进行卷积操作，得到输出图像中的一个值。</li>
</ul>
<p><img src="/img/ch5/5.6.1.png" alt="image"></p>
<ul>
<li><strong>三维卷积</strong><br>3D卷积操作如图所示，同样分为单通道和多通道，且假定只使用1个卷积核，即输出图像仅有一个通道。对于单通道输入，与2D卷积不同之处在于，输入图像多了一个深度(depth)维度，卷积核也多了一个$k_d​$维度，因此3D卷积核的尺寸为$(k_h, k_w, k_d)​$，每次滑窗与$(k_h, k_w, k_d)​$窗口内的值进行相关操作，得到输出3D图像中的一个值。对于多通道输入，则与2D卷积的操作一样，每次滑窗与3个channels上的$(k_h, k_w, k_d)​$窗口内的所有值进行相关操作，得到输出3D图像中的一个值。</li>
</ul>
<p><img src="/img/ch5/5.6.2.png" alt="image"></p>
<h2 id="5-7-有哪些池化方法？"><a href="#5-7-有哪些池化方法？" class="headerlink" title="5.7 有哪些池化方法？"></a>5.7 有哪些池化方法？</h2><p>​    池化操作通常也叫做子采样(Subsampling)或降采样(Downsampling)，在构建卷积神经网络时，往往会用在卷积层之后，通过池化来降低卷积层输出的特征维度，有效减少网络参数的同时还可以防止过拟合现象。池化操作可以降低图像维度的原因，本质上是因为图像具有一种“静态性”的属性，这个意思是说在一个图像区域有用的特征极有可能在另一个区域同样有用。因此，为了描述一个大的图像，很直观的想法就是对不同位置的特征进行聚合统计。例如，可以计算图像在固定区域上特征的平均值 (或最大值)来代表这个区域的特征。<br>​                                                                              表5.6 池化分类</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">池化类型</th>
<th style="text-align:center">示意图</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">一般池化(General Pooling)</td>
<td style="text-align:center"><img src="/img/ch5/general_pooling.png" alt="max_pooling"></td>
<td style="text-align:left">通常包括最大池化(Max Pooling)和平均池化(Mean Pooling)。以最大池化为例，池化范围$(2\times2)$和滑窗步长$(stride=2)$ 相同，仅提取一次相同区域的范化特征。</td>
</tr>
<tr>
<td style="text-align:center">重叠池化(Overlapping Pooling)</td>
<td style="text-align:center"><img src="/img/ch5/overlap_pooling.png" alt="overlap_pooling"></td>
<td style="text-align:left">与一般池化操作相同，但是池化范围$P_{size}$与滑窗步长$stride$关系为$P_{size}&gt;stride$，同一区域内的像素特征可以参与多次滑窗提取，得到的特征表达能力更强，但计算量更大。</td>
</tr>
<tr>
<td style="text-align:center">空间金字塔池化$^*$(Spatial Pyramid Pooling)</td>
<td style="text-align:center"><img src="/img/ch5/spatial_pooling.png" alt="spatial_pooling"></td>
<td style="text-align:left">在进行多尺度目标的训练时，卷积层允许输入的图像特征尺度是可变的，紧接的池化层若采用一般的池化方法会使得不同的输入特征输出相应变化尺度的特征，而卷积神经网络中最后的全连接层则无法对可变尺度进行运算，因此需要对不同尺度的输出特征采样到相同输出尺度。</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>SPPNet$^{[3]}$就引入了空间池化的组合，对不同输出尺度采用不同的滑窗大小和步长以确保输出尺度相同$(win_{size}=\lceil \frac{in}{out}\rceil; stride=\lfloor \frac{in}{out}\rfloor; )$，同时用如金字塔式叠加的多种池化尺度组合，以提取更加丰富的图像特征。常用于多尺度训练和目标检测中的区域提议网络(Region Proposal Network)的兴趣区域(Region of Interest)提取</p>
</blockquote>
<h2 id="5-8-1-times1-卷积作用？"><a href="#5-8-1-times1-卷积作用？" class="headerlink" title="5.8 $1\times1$卷积作用？"></a>5.8 $1\times1$卷积作用？</h2><p>​    NIN(Network in Network)$^{[4]}​$是第一篇探索$1\times1​$卷积核的论文，这篇论文通过在卷积层中使用MLP替代传统线性的卷积核，使单层卷积层内具有非线性映射的能力，也因其网络结构中嵌套MLP子网络而得名NIN。NIN对不同通道的特征整合到MLP自网络中，让不同通道的特征能够交互整合，使通道之间的信息得以流通，其中的MLP子网络恰恰可以用$1\times1​$的卷积进行代替。</p>
<p>​    GoogLeNet$^{[5]}​$则采用$1\times1​$卷积核来减少模型的参数量。在原始版本的Inception模块中，由于每一层网络采用了更多的卷积核，大大增加了模型的参数量。此时在每一个较大卷积核的卷积层前引入$1\times1​$卷积，可以通过分离通道与宽高卷积来减少模型参数量。以图5.2为例，在不考虑参数偏置项的情况下，若输入和输出的通道数为$C_1=16​$，则左半边网络模块所需的参数为$(1\times1+3\times3+5\times5+0)\times C_1\times C_1=8960​$；假定右半边网络模块采用的$1\times1​$卷积通道数为$C_2=8​$$(满足C_1&gt;C_2)​$，则右半部分的网络结构所需参数量为$(1\times1\times (3C_1+C_2)+3\times3\times C_2 +5\times5\times C_2)\times C_1=5248​$ ，可以在不改变模型表达能力的前提下大大减少所使用的参数量。</p>
<p><img src="/img/ch5/5.8-1.png" alt="image"></p>
<p>​                                图5.2 Inception模块</p>
<p>综上所述，$1\times 1​$卷积的作用主要为以下两点：</p>
<ul>
<li>实现信息的跨通道交互和整合。</li>
<li>对卷积核通道数进行降维和升维，减小参数量。</li>
</ul>
<h2 id="5-9-卷积层和池化层有什么区别？"><a href="#5-9-卷积层和池化层有什么区别？" class="headerlink" title="5.9 卷积层和池化层有什么区别？"></a>5.9 卷积层和池化层有什么区别？</h2><p>​    卷积层核池化层在结构上具有一定的相似性，都是对感受域内的特征进行提取，并且根据步长设置获取到不同维度的输出，但是其内在操作是有本质区别的，如表5.7所示。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">卷积层</th>
<th style="text-align:center">池化层</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>结构</strong></td>
<td style="text-align:center">零填充时输出维度不变，而通道数改变</td>
<td style="text-align:center">通常特征维度会降低，通道数不变</td>
</tr>
<tr>
<td style="text-align:center"><strong>稳定性</strong></td>
<td style="text-align:center">输入特征发生细微改变时，输出结果会改变</td>
<td style="text-align:center">感受域内的细微变化不影响输出结果</td>
</tr>
<tr>
<td style="text-align:center"><strong>作用</strong></td>
<td style="text-align:center">感受域内提取局部关联特征</td>
<td style="text-align:center">感受域内提取泛化特征，降低维度</td>
</tr>
<tr>
<td style="text-align:center"><strong>参数量</strong></td>
<td style="text-align:center">与卷积核尺寸、卷积核个数相关</td>
<td style="text-align:center">不引入额外参数</td>
</tr>
</tbody>
</table>
</div>
<h2 id="5-10-卷积核是否一定越大越好？"><a href="#5-10-卷积核是否一定越大越好？" class="headerlink" title="5.10 卷积核是否一定越大越好？"></a>5.10 卷积核是否一定越大越好？</h2><p>​    在早期的卷积神经网络中（如LeNet-5、AlexNet），用到了一些较大的卷积核（$11\times11$和$5\times 5$），受限于当时的计算能力和模型结构的设计，无法将网络叠加得很深，因此卷积网络中的卷积层需要设置较大的卷积核以获取更大的感受域。但是这种大卷积核反而会导致计算量大幅增加，不利于训练更深层的模型，相应的计算性能也会降低。后来的卷积神经网络（VGG、GoogLeNet等），发现通过堆叠2个$3\times 3$卷积核可以获得与$5\times 5$卷积核相同的感受视野，同时参数量会更少（$3×3×2+1$ &lt; $ 5×5×1+1$），$3\times 3$卷积核被广泛应用在许多卷积神经网络中。因此可以认为，在大多数情况下通过堆叠较小的卷积核比直接采用单个更大的卷积核会更加有效。</p>
<p>​    但是，这并不是表示更大的卷积核就没有作用，在某些领域应用卷积神经网络时仍然可以采用较大的卷积核。譬如在自然语言处理领域，由于文本内容不像图像数据可以对特征进行很深层的抽象，往往在该领域的特征提取只需要较浅层的神经网络即可。在将卷积神经网络应用在自然语言处理领域时，通常都是较为浅层的卷积层组成，但是文本特征有时又需要有较广的感受域让模型能够组合更多的特征（如词组和字符），此时直接采用较大的卷积核将是更好的选择。</p>
<p>​    综上所述，卷积核的大小并没有绝对的优劣，需要视具体的应用场景而定，但是极大和极小的卷积核都是不合适的，单独的$1\times 1$极小卷积核只能用作分离卷积而不能对输入的原始特征进行有效的组合，极大的卷积核通常会组合过多的无意义特征从而浪费了大量的计算资源。</p>
<h2 id="5-11-每层卷积是否只能用一种尺寸的卷积核？"><a href="#5-11-每层卷积是否只能用一种尺寸的卷积核？" class="headerlink" title="5.11 每层卷积是否只能用一种尺寸的卷积核？"></a>5.11 每层卷积是否只能用一种尺寸的卷积核？</h2><p>​    经典的神经网络一般都属于层叠式网络，每层仅用一个尺寸的卷积核，如VGG结构中使用了大量的$3×3$卷积层。事实上，同一层特征图可以分别使用多个不同尺寸的卷积核，以获得不同尺度的特征，再把这些特征结合起来，得到的特征往往比使用单一卷积核的要好，如GoogLeNet、Inception系列的网络，均是每层使用了多个卷积核结构。如图5.3所示，输入的特征在同一层分别经过$1×1$、$3×3$和$5×5$三种不同尺寸的卷积核，再将分别得到的特征进行整合，得到的新特征可以看作不同感受域提取的特征组合，相比于单一卷积核会有更强的表达能力。</p>
<p><img src="/img/ch5/5.11-1.png" alt="image"></p>
<p>​                                图5.3 Inception模块结构</p>
<h2 id="5-12-怎样才能减少卷积层参数量？"><a href="#5-12-怎样才能减少卷积层参数量？" class="headerlink" title="5.12 怎样才能减少卷积层参数量？"></a>5.12 怎样才能减少卷积层参数量？</h2><p>减少卷积层参数量的方法可以简要地归为以下几点：</p>
<ul>
<li>使用堆叠小卷积核代替大卷积核：VGG网络中2个$3\times 3$的卷积核可以代替1个$5\times 5$的卷积核</li>
<li>使用分离卷积操作：将原本$K\times K\times C$的卷积操作分离为$K\times K\times 1$和$1\times1\times C$的两部分操作</li>
<li>添加$1\times 1$的卷积操作：与分离卷积类似，但是通道数可变，在$K\times K\times C_1$卷积前添加$1\times1\times C_2$的卷积核（满足$C_2 &lt;C_1$）</li>
<li>在卷积层前使用池化操作：池化可以降低卷积层的输入特征维度</li>
</ul>
<h2 id="5-13-在进行卷积操作时，必须同时考虑通道和区域吗？"><a href="#5-13-在进行卷积操作时，必须同时考虑通道和区域吗？" class="headerlink" title="5.13 在进行卷积操作时，必须同时考虑通道和区域吗？"></a>5.13 在进行卷积操作时，必须同时考虑通道和区域吗？</h2><p>​    标准卷积中，采用区域与通道同时处理的操作，如下图所示：</p>
<p><img src="/img/ch5/5.13-1.png" alt="image"></p>
<p>​    这样做可以简化卷积层内部的结构，每一个输出的特征像素都由所有通道的同一个区域提取而来。</p>
<p>​    但是这种方式缺乏灵活性，并且在深层的网络结构中使得运算变得相对低效，更为灵活的方式是使区域和通道的卷积分离开来，通道分离（深度分离）卷积网络由此诞生。如下图所示，Xception网络可解决上述问题。</p>
<p><img src="/img/ch5/5.13-2.png" alt="image"></p>
<p>​    我们首先对每一个通道进行各自的卷积操作，有多少个通道就有多少个过滤器。得到新的通道特征矩阵之后，再对这批新通道特征进行标准的$1×1​$跨通道卷积操作。</p>
<h2 id="5-14-采用宽卷积的好处有什么？"><a href="#5-14-采用宽卷积的好处有什么？" class="headerlink" title="5.14 采用宽卷积的好处有什么？"></a>5.14 采用宽卷积的好处有什么？</h2><p>​    宽卷积对应的是窄卷积，实际上并不是卷积操作的类型，指的是卷积过程中的填充方法，对应的是’SAME’填充和’VALID’填充。’SAME’填充通常采用零填充的方式对卷积核不满足整除条件的输入特征进行补全，以使卷积层的输出维度保持与输入特征维度一致；’VALID’填充的方式则相反，实际并不进行任何填充，在输入特征边缘位置若不足以进行卷积操作，则对边缘信息进行舍弃，因此在步长为1的情况下该填充方式的卷积层输出特征维度可能会略小于输入特征的维度。此外，由于前一种方式通过补零来进行完整的卷积操作，可以有效地保留原始的输入特征信息。</p>
<p>​    比如下图左部分为窄卷积。注意到越在边缘的位置被卷积的次数越少。宽卷积可以看作在卷积之前在边缘用0补充，常见有两种情况，一个是全补充，如下图右部分，这样输出大于输入的维度。另一种常用的方法是补充一一部分0值，使得输出和输入的维度一致。</p>
<p><img src="/img/ch5/5.14.1.png" alt="image"></p>
<h2 id="5-15-理解转置卷积与棋盘效应"><a href="#5-15-理解转置卷积与棋盘效应" class="headerlink" title="5.15 理解转置卷积与棋盘效应"></a>5.15 理解转置卷积与棋盘效应</h2><h3 id="5-15-1-标准卷积"><a href="#5-15-1-标准卷积" class="headerlink" title="5.15.1 标准卷积"></a>5.15.1 标准卷积</h3><p>在理解转置卷积之前，需要先理解标准卷积的运算方式。</p>
<p>首先给出一个输入输出结果</p>
<p><img src="/img/ch5/img32.png" alt="image"></p>
<p>那是怎样计算的呢？</p>
<p>卷积的时候需要对卷积核进行180的旋转，同时卷积核中心与需计算的图像像素对齐，输出结构为中心对齐像素的一个新的像素值，计算例子如下：</p>
<p><img src="/img/ch5/5.19.1-2.png" alt="image"></p>
<p>这样计算出左上角(即第一行第一列)像素的卷积后像素值。</p>
<p>给出一个更直观的例子，从左到右看，原像素经过卷积由1变成-8。</p>
<p><img src="/img/ch5/5.19.1-3.png" alt="image"></p>
<p>通过滑动卷积核，就可以得到整张图片的卷积结果。</p>
<h3 id="5-15-2-转置卷积"><a href="#5-15-2-转置卷积" class="headerlink" title="5.15.2 转置卷积"></a>5.15.2 转置卷积</h3><p>图像的deconvolution过程如下：</p>
<p><img src="/img/ch5/5.19.2-5.png" alt="image"></p>
<p>输入：2x2， 卷积核：4x4， 滑动步长：3， 输出：7x7 </p>
<p>过程如下： </p>
<ol>
<li><p>输入图片每个像素进行一次full卷积，根据full卷积大小计算可以知道每个像素的卷积后大小为 1+4-1=4， 即4x4大小的特征图，输入有4个像素所以4个4x4的特征图 </p>
</li>
<li><p>将4个特征图进行步长为3的相加； 输出的位置和输入的位置相同。步长为3是指每隔3个像素进行相加，重叠部分进行相加，即输出的第1行第4列是由红色特阵图的第一行第四列与绿色特征图的第一行第一列相加得到，其他如此类推。  </p>
<p>可以看出翻卷积的大小是由卷积核大小与滑动步长决定， in是输入大小， k是卷积核大小， s是滑动步长， out是输出大小 得到 out = (in - 1) <em> s + k 上图过程就是， (2 - 1) </em> 3 + 4 = 7。</p>
</li>
</ol>
<h3 id="5-15-3-棋盘效应"><a href="#5-15-3-棋盘效应" class="headerlink" title="5.15.3 棋盘效应"></a>5.15.3 棋盘效应</h3><h2 id="5-16-卷积神经网络的参数设置"><a href="#5-16-卷积神经网络的参数设置" class="headerlink" title="5.16 卷积神经网络的参数设置"></a>5.16 卷积神经网络的参数设置</h2><p>​    卷积神经网络中常见的参数在其他类型的神经网络中也是类似的，但是参数的设置还得结合具体的任务才能设置在合理的范围，具体的参数列表如表XX所示。<br>​                                                    表XX 卷积神经网络常见参数</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">参数名</th>
<th style="text-align:center">常见设置</th>
<th style="text-align:left">参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">学习率(Learning Rate)</td>
<td style="text-align:center">$0-1$</td>
<td style="text-align:left">反向传播网络中更新权值矩阵的步长，在一些常见的网络中会在固定迭代次数或模型不再收敛后对学习率进行指数下降(如$lr=lr\times 0.1$)。当学习率越大计算误差对权值矩阵的影响越大，容易在某个局部最优解附近震荡；越小的学习率对网络权值的更新越精细，但是需要花费更多的时间去迭代</td>
</tr>
<tr>
<td style="text-align:center">批次大小(Batch Size)</td>
<td style="text-align:center">$1-N$</td>
<td style="text-align:left">批次大小指定一次性流入模型的数据样本个数，根据任务和计算性能限制判断实际取值，在一些图像任务中往往由于计算性能和存储容量限制只能选取较小的值。在相同迭代次数的前提下，数值越大模型越稳定，泛化能力越强，损失值曲线越平滑，模型也更快地收敛，但是每次迭代需要花费更多的时间</td>
</tr>
<tr>
<td style="text-align:center">数据轮次(Epoch)</td>
<td style="text-align:center">$1-N$</td>
<td style="text-align:left">数据轮次指定所有训练数据在模型中训练的次数，根据数据集规模和分布情况会设置为不同的值。当模型较为简单或训练数据规模较小时，通常轮次不宜过高，否则模型容易过拟合；模型较为复杂或训练数据规模足够大时，可适当提高数据的训练轮次。</td>
</tr>
<tr>
<td style="text-align:center">权重衰减系数(Weight Decay)</td>
<td style="text-align:center">$0-0.001$</td>
<td style="text-align:left">模型训练过程中反向传播权值更新的权重衰减值</td>
</tr>
</tbody>
</table>
</div>
<h2 id="5-17-提高卷积神经网络的泛化能力"><a href="#5-17-提高卷积神经网络的泛化能力" class="headerlink" title="5.17 提高卷积神经网络的泛化能力"></a>5.17 提高卷积神经网络的泛化能力</h2><p>​    卷积神经网络与其他类型的神经网络类似，在采用反向传播进行训练的过程中比较依赖输入的数据分布，当数据分布较为极端的情况下容易导致模型欠拟合或过拟合，表XX记录了提高卷积网络泛化能力的方法。<br>​                                                                   表XX 提高卷积网络化能力的方法</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">方法</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">使用更多数据</td>
<td style="text-align:left">在有条件的前提下，尽可能多地获取训练数据是最理想的方法，更多的数据可以让模型得到充分的学习，也更容易提高泛化能力</td>
</tr>
<tr>
<td style="text-align:center">使用更大批次</td>
<td style="text-align:left">在相同迭代次数和学习率的条件下，每批次采用更多的数据将有助于模型更好的学习到正确的模式，模型输出结果也会更加稳定</td>
</tr>
<tr>
<td style="text-align:center">调整数据分布</td>
<td style="text-align:left">大多数场景下的数据分布是不均匀的，模型过多地学习某类数据容易导致其输出结果偏向于该类型的数据，此时通过调整输入的数据分布可以一定程度提高泛化能力</td>
</tr>
<tr>
<td style="text-align:center">调整目标函数</td>
<td style="text-align:left">在某些情况下，目标函数的选择会影响模型的泛化能力，如目标函数$f(y,y’)=</td>
<td>y-y’</td>
<td>$在某类样本已经识别较为准确而其他样本误差较大的侵害概况下，不同类别在计算损失结果的时候距离权重是相同的，若将目标函数改成$f(y,y’)=(y-y’)^2$则可以使误差小的样本计算损失的梯度比误差大的样本更小，进而有效地平衡样本作用，提高模型泛化能力</td>
</tr>
<tr>
<td style="text-align:center">调整网络结构</td>
<td style="text-align:left">在浅层卷积神经网络中，参数量较少往往使模型的泛化能力不足而导致欠拟合，此时通过叠加卷积层可以有效地增加网络参数，提高模型表达能力；在深层卷积网络中，若没有充足的训练数据则容易导致模型过拟合，此时通过简化网络结构减少卷积层数可以起到提高模型泛化能力的作用</td>
</tr>
<tr>
<td style="text-align:center">数据增强</td>
<td style="text-align:left">数据增强又叫数据增广，在有限数据的前提下通过平移、旋转、加噪声等一些列变换来增加训练数据，同类数据的表现形式也变得更多样，有助于模型提高泛化能力，需要注意的是数据变化应尽可能不破坏元数数据的主体特征(如在图像分类任务中对图像进行裁剪时不能将分类主体目标裁出边界)。</td>
</tr>
<tr>
<td style="text-align:center">权值正则化</td>
<td style="text-align:left">权值正则化就是通常意义上的正则化，一般是在损失函数中添加一项权重矩阵的正则项作为惩罚项，用来惩罚损失值较小时网络权重过大的情况，此时往往是网络权值过拟合了数据样本(如$Loss=f(WX+b,y’)+\frac{\lambda}{\eta}\sum{</td>
<td>W</td>
<td>}$)。</td>
</tr>
<tr>
<td style="text-align:center">屏蔽网络节点</td>
<td style="text-align:left">该方法可以认为是网络结构上的正则化，通过随机性地屏蔽某些神经元的输出让剩余激活的神经元作用，可以使模型的容错性更强。</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>对大多数神经网络模型同样通用</p>
</blockquote>
<h2 id="5-18-卷积神经网络在不同领域的应用"><a href="#5-18-卷积神经网络在不同领域的应用" class="headerlink" title="5.18 卷积神经网络在不同领域的应用"></a>5.18 卷积神经网络在不同领域的应用</h2><p>​    卷积神经网络中的卷积操作是其关键组成，而卷积操作只是一种数学运算方式，实际上对不同类型的数值表示数据都是通用的，尽管这些数值可能表示的是图像像素值、文本序列中单个字符或是语音片段中单字的音频。只要使原始数据能够得到有效地数值化表示，卷积神经网络能够在不同的领域中得到应用，要关注的是如何将卷积的特性更好地在不同领域中应用，如表XX所示。<br>​                                                    表XX 卷积神经网络不同领域的应用<br>| 应用领域 | 输入数据图示 | 说明 |<br>| :——-: | :—————: | :— |<br>|   图像处理   | <img src="img/ch5/Image-process.png" alt="image_process"> | 卷积神经网络在图像处理领域有非常广泛的应用，这是因为图像数据本身具有的局部完整性非常 |<br>| 自然语言处理 | <img src="img/ch5/NLP.png" alt="NLP"> |  |<br>|   语音处理   | <img src="img/ch5/audio-recognition.png" alt="audio_process"> |  |</p>
<h3 id="5-18-1-联系"><a href="#5-18-1-联系" class="headerlink" title="5.18.1 联系"></a>5.18.1 联系</h3><p>​    自然语言处理是对一维信号（词序列）做操作。<br>​    计算机视觉是对二维（图像）或三维（视频流）信号做操作。</p>
<h3 id="5-18-2-区别"><a href="#5-18-2-区别" class="headerlink" title="5.18.2 区别"></a>5.18.2 区别</h3><p>​    自然语言处理的输入数据通常是离散取值（例如表示一个单词或字母通常表示为词典中的one hot向量），计算机视觉则是连续取值（比如归一化到0，1之间的灰度值）。CNN有两个主要特点，区域不变性(location invariance)和组合性(Compositionality)。</p>
<ol>
<li>区域不变性：滤波器在每层的输入向量(图像)上滑动，检测的是局部信息，然后通过pooling取最大值或均值。pooling这步综合了局部特征，失去了每个特征的位置信息。这很适合基于图像的任务，比如要判断一幅图里有没有猫这种生物，你可能不会去关心这只猫出现在图像的哪个区域。但是在NLP里，词语在句子或是段落里出现的位置，顺序，都是很重要的信息。</li>
<li>局部组合性：CNN中，每个滤波器都把较低层的局部特征组合生成较高层的更全局化的特征。这在CV里很好理解，像素组合成边缘，边缘生成形状，最后把各种形状组合起来得到复杂的物体表达。在语言里，当然也有类似的组合关系，但是远不如图像来的直接。而且在图像里，相邻像素必须是相关的，相邻的词语却未必相关。</li>
</ol>
<h2 id="5-19-卷积神经网络凸显共性的方法？"><a href="#5-19-卷积神经网络凸显共性的方法？" class="headerlink" title="5.19 卷积神经网络凸显共性的方法？"></a>5.19 卷积神经网络凸显共性的方法？</h2><h3 id="5-19-1-局部连接"><a href="#5-19-1-局部连接" class="headerlink" title="5.19.1 局部连接"></a>5.19.1 局部连接</h3><p>​    我们首先了解一个概念，感受野，即每个神经元仅与输入神经元相连接的一块区域。<br>在图像卷积操作中，神经元在空间维度上是局部连接，但在深度上是全连接。局部连接的思想，是受启发于生物学里的视觉系统结构，视觉皮层的神经元就是仅用局部接受信息。对于二维图像，局部像素关联性较强。这种局部连接保证了训练后的滤波器能够对局部特征有最强的响应，使神经网络可以提取数据的局部特征；<br>下图是一个很经典的图示，左边是全连接，右边是局部连接。</p>
<p><img src="/img/ch5/5.27.1.png" alt="image"></p>
<p>对于一个1000 × 1000的输入图像而言，如果下一个隐藏层的神经元数目为10^6个，采用全连接则有1000 × 1000 × 10^6 = 10^12个权值参数，如此巨大的参数量几乎难以训练；而采用局部连接，隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8，将直接减少4个数量级。</p>
<h3 id="5-19-2-权值共享"><a href="#5-19-2-权值共享" class="headerlink" title="5.19.2 权值共享"></a>5.19.2 权值共享</h3><p>​    权值共享，即计算同一深度的神经元时采用的卷积核参数是共享的。权值共享在一定程度上讲是有意义的，是由于在神经网络中，提取的底层边缘特征与其在图中的位置无关。但是在另一些场景中是无意的，如在人脸识别任务，我们期望在不同的位置学到不同的特征。<br>需要注意的是，权重只是对于同一深度切片的神经元是共享的。在卷积层中，通常采用多组卷积核提取不同的特征，即对应的是不同深度切片的特征，而不同深度切片的神经元权重是不共享。相反，偏置这一权值对于同一深度切片的所有神经元都是共享的。<br>权值共享带来的好处是大大降低了网络的训练难度。如下图，假设在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 10 × 10个权值参数（也就是卷积核的大小）。</p>
<p><img src="/img/ch5/5.27.2.png" alt="image"></p>
<p>这里就体现了卷积神经网络的奇妙之处，使用少量的参数，却依然能有非常出色的性能。上述仅仅是提取图像一种特征的过程。如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像不同尺度下的特征，称之为特征图（feature map）。</p>
<h3 id="5-19-3-池化操作"><a href="#5-19-3-池化操作" class="headerlink" title="5.19.3 池化操作"></a>5.19.3 池化操作</h3><p>池化操作与多层次结构一起，实现了数据的降维，将低层次的局部特征组合成为较高层次的特征，从而对整个图片进行表示。如下图：</p>
<p><img src="/img/ch5/5.27.3.png" alt="image"></p>
<h2 id="5-20-全连接、局部连接、全卷积与局部卷积"><a href="#5-20-全连接、局部连接、全卷积与局部卷积" class="headerlink" title="5.20 全连接、局部连接、全卷积与局部卷积"></a>5.20 全连接、局部连接、全卷积与局部卷积</h2><p>​    大多数神经网络中高层网络通常会采用全连接层(Global Connected Layer)，通过多对多的连接方式对特征进行全局汇总，可以有效地提取全局信息。但是全连接的方式需要大量的参数，是神经网络中最占资源的部分之一，因此就需要由局部连接(Local Connected Layer)，仅在局部区域范围内产生神经元连接，能够有效地减少参数量。根据卷积操作的作用范围可以分为全卷积(Global Convolution)和局部卷积(Local Convolution)。实际上这里所说的全卷积就是标准卷积，即在整个输入特征维度范围内采用相同的卷积核参数进行运算，全局共享参数的连接方式可以使神经元之间的连接参数大大减少;局部卷积又叫平铺卷积(Tiled Convolution)或非共享卷积(Unshared Convolution)，是局部连接与全卷积的折衷。四者的比较如表XX所示。<br>​                                                     表XX 卷积网络中连接方式的对比</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">连接方式</th>
<th style="text-align:center">示意图</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">全连接</td>
<td style="text-align:center"><img src="img/ch5/full-connected.png" alt="full-connected"></td>
<td style="text-align:left">层间神经元完全连接，每个输出神经元可以获取到所有输入神经元的信息，有利于信息汇总，常置于网络末层；连接与连接之间独立参数，大量的连接大大增加模型的参数规模。</td>
</tr>
<tr>
<td style="text-align:center">局部连接</td>
<td style="text-align:center"><img src="img/ch5/local-connected.png" alt="local-connected"></td>
<td style="text-align:left">层间神经元只有局部范围内的连接，在这个范围内采用全连接的方式，超过这个范围的神经元则没有连接；连接与连接之间独立参数，相比于全连接减少了感受域外的连接，有效减少参数规模</td>
</tr>
<tr>
<td style="text-align:center">全卷积</td>
<td style="text-align:center"><img src="img/ch5/conv.png" alt="convolution"></td>
<td style="text-align:left">层间神经元只有局部范围内的连接，在这个范围内采用全连接的方式，连接所采用的参数在不同感受域之间共享，有利于提取特定模式的特征；相比于局部连接，共用感受域之间的参数可以进一步减少参数量。</td>
</tr>
<tr>
<td style="text-align:center">局部卷积</td>
<td style="text-align:center"><img src="img/ch5/local-conv.png" alt="local-conv"></td>
<td style="text-align:left">层间神经元只有局部范围内的连接，感受域内采用全连接的方式，而感受域之间间隔采用局部连接与全卷积的连接方式；相比与全卷积成倍引入额外参数，但有更强的灵活性和表达能力；相比于局部连接，可以有效控制参数量</td>
</tr>
</tbody>
</table>
</div>
<h2 id="5-21-局部卷积的应用"><a href="#5-21-局部卷积的应用" class="headerlink" title="5.21 局部卷积的应用"></a>5.21 局部卷积的应用</h2><p>并不是所有的卷积都会进行权重共享，在某些特定任务中，会使用不权重共享的卷积。下面通过人脸这一任务来进行讲解。在读人脸方向的一些paper时，会发现很多都会在最后加入一个Local Connected Conv，也就是不进行权重共享的卷积层。总的来说，这一步的作用就是使用3D模型来将人脸对齐，从而使CNN发挥最大的效果。<br><img src="/img/ch5/img66.png" alt="image"></p>
<p>截取论文中的一部分图，经过3D对齐以后，形成的图像均是152×152，输入到上述的网络结构中。该结构的参数如下：</p>
<p>Conv：32个11×11×3的卷积核，</p>
<p>Max-pooling: 3×3，stride=2，</p>
<p>Conv: 16个9×9的卷积核，</p>
<p>Local-Conv: 16个9×9的卷积核，</p>
<p>Local-Conv: 16个7×7的卷积核，</p>
<p>Local-Conv: 16个5×5的卷积核，</p>
<p>Fully-connected: 4096维，</p>
<p>Softmax: 4030维。</p>
<p>前三层的目的在于提取低层次的特征，比如简单的边和纹理。其中Max-pooling层使得卷积的输出对微小的偏移情况更加鲁棒。但不能使用更多的Max-pooling层，因为太多的Max-pooling层会使得网络损失图像信息。全连接层将上一层的每个单元和本层的所有单元相连，用来捕捉人脸图像不同位置特征之间的相关性。最后使用softmax层用于人脸分类。<br>中间三层都是使用参数不共享的卷积核，之所以使用参数不共享，有如下原因：</p>
<p>（1）对齐的人脸图片中，不同的区域会有不同的统计特征，因此并不存在特征的局部稳定性，所以使用相同的卷积核会导致信息的丢失。</p>
<p>（2）不共享的卷积核并不增加inference时特征的计算量，仅会增加训练时的计算量。<br>使用不共享的卷积核，由于需要训练的参数量大大增加，因此往往需要通过其他方法增加数据量。</p>
<h2 id="5-22-NetVLAD池化-（贡献者：熊楚原-中国人民大学）"><a href="#5-22-NetVLAD池化-（贡献者：熊楚原-中国人民大学）" class="headerlink" title="5.22 NetVLAD池化    （贡献者：熊楚原-中国人民大学）"></a>5.22 NetVLAD池化    （贡献者：熊楚原-中国人民大学）</h2><p>NetVLAD是论文[15]提出的一个局部特征聚合的方法。</p>
<p>在传统的网络里面，例如VGG啊，最后一层卷积层输出的特征都是类似于Batchsize x 3 x 3 x 512的这种东西，然后会经过FC聚合，或者进行一个Global Average Pooling（NIN里的做法），或者怎么样，变成一个向量型的特征，然后进行Softmax or 其他的Loss。</p>
<p>这种方法说简单点也就是输入一个图片或者什么的结构性数据，然后经过特征提取得到一个长度固定的向量，之后可以用度量的方法去进行后续的操作，比如分类啊，检索啊，相似度对比等等。</p>
<p>那么NetVLAD考虑的主要是最后一层卷积层输出的特征这里，我们不想直接进行欠采样或者全局映射得到特征，对于最后一层输出的W x H x D，设计一个新的池化，去聚合一个“局部特征“，这即是NetVLAD的作用。</p>
<p>NetVLAD的一个输入是一个W x H x D的图像特征，例如VGG-Net最后的3 x 3 x 512这样的矩阵，在网络中还需加一个维度为Batchsize。</p>
<p>NetVLAD还需要另输入一个标量K即表示VLAD的聚类中心数量，它主要是来构成一个矩阵C，是通过原数据算出来的每一个$W \times H$特征的聚类中心，C的shape即$C: K \times D$，然后根据三个输入，VLAD是计算下式的V:</p>
<script type="math/tex; mode=display">V(j, k) = \sum_{i=1}^{N}{a_k(x_i)(x_i(j) - c_k(j))}</script><p>其中j表示维度，从1到D，可以看到V的j是和输入与c对应的，对每个类别k，都对所有的x进行了计算，如果$x_i$属于当前类别k，$a_k=1$，否则$a_k=0$，计算每一个x和它聚类中心的残差，然后把残差加起来，即是每个类别k的结果，最后分别L2正则后拉成一个长向量后再做L2正则，正则非常的重要，因为这样才能统一所有聚类算出来的值，而残差和的目的主要是消减不同聚类上的分布不均，两者共同作用才能得到最后正常的输出。</p>
<p>输入与输出如下图所示：</p>
<p><img src="http://www.ecohnoch.cn/img/netvlad.jpeg" alt="image"></p>
<p>中间得到的K个D维向量即是对D个x都进行了与聚类中心计算残差和的过程，最终把K个D维向量合起来后进行即得到最终输出的$K \times D$长度的一维向量。</p>
<p>而VLAD本身是不可微的，因为上面的a要么是0要么是1，表示要么当前描述x是当前聚类，要么不是，是个离散的，NetVLAD为了能够在深度卷积网络里使用反向传播进行训练，对a进行了修正。</p>
<p>那么问题就是如何重构一个a，使其能够评估当前的这个x和各个聚类的关联程度？用softmax来得到：</p>
<script type="math/tex; mode=display">a_k = \frac{e^{W_k^T x_i + b_k}}{e^{W_{k'}^T x_i + b_{k'}}}</script><p>将这个把上面的a替换后，即是NetVLAD的公式，可以进行反向传播更新参数。</p>
<p>所以一共有三个可训练参数，上式a中的$W: K \times D$，上式a中的$b: K \times 1$，聚类中心$c: K \times D$，而原始VLAD只有一个参数c。</p>
<p>最终池化得到的输出是一个恒定的K x D的一维向量（经过了L2正则），如果带Batchsize，输出即为Batchsize x (K x D)的二维矩阵。</p>
<p>NetVLAD作为池化层嵌入CNN网络即如下图所示，</p>
<p><img src="http://www.ecohnoch.cn/img/netvlad_emb.png" alt="image"></p>
<p>原论文中采用将传统图像检索方法VLAD进行改进后应用在CNN的池化部分作为一种另类的局部特征池化，在场景检索上取得了很好的效果。</p>
<p>后续相继又提出了ActionVLAD、ghostVLAD等改进。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 卷积神经网络研究综述[J]. 计算机学报, 2017, 40(6):1229-1251.</p>
<p>[2] 常亮, 邓小明, 周明全,等. 图像理解中的卷积神经网络[J]. 自动化学报, 2016, 42(9):1300-1312.</p>
<p>[3] Chua L O. CNN: A Paradigm for Complexity[M]// CNN a paradigm for complexity /.  1998.</p>
<p>[4] He K, Gkioxari G, Dollar P, et al. Mask R-CNN[J]. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2017, PP(99):1-1.</p>
<p>[5] Hoochang S, Roth H R, Gao M, et al. Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning[J]. IEEE Transactions on Medical Imaging, 2016, 35(5):1285-1298.</p>
<p>[6] 许可. 卷积神经网络在图像识别上的应用的研究[D]. 浙江大学, 2012.</p>
<p>[7] 陈先昌. 基于卷积神经网络的深度学习算法与应用研究[D]. 浙江工商大学, 2014.</p>
<p>[8] <a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">CS231n Convolutional Neural Networks for Visual Recognition, Stanford</a></p>
<p>[9] <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.2gfx5zcw3" target="_blank" rel="noopener">Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks</a></p>
<p>[10] cs231n 动态卷积图：<a href="http://cs231n.github.io/assets/conv-demo/index.html" target="_blank" rel="noopener">http://cs231n.github.io/assets/conv-demo/index.html</a></p>
<p>[11] Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.</p>
<p>[12] Sun Y, Wang X, Tang X. Deep learning face representation from predicting 10,000 classes[C]//Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. IEEE, 2014: 1891-1898.</p>
<p>[13] 魏秀参.解析深度学习——卷积神经网络原理与视觉实践[M].电子工业出版社, 2018</p>
<p>[14]  Jianxin W U ,  Gao B B ,  Wei X S , et al. Resource-constrained deep learning: challenges and practices[J]. Scientia Sinica(Informationis), 2018.</p>
<p>[15] Arandjelovic R , Gronat P , Torii A , et al. [IEEE 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) - Las Vegas, NV, USA (2016.6.27-2016.6.30)] 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) - NetVLAD: CNN Architecture for Weakly Supervised Place Recognition[C]// 2016:5297-5307.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/03/03/%E7%AC%AC%E5%9B%9B%E7%AB%A0_%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/03/%E7%AC%AC%E5%9B%9B%E7%AB%A0_%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">第四章_经典网络</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-03 12:23:28 / 修改时间：12:24:03" itemprop="dateCreated datePublished" datetime="2020-03-03T12:23:28+08:00">2020-03-03</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h1 id="第四章-经典网络解读"><a href="#第四章-经典网络解读" class="headerlink" title="第四章 经典网络解读"></a>第四章 经典网络解读</h1><h2 id="4-1-LeNet-5"><a href="#4-1-LeNet-5" class="headerlink" title="4.1 LeNet-5"></a>4.1 LeNet-5</h2><h3 id="4-1-1-模型介绍"><a href="#4-1-1-模型介绍" class="headerlink" title="4.1.1 模型介绍"></a>4.1.1 模型介绍</h3><p>​    LeNet-5是由$LeCun$ 提出的一种用于识别手写数字和机器印刷字符的卷积神经网络（Convolutional Neural Network，CNN）$^{[1]}$，其命名来源于作者$LeCun$的名字，5则是其研究成果的代号，在LeNet-5之前还有LeNet-4和LeNet-1鲜为人知。LeNet-5阐述了图像中像素特征之间的相关性能够由参数共享的卷积操作所提取，同时使用卷积、下采样（池化）和非线性映射这样的组合结构，是当前流行的大多数深度图像识别网络的基础。</p>
<h3 id="4-1-2-模型结构"><a href="#4-1-2-模型结构" class="headerlink" title="4.1.2 模型结构"></a>4.1.2 模型结构</h3><p><img src="/img/ch4/image1.png" alt=""></p>
<p>​                                                                 图4.1 LeNet-5网络结构图</p>
<p>​    如图4.1所示，LeNet-5一共包含7层（输入层不作为网络结构），分别由2个卷积层、2个下采样层和3个连接层组成，网络的参数配置如表4.1所示，其中下采样层和全连接层的核尺寸分别代表采样范围和连接矩阵的尺寸（如卷积核尺寸中的$“5\times5\times1/1,6”$表示核大小为$5\times5\times1$、步长为$1​$且核个数为6的卷积核）。</p>
<p>​                                                                 表4.1 LeNet-5网络参数配置</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">网络层</th>
<th style="text-align:center">输入尺寸</th>
<th style="text-align:center">核尺寸</th>
<th style="text-align:center">输出尺寸</th>
<th style="text-align:center">可训练参数量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">卷积层$C_1$</td>
<td style="text-align:center">$32\times32\times1$</td>
<td style="text-align:center">$5\times5\times1/1,6$</td>
<td style="text-align:center">$28\times28\times6$</td>
<td style="text-align:center">$(5\times5\times1+1)\times6$</td>
</tr>
<tr>
<td style="text-align:center">下采样层$S_2$</td>
<td style="text-align:center">$28\times28\times6$</td>
<td style="text-align:center">$2\times2/2$</td>
<td style="text-align:center">$14\times14\times6$</td>
<td style="text-align:center">$(1+1)\times6$ $^*$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_3$</td>
<td style="text-align:center">$14\times14\times6$</td>
<td style="text-align:center">$5\times5\times6/1,16$</td>
<td style="text-align:center">$10\times10\times16$</td>
<td style="text-align:center">$1516^*$</td>
</tr>
<tr>
<td style="text-align:center">下采样层$S_4$</td>
<td style="text-align:center">$10\times10\times16$</td>
<td style="text-align:center">$2\times2/2$</td>
<td style="text-align:center">$5\times5\times16$</td>
<td style="text-align:center">$(1+1)\times16$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_5$$^*$</td>
<td style="text-align:center">$5\times5\times16$</td>
<td style="text-align:center">$5\times5\times16/1,120$</td>
<td style="text-align:center">$1\times1\times120$</td>
<td style="text-align:center">$(5\times5\times16+1)\times120$</td>
</tr>
<tr>
<td style="text-align:center">全连接层$F_6$</td>
<td style="text-align:center">$1\times1\times120$</td>
<td style="text-align:center">$120\times84$</td>
<td style="text-align:center">$1\times1\times84$</td>
<td style="text-align:center">$(120+1)\times84$</td>
</tr>
<tr>
<td style="text-align:center">输出层</td>
<td style="text-align:center">$1\times1\times84$</td>
<td style="text-align:center">$84\times10$</td>
<td style="text-align:center">$1\times1\times10$</td>
<td style="text-align:center">$(84+1)\times10$</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>​    $^*$ 在LeNet中，下采样操作和池化操作类似，但是在得到采样结果后会乘以一个系数和加上一个偏置项，所以下采样的参数个数是$(1+1)\times6​$而不是零。</p>
<p>​    $^*$ $C_3$卷积层可训练参数并未直接连接$S_2$中所有的特征图（Feature Map），而是采用如图4.2所示的采样特征方式进行连接（稀疏连接），生成的16个通道特征图中分别按照相邻3个特征图、相邻4个特征图、非相邻4个特征图和全部6个特征图进行映射，得到的参数个数计算公式为$6\times(25\times3+1)+6\times(25\times4+1)+3\times(25\times4+1)+1\times(25\times6+1)=1516$，在原论文中解释了使用这种采样方式原因包含两点：限制了连接数不至于过大（当年的计算能力比较弱）;强制限定不同特征图的组合可以使映射得到的特征图学习到不同的特征模式。</p>
</blockquote>
<p><img src="/img/ch4/featureMap.jpg" alt="FeatureMap"></p>
<p>​                                                                图4.2 $S_2$与$C_3$之间的特征图稀疏连接</p>
<blockquote>
<p>​    $^*$ $C_5$卷积层在图4.1中显示为全连接层，原论文中解释这里实际采用的是卷积操作，只是刚好在$5\times5$卷积后尺寸被压缩为$1\times1​$，输出结果看起来和全连接很相似。</p>
</blockquote>
<h3 id="4-1-3-模型特性"><a href="#4-1-3-模型特性" class="headerlink" title="4.1.3 模型特性"></a>4.1.3 模型特性</h3><ul>
<li>卷积网络使用一个3层的序列组合：卷积、下采样（池化）、非线性映射（LeNet-5最重要的特性，奠定了目前深层卷积网络的基础）</li>
<li>使用卷积提取空间特征</li>
<li>使用映射的空间均值进行下采样</li>
<li>使用$tanh$或$sigmoid$进行非线性映射</li>
<li>多层神经网络（MLP）作为最终的分类器</li>
<li>层间的稀疏连接矩阵以避免巨大的计算开销</li>
</ul>
<h2 id="4-2-AlexNet"><a href="#4-2-AlexNet" class="headerlink" title="4.2 AlexNet"></a>4.2 AlexNet</h2><h3 id="4-2-1-模型介绍"><a href="#4-2-1-模型介绍" class="headerlink" title="4.2.1 模型介绍"></a>4.2.1 模型介绍</h3><p>​    AlexNet是由$Alex$ $Krizhevsky $提出的首个应用于图像分类的深层卷积神经网络，该网络在2012年ILSVRC（ImageNet Large Scale Visual Recognition Competition）图像分类竞赛中以15.3%的top-5测试错误率赢得第一名$^{[2]}$。AlexNet使用GPU代替CPU进行运算，使得在可接受的时间范围内模型结构能够更加复杂，它的出现证明了深层卷积神经网络在复杂模型下的有效性，使CNN在计算机视觉中流行开来，直接或间接地引发了深度学习的热潮。</p>
<h3 id="4-2-2-模型结构"><a href="#4-2-2-模型结构" class="headerlink" title="4.2.2 模型结构"></a>4.2.2 模型结构</h3><p><img src="/img/ch4/alexnet.png" alt=""></p>
<p>​                                                                         图4.3 AlexNet网络结构图</p>
<p>​    如图4.3所示，除去下采样（池化层）和局部响应规范化操作（Local Responsible Normalization, LRN），AlexNet一共包含8层，前5层由卷积层组成，而剩下的3层为全连接层。网络结构分为上下两层，分别对应两个GPU的操作过程，除了中间某些层（$C_3$卷积层和$F_{6-8}$全连接层会有GPU间的交互），其他层两个GPU分别计算结 果。最后一层全连接层的输出作为$softmax$的输入，得到1000个图像分类标签对应的概率值。除去GPU并行结构的设计，AlexNet网络结构与LeNet十分相似，其网络的参数配置如表4.2所示。</p>
<p>​                                    表4.2 AlexNet网络参数配置</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">网络层</th>
<th style="text-align:center">输入尺寸</th>
<th style="text-align:center">核尺寸</th>
<th style="text-align:center">输出尺寸</th>
<th style="text-align:center">可训练参数量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">卷积层$C_1$ $^*$</td>
<td style="text-align:center">$224\times224\times3$</td>
<td style="text-align:center">$11\times11\times3/4,48(\times2_{GPU})$</td>
<td style="text-align:center">$55\times55\times48(\times2_{GPU})$</td>
<td style="text-align:center">$(11\times11\times3+1)\times48\times2$</td>
</tr>
<tr>
<td style="text-align:center">下采样层$S_{max}$$^*$</td>
<td style="text-align:center">$55\times55\times48(\times2_{GPU})$</td>
<td style="text-align:center">$3\times3/2(\times2_{GPU})$</td>
<td style="text-align:center">$27\times27\times48(\times2_{GPU})$</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_2$</td>
<td style="text-align:center">$27\times27\times48(\times2_{GPU})$</td>
<td style="text-align:center">$5\times5\times48/1,128(\times2_{GPU})$</td>
<td style="text-align:center">$27\times27\times128(\times2_{GPU})$</td>
<td style="text-align:center">$(5\times5\times48+1)\times128\times2$</td>
</tr>
<tr>
<td style="text-align:center">下采样层$S_{max}$</td>
<td style="text-align:center">$27\times27\times128(\times2_{GPU})$</td>
<td style="text-align:center">$3\times3/2(\times2_{GPU})$</td>
<td style="text-align:center">$13\times13\times128(\times2_{GPU})$</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_3$ $^*$</td>
<td style="text-align:center">$13\times13\times128\times2_{GPU}$</td>
<td style="text-align:center">$3\times3\times256/1,192(\times2_{GPU})$</td>
<td style="text-align:center">$13\times13\times192(\times2_{GPU})$</td>
<td style="text-align:center">$(3\times3\times256+1)\times192\times2$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_4$</td>
<td style="text-align:center">$13\times13\times192(\times2_{GPU})$</td>
<td style="text-align:center">$3\times3\times192/1,192(\times2_{GPU})$</td>
<td style="text-align:center">$13\times13\times192(\times2_{GPU})$</td>
<td style="text-align:center">$(3\times3\times192+1)\times192\times2$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_5$</td>
<td style="text-align:center">$13\times13\times192(\times2_{GPU})$</td>
<td style="text-align:center">$3\times3\times192/1,128(\times2_{GPU})$</td>
<td style="text-align:center">$13\times13\times128(\times2_{GPU})$</td>
<td style="text-align:center">$(3\times3\times192+1)\times128\times2$</td>
</tr>
<tr>
<td style="text-align:center">下采样层$S_{max}$</td>
<td style="text-align:center">$13\times13\times128(\times2_{GPU})$</td>
<td style="text-align:center">$3\times3/2(\times2_{GPU})$</td>
<td style="text-align:center">$6\times6\times128(\times2_{GPU})$</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">全连接层$F_6$  $^*$</td>
<td style="text-align:center">$6\times6\times128\times2_{GPU}$</td>
<td style="text-align:center">$9216\times2048(\times2_{GPU})$</td>
<td style="text-align:center">$1\times1\times2048(\times2_{GPU})$</td>
<td style="text-align:center">$(9216+1)\times2048\times2$</td>
</tr>
<tr>
<td style="text-align:center">全连接层$F_7$</td>
<td style="text-align:center">$1\times1\times2048\times2_{GPU}$</td>
<td style="text-align:center">$4096\times2048(\times2_{GPU})$</td>
<td style="text-align:center">$1\times1\times2048(\times2_{GPU})$</td>
<td style="text-align:center">$(4096+1)\times2048\times2$</td>
</tr>
<tr>
<td style="text-align:center">全连接层$F_8$</td>
<td style="text-align:center">$1\times1\times2048\times2_{GPU}$</td>
<td style="text-align:center">$4096\times1000$</td>
<td style="text-align:center">$1\times1\times1000$</td>
<td style="text-align:center">$(4096+1)\times1000\times2$</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>卷积层$C_1$输入为$224\times224\times3$的图片数据，分别在两个GPU中经过核为$11\times11\times3$、步长（stride）为4的卷积卷积后，分别得到两条独立的$55\times55\times48$的输出数据。</p>
<p>下采样层$S_{max}$实际上是嵌套在卷积中的最大池化操作，但是为了区分没有采用最大池化的卷积层单独列出来。在$C_{1-2}$卷积层中的池化操作之后（ReLU激活操作之前），还有一个LRN操作，用作对相邻特征点的归一化处理。</p>
<p>卷积层$C_3$ 的输入与其他卷积层不同，$13\times13\times192\times2_{GPU}$表示汇聚了上一层网络在两个GPU上的输出结果作为输入，所以在进行卷积操作时通道上的卷积核维度为384。</p>
<p>全连接层$F_{6-8}$中输入数据尺寸也和$C_3$类似，都是融合了两个GPU流向的输出结果作为输入。</p>
</blockquote>
<h3 id="4-2-3-模型特性"><a href="#4-2-3-模型特性" class="headerlink" title="4.2.3 模型特性"></a>4.2.3 模型特性</h3><ul>
<li>所有卷积层都使用ReLU作为非线性映射函数，使模型收敛速度更快</li>
<li>在多个GPU上进行模型的训练，不但可以提高模型的训练速度，还能提升数据的使用规模</li>
<li>使用LRN对局部的特征进行归一化，结果作为ReLU激活函数的输入能有效降低错误率</li>
<li>重叠最大池化（overlapping max pooling），即池化范围z与步长s存在关系$z&gt;s$（如$S_{max}$中核尺度为$3\times3/2$），避免平均池化（average pooling）的平均效应</li>
<li>使用随机丢弃技术（dropout）选择性地忽略训练中的单个神经元，避免模型的过拟合</li>
</ul>
<h2 id="4-3-ZFNet"><a href="#4-3-ZFNet" class="headerlink" title="4.3 ZFNet"></a>4.3 ZFNet</h2><h3 id="4-3-1-模型介绍"><a href="#4-3-1-模型介绍" class="headerlink" title="4.3.1 模型介绍"></a>4.3.1 模型介绍</h3><p>​    ZFNet是由$Matthew$ $D. Zeiler$和$Rob$ $Fergus$在AlexNet基础上提出的大型卷积网络，在2013年ILSVRC图像分类竞赛中以11.19%的错误率获得冠军（实际上原ZFNet所在的队伍并不是真正的冠军，原ZFNet以13.51%错误率排在第8，真正的冠军是$Clarifai$这个队伍，而$Clarifai$这个队伍所对应的一家初创公司的CEO又是$Zeiler$，而且$Clarifai$对ZFNet的改动比较小，所以通常认为是ZFNet获得了冠军）$^{[3-4]}​$。ZFNet实际上是微调（fine-tuning）了的AlexNet，并通过反卷积（Deconvolution）的方式可视化各层的输出特征图，进一步解释了卷积操作在大型网络中效果显著的原因。</p>
<h3 id="4-3-2-模型结构"><a href="#4-3-2-模型结构" class="headerlink" title="4.3.2 模型结构"></a>4.3.2 模型结构</h3><p><img src="/img/ch4/image21.png" alt=""></p>
<p><img src="/img/ch4/image21.jpeg" alt=""></p>
<p>​                        图4.4 ZFNet网络结构图（原始结构图与AlexNet风格结构图）</p>
<p>​    如图4.4所示，ZFNet与AlexNet类似，都是由8层网络组成的卷积神经网络，其中包含5层卷积层和3层全连接层。两个网络结构最大的不同在于，ZFNet第一层卷积采用了$7\times7\times3/2$的卷积核替代了AlexNet中第一层卷积核$11\times11\times3/4$的卷积核。图4.5中ZFNet相比于AlexNet在第一层输出的特征图中包含更多中间频率的信息，而AlexNet第一层输出的特征图大多是低频或高频的信息，对中间频率特征的缺失导致后续网络层次如图4.5（c）能够学习到的特征不够细致，而导致这个问题的根本原因在于AlexNet在第一层中采用的卷积核和步长过大。</p>
<p><img src="/img/ch4/zfnet-layer1.png" alt=""></p>
<p><img src="/img/ch4/zfnet-layer2.png" alt=""></p>
<p>​    图4.5 （a）ZFNet第一层输出的特征图（b）AlexNet第一层输出的特征图（c）AlexNet第二层输出的特征图（d）ZFNet第二层输出的特征图</p>
<p>​                                    表4.3 ZFNet网络参数配置<br>|        网络层         |               输入尺寸               |                  核尺寸                  |               输出尺寸               |              可训练参数量               |<br>| :—————————-: | :—————————————————: | :———————————————————: | :—————————————————: | :——————————————————-: |<br>|   卷积层$C_1$ $^<em>$  |        $224\times224\times3$         |          $7\times7\times3/2,96$          |        $110\times110\times96$        |      $(7\times7\times3+1)\times96$      |<br>| 下采样层$S_{max}$ |        $110\times110\times96$        |               $3\times3/2$               |         $55\times55\times96$         |                    0                    |<br>|      卷积层$C_2$ $^</em>$      |         $55\times55\times96$         |         $5\times5\times96/2,256$         |        $26\times26\times256$        | $(5\times5\times96+1)\times256$ |<br>|   下采样层$S_{max}$   | $26\times26\times256$ |       $3\times3/2$       | $13\times13\times256$ |                    0                    |<br>|   卷积层$C_3$  |  $13\times13\times256$  | $3\times3\times256/1,384$ | $13\times13\times384$ | $(3\times3\times256+1)\times384$ |<br>|      卷积层$C_4$      | $13\times13\times384$ | $3\times3\times384/1,384$ | $13\times13\times384$ | $(3\times3\times384+1)\times384$ |<br>|      卷积层$C_5$      | $13\times13\times384$ | $3\times3\times384/1,256$ | $13\times13\times256$ | $(3\times3\times384+1)\times256$ |<br>|   下采样层$S_{max}$   | $13\times13\times256$ |       $3\times3/2$       |  $6\times6\times256$  |                    0                    |<br>|  全连接层$F_6$  |   $6\times6\times256$   |     $9216\times4096$     | $1\times1\times4096$ |       $(9216+1)\times4096$       |<br>|     全连接层$F_7$     |  $1\times1\times4096$  |     $4096\times4096$     | $1\times1\times4096$ |       $(4096+1)\times4096$       |<br>|     全连接层$F_8$     | $1\times1\times4096$ |             $4096\times1000$             |         $1\times1\times1000$         |       $(4096+1)\times1000$       |</p>
<blockquote>
<p>卷积层$C_1$与AlexNet中的$C_1$有所不同，采用$7\times7\times3/2$的卷积核代替$11\times11\times3/4​$，使第一层卷积输出的结果可以包含更多的中频率特征，对后续网络层中多样化的特征组合提供更多选择，有利于捕捉更细致的特征。</p>
<p>卷积层$C_2$采用了步长2的卷积核，区别于AlexNet中$C_2$的卷积核步长，所以输出的维度有所差异。</p>
</blockquote>
<h3 id="4-3-3-模型特性"><a href="#4-3-3-模型特性" class="headerlink" title="4.3.3 模型特性"></a>4.3.3 模型特性</h3><p>​    ZFNet与AlexNet在结构上几乎相同，此部分虽属于模型特性，但准确地说应该是ZFNet原论文中可视化技术的贡献。</p>
<ul>
<li>可视化技术揭露了激发模型中每层单独的特征图。</li>
<li>可视化技术允许观察在训练阶段特征的演变过程且诊断出模型的潜在问题。</li>
<li>可视化技术用到了多层解卷积网络，即由特征激活返回到输入像素空间。</li>
<li>可视化技术进行了分类器输出的敏感性分析，即通过阻止部分输入图像来揭示那部分对于分类是重要的。</li>
<li>可视化技术提供了一个非参数的不变性来展示来自训练集的哪一块激活哪个特征图，不仅需要裁剪输入图片，而且自上而下的投影来揭露来自每块的结构激活一个特征图。</li>
<li>可视化技术依赖于解卷积操作，即卷积操作的逆过程，将特征映射到像素上。</li>
</ul>
<h2 id="4-4-Network-in-Network"><a href="#4-4-Network-in-Network" class="headerlink" title="4.4 Network in Network"></a>4.4 Network in Network</h2><h3 id="4-4-1-模型介绍"><a href="#4-4-1-模型介绍" class="headerlink" title="4.4.1 模型介绍"></a>4.4.1 模型介绍</h3><p>​    Network In Network (NIN)是由$Min Lin$等人提出，在CIFAR-10和CIFAR-100分类任务中达到当时的最好水平，因其网络结构是由三个多层感知机堆叠而被成为NIN$^{[5]}$。NIN以一种全新的角度审视了卷积神经网络中的卷积核设计，通过引入子网络结构代替纯卷积中的线性映射部分，这种形式的网络结构激发了更复杂的卷积神经网络的结构设计，其中下一节中介绍的GoogLeNet的Inception结构就是来源于这个思想。</p>
<h3 id="4-4-2-模型结构"><a href="#4-4-2-模型结构" class="headerlink" title="4.4.2 模型结构"></a>4.4.2 模型结构</h3><p><img src="/img/ch4/image23.png" alt=""><br>​                                    图 4.6 NIN网络结构图</p>
<p>​    NIN由三层的多层感知卷积层（MLPConv Layer）构成，每一层多层感知卷积层内部由若干层的局部全连接层和非线性激活函数组成，代替了传统卷积层中采用的线性卷积核。在网络推理（inference）时，这个多层感知器会对输入特征图的局部特征进行划窗计算，并且每个划窗的局部特征图对应的乘积的权重是共享的，这两点是和传统卷积操作完全一致的，最大的不同在于多层感知器对局部特征进行了非线性的映射，而传统卷积的方式是线性的。NIN的网络参数配置表4.4所示（原论文并未给出网络参数，表中参数为编者结合网络结构图和CIFAR-100数据集以$3\times3$卷积为例给出）。</p>
<p>​                    表4.4 NIN网络参数配置（结合原论文NIN结构和CIFAR-100数据给出）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">网络层</th>
<th style="text-align:center">输入尺寸</th>
<th style="text-align:center">核尺寸</th>
<th style="text-align:center">输出尺寸</th>
<th style="text-align:center">参数个数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">局部全连接层$L_{11}$ $^*$</td>
<td style="text-align:center">$32\times32\times3$</td>
<td style="text-align:center">$(3\times3)\times16/1$</td>
<td style="text-align:center">$30\times30\times16$</td>
<td style="text-align:center">$(3\times3\times3+1)\times16$</td>
</tr>
<tr>
<td style="text-align:center">全连接层$L_{12}$ $^*$</td>
<td style="text-align:center">$30\times30\times16$</td>
<td style="text-align:center">$16\times16$</td>
<td style="text-align:center">$30\times30\times16$</td>
<td style="text-align:center">$((16+1)\times16)$</td>
</tr>
<tr>
<td style="text-align:center">局部全连接层$L_{21}$</td>
<td style="text-align:center">$30\times30\times16$</td>
<td style="text-align:center">$(3\times3)\times64/1$</td>
<td style="text-align:center">$28\times28\times64$</td>
<td style="text-align:center">$(3\times3\times16+1)\times64$</td>
</tr>
<tr>
<td style="text-align:center">全连接层$L_{22}$</td>
<td style="text-align:center">$28\times28\times64$</td>
<td style="text-align:center">$64\times64$</td>
<td style="text-align:center">$28\times28\times64$</td>
<td style="text-align:center">$((64+1)\times64)$</td>
</tr>
<tr>
<td style="text-align:center">局部全连接层$L_{31}$</td>
<td style="text-align:center">$28\times28\times64$</td>
<td style="text-align:center">$(3\times3)\times100/1$</td>
<td style="text-align:center">$26\times26\times100$</td>
<td style="text-align:center">$(3\times3\times64+1)\times100$</td>
</tr>
<tr>
<td style="text-align:center">全连接层$L_{32}$</td>
<td style="text-align:center">$26\times26\times100$</td>
<td style="text-align:center">$100\times100$</td>
<td style="text-align:center">$26\times26\times100$</td>
<td style="text-align:center">$((100+1)\times100)$</td>
</tr>
<tr>
<td style="text-align:center">全局平均采样$GAP$ $^*$</td>
<td style="text-align:center">$26\times26\times100$</td>
<td style="text-align:center">$26\times26\times100/1$</td>
<td style="text-align:center">$1\times1\times100$</td>
<td style="text-align:center">$0$</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>局部全连接层$L_{11}$实际上是对原始输入图像进行划窗式的全连接操作，因此划窗得到的输出特征尺寸为$30\times30$（$\frac{32-3_k+1}{1_{stride}}=30$）<br>全连接层$L_{12}$是紧跟$L_{11}$后的全连接操作，输入的特征是划窗后经过激活的局部响应特征，因此仅需连接$L_{11}$和$L_{12}$的节点即可，而每个局部全连接层和紧接的全连接层构成代替卷积操作的多层感知卷积层（MLPConv）。<br>全局平均采样层或全局平均池化层$GAP$（Global Average Pooling）将$L_{32}$输出的每一个特征图进行全局的平均池化操作，直接得到最后的类别数，可以有效地减少参数量。</p>
</blockquote>
<h3 id="4-4-3-模型特点"><a href="#4-4-3-模型特点" class="headerlink" title="4.4.3 模型特点"></a>4.4.3 模型特点</h3><ul>
<li>使用多层感知机结构来代替卷积的滤波操作，不但有效减少卷积核数过多而导致的参数量暴涨问题，还能通过引入非线性的映射来提高模型对特征的抽象能力。</li>
<li>使用全局平均池化来代替最后一个全连接层，能够有效地减少参数量（没有可训练参数），同时池化用到了整个特征图的信息，对空间信息的转换更加鲁棒，最后得到的输出结果可直接作为对应类别的置信度。</li>
</ul>
<h2 id="4-5-VGGNet"><a href="#4-5-VGGNet" class="headerlink" title="4.5 VGGNet"></a>4.5 VGGNet</h2><h3 id="4-5-1-模型介绍"><a href="#4-5-1-模型介绍" class="headerlink" title="4.5.1 模型介绍"></a>4.5.1 模型介绍</h3><p>​    VGGNet是由牛津大学视觉几何小组（Visual Geometry Group, VGG）提出的一种深层卷积网络结构，他们以7.32%的错误率赢得了2014年ILSVRC分类任务的亚军（冠军由GoogLeNet以6.65%的错误率夺得）和25.32%的错误率夺得定位任务（Localization）的第一名（GoogLeNet错误率为26.44%）$^{[5]}$，网络名称VGGNet取自该小组名缩写。VGGNet是首批把图像分类的错误率降低到10%以内模型，同时该网络所采用的$3\times3$卷积核的思想是后来许多模型的基础，该模型发表在2015年国际学习表征会议（International Conference On Learning Representations, ICLR）后至今被引用的次数已经超过1万4千余次。</p>
<h3 id="4-5-2-模型结构"><a href="#4-5-2-模型结构" class="headerlink" title="4.5.2 模型结构"></a>4.5.2 模型结构</h3><p><img src="/img/ch4/vgg16.png" alt=""></p>
<p>​                                图 4.7 VGG16网络结构图</p>
<p>​    在原论文中的VGGNet包含了6个版本的演进，分别对应VGG11、VGG11-LRN、VGG13、VGG16-1、VGG16-3和VGG19，不同的后缀数值表示不同的网络层数（VGG11-LRN表示在第一层中采用了LRN的VGG11，VGG16-1表示后三组卷积块中最后一层卷积采用卷积核尺寸为$1\times1$，相应的VGG16-3表示卷积核尺寸为$3\times3$），本节介绍的VGG16为VGG16-3。图4.7中的VGG16体现了VGGNet的核心思路，使用$3\times3$的卷积组合代替大尺寸的卷积（2个$3\times3卷积即可与$$5\times5$卷积拥有相同的感受视野），网络参数设置如表4.5所示。</p>
<p>​                                表4.5 VGG16网络参数配置</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">网络层</th>
<th style="text-align:center">输入尺寸</th>
<th style="text-align:center">核尺寸</th>
<th style="text-align:center">输出尺寸</th>
<th style="text-align:center">参数个数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">卷积层$C_{11}$</td>
<td style="text-align:center">$224\times224\times3$</td>
<td style="text-align:center">$3\times3\times64/1$</td>
<td style="text-align:center">$224\times224\times64$</td>
<td style="text-align:center">$(3\times3\times3+1)\times64$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{12}$</td>
<td style="text-align:center">$224\times224\times64$</td>
<td style="text-align:center">$3\times3\times64/1$</td>
<td style="text-align:center">$224\times224\times64$</td>
<td style="text-align:center">$(3\times3\times64+1)\times64$</td>
</tr>
<tr>
<td style="text-align:center">下采样层$S_{max1}$</td>
<td style="text-align:center">$224\times224\times64$</td>
<td style="text-align:center">$2\times2/2$</td>
<td style="text-align:center">$112\times112\times64$</td>
<td style="text-align:center">$0$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{21}$</td>
<td style="text-align:center">$112\times112\times64$</td>
<td style="text-align:center">$3\times3\times128/1$</td>
<td style="text-align:center">$112\times112\times128$</td>
<td style="text-align:center">$(3\times3\times64+1)\times128$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{22}$</td>
<td style="text-align:center">$112\times112\times128$</td>
<td style="text-align:center">$3\times3\times128/1$</td>
<td style="text-align:center">$112\times112\times128$</td>
<td style="text-align:center">$(3\times3\times128+1)\times128$</td>
</tr>
<tr>
<td style="text-align:center">下采样层$S_{max2}$</td>
<td style="text-align:center">$112\times112\times128$</td>
<td style="text-align:center">$2\times2/2$</td>
<td style="text-align:center">$56\times56\times128$</td>
<td style="text-align:center">$0$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{31}$</td>
<td style="text-align:center">$56\times56\times128$</td>
<td style="text-align:center">$3\times3\times256/1$</td>
<td style="text-align:center">$56\times56\times256$</td>
<td style="text-align:center">$(3\times3\times128+1)\times256$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{32}$</td>
<td style="text-align:center">$56\times56\times256$</td>
<td style="text-align:center">$3\times3\times256/1$</td>
<td style="text-align:center">$56\times56\times256$</td>
<td style="text-align:center">$(3\times3\times256+1)\times256$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{33}$</td>
<td style="text-align:center">$56\times56\times256$</td>
<td style="text-align:center">$3\times3\times256/1$</td>
<td style="text-align:center">$56\times56\times256$</td>
<td style="text-align:center">$(3\times3\times256+1)\times256$</td>
</tr>
<tr>
<td style="text-align:center">下采样层$S_{max3}$</td>
<td style="text-align:center">$56\times56\times256$</td>
<td style="text-align:center">$2\times2/2$</td>
<td style="text-align:center">$28\times28\times256$</td>
<td style="text-align:center">$0$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{41}$</td>
<td style="text-align:center">$28\times28\times256$</td>
<td style="text-align:center">$3\times3\times512/1$</td>
<td style="text-align:center">$28\times28\times512$</td>
<td style="text-align:center">$(3\times3\times256+1)\times512$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{42}$</td>
<td style="text-align:center">$28\times28\times512$</td>
<td style="text-align:center">$3\times3\times512/1$</td>
<td style="text-align:center">$28\times28\times512$</td>
<td style="text-align:center">$(3\times3\times512+1)\times512$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{43}$</td>
<td style="text-align:center">$28\times28\times512$</td>
<td style="text-align:center">$3\times3\times512/1$</td>
<td style="text-align:center">$28\times28\times512$</td>
<td style="text-align:center">$(3\times3\times512+1)\times512$</td>
</tr>
<tr>
<td style="text-align:center">下采样层$S_{max4}$</td>
<td style="text-align:center">$28\times28\times512$</td>
<td style="text-align:center">$2\times2/2$</td>
<td style="text-align:center">$14\times14\times512$</td>
<td style="text-align:center">$0$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{51}$</td>
<td style="text-align:center">$14\times14\times512$</td>
<td style="text-align:center">$3\times3\times512/1$</td>
<td style="text-align:center">$14\times14\times512$</td>
<td style="text-align:center">$(3\times3\times512+1)\times512$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{52}$</td>
<td style="text-align:center">$14\times14\times512$</td>
<td style="text-align:center">$3\times3\times512/1$</td>
<td style="text-align:center">$14\times14\times512$</td>
<td style="text-align:center">$(3\times3\times512+1)\times512$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{53}$</td>
<td style="text-align:center">$14\times14\times512$</td>
<td style="text-align:center">$3\times3\times512/1$</td>
<td style="text-align:center">$14\times14\times512$</td>
<td style="text-align:center">$(3\times3\times512+1)\times512$</td>
</tr>
<tr>
<td style="text-align:center">下采样层$S_{max5}$</td>
<td style="text-align:center">$14\times14\times512$</td>
<td style="text-align:center">$2\times2/2$</td>
<td style="text-align:center">$7\times7\times512$</td>
<td style="text-align:center">$0$</td>
</tr>
<tr>
<td style="text-align:center">全连接层$FC_{1}$</td>
<td style="text-align:center">$7\times7\times512$</td>
<td style="text-align:center">$(7\times7\times512)\times4096$</td>
<td style="text-align:center">$1\times4096$</td>
<td style="text-align:center">$(7\times7\times512+1)\times4096$</td>
</tr>
<tr>
<td style="text-align:center">全连接层$FC_{2}$</td>
<td style="text-align:center">$1\times4096$</td>
<td style="text-align:center">$4096\times4096$</td>
<td style="text-align:center">$1\times4096$</td>
<td style="text-align:center">$(4096+1)\times4096$</td>
</tr>
<tr>
<td style="text-align:center">全连接层$FC_{3}$</td>
<td style="text-align:center">$1\times4096$</td>
<td style="text-align:center">$4096\times1000$</td>
<td style="text-align:center">$1\times1000$</td>
<td style="text-align:center">$(4096+1)\times1000$</td>
</tr>
</tbody>
</table>
</div>
<h3 id="4-5-3-模型特性"><a href="#4-5-3-模型特性" class="headerlink" title="4.5.3 模型特性"></a>4.5.3 模型特性</h3><ul>
<li>整个网络都使用了同样大小的卷积核尺寸$3\times3$和最大池化尺寸$2\times2$。</li>
<li>$1\times1$卷积的意义主要在于线性变换，而输入通道数和输出通道数不变，没有发生降维。</li>
<li>两个$3\times3$的卷积层串联相当于1个$5\times5$的卷积层，感受野大小为$5\times5$。同样地，3个$3\times3$的卷积层串联的效果则相当于1个$7\times7$的卷积层。这样的连接方式使得网络参数量更小，而且多层的激活函数令网络对特征的学习能力更强。</li>
<li>VGGNet在训练时有一个小技巧，先训练浅层的的简单网络VGG11，再复用VGG11的权重来初始化VGG13，如此反复训练并初始化VGG19，能够使训练时收敛的速度更快。</li>
<li>在训练过程中使用多尺度的变换对原始数据做数据增强，使得模型不易过拟合。</li>
</ul>
<h2 id="4-6-GoogLeNet"><a href="#4-6-GoogLeNet" class="headerlink" title="4.6 GoogLeNet"></a>4.6 GoogLeNet</h2><h3 id="4-6-1-模型介绍"><a href="#4-6-1-模型介绍" class="headerlink" title="4.6.1 模型介绍"></a>4.6.1 模型介绍</h3><p>​    GoogLeNet作为2014年ILSVRC在分类任务上的冠军，以6.65%的错误率力压VGGNet等模型，在分类的准确率上面相比过去两届冠军ZFNet和AlexNet都有很大的提升。从名字<strong>GoogLe</strong>Net可以知道这是来自谷歌工程师所设计的网络结构，而名字中Goog<strong>LeNet</strong>更是致敬了LeNet$^{[0]}$。GoogLeNet中最核心的部分是其内部子网络结构Inception，该结构灵感来源于NIN，至今已经经历了四次版本迭代（Inception$_{v1-4}$）。</p>
<p><img src="/img/ch4/img_inception_01.png" alt=""><br>​                    图 4.8 Inception性能比较图</p>
<h3 id="4-6-2-模型结构"><a href="#4-6-2-模型结构" class="headerlink" title="4.6.2 模型结构"></a>4.6.2 模型结构</h3><p><img src="/img/ch4/image25.jpeg" alt=""><br>​                    图 4.9 GoogLeNet网络结构图<br>​    如图4.9中所示，GoogLeNet相比于以前的卷积神经网络结构，除了在深度上进行了延伸，还对网络的宽度进行了扩展，整个网络由许多块状子网络的堆叠而成，这个子网络构成了Inception结构。图4.9为Inception的四个版本：$Inception_{v1}​$在同一层中采用不同的卷积核，并对卷积结果进行合并;$Inception_{v2}​$组合不同卷积核的堆叠形式，并对卷积结果进行合并;$Inception_{v3}​$则在$v_2​$基础上进行深度组合的尝试;$Inception_{v4}​$结构相比于前面的版本更加复杂，子网络中嵌套着子网络。</p>
<p>$Inception_{v1}$</p>
<p><img src="/img/ch4/image27.png" alt=""></p>
<p><img src="/img/ch4/image28.png" alt=""></p>
<p>$Inception_{v2}$</p>
<p><img src="/img/ch4/image34.png" alt=""></p>
<p><img src="/img/ch4/image36.png" alt=""></p>
<p><img src="/img/ch4/image38.png" alt=""></p>
<p>$Inception_{v3}$</p>
<p><img src="/img/ch4/image37.png" alt=""></p>
<p>$Inception_{v4}$</p>
<p><img src="/img/ch4/image46.png" alt=""></p>
<p><img src="/img/ch4/image47.png" alt=""></p>
<p><img src="/img/ch4/image63.png" alt=""></p>
<p>​                    图 4.10 Inception$_{v1-4}$结构图</p>
<p>​                    表 4.6 GoogLeNet中Inception$_{v1}$网络参数配置</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">网络层</th>
<th style="text-align:center">输入尺寸</th>
<th style="text-align:center">核尺寸</th>
<th style="text-align:center">输出尺寸</th>
<th style="text-align:center">参数个数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">卷积层$C_{11}$</td>
<td style="text-align:center">$H\times{W}\times{C_1}$</td>
<td style="text-align:center">$1\times1\times{C_2}/2$</td>
<td style="text-align:center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td style="text-align:center">$(1\times1\times{C_1}+1)\times{C_2}$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{21}$</td>
<td style="text-align:center">$H\times{W}\times{C_2}$</td>
<td style="text-align:center">$1\times1\times{C_2}/2$</td>
<td style="text-align:center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td style="text-align:center">$(1\times1\times{C_2}+1)\times{C_2}$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{22}$</td>
<td style="text-align:center">$H\times{W}\times{C_2}$</td>
<td style="text-align:center">$3\times3\times{C_2}/1$</td>
<td style="text-align:center">$H\times{W}\times{C_2}/1$</td>
<td style="text-align:center">$(3\times3\times{C_2}+1)\times{C_2}$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{31}$</td>
<td style="text-align:center">$H\times{W}\times{C_1}$</td>
<td style="text-align:center">$1\times1\times{C_2}/2$</td>
<td style="text-align:center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td style="text-align:center">$(1\times1\times{C_1}+1)\times{C_2}$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{32}$</td>
<td style="text-align:center">$H\times{W}\times{C_2}$</td>
<td style="text-align:center">$5\times5\times{C_2}/1$</td>
<td style="text-align:center">$H\times{W}\times{C_2}/1$</td>
<td style="text-align:center">$(5\times5\times{C_2}+1)\times{C_2}$</td>
</tr>
<tr>
<td style="text-align:center">下采样层$S_{41}$</td>
<td style="text-align:center">$H\times{W}\times{C_1}$</td>
<td style="text-align:center">$3\times3/2$</td>
<td style="text-align:center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td style="text-align:center">$0$</td>
</tr>
<tr>
<td style="text-align:center">卷积层$C_{42}$</td>
<td style="text-align:center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td style="text-align:center">$1\times1\times{C_2}/1$</td>
<td style="text-align:center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td style="text-align:center">$(3\times3\times{C_2}+1)\times{C_2}$</td>
</tr>
<tr>
<td style="text-align:center">合并层$M$</td>
<td style="text-align:center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}(\times4)$</td>
<td style="text-align:center">拼接</td>
<td style="text-align:center">$\frac{H}{2}\times\frac{W}{2}\times({C_2}\times4)$</td>
<td style="text-align:center">$0$</td>
</tr>
</tbody>
</table>
</div>
<h3 id="4-6-3-模型特性"><a href="#4-6-3-模型特性" class="headerlink" title="4.6.3 模型特性"></a>4.6.3 模型特性</h3><ul>
<li><p>采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合； </p>
</li>
<li><p>之所以卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以直接拼接在一起了；</p>
</li>
<li><p>网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。但是，使用5x5的卷积核仍然会带来巨大的计算量。 为此，文章借鉴NIN2，采用1x1卷积核来进行降维。</p>
<h1 id=""><a href="#" class="headerlink" title=" "></a> </h1></li>
</ul>
<h2 id="Restnet"><a href="#Restnet" class="headerlink" title="Restnet"></a>Restnet</h2><h2 id="Densenet"><a href="#Densenet" class="headerlink" title="Densenet"></a>Densenet</h2><h2 id="4-7-为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？"><a href="#4-7-为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？" class="headerlink" title="4.7 为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？"></a>4.7 为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？</h2><ul>
<li>评测对比：为了让自己的结果更有说服力，在发表自己成果的时候会同一个标准的baseline及在baseline上改进而进行比较，常见的比如各种检测分割的问题都会基于VGG或者Resnet101这样的基础网络。</li>
<li>时间和精力有限：在科研压力和工作压力中，时间和精力只允许大家在有限的范围探索。</li>
<li>模型创新难度大：进行基本模型的改进需要大量的实验和尝试，并且需要大量的实验积累和强大灵感，很有可能投入产出比比较小。</li>
<li>资源限制：创造一个新的模型需要大量的时间和计算资源，往往在学校和小型商业团队不可行。</li>
<li>在实际的应用场景中，其实是有大量的非标准模型的配置。</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. <em>Proceedings of the IEEE</em>, november 1998.</p>
<p>[2] A. Krizhevsky, I. Sutskever and G. E. Hinton. ImageNet Classification with Deep Convolutional Neural Networks. <em>Advances in Neural Information Processing Systems 25</em>. Curran Associates, Inc. 1097–1105.</p>
<p>[3] LSVRC-2013. <a href="http://www.image-net.org/challenges/LSVRC/2013/results.php" target="_blank" rel="noopener">http://www.image-net.org/challenges/LSVRC/2013/results.php</a></p>
<p>[4] M. D. Zeiler and R. Fergus. Visualizing and Understanding Convolutional Networks. <em>European Conference on Computer Vision</em>. </p>
<p>[5] M. Lin,  Q. Chen,  and S. Yan.   Network in network. <em>Computing Research Repository</em>, abs/1312.4400, 2013.</p>
<p>[6] K. Simonyan and A. Zisserman.  Very Deep Convolutional Networks for Large-Scale Image Recognition. <em>International Conference on Machine Learning</em>, 2015.</p>
<p>[7] Bharath Raj. <a href="https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202" target="_blank" rel="noopener">a-simple-guide-to-the-versions-of-the-inception-network</a>, 2018.</p>
<p>[8] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi. <a href="https://arxiv.org/pdf/1602.07261.pdf" target="_blank" rel="noopener">Inception-v4, Inception-ResNet and<br>the Impact of Residual Connections on Learning</a>, 2016.</p>
<p>[9] Sik-Ho Tsang. <a href="https://towardsdatascience.com/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc" target="_blank" rel="noopener">review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification</a>, 2018.</p>
<p>[10] Zbigniew Wojna, Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens. <a href="https://arxiv.org/pdf/1512.00567v3.pdf" target="_blank" rel="noopener">Rethinking the Inception Architecture for Computer Vision</a>, 2015.</p>
<p>[11] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich. <a href="https://arxiv.org/pdf/1409.4842v1.pdf" target="_blank" rel="noopener">Going deeper with convolutions</a>, 2014.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/03/03/%E7%AC%AC%E4%B8%89%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/03/%E7%AC%AC%E4%B8%89%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">第三章_深度学习基础</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-03 12:22:27 / 修改时间：12:23:08" itemprop="dateCreated datePublished" datetime="2020-03-03T12:22:27+08:00">2020-03-03</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h1 id="第三章-深度学习基础"><a href="#第三章-深度学习基础" class="headerlink" title="第三章 深度学习基础"></a>第三章 深度学习基础</h1><h2 id="3-1-基本概念"><a href="#3-1-基本概念" class="headerlink" title="3.1 基本概念"></a>3.1 基本概念</h2><h3 id="3-1-1-神经网络组成？"><a href="#3-1-1-神经网络组成？" class="headerlink" title="3.1.1 神经网络组成？"></a>3.1.1 神经网络组成？</h3><p>神经网络类型众多，其中最为重要的是多层感知机。为了详细地描述神经网络，我们先从最简单的神经网络说起。</p>
<p><strong>感知机</strong></p>
<p>多层感知机中的特征神经元模型称为感知机，由<em>Frank Rosenblatt</em>于1957年发明。</p>
<p>简单的感知机如下图所示：</p>
<p><img src="/img/ch3/3-1.png" alt=""></p>
<p>其中$x_1$，$x_2$，$x_3$为感知机的输入，其输出为：</p>
<script type="math/tex; mode=display">
output = \left\{
\begin{aligned}
0, \quad if \ \ \sum_i w_i x_i \leqslant threshold \\
1, \quad if \ \ \sum_i w_i x_i > threshold
\end{aligned}
\right.</script><p>假如把感知机想象成一个加权投票机制，比如 3 位评委给一个歌手打分，打分分别为$ 4 $分、$1$ 分、$-3 $分，这$ 3$ 位评分的权重分别是 $1、3、2$，则该歌手最终得分为 $4 \times 1 + 1 \times 3 + (-3) \times 2 = 1$ 。按照比赛规则，选取的 $threshold$ 为 $3$，说明只有歌手的综合评分大于$ 3$ 时，才可顺利晋级。对照感知机，该选手被淘汰，因为：</p>
<script type="math/tex; mode=display">
\sum_i w_i x_i < threshold=3, output = 0</script><p>用 $-b$  代替 $threshold$，输出变为：</p>
<script type="math/tex; mode=display">
output = \left\{
\begin{aligned}
0, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b \leqslant 0 \\
1, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b > 0
\end{aligned}
\right.</script><p>设置合适的  $\boldsymbol{x}$  和  $b$ ，一个简单的感知机单元的与非门表示如下：</p>
<p><img src="/img/ch3/3-2.png" alt=""></p>
<p>当输入为 $0$，$1$ 时，感知机输出为 $ 0 \times (-2) + 1 \times (-2) + 3 = 1$。</p>
<p>复杂一些的感知机由简单的感知机单元组合而成：</p>
<p><img src="/img/ch3/3-3.png" alt=""></p>
<p><strong>多层感知机</strong></p>
<p>多层感知机由感知机推广而来，最主要的特点是有多个神经元层，因此也叫深度神经网络。相比于单独的感知机，多层感知机的第 $ i $ 层的每个神经元和第 $ i-1 $ 层的每个神经元都有连接。</p>
<p><img src="/img/ch3/3.1.1.5.png" alt=""></p>
<p>输出层可以不止有$ 1$ 个神经元。隐藏层可以只有$ 1$ 层，也可以有多层。输出层为多个神经元的神经网络例如下图所示：</p>
<p><img src="/img/ch3/3.1.1.6.png" alt=""></p>
<h3 id="3-1-2-神经网络有哪些常用模型结构？"><a href="#3-1-2-神经网络有哪些常用模型结构？" class="headerlink" title="3.1.2 神经网络有哪些常用模型结构？"></a>3.1.2 神经网络有哪些常用模型结构？</h3><p>下图包含了大部分常用的模型：</p>
<p><img src="/img/ch3/3-7.jpg" alt=""></p>
<h3 id="3-1-3-如何选择深度学习开发平台？"><a href="#3-1-3-如何选择深度学习开发平台？" class="headerlink" title="3.1.3 如何选择深度学习开发平台？"></a>3.1.3 如何选择深度学习开发平台？</h3><p>​    现有的深度学习开源平台主要有 Caffe, PyTorch, MXNet, CNTK, Theano, TensorFlow, Keras, fastai等。那如何选择一个适合自己的平台呢，下面列出一些衡量做参考。</p>
<p><strong>参考1：与现有编程平台、技能整合的难易程度</strong></p>
<p>​    主要是前期积累的开发经验和资源，比如编程语言，前期数据集存储格式等。</p>
<p><strong>参考2: 与相关机器学习、数据处理生态整合的紧密程度</strong></p>
<p>​    深度学习研究离不开各种数据处理、可视化、统计推断等软件包。考虑建模之前，是否具有方便的数据预处理工具？建模之后，是否具有方便的工具进行可视化、统计推断、数据分析。  </p>
<p><strong>参考3：对数据量及硬件的要求和支持</strong></p>
<p>​    深度学习在不同应用场景的数据量是不一样的，这也就导致我们可能需要考虑分布式计算、多GPU计算的问题。例如，对计算机图像处理研究的人员往往需要将图像文件和计算任务分部到多台计算机节点上进行执行。当下每个深度学习平台都在快速发展，每个平台对分布式计算等场景的支持也在不断演进。</p>
<p><strong>参考4：深度学习平台的成熟程度</strong></p>
<p>​    成熟程度的考量是一个比较主观的考量因素，这些因素可包括：社区的活跃程度；是否容易和开发人员进行交流；当前应用的势头。</p>
<p><strong>参考5：平台利用是否多样性？</strong></p>
<p>​    有些平台是专门为深度学习研究和应用进行开发的，有些平台对分布式计算、GPU 等构架都有强大的优化，能否用这些平台/软件做其他事情？比如有些深度学习软件是可以用来求解二次型优化；有些深度学习平台很容易被扩展，被运用在强化学习的应用中。</p>
<h3 id="3-1-4-为什么使用深层表示"><a href="#3-1-4-为什么使用深层表示" class="headerlink" title="3.1.4 为什么使用深层表示?"></a>3.1.4 为什么使用深层表示?</h3><ol>
<li>深度神经网络是一种特征递进式的学习算法，浅层的神经元直接从输入数据中学习一些低层次的简单特征，例如边缘、纹理等。而深层的特征则基于已学习到的浅层特征继续学习更高级的特征，从计算机的角度学习深层的语义信息。</li>
<li>深层的网络隐藏单元数量相对较少，隐藏层数目较多，如果浅层的网络想要达到同样的计算结果则需要指数级增长的单元数量才能达到。</li>
</ol>
<h3 id="3-1-5-为什么深层神经网络难以训练？"><a href="#3-1-5-为什么深层神经网络难以训练？" class="headerlink" title="3.1.5 为什么深层神经网络难以训练？"></a>3.1.5 为什么深层神经网络难以训练？</h3><ol>
<li><p>梯度消失</p>
<pre><code> 梯度消失是指通过隐藏层从后向前看，梯度会变的越来越小，说明前面层的学习会显著慢于后面层的学习，所以学习会卡住，除非梯度变大。
</code></pre><p> ​    梯度消失的原因受到多种因素影响，例如学习率的大小，网络参数的初始化，激活函数的边缘效应等。在深层神经网络中，每一个神经元计算得到的梯度都会传递给前一层，较浅层的神经元接收到的梯度受到之前所有层梯度的影响。如果计算得到的梯度值非常小，随着层数增多，求出的梯度更新信息将会以指数形式衰减，就会发生梯度消失。下图是不同隐含层的学习速率：</p>
</li>
</ol>
<p><img src="/img/ch3/3-8.png" alt=""></p>
<ol>
<li><p>梯度爆炸</p>
<pre><code> 在深度网络或循环神经网络（Recurrent Neural Network, RNN）等网络结构中，梯度可在网络更新的过程中不断累积，变成非常大的梯度，导致网络权重值的大幅更新，使得网络不稳定；在极端情况下，权重值甚至会溢出，变为$NaN$值，再也无法更新。
</code></pre></li>
<li><p>权重矩阵的退化导致模型的有效自由度减少。</p>
<p> ​    参数空间中学习的退化速度减慢，导致减少了模型的有效维数，网络的可用自由度对学习中梯度范数的贡献不均衡，随着相乘矩阵的数量（即网络深度）的增加，矩阵的乘积变得越来越退化。在有硬饱和边界的非线性网络中（例如 ReLU 网络），随着深度增加，退化过程会变得越来越快。Duvenaud等人2014年的论文里展示了关于该退化过程的可视化：</p>
</li>
</ol>
<p><img src="/img/ch3/3-9.jpg" alt=""></p>
<p>随着深度的增加，输入空间（左上角所示）会在输入空间中的每个点处被扭曲成越来越细的单丝，只有一个与细丝正交的方向影响网络的响应。沿着这个方向，网络实际上对变化变得非常敏感。</p>
<h3 id="3-1-6-深度学习和机器学习有什么不同？"><a href="#3-1-6-深度学习和机器学习有什么不同？" class="headerlink" title="3.1.6 深度学习和机器学习有什么不同？"></a>3.1.6 深度学习和机器学习有什么不同？</h3><p>​    <strong>机器学习</strong>：利用计算机、概率论、统计学等知识，输入数据，让计算机学会新知识。机器学习的过程，就是训练数据去优化目标函数。</p>
<p>​    <strong>深度学习</strong>：是一种特殊的机器学习，具有强大的能力和灵活性。它通过学习将世界表示为嵌套的层次结构，每个表示都与更简单的特征相关，而抽象的表示则用于计算更抽象的表示。</p>
<p>​    传统的机器学习需要定义一些手工特征，从而有目的的去提取目标信息， 非常依赖任务的特异性以及设计特征的专家经验。而深度学习可以从大数据中先学习简单的特征，并从其逐渐学习到更为复杂抽象的深层特征，不依赖人工的特征工程，这也是深度学习在大数据时代受欢迎的一大原因。</p>
<p><img src="/img/ch3/3.1.6.1.png" alt=""></p>
<p><img src="/img/ch3/3-11.jpg" alt=""></p>
<h2 id="3-2-网络操作与计算"><a href="#3-2-网络操作与计算" class="headerlink" title="3.2 网络操作与计算"></a>3.2 网络操作与计算</h2><h3 id="3-2-1-前向传播与反向传播？"><a href="#3-2-1-前向传播与反向传播？" class="headerlink" title="3.2.1 前向传播与反向传播？"></a>3.2.1 前向传播与反向传播？</h3><p>神经网络的计算主要有两种：前向传播（foward propagation, FP）作用于每一层的输入，通过逐层计算得到输出结果；反向传播（backward propagation, BP）作用于网络的输出，通过计算梯度由深到浅更新网络参数。</p>
<p><strong>前向传播</strong></p>
<p><img src="/img/ch3/3.2.1.1.png" alt=""></p>
<p>假设上一层结点 $ i,j,k,… $ 等一些结点与本层的结点 $ w $ 有连接，那么结点 $ w $ 的值怎么算呢？就是通过上一层的 $ i,j,k,… $ 等结点以及对应的连接权值进行加权和运算，最终结果再加上一个偏置项（图中为了简单省略了），最后在通过一个非线性函数（即激活函数），如 $ReLu$，$sigmoid$ 等函数，最后得到的结果就是本层结点 $ w $ 的输出。 </p>
<p>最终不断的通过这种方法一层层的运算，得到输出层结果。</p>
<p><strong>反向传播</strong></p>
<p><img src="/img/ch3/3.2.1.2.png" alt=""></p>
<p>由于我们前向传播最终得到的结果，以分类为例，最终总是有误差的，那么怎么减少误差呢，当前应用广泛的一个算法就是梯度下降算法，但是求梯度就要求偏导数，下面以图中字母为例讲解一下：</p>
<p>设最终误差为 $ E $且输出层的激活函数为线性激活函数，对于输出那么 $ E $ 对于输出节点 $ y_l $ 的偏导数是 $ y_l - t_l $，其中 $ t_l $ 是真实值，$ \frac{\partial y_l}{\partial z_l} $ 是指上面提到的激活函数，$ z_l $ 是上面提到的加权和，那么这一层的 $ E $ 对于 $ z_l $ 的偏导数为 $ \frac{\partial E}{\partial z_l} = \frac{\partial E}{\partial y_l} \frac{\partial y_l}{\partial z_l} $。同理，下一层也是这么计算，只不过 $ \frac{\partial E}{\partial y_k} $ 计算方法变了，一直反向传播到输入层，最后有 $ \frac{\partial E}{\partial x_i} = \frac{\partial E}{\partial y_j} \frac{\partial y_j}{\partial z_j} $，且 $ \frac{\partial z_j}{\partial x_i} = w_i j $。然后调整这些过程中的权值，再不断进行前向传播和反向传播的过程，最终得到一个比较好的结果。</p>
<h3 id="3-2-2-如何计算神经网络的输出？"><a href="#3-2-2-如何计算神经网络的输出？" class="headerlink" title="3.2.2 如何计算神经网络的输出？"></a>3.2.2 如何计算神经网络的输出？</h3><p><img src="/img/ch3/3.2.2.1.png" alt=""></p>
<p>如上图，输入层有三个节点，我们将其依次编号为 1、2、3；隐藏层的 4 个节点，编号依次为 4、5、6、7；最后输出层的两个节点编号为 8、9。比如，隐藏层的节点 4，它和输入层的三个节点 1、2、3 之间都有连接，其连接上的权重分别为是 $ w_{41}, w_{42}, w_{43} $。</p>
<p>为了计算节点 4 的输出值，我们必须先得到其所有上游节点（也就是节点 1、2、3）的输出值。节点 1、2、3 是输入层的节点，所以，他们的输出值就是输入向量本身。按照上图画出的对应关系，可以看到节点 1、2、3 的输出值分别是 $ x_1, x_2, x_3 $。</p>
<script type="math/tex; mode=display">
a_4 = \sigma(w^T \cdot a) = \sigma(w_{41}x_4 + w_{42}x_2 + w_{43}a_3 + w_{4b})</script><p>其中 $ w_{4b} $ 是节点 4 的偏置项。</p>
<p>同样，我们可以继续计算出节点 5、6、7 的输出值 $ a_5, a_6, a_7 $。</p>
<p>计算输出层的节点 8 的输出值 $ y_1 $：</p>
<script type="math/tex; mode=display">
y_1 = \sigma(w^T \cdot a) = \sigma(w_{84}a_4 + w_{85}a_5 + w_{86}a_6 + w_{87}a_7 + w_{8b})</script><p>其中 $ w_{8b} $ 是节点 8 的偏置项。</p>
<p>同理，我们还可以计算出 $ y_2 $。这样输出层所有节点的输出值计算完毕，我们就得到了在输入向量 $ x_1, x_2, x_3, x_4 $ 时，神经网络的输出向量 $ y_1, y_2 $ 。这里我们也看到，输出向量的维度和输出层神经元个数相同。</p>
<h3 id="3-2-3-如何计算卷积神经网络输出值？"><a href="#3-2-3-如何计算卷积神经网络输出值？" class="headerlink" title="3.2.3 如何计算卷积神经网络输出值？"></a>3.2.3 如何计算卷积神经网络输出值？</h3><p>假设有一个 5*5 的图像，使用一个 3*3 的 filter 进行卷积，想得到一个 3*3 的 Feature Map，如下所示：</p>
<p><img src="/img/ch3/3.2.3.1.png" alt=""></p>
<p>$ x_{i,j} $ 表示图像第  $ i $ 行第 $ j $ 列元素。$ w_{m,n} $ 表示 filter​ 第 $ m $ 行第 $ n $ 列权重。 $ w_b $ 表示 $filter$ 的偏置项。 表$a_i,_j$示 feature map 第 $ i$ 行第 $ j $ 列元素。 $f$ 表示激活函数，这里以$ ReLU$ 函数为例。</p>
<p>卷积计算公式如下：</p>
<script type="math/tex; mode=display">
a_{i,j} = f(\sum_{m=0}^2 \sum_{n=0}^2 w_{m,n} x_{i+m, j+n} + w_b )</script><p>当步长为 $1$ 时，计算 feature map 元素 $ a_{0,0} $ 如下：</p>
<script type="math/tex; mode=display">
a_{0,0} = f(\sum_{m=0}^2 \sum_{n=0}^2 w_{m,n} x_{0+m, 0+n} + w_b )

= relu(w_{0,0} x_{0,0} + w_{0,1} x_{0,1} + w_{0,2} x_{0,2} + w_{1,0} x_{1,0} + \\w_{1,1} x_{1,1} + w_{1,2} x_{1,2} + w_{2,0} x_{2,0} + w_{2,1} x_{2,1} + w_{2,2} x_{2,2}) \\

= 1 + 0 + 1 + 0 + 1 + 0 + 0 + 0 + 1 \\

= 4</script><p>其计算过程图示如下：</p>
<p><img src="/img/ch3/3.2.3.2.png" alt=""></p>
<p>以此类推，计算出全部的Feature Map。</p>
<p><img src="/img/ch3/3.2.3.4.png" alt=""></p>
<p>当步幅为 2 时，Feature Map计算如下</p>
<p><img src="/img/ch3/3.2.3.5.png" alt=""></p>
<p>注：图像大小、步幅和卷积后的Feature Map大小是有关系的。它们满足下面的关系：</p>
<script type="math/tex; mode=display">
W_2 = (W_1 - F + 2P)/S + 1\\
H_2 = (H_1 - F + 2P)/S + 1</script><p>​    其中 $ W_2 $， 是卷积后 Feature Map 的宽度；$ W_1 $ 是卷积前图像的宽度；$ F $ 是 filter 的宽度；$ P $ 是 Zero Padding 数量，Zero Padding 是指在原始图像周围补几圈 $0$，如果 $P$ 的值是 $1$，那么就补 $1$ 圈 $0$；$S$ 是步幅；$ H_2 $ 卷积后 Feature Map 的高度；$ H_1 $ 是卷积前图像的宽度。</p>
<p>​    举例：假设图像宽度 $ W_1 = 5 $，filter 宽度 $ F=3 $，Zero Padding $ P=0 $，步幅 $ S=2 $，$ Z $ 则</p>
<script type="math/tex; mode=display">
W_2 = (W_1 - F + 2P)/S + 1

= (5-3+0)/2 + 1

= 2</script><p>​    说明 Feature Map 宽度是2。同样，我们也可以计算出 Feature Map 高度也是 2。</p>
<p>如果卷积前的图像深度为 $ D $，那么相应的 filter 的深度也必须为 $ D $。深度大于 1 的卷积计算公式：</p>
<script type="math/tex; mode=display">
a_{i,j} = f(\sum_{d=0}^{D-1} \sum_{m=0}^{F-1} \sum_{n=0}^{F-1} w_{d,m,n} x_{d,i+m,j+n} + w_b)</script><p>​    其中，$ D $ 是深度；$ F $ 是 filter 的大小；$ w_{d,m,n} $ 表示 filter 的第 $ d $ 层第 $ m $ 行第 $ n $ 列权重；$ a_{d,i,j} $ 表示 feature map 的第 $ d $ 层第 $ i $ 行第 $ j $ 列像素；其它的符号含义前面相同，不再赘述。</p>
<p>​    每个卷积层可以有多个 filter。每个 filter 和原始图像进行卷积后，都可以得到一个 Feature Map。卷积后 Feature Map 的深度(个数)和卷积层的 filter 个数相同。下面的图示显示了包含两个 filter 的卷积层的计算。$7<em>7</em>3$ 输入，经过两个 $3<em>3</em>3$ filter 的卷积(步幅为 $2$)，得到了 $3<em>3</em>2$ 的输出。图中的 Zero padding 是 $1$，也就是在输入元素的周围补了一圈 $0$。</p>
<p><img src="/img/ch3/3.2.3.6.png" alt=""></p>
<p>​    以上就是卷积层的计算方法。这里面体现了局部连接和权值共享：每层神经元只和上一层部分神经元相连(卷积计算规则)，且 filter 的权值对于上一层所有神经元都是一样的。对于包含两个 $ 3 <em> 3 </em> 3 $ 的 fitler 的卷积层来说，其参数数量仅有 $ (3 <em> 3 </em> 3+1) * 2 = 56 $ 个，且参数数量与上一层神经元个数无关。与全连接神经网络相比，其参数数量大大减少了。</p>
<h3 id="3-2-4-如何计算-Pooling-层输出值输出值？"><a href="#3-2-4-如何计算-Pooling-层输出值输出值？" class="headerlink" title="3.2.4 如何计算 Pooling 层输出值输出值？"></a>3.2.4 如何计算 Pooling 层输出值输出值？</h3><p>​    Pooling 层主要的作用是下采样，通过去掉 Feature Map 中不重要的样本，进一步减少参数数量。Pooling 的方法很多，最常用的是 Max Pooling。Max Pooling 实际上就是在 n*n 的样本中取最大值，作为采样后的样本值。下图是 2*2 max pooling：</p>
<p><img src="/img/ch3/3.2.4.1.png" alt=""></p>
<p>​    除了 Max Pooing 之外，常用的还有 Average Pooling ——取各样本的平均值。<br>​    对于深度为 $ D $ 的 Feature Map，各层独立做 Pooling，因此 Pooling 后的深度仍然为 $ D $。</p>
<h3 id="3-2-5-实例理解反向传播"><a href="#3-2-5-实例理解反向传播" class="headerlink" title="3.2.5 实例理解反向传播"></a>3.2.5 实例理解反向传播</h3><p>​    一个典型的三层神经网络如下所示：</p>
<p><img src="/img/ch3/3.2.5.1.png" alt=""></p>
<p>​    其中 Layer $ L_1 $ 是输入层，Layer $ L_2 $ 是隐含层，Layer $ L_3 $ 是输出层。</p>
<p>​    假设输入数据集为 $ D={x_1, x_2, …, x_n} $，输出数据集为 $ y_1, y_2, …, y_n $。</p>
<p>​    如果输入和输出是一样，即为自编码模型。如果原始数据经过映射，会得到不同于输入的输出。</p>
<p>假设有如下的网络层：</p>
<p><img src="/img/ch3/3.2.5.2.png" alt=""></p>
<p>​    输入层包含神经元 $ i_1, i_2 $，偏置 $ b_1 $；隐含层包含神经元 $ h_1, h_2 $，偏置 $ b_2 $，输出层为  $ o_1, o_2 $，$ w_i $ 为层与层之间连接的权重，激活函数为 $sigmoid$ 函数。对以上参数取初始值，如下图所示：</p>
<p><img src="/img/ch3/3.2.5.3.png" alt=""></p>
<p>其中：</p>
<ul>
<li>输入数据 $ i1=0.05, i2 = 0.10 $</li>
<li>输出数据 $ o1=0.01, o2=0.99 $;</li>
<li>初始权重 $ w1=0.15, w2=0.20, w3=0.25,w4=0.30, w5=0.40, w6=0.45, w7=0.50, w8=0.55 $</li>
<li>目标：给出输入数据 $ i1,i2 $ ( $0.05$和$0.10$ )，使输出尽可能与原始输出 $ o1,o2 $，( $0.01$和$0.99$)接近。</li>
</ul>
<p><strong>前向传播</strong></p>
<ol>
<li>输入层 —&gt; 输出层</li>
</ol>
<p>计算神经元 $ h1 $ 的输入加权和：</p>
<script type="math/tex; mode=display">
net_{h1} = w_1 * i_1 + w_2 * i_2 + b_1 * 1\\

net_{h1} = 0.15 * 0.05 + 0.2 * 0.1 + 0.35 * 1 = 0.3775</script><p>神经元 $ h1 $ 的输出 $ o1 $ ：（此处用到激活函数为 sigmoid 函数）：</p>
<script type="math/tex; mode=display">
out_{h1} = \frac{1}{1 + e^{-net_{h1}}} = \frac{1}{1 + e^{-0.3775}} = 0.593269992</script><p>同理，可计算出神经元 $ h2 $ 的输出 $ o1 $：</p>
<script type="math/tex; mode=display">
out_{h2} = 0.596884378</script><ol>
<li>隐含层—&gt;输出层：  　　</li>
</ol>
<p>计算输出层神经元 $ o1 $ 和 $ o2 $ 的值：</p>
<script type="math/tex; mode=display">
net_{o1} = w_5 * out_{h1} + w_6 * out_{h2} + b_2 * 1</script><script type="math/tex; mode=display">
net_{o1} = 0.4 * 0.593269992 + 0.45 * 0.596884378 + 0.6 * 1 = 1.105905967</script><script type="math/tex; mode=display">
out_{o1} = \frac{1}{1 + e^{-net_{o1}}} = \frac{1}{1 + e^{1.105905967}} = 0.75136079</script><p>这样前向传播的过程就结束了，我们得到输出值为 $ [0.75136079 ,  0.772928465] $，与实际值 $ [0.01 , 0.99] $ 相差还很远，现在我们对误差进行反向传播，更新权值，重新计算输出。</p>
<p><strong>反向传播 </strong></p>
<p>​    1.计算总误差</p>
<p>总误差：(这里使用Square Error)</p>
<script type="math/tex; mode=display">
E_{total} = \sum \frac{1}{2}(target - output)^2</script><p>但是有两个输出，所以分别计算 $ o1 $ 和 $ o2 $ 的误差，总误差为两者之和：</p>
<p>$E_{o1} = \frac{1}{2}(target_{o1} - out_{o1})^2<br>= \frac{1}{2}(0.01 - 0.75136507)^2 = 0.274811083$.</p>
<p>$E_{o2} = 0.023560026$.</p>
<p>$E_{total} = E_{o1} + E_{o2} = 0.274811083 + 0.023560026 = 0.298371109$.</p>
<p>​    2.隐含层 —&gt; 输出层的权值更新：</p>
<p>以权重参数 $ w5 $ 为例，如果我们想知道 $ w5 $ 对整体误差产生了多少影响，可以用整体误差对 $ w5 $ 求偏导求出：（链式法则）</p>
<script type="math/tex; mode=display">
\frac{\partial E_{total}}{\partial w5} = \frac{\partial E_{total}}{\partial out_{o1}} * \frac{\partial out_{o1}}{\partial net_{o1}} * \frac{\partial net_{o1}}{\partial w5}</script><p>下面的图可以更直观的看清楚误差是怎样反向传播的：</p>
<p><img src="/img/ch3/3.2.5.4.png" alt=""></p>
<h3 id="3-2-6-神经网络更“深”有什么意义？"><a href="#3-2-6-神经网络更“深”有什么意义？" class="headerlink" title="3.2.6 神经网络更“深”有什么意义？"></a>3.2.6 神经网络更“深”有什么意义？</h3><p>前提：在一定范围内。</p>
<ul>
<li>在神经元数量相同的情况下，深层网络结构具有更大容量，分层组合带来的是指数级的表达空间，能够组合成更多不同类型的子结构，这样可以更容易地学习和表示各种特征。</li>
<li>隐藏层增加则意味着由激活函数带来的非线性变换的嵌套层数更多，就能构造更复杂的映射关系。</li>
</ul>
<h2 id="3-3-超参数"><a href="#3-3-超参数" class="headerlink" title="3.3 超参数"></a>3.3 超参数</h2><h3 id="3-3-1-什么是超参数？"><a href="#3-3-1-什么是超参数？" class="headerlink" title="3.3.1 什么是超参数？"></a>3.3.1 什么是超参数？</h3><p>​    <strong>超参数</strong> : 在机器学习的上下文中，超参数是在开始学习过程之前设置值的参数，而不是通过训练得到的参数数据。通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果。</p>
<p>​    超参数通常存在于：</p>
<pre><code>1.  定义关于模型的更高层次的概念，如复杂性或学习能力。
2.  不能直接从标准模型培训过程中的数据中学习，需要预先定义。
3.  可以通过设置不同的值，训练不同的模型和选择更好的测试值来决定
</code></pre><p>​    超参数具体来讲比如算法中的学习率（learning rate）、梯度下降法迭代的数量（iterations）、隐藏层数目（hidden layers）、隐藏层单元数目、激活函数（ activation function）都需要根据实际情况来设置，这些数字实际上控制了最后的参数和的值，所以它们被称作超参数。</p>
<h3 id="3-3-2-如何寻找超参数的最优值？"><a href="#3-3-2-如何寻找超参数的最优值？" class="headerlink" title="3.3.2 如何寻找超参数的最优值？"></a>3.3.2 如何寻找超参数的最优值？</h3><p>​    在使用机器学习算法时，总有一些难调的超参数。例如权重衰减大小，高斯核宽度等等。这些参数需要人为设置，设置的值对结果产生较大影响。常见设置超参数的方法有：</p>
<ol>
<li><p>猜测和检查：根据经验或直觉，选择参数，一直迭代。</p>
</li>
<li><p>网格搜索：让计算机尝试在一定范围内均匀分布的一组值。</p>
</li>
<li><p>随机搜索：让计算机随机挑选一组值。</p>
</li>
<li><p>贝叶斯优化：使用贝叶斯优化超参数，会遇到贝叶斯优化算法本身就需要很多的参数的困难。</p>
</li>
<li><p>MITIE方法，好初始猜测的前提下进行局部优化。它使用BOBYQA算法，并有一个精心选择的起始点。由于BOBYQA只寻找最近的局部最优解，所以这个方法是否成功很大程度上取决于是否有一个好的起点。在MITIE的情况下，我们知道一个好的起点，但这不是一个普遍的解决方案，因为通常你不会知道好的起点在哪里。从好的方面来说，这种方法非常适合寻找局部最优解。稍后我会再讨论这一点。</p>
</li>
<li><p>最新提出的LIPO的全局优化方法。这个方法没有参数，而且经验证比随机搜索方法好。</p>
</li>
</ol>
<h3 id="3-3-3-超参数搜索一般过程？"><a href="#3-3-3-超参数搜索一般过程？" class="headerlink" title="3.3.3 超参数搜索一般过程？"></a>3.3.3 超参数搜索一般过程？</h3><p>超参数搜索一般过程：</p>
<ol>
<li>将数据集划分成训练集、验证集及测试集。</li>
<li>在训练集上根据模型的性能指标对模型参数进行优化。</li>
<li>在验证集上根据模型的性能指标对模型的超参数进行搜索。</li>
<li>步骤 2 和步骤 3 交替迭代，最终确定模型的参数和超参数，在测试集中验证评价模型的优劣。</li>
</ol>
<p>其中，搜索过程需要搜索算法，一般有：网格搜索、随机搜过、启发式智能搜索、贝叶斯搜索。</p>
<h2 id="3-4-激活函数"><a href="#3-4-激活函数" class="headerlink" title="3.4 激活函数"></a>3.4 激活函数</h2><h3 id="3-4-1-为什么需要非线性激活函数？"><a href="#3-4-1-为什么需要非线性激活函数？" class="headerlink" title="3.4.1 为什么需要非线性激活函数？"></a>3.4.1 为什么需要非线性激活函数？</h3><p><strong>为什么需要激活函数？</strong></p>
<ol>
<li>激活函数对模型学习、理解非常复杂和非线性的函数具有重要作用。</li>
<li>激活函数可以引入非线性因素。如果不使用激活函数，则输出信号仅是一个简单的线性函数。线性函数一个一级多项式，线性方程的复杂度有限，从数据中学习复杂函数映射的能力很小。没有激活函数，神经网络将无法学习和模拟其他复杂类型的数据，例如图像、视频、音频、语音等。</li>
<li>激活函数可以把当前特征空间通过一定的线性映射转换到另一个空间，让数据能够更好的被分类。</li>
</ol>
<p><strong>为什么激活函数需要非线性函数？</strong></p>
<ol>
<li>假若网络中全部是线性部件，那么线性的组合还是线性，与单独一个线性分类器无异。这样就做不到用非线性来逼近任意函数。</li>
<li>使用非线性激活函数 ，以便使网络更加强大，增加它的能力，使它可以学习复杂的事物，复杂的表单数据，以及表示输入输出之间非线性的复杂的任意函数映射。使用非线性激活函数，能够从输入输出之间生成非线性映射。</li>
</ol>
<h3 id="3-4-2-常见的激活函数及图像"><a href="#3-4-2-常见的激活函数及图像" class="headerlink" title="3.4.2 常见的激活函数及图像"></a>3.4.2 常见的激活函数及图像</h3><ol>
<li><p>sigmoid 激活函数</p>
<p>函数的定义为：$ f(x) = \frac{1}{1 + e^{-x}} $，其值域为 $ (0,1) $。</p>
<p>函数图像如下：</p>
</li>
</ol>
<p><img src="/img/ch3/3-26.png" alt=""></p>
<ol>
<li><p>tanh激活函数</p>
<p>函数的定义为：$ f(x) = tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} $，值域为 $ (-1,1) $。</p>
<p>函数图像如下：</p>
</li>
</ol>
<p><img src="/img/ch3/3-27.png" alt=""></p>
<ol>
<li><p>Relu激活函数</p>
<p>函数的定义为：$ f(x) = max(0, x) $  ，值域为 $ [0,+∞) $；</p>
<p>函数图像如下：</p>
</li>
</ol>
<p><img src="/img/ch3/3-28.png" alt=""></p>
<ol>
<li><p>Leak Relu 激活函数 </p>
<p>函数定义为： $ f(x) =  \left\{<br>\begin{aligned}<br>ax, \quad x<0 \\
x, \quad x>0<br>\end{aligned}<br>\right. $，值域为 $ (-∞,+∞) $。 </p>
<p>图像如下（$ a = 0.5 $）：</p>
</li>
</ol>
<p><img src="/img/ch3/3-29.png" alt=""></p>
<ol>
<li><p>SoftPlus 激活函数</p>
<p>函数的定义为：$ f(x) = ln( 1 + e^x) $，值域为 $ (0,+∞) $。</p>
<p>函数图像如下:</p>
</li>
</ol>
<p><img src="/img/ch3/3-30.png" alt=""></p>
<ol>
<li><p>softmax 函数</p>
<p>函数定义为： $ \sigma(z)_j = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} $。</p>
<p>Softmax 多用于多分类神经网络输出。</p>
</li>
</ol>
<h3 id="3-4-3-常见激活函数的导数计算？"><a href="#3-4-3-常见激活函数的导数计算？" class="headerlink" title="3.4.3 常见激活函数的导数计算？"></a>3.4.3 常见激活函数的导数计算？</h3><p>对常见激活函数，导数计算如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>原函数</th>
<th>函数表达式</th>
<th>导数</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sigmoid激活函数</td>
<td>$f(x)=\frac{1}{1+e^{-x}}$</td>
<td>$f^{‘}(x)=\frac{1}{1+e^{-x}}\left( 1- \frac{1}{1+e^{-x}} \right)=f(x)(1-f(x))$</td>
<td>当$x=10$,或$x=-10​$，$f^{‘}(x) \approx0​$,当$x=0​$$f^{‘}(x) =0.25​$</td>
</tr>
<tr>
<td>Tanh激活函数</td>
<td>$f(x)=tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}$</td>
<td>$f^{‘}(x)=-(tanh(x))^2$</td>
<td>当$x=10$,或$x=-10$，$f^{‘}(x) \approx0$,当$x=0$$f^{`}(x) =1$</td>
</tr>
<tr>
<td>Relu激活函数</td>
<td>$f(x)=max(0,x)$</td>
<td>$c(u)=\begin{cases} 0,x<0 \\ 1,x>0 \ undefined,x=0\end{cases}$</td>
<td>通常$x=0$时，给定其导数为1和0</td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-4-4-激活函数有哪些性质？"><a href="#3-4-4-激活函数有哪些性质？" class="headerlink" title="3.4.4 激活函数有哪些性质？"></a>3.4.4 激活函数有哪些性质？</h3><ol>
<li>非线性： 当激活函数是线性的，一个两层的神经网络就可以基本上逼近所有的函数。但如果激活函数是恒等激活函数的时候，即 $ f(x)=x $，就不满足这个性质，而且如果 MLP 使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的；</li>
<li>可微性： 当优化方法是基于梯度的时候，就体现了该性质；</li>
<li>单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数；</li>
<li>$ f(x)≈x $： 当激活函数满足这个性质的时候，如果参数的初始化是随机的较小值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要详细地去设置初始值；</li>
<li>输出值的范围： 当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的 Learning Rate。</li>
</ol>
<h3 id="3-4-5-如何选择激活函数？"><a href="#3-4-5-如何选择激活函数？" class="headerlink" title="3.4.5 如何选择激活函数？"></a>3.4.5 如何选择激活函数？</h3><p>​    选择一个适合的激活函数并不容易，需要考虑很多因素，通常的做法是，如果不确定哪一个激活函数效果更好，可以把它们都试试，然后在验证集或者测试集上进行评价。然后看哪一种表现的更好，就去使用它。</p>
<p>以下是常见的选择情况：</p>
<ol>
<li>如果输出是 0、1 值（二分类问题），则输出层选择 sigmoid 函数，然后其它的所有单元都选择 Relu 函数。</li>
<li>如果在隐藏层上不确定使用哪个激活函数，那么通常会使用 Relu 激活函数。有时，也会使用 tanh 激活函数，但 Relu 的一个优点是：当是负值的时候，导数等于 0。</li>
<li>sigmoid 激活函数：除了输出层是一个二分类问题基本不会用它。</li>
<li>tanh 激活函数：tanh 是非常优秀的，几乎适合所有场合。</li>
<li>ReLu 激活函数：最常用的默认函数，如果不确定用哪个激活函数，就使用 ReLu 或者 Leaky ReLu，再去尝试其他的激活函数。</li>
<li>如果遇到了一些死的神经元，我们可以使用 Leaky ReLU 函数。</li>
</ol>
<h3 id="3-4-6-使用-ReLu-激活函数的优点？"><a href="#3-4-6-使用-ReLu-激活函数的优点？" class="headerlink" title="3.4.6 使用 ReLu 激活函数的优点？"></a>3.4.6 使用 ReLu 激活函数的优点？</h3><ol>
<li>在区间变动很大的情况下，ReLu 激活函数的导数或者激活函数的斜率都会远大于 0，在程序实现就是一个 if-else 语句，而 sigmoid 函数需要进行浮点四则运算，在实践中，使用 ReLu 激活函数神经网络通常会比使用 sigmoid 或者 tanh 激活函数学习的更快。</li>
<li>sigmoid 和 tanh 函数的导数在正负饱和区的梯度都会接近于 0，这会造成梯度弥散，而 Relu 和Leaky ReLu 函数大于 0 部分都为常数，不会产生梯度弥散现象。</li>
<li>需注意，Relu 进入负半区的时候，梯度为 0，神经元此时不会训练，产生所谓的稀疏性，而 Leaky ReLu 不会产生这个问题。</li>
</ol>
<h3 id="3-4-7-什么时候可以用线性激活函数？"><a href="#3-4-7-什么时候可以用线性激活函数？" class="headerlink" title="3.4.7 什么时候可以用线性激活函数？"></a>3.4.7 什么时候可以用线性激活函数？</h3><ol>
<li>输出层，大多使用线性激活函数。</li>
<li>在隐含层可能会使用一些线性激活函数。</li>
<li>一般用到的线性激活函数很少。</li>
</ol>
<h3 id="3-4-8-怎样理解-Relu（-lt-0-时）是非线性激活函数？"><a href="#3-4-8-怎样理解-Relu（-lt-0-时）是非线性激活函数？" class="headerlink" title="3.4.8 怎样理解 Relu（&lt; 0 时）是非线性激活函数？"></a>3.4.8 怎样理解 Relu（&lt; 0 时）是非线性激活函数？</h3><p>Relu 激活函数图像如下：</p>
<p><img src="/img/ch3/3-32.png" alt=""></p>
<p>根据图像可看出具有如下特点：</p>
<ol>
<li><p>单侧抑制；</p>
</li>
<li><p>相对宽阔的兴奋边界；</p>
</li>
<li><p>稀疏激活性；</p>
<p>ReLU 函数从图像上看，是一个分段线性函数，把所有的负值都变为 0，而正值不变，这样就成为单侧抑制。</p>
<p>因为有了这单侧抑制，才使得神经网络中的神经元也具有了稀疏激活性。</p>
<p><strong>稀疏激活性</strong>：从信号方面来看，即神经元同时只对输入信号的少部分选择性响应，大量信号被刻意的屏蔽了，这样可以提高学习的精度，更好更快地提取稀疏特征。当 $ x<0 $ 时，ReLU 硬饱和，而当 $ x>0 $ 时，则不存在饱和问题。ReLU 能够在 $ x&gt;0 $ 时保持梯度不衰减，从而缓解梯度消失问题。</p>
</li>
</ol>
<h3 id="3-4-9-Softmax-定义及作用"><a href="#3-4-9-Softmax-定义及作用" class="headerlink" title="3.4.9 Softmax 定义及作用"></a>3.4.9 Softmax 定义及作用</h3><p>Softmax 是一种形如下式的函数：</p>
<script type="math/tex; mode=display">
P(i) = \frac{exp(\theta_i^T x)}{\sum_{k=1}^{K} exp(\theta_i^T x)}</script><p>​    其中，$ \theta_i $ 和 $ x $ 是列向量，$ \theta_i^T x $ 可能被换成函数关于 $ x $ 的函数 $ f_i(x) $</p>
<p>​    通过 softmax 函数，可以使得 $ P(i) $ 的范围在 $ [0,1] $ 之间。在回归和分类问题中，通常 $ \theta $ 是待求参数，通过寻找使得 $ P(i) $ 最大的 $ \theta_i $ 作为最佳参数。</p>
<p>​    但是，使得范围在 $ [0,1] $  之间的方法有很多，为啥要在前面加上以 $ e $ 的幂函数的形式呢？参考 logistic 函数：</p>
<script type="math/tex; mode=display">
P(i) = \frac{1}{1+exp(-\theta_i^T x)}</script><p>​    这个函数的作用就是使得 $ P(i) $ 在负无穷到 0 的区间趋向于 0， 在 0 到正无穷的区间趋向 1,。同样 softmax 函数加入了 $ e $ 的幂函数正是为了两极化：正样本的结果将趋近于 1，而负样本的结果趋近于 0。这样为多类别提供了方便（可以把 $ P(i) $ 看做是样本属于类别的概率）。可以说，Softmax 函数是 logistic 函数的一种泛化。</p>
<p>​    softmax 函数可以把它的输入，通常被称为 logits 或者 logit scores，处理成 0 到 1 之间，并且能够把输出归一化到和为 1。这意味着 softmax 函数与分类的概率分布等价。它是一个网络预测多酚类问题的最佳输出激活函数。</p>
<h3 id="3-4-10-Softmax-函数如何应用于多分类？"><a href="#3-4-10-Softmax-函数如何应用于多分类？" class="headerlink" title="3.4.10 Softmax 函数如何应用于多分类？"></a>3.4.10 Softmax 函数如何应用于多分类？</h3><p>​    softmax 用于多分类过程中，它将多个神经元的输出，映射到 $ (0,1) $ 区间内，可以看成概率来理解，从而来进行多分类！</p>
<p>​    假设我们有一个数组，$ V_i $ 表示 $ V $  中的第 $ i $ 个元素，那么这个元素的 softmax 值就是</p>
<script type="math/tex; mode=display">
S_i = \frac{e^{V_i}}{\sum_j e^{V_j}}</script><p>​    从下图看，神经网络中包含了输入层，然后通过两个特征层处理，最后通过 softmax 分析器就能得到不同条件下的概率，这里需要分成三个类别，最终会得到 $ y=0, y=1, y=2 $ 的概率值。</p>
<p><img src="/img/ch3/3.4.9.1.png" alt=""></p>
<p>继续看下面的图，三个输入通过 softmax 后得到一个数组 $ [0.05 , 0.10 , 0.85] $，这就是 soft 的功能。</p>
<p><img src="/img/ch3/3.4.9.2.png" alt=""></p>
<p>更形象的映射过程如下图所示：</p>
<p><img src="/img/ch3/3.4.9.3.png" alt="****"></p>
<p>​    softmax 直白来说就是将原来输出是 $ 3,1,-3 $ 通过 softmax 函数一作用，就映射成为 $ (0,1) $ 的值，而这些值的累和为 $ 1 $（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标！</p>
<h3 id="3-4-11-交叉熵代价函数定义及其求导推导"><a href="#3-4-11-交叉熵代价函数定义及其求导推导" class="headerlink" title="3.4.11 交叉熵代价函数定义及其求导推导"></a>3.4.11 交叉熵代价函数定义及其求导推导</h3><p>(<strong>贡献者：黄钦建－华南理工大学</strong>)</p>
<p>​    神经元的输出就是 a = σ(z)，其中$z=\sum w_{j}i_{j}+b$是输⼊的带权和。</p>
<p>$C=-\frac{1}{n}\sum[ylna+(1-y)ln(1-a)]$</p>
<p>​    其中 n 是训练数据的总数，求和是在所有的训练输⼊ x 上进⾏的， y 是对应的⽬标输出。</p>
<p>​    表达式是否解决学习缓慢的问题并不明显。实际上，甚⾄将这个定义看做是代价函数也不是显⽽易⻅的！在解决学习缓慢前，我们来看看交叉熵为何能够解释成⼀个代价函数。</p>
<p>​    将交叉熵看做是代价函数有两点原因。</p>
<p>​    第⼀，它是⾮负的， C &gt; 0。可以看出：式子中的求和中的所有独⽴的项都是负数的，因为对数函数的定义域是 (0，1)，并且求和前⾯有⼀个负号，所以结果是非负。</p>
<p>​    第⼆，如果对于所有的训练输⼊ x，神经元实际的输出接近⽬标值，那么交叉熵将接近 0。</p>
<p>​    假设在这个例⼦中， y = 0 ⽽ a ≈ 0。这是我们想到得到的结果。我们看到公式中第⼀个项就消去了，因为 y = 0，⽽第⼆项实际上就是 − ln(1 − a) ≈ 0。反之， y = 1 ⽽ a ≈ 1。所以在实际输出和⽬标输出之间的差距越⼩，最终的交叉熵的值就越低了。（这里假设输出结果不是0，就是1，实际分类也是这样的）</p>
<p>​    综上所述，交叉熵是⾮负的，在神经元达到很好的正确率的时候会接近 0。这些其实就是我们想要的代价函数的特性。其实这些特性也是⼆次代价函数具备的。所以，交叉熵就是很好的选择了。但是交叉熵代价函数有⼀个⽐⼆次代价函数更好的特性就是它避免了学习速度下降的问题。为了弄清楚这个情况，我们来算算交叉熵函数关于权重的偏导数。我们将$a={\varsigma}(z)$代⼊到 公式中应⽤两次链式法则，得到：</p>
<p>$\begin{eqnarray}\frac{\partial C}{\partial w_{j}}&amp;=&amp;-\frac{1}{n}\sum \frac{\partial }{\partial w_{j}}[ylna+(1-y)ln(1-a)]\\&amp;=&amp;-\frac{1}{n}\sum \frac{\partial }{\partial a}[ylna+(1-y)ln(1-a)]<em>\frac{\partial a}{\partial w_{j}}\\&amp;=&amp;-\frac{1}{n}\sum (\frac{y}{a}-\frac{1-y}{1-a})</em>\frac{\partial a}{\partial w_{j}}\\&amp;=&amp;-\frac{1}{n}\sum (\frac{y}{\varsigma(z)}-\frac{1-y}{1-\varsigma(z)})\frac{\partial \varsigma(z)}{\partial w_{j}}\\&amp;=&amp;-\frac{1}{n}\sum (\frac{y}{\varsigma(z)}-\frac{1-y}{1-\varsigma(z)}){\varsigma}’(z)x_{j}\end{eqnarray}$</p>
<p>​    根据$\varsigma(z)=\frac{1}{1+e^{-z}}$ 的定义，和⼀些运算，我们可以得到 ${\varsigma}’(z)=\varsigma(z)(1-\varsigma(z))$。化简后可得：</p>
<p>$\frac{\partial C}{\partial w_{j}}=\frac{1}{n}\sum x_{j}({\varsigma}(z)-y)$</p>
<p>​    这是⼀个优美的公式。它告诉我们权重学习的速度受到$\varsigma(z)-y$，也就是输出中的误差的控制。更⼤的误差，更快的学习速度。这是我们直觉上期待的结果。特别地，这个代价函数还避免了像在⼆次代价函数中类似⽅程中${\varsigma}’(z)$导致的学习缓慢。当我们使⽤交叉熵的时候，${\varsigma}’(z)$被约掉了，所以我们不再需要关⼼它是不是变得很⼩。这种约除就是交叉熵带来的特效。实际上，这也并不是⾮常奇迹的事情。我们在后⾯可以看到，交叉熵其实只是满⾜这种特性的⼀种选择罢了。</p>
<p>​    根据类似的⽅法，我们可以计算出关于偏置的偏导数。我这⾥不再给出详细的过程，你可以轻易验证得到：</p>
<p>$\frac{\partial C}{\partial b}=\frac{1}{n}\sum ({\varsigma}(z)-y)$</p>
<p>​    再⼀次, 这避免了⼆次代价函数中类似${\varsigma}’(z)$项导致的学习缓慢。</p>
<h3 id="3-4-12-为什么Tanh收敛速度比Sigmoid快？"><a href="#3-4-12-为什么Tanh收敛速度比Sigmoid快？" class="headerlink" title="3.4.12 为什么Tanh收敛速度比Sigmoid快？"></a>3.4.12 为什么Tanh收敛速度比Sigmoid快？</h3><p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<p>首先看如下两个函数的求导：</p>
<p>$tanh^{,}(x)=1-tanh(x)^{2}\in (0,1)$</p>
<p>$s^{,}(x)=s(x)*(1-s(x))\in (0,\frac{1}{4}]$</p>
<p>由上面两个公式可知tanh(x)梯度消失的问题比sigmoid轻，所以Tanh收敛速度比Sigmoid快。</p>
<p>3.4.13</p>
<h3 id="3-4-12-内聚外斥-Center-Loss"><a href="#3-4-12-内聚外斥-Center-Loss" class="headerlink" title="3.4.12 内聚外斥 - Center Loss"></a>3.4.12 内聚外斥 - Center Loss</h3><p><strong>（贡献者：李世轩－加州大学伯克利分校）</strong></p>
<p>在计算机视觉任务中, 由于其简易性, 良好的表现, 与对分类任务的概率性理解, Cross Entropy Loss (交叉熵代价) + Softmax 组合被广泛应用于以分类任务为代表的任务中. 在此应用下, 我们可将其学习过程进一步理解为: 更相似(同类/同物体)的图像在特征域中拥有“更近的距离”, 相反则”距离更远“. 换而言之, 我们可以进一步理解为其学习了一种低类内距离(Intra-class Distance)与高类间距离(Inter-class Distance)的特征判别模型. 在此Center Loss则可以高效的计算出这种具判别性的特征. 不同于传统的Softmax Loss, Center Loss通过学习“特征中心”从而最小化其类内距离. 其表达形式如下:</p>
<p>$L_{C} = \frac{1}{2}\sum^{m}_{i=1}||x_{i}-c_{y_{i}}||^{2}_{2}$</p>
<p>其中$x_{i}$表示FCN(全连接层)之前的特征, $c_{y_{i}}$表示第$y_{i} $个类别的特征中心, $m$表示mini-batch的大小. 我们很清楚的看到$L_{C}$的终极目标为最小化每个特征与其特征中心的方差, 即最小化类内距离. 其迭代公式为:</p>
<p>$\frac{\partial L_{C}}{\partial x_{i}}=x_{i}-c_{y_{i}}$</p>
<p>$\Delta{c_{j}} = \frac{\sum^{m}_{i=1}\delta(y_{i}=j)\cdot(c_{j}-x_{i})}{1+\sum^{m}_{i=1}\delta(y_{i}=j)}$</p>
<p>其中$ \delta(condition)=\left\{<br>\begin{array}{rcl}<br>1       &amp;      &amp; {condition is True}\\<br>0     &amp;      &amp; {otherwise}\ \end{array} \right.$</p>
<p>结合Softmax, 我们可以搭配二者使用, 适当平衡这两种监督信号. 在Softmax拉开类间距离的同时, 利用Center Loss最小化类内距离. 例如:</p>
<p>$\begin{eqnarray}L &amp; = &amp; L_{S} + \lambda L_{C} \ &amp;=&amp; -\sum^{m}_{i=1}log\frac{e^{W_{y}^{T}x_{i}+b_{y_{i}}}}{\sum^{m}_{i=1}e^{W^{T}_{j}x_{i}+b_{j}}} + \frac{\lambda}{2}\sum^{m}_{i=1}||x_{i}-c_{y_{i}}||^{2}_{2}\ \end{eqnarray}$</p>
<p>即便如此, Center Loss仍有它的不足之处: 其特征中心为存储在网络模型之外的额外参数, 不能与模型参数一同优化. 这些额外参数将与记录每一步特征变化的自动回归均值估计(autoregressive mean estimator)进行更迭. 当需要学习的类别数量较大时, mini-batch可能无力提供足够的样本进行均值估计. 若此Center Loss将需要平衡两种监督损失来以确定更迭, 其过程需要一个对平衡超参数的搜索过程, 使得其择值消耗昂贵.</p>
<h2 id="3-5-Batch-Size"><a href="#3-5-Batch-Size" class="headerlink" title="3.5 Batch_Size"></a>3.5 Batch_Size</h2><h3 id="3-5-1-为什么需要-Batch-Size？"><a href="#3-5-1-为什么需要-Batch-Size？" class="headerlink" title="3.5.1 为什么需要 Batch_Size？"></a>3.5.1 为什么需要 Batch_Size？</h3><p>Batch的选择，首先决定的是下降的方向。</p>
<p>如果数据集比较小，可采用全数据集的形式，好处是：</p>
<ol>
<li>由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。</li>
<li>由于不同权重的梯度值差别巨大，因此选取一个全局的学习率很困难。 Full Batch Learning 可以使用 Rprop 只基于梯度符号并且针对性单独更新各权值。</li>
</ol>
<p>对于更大的数据集，假如采用全数据集的形式，坏处是：</p>
<ol>
<li>随着数据集的海量增长和内存限制，一次性载入所有的数据进来变得越来越不可行。</li>
<li>以 Rprop 的方式迭代，会由于各个 Batch 之间的采样差异性，各次梯度修正值相互抵消，无法修正。这才有了后来 RMSProp 的妥协方案。 </li>
</ol>
<h3 id="3-5-2-Batch-Size-值的选择"><a href="#3-5-2-Batch-Size-值的选择" class="headerlink" title="3.5.2 Batch_Size 值的选择"></a>3.5.2 Batch_Size 值的选择</h3><p>​    假如每次只训练一个样本，即 Batch_Size = 1。线性神经元在均方误差代价函数的错误面是一个抛物面，横截面是椭圆。对于多层神经元、非线性网络，在局部依然近似是抛物面。此时，每次修正方向以各自样本的梯度方向修正，横冲直撞各自为政，难以达到收敛。</p>
<p>​    既然 Batch_Size 为全数据集或者Batch_Size = 1都有各自缺点，可不可以选择一个适中的Batch_Size值呢？</p>
<p>​    此时，可采用批梯度下降法（Mini-batches Learning）。因为如果数据集足够充分，那么用一半（甚至少得多）的数据训练算出来的梯度与用全部数据训练出来的梯度是几乎一样的。</p>
<h3 id="3-5-3-在合理范围内，增大Batch-Size有何好处？"><a href="#3-5-3-在合理范围内，增大Batch-Size有何好处？" class="headerlink" title="3.5.3 在合理范围内，增大Batch_Size有何好处？"></a>3.5.3 在合理范围内，增大Batch_Size有何好处？</h3><ol>
<li>内存利用率提高了，大矩阵乘法的并行化效率提高。</li>
<li>跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。</li>
<li>在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。</li>
</ol>
<h3 id="3-5-4-盲目增大-Batch-Size-有何坏处？"><a href="#3-5-4-盲目增大-Batch-Size-有何坏处？" class="headerlink" title="3.5.4 盲目增大 Batch_Size 有何坏处？"></a>3.5.4 盲目增大 Batch_Size 有何坏处？</h3><ol>
<li>内存利用率提高了，但是内存容量可能撑不住了。</li>
<li>跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。</li>
<li>Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。</li>
</ol>
<h3 id="3-5-5-调节-Batch-Size-对训练效果影响到底如何？"><a href="#3-5-5-调节-Batch-Size-对训练效果影响到底如何？" class="headerlink" title="3.5.5 调节 Batch_Size 对训练效果影响到底如何？"></a>3.5.5 调节 Batch_Size 对训练效果影响到底如何？</h3><ol>
<li>Batch_Size 太小，模型表现效果极其糟糕(error飙升)。</li>
<li>随着 Batch_Size 增大，处理相同数据量的速度越快。</li>
<li>随着 Batch_Size 增大，达到相同精度所需要的 epoch 数量越来越多。</li>
<li>由于上述两种因素的矛盾， Batch_Size 增大到某个时候，达到时间上的最优。</li>
<li>由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到某些时候，达到最终收敛精度上的最优。 </li>
</ol>
<h2 id="3-6-归一化"><a href="#3-6-归一化" class="headerlink" title="3.6 归一化"></a>3.6 归一化</h2><h3 id="3-6-1-归一化含义？"><a href="#3-6-1-归一化含义？" class="headerlink" title="3.6.1 归一化含义？"></a>3.6.1 归一化含义？</h3><ol>
<li><p>归纳统一样本的统计分布性。归一化在 $ 0-1$ 之间是统计的概率分布，归一化在$ -1—+1$ 之间是统计的坐标分布。</p>
</li>
<li><p>无论是为了建模还是为了计算，首先基本度量单位要同一，神经网络是以样本在事件中的统计分别几率来进行训练（概率计算）和预测，且 sigmoid 函数的取值是 0 到 1 之间的，网络最后一个节点的输出也是如此，所以经常要对样本的输出归一化处理。</p>
</li>
<li><p>归一化是统一在 $ 0-1 $ 之间的统计概率分布，当所有样本的输入信号都为正值时，与第一隐含层神经元相连的权值只能同时增加或减小，从而导致学习速度很慢。</p>
</li>
<li><p>另外在数据中常存在奇异样本数据，奇异样本数据存在所引起的网络训练时间增加，并可能引起网络无法收敛。为了避免出现这种情况及后面数据处理的方便，加快网络学习速度，可以对输入信号进行归一化，使得所有样本的输入信号其均值接近于 0 或与其均方差相比很小。</p>
</li>
</ol>
<h3 id="3-6-2-为什么要归一化？"><a href="#3-6-2-为什么要归一化？" class="headerlink" title="3.6.2 为什么要归一化？"></a>3.6.2 为什么要归一化？</h3><ol>
<li>为了后面数据处理的方便，归一化的确可以避免一些不必要的数值问题。</li>
<li>为了程序运行时收敛加快。 </li>
<li>同一量纲。样本数据的评价标准不一样，需要对其量纲化，统一评价标准。这算是应用层面的需求。</li>
<li>避免神经元饱和。啥意思？就是当神经元的激活在接近 0 或者 1 时会饱和，在这些区域，梯度几乎为 0，这样，在反向传播过程中，局部梯度就会接近 0，这会有效地“杀死”梯度。</li>
<li>保证输出数据中数值小的不被吞食。 </li>
</ol>
<h3 id="3-6-3-为什么归一化能提高求解最优解速度？"><a href="#3-6-3-为什么归一化能提高求解最优解速度？" class="headerlink" title="3.6.3 为什么归一化能提高求解最优解速度？"></a>3.6.3 为什么归一化能提高求解最优解速度？</h3><p><img src="/img/ch3/3.6.3.1.png" alt=""></p>
<p>​    上图是代表数据是否均一化的最优解寻解过程（圆圈可以理解为等高线）。左图表示未经归一化操作的寻解过程，右图表示经过归一化后的寻解过程。</p>
<p>​    当使用梯度下降法寻求最优解时，很有可能走“之字型”路线（垂直等高线走），从而导致需要迭代很多次才能收敛；而右图对两个原始特征进行了归一化，其对应的等高线显得很圆，在梯度下降进行求解时能较快的收敛。</p>
<p>​    因此如果机器学习模型使用梯度下降法求最优解时，归一化往往非常有必要，否则很难收敛甚至不能收敛。</p>
<h3 id="3-6-4-3D-图解未归一化"><a href="#3-6-4-3D-图解未归一化" class="headerlink" title="3.6.4 3D 图解未归一化"></a>3.6.4 3D 图解未归一化</h3><p>例子：</p>
<p>​    假设 $ w1 $ 的范围在 $ [-10, 10] $，而 $ w2 $ 的范围在 $ [-100, 100] $，梯度每次都前进 1 单位，那么在 $ w1 $ 方向上每次相当于前进了 $ 1/20 $，而在 $ w2 $ 上只相当于 $ 1/200 $！某种意义上来说，在 $ w2 $ 上前进的步长更小一些,而 $ w1 $ 在搜索过程中会比 $ w2 $ “走”得更快。</p>
<p>​    这样会导致，在搜索过程中更偏向于 $ w1 $ 的方向。走出了“L”形状，或者成为“之”字形。</p>
<p><img src="/img/ch3/3-37.png" alt=""></p>
<h3 id="3-6-5-归一化有哪些类型？"><a href="#3-6-5-归一化有哪些类型？" class="headerlink" title="3.6.5 归一化有哪些类型？"></a>3.6.5 归一化有哪些类型？</h3><ol>
<li>线性归一化</li>
</ol>
<script type="math/tex; mode=display">
x^{\prime} = \frac{x-min(x)}{max(x) - min(x)}</script><p>​    适用范围：比较适用在数值比较集中的情况。</p>
<p>​    缺点：如果 max 和 min 不稳定，很容易使得归一化结果不稳定，使得后续使用效果也不稳定。</p>
<ol>
<li>标准差标准化</li>
</ol>
<script type="math/tex; mode=display">
x^{\prime} = \frac{x-\mu}{\sigma}</script><p>​    含义：经过处理的数据符合标准正态分布，即均值为 0，标准差为 1 其中 $ \mu $ 为所有样本数据的均值，$ \sigma $ 为所有样本数据的标准差。</p>
<ol>
<li><p>非线性归一化</p>
<p>适用范围：经常用在数据分化比较大的场景，有些数值很大，有些很小。通过一些数学函数，将原始值进行映射。该方法包括 $ log $、指数，正切等。</p>
</li>
</ol>
<h3 id="3-6-6-局部响应归一化作用"><a href="#3-6-6-局部响应归一化作用" class="headerlink" title="3.6.6 局部响应归一化作用"></a>3.6.6 局部响应归一化作用</h3><p>​    LRN 是一种提高深度学习准确度的技术方法。LRN 一般是在激活、池化函数后的一种方法。</p>
<p>​    在 ALexNet 中，提出了 LRN 层，对局部神经元的活动创建竞争机制，使其中响应比较大对值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。</p>
<h3 id="3-6-7-理解局部响应归一化"><a href="#3-6-7-理解局部响应归一化" class="headerlink" title="3.6.7 理解局部响应归一化"></a>3.6.7 理解局部响应归一化</h3><p>​    局部响应归一化原理是仿造生物学上活跃的神经元对相邻神经元的抑制现象（侧抑制），其公式如下：</p>
<script type="math/tex; mode=display">
b_{x,y}^i = a_{x,y}^i / (k + \alpha \sum_{j=max(0, i-n/2)}^{min(N-1, i+n/2)}(a_{x,y}^j)^2 )^\beta</script><p>其中，<br>1) $ a $：表示卷积层（包括卷积操作和池化操作）后的输出结果，是一个四维数组[batch,height,width,channel]。</p>
<ul>
<li>batch：批次数(每一批为一张图片)。</li>
<li>height：图片高度。</li>
<li>width：图片宽度。</li>
<li>channel：通道数。可以理解成一批图片中的某一个图片经过卷积操作后输出的神经元个数，或理解为处理后的图片深度。</li>
</ul>
<p>2) $ a_{x,y}^i $ 表示在这个输出结构中的一个位置 $ [a,b,c,d] $，可以理解成在某一张图中的某一个通道下的某个高度和某个宽度位置的点，即第 $ a $ 张图的第 $ d $ 个通道下的高度为b宽度为c的点。</p>
<p>3) $ N $：论文公式中的 $ N $ 表示通道数 (channel)。</p>
<p>4) $ a $，$ n/2 $， $ k $ 分别表示函数中的 input,depth_radius,bias。参数 $ k, n, \alpha, \beta $ 都是超参数，一般设置 $ k=2, n=5, \alpha=1*e-4, \beta=0.75 $</p>
<p>5) $ \sum $：$ \sum $ 叠加的方向是沿着通道方向的，即每个点值的平方和是沿着 $ a $ 中的第 3 维 channel 方向的，也就是一个点同方向的前面 $ n/2 $ 个通道（最小为第 $ 0 $ 个通道）和后 $ n/2 $ 个通道（最大为第 $ d-1 $ 个通道）的点的平方和(共 $ n+1 $ 个点)。而函数的英文注解中也说明了把 input 当成是 $ d $ 个 3 维的矩阵，说白了就是把 input 的通道数当作 3 维矩阵的个数，叠加的方向也是在通道方向。 </p>
<p>简单的示意图如下：</p>
<p><img src="/img/ch3/3.6.7.1.png" alt=""></p>
<h3 id="3-6-8-什么是批归一化（Batch-Normalization）"><a href="#3-6-8-什么是批归一化（Batch-Normalization）" class="headerlink" title="3.6.8 什么是批归一化（Batch Normalization）"></a>3.6.8 什么是批归一化（Batch Normalization）</h3><p>​    以前在神经网络训练中，只是对输入层数据进行归一化处理，却没有在中间层进行归一化处理。要知道，虽然我们对输入数据进行了归一化处理，但是输入数据经过 $ \sigma(WX+b) $ 这样的矩阵乘法以及非线性运算之后，其数据分布很可能被改变，而随着深度网络的多层运算之后，数据分布的变化将越来越大。如果我们能在网络的中间也进行归一化处理，是否对网络的训练起到改进作用呢？答案是肯定的。 </p>
<p>​    这种在神经网络中间层也进行归一化处理，使训练效果更好的方法，就是批归一化Batch Normalization（BN）。</p>
<h3 id="3-6-9-批归一化（BN）算法的优点"><a href="#3-6-9-批归一化（BN）算法的优点" class="headerlink" title="3.6.9 批归一化（BN）算法的优点"></a>3.6.9 批归一化（BN）算法的优点</h3><p>下面我们来说一下BN算法的优点： </p>
<ol>
<li>减少了人为选择参数。在某些情况下可以取消 dropout 和 L2 正则项参数,或者采取更小的 L2 正则项约束参数； </li>
<li>减少了对学习率的要求。现在我们可以使用初始很大的学习率或者选择了较小的学习率，算法也能够快速训练收敛； </li>
<li>可以不再使用局部响应归一化。BN 本身就是归一化网络(局部响应归一化在 AlexNet 网络中存在) </li>
<li>破坏原来的数据分布，一定程度上缓解过拟合（防止每批训练中某一个样本经常被挑选到，文献说这个可以提高 1% 的精度）。 </li>
<li>减少梯度消失，加快收敛速度，提高训练精度。</li>
</ol>
<h3 id="3-6-10-批归一化（BN）算法流程"><a href="#3-6-10-批归一化（BN）算法流程" class="headerlink" title="3.6.10 批归一化（BN）算法流程"></a>3.6.10 批归一化（BN）算法流程</h3><p>下面给出 BN 算法在训练时的过程</p>
<p>输入：上一层输出结果 $ X = {x_1, x_2, …, x_m} $，学习参数 $ \gamma, \beta $</p>
<p>算法流程：</p>
<ol>
<li>计算上一层输出数据的均值</li>
</ol>
<script type="math/tex; mode=display">
\mu_{\beta} = \frac{1}{m} \sum_{i=1}^m(x_i)</script><p>其中，$ m $ 是此次训练样本 batch 的大小。</p>
<ol>
<li>计算上一层输出数据的标准差</li>
</ol>
<script type="math/tex; mode=display">
\sigma_{\beta}^2 = \frac{1}{m} \sum_{i=1}^m (x_i - \mu_{\beta})^2</script><ol>
<li>归一化处理，得到</li>
</ol>
<script type="math/tex; mode=display">
\hat x_i = \frac{x_i + \mu_{\beta}}{\sqrt{\sigma_{\beta}^2} + \epsilon}</script><p>其中 $ \epsilon $ 是为了避免分母为 0 而加进去的接近于 0 的很小值</p>
<ol>
<li>重构，对经过上面归一化处理得到的数据进行重构，得到</li>
</ol>
<script type="math/tex; mode=display">
y_i = \gamma \hat x_i + \beta</script><p>其中，$ \gamma, \beta $ 为可学习参数。</p>
<p>注：上述是 BN 训练时的过程，但是当在投入使用时，往往只是输入一个样本，没有所谓的均值 $ \mu_{\beta} $ 和标准差 $ \sigma_{\beta}^2 $。此时，均值 $ \mu_{\beta} $ 是计算所有 batch $ \mu_{\beta} $ 值的平均值得到，标准差 $ \sigma_{\beta}^2 $ 采用每个batch $ \sigma_{\beta}^2 $  的无偏估计得到。</p>
<h3 id="3-6-11-批归一化和群组归一化比较"><a href="#3-6-11-批归一化和群组归一化比较" class="headerlink" title="3.6.11 批归一化和群组归一化比较"></a>3.6.11 批归一化和群组归一化比较</h3><div class="table-container">
<table>
<thead>
<tr>
<th>名称</th>
<th style="text-align:left">特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>批量归一化（Batch Normalization，以下简称 BN）</td>
<td style="text-align:left">可让各种网络并行训练。但是，批量维度进行归一化会带来一些问题——批量统计估算不准确导致批量变小时，BN 的误差会迅速增加。在训练大型网络和将特征转移到计算机视觉任务中（包括检测、分割和视频），内存消耗限制了只能使用小批量的 BN。</td>
</tr>
<tr>
<td>群组归一化 Group Normalization (简称 GN)</td>
<td style="text-align:left">GN 将通道分成组，并在每组内计算归一化的均值和方差。GN 的计算与批量大小无关，并且其准确度在各种批量大小下都很稳定。</td>
</tr>
<tr>
<td>比较</td>
<td style="text-align:left">在 ImageNet 上训练的 ResNet-50上，GN 使用批量大小为 2 时的错误率比 BN 的错误率低 10.6％ ;当使用典型的批量时，GN 与 BN 相当，并且优于其他标归一化变体。而且，GN 可以自然地从预训练迁移到微调。在进行 COCO 中的目标检测和分割以及 Kinetics 中的视频分类比赛中，GN 可以胜过其竞争对手，表明 GN 可以在各种任务中有效地取代强大的 BN。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-6-12-Weight-Normalization和Batch-Normalization比较"><a href="#3-6-12-Weight-Normalization和Batch-Normalization比较" class="headerlink" title="3.6.12 Weight Normalization和Batch Normalization比较"></a>3.6.12 Weight Normalization和Batch Normalization比较</h3><p>​    Weight Normalization 和 Batch Normalization 都属于参数重写（Reparameterization）的方法，只是采用的方式不同。</p>
<p>​    Weight Normalization 是对网络权值$  W $ 进行 normalization，因此也称为 Weight Normalization；</p>
<p>​    Batch Normalization 是对网络某一层输入数据进行 normalization。</p>
<p>​    Weight Normalization相比Batch Normalization有以下三点优势：</p>
<ol>
<li><p>Weight Normalization 通过重写深度学习网络的权重W的方式来加速深度学习网络参数收敛，没有引入 minbatch 的依赖，适用于 RNN（LSTM）网络（Batch Normalization 不能直接用于RNN，进行 normalization 操作，原因在于：1) RNN 处理的 Sequence 是变长的；2) RNN 是基于 time step 计算，如果直接使用 Batch Normalization 处理，需要保存每个 time step 下，mini btach 的均值和方差，效率低且占内存）。</p>
</li>
<li><p>Batch Normalization 基于一个 mini batch 的数据计算均值和方差，而不是基于整个 Training set 来做，相当于进行梯度计算式引入噪声。因此，Batch Normalization 不适用于对噪声敏感的强化学习、生成模型（Generative model：GAN，VAE）使用。相反，Weight Normalization 对通过标量 $ g $ 和向量 $ v $ 对权重 $ W $ 进行重写，重写向量 $ v $ 是固定的，因此，基于 Weight Normalization 的 Normalization 可以看做比 Batch Normalization 引入更少的噪声。    </p>
</li>
<li><p>不需要额外的存储空间来保存 mini batch 的均值和方差，同时实现 Weight Normalization 时，对深度学习网络进行正向信号传播和反向梯度计算带来的额外计算开销也很小。因此，要比采用 Batch Normalization 进行 normalization 操作时，速度快。  但是 Weight Normalization 不具备 Batch Normalization 把网络每一层的输出 Y 固定在一个变化范围的作用。因此，采用 Weight Normalization 进行 Normalization 时需要特别注意参数初始值的选择。</p>
</li>
</ol>
<h3 id="3-6-13-Batch-Normalization在什么时候用比较合适？"><a href="#3-6-13-Batch-Normalization在什么时候用比较合适？" class="headerlink" title="3.6.13 Batch Normalization在什么时候用比较合适？"></a>3.6.13 Batch Normalization在什么时候用比较合适？</h3><p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<p>​    在CNN中，BN应作用在非线性映射前。在神经网络训练时遇到收敛速度很慢，或梯度爆炸等无法训练的状况时可以尝试BN来解决。另外，在一般使用情况下也可以加入BN来加快训练速度，提高模型精度。</p>
<p>​    BN比较适用的场景是：每个mini-batch比较大，数据分布比较接近。在进行训练之前，要做好充分的shuffle，否则效果会差很多。另外，由于BN需要在运行过程中统计每个mini-batch的一阶统计量和二阶统计量，因此不适用于动态的网络结构和RNN网络。</p>
<h2 id="3-7-预训练与微调-fine-tuning"><a href="#3-7-预训练与微调-fine-tuning" class="headerlink" title="3.7 预训练与微调(fine tuning)"></a>3.7 预训练与微调(fine tuning)</h2><h3 id="3-7-1-为什么无监督预训练可以帮助深度学习？"><a href="#3-7-1-为什么无监督预训练可以帮助深度学习？" class="headerlink" title="3.7.1 为什么无监督预训练可以帮助深度学习？"></a>3.7.1 为什么无监督预训练可以帮助深度学习？</h3><p>深度网络存在问题:</p>
<ol>
<li><p>网络越深，需要的训练样本数越多。若用监督则需大量标注样本，不然小规模样本容易造成过拟合。深层网络特征比较多，会出现的多特征问题主要有多样本问题、规则化问题、特征选择问题。</p>
</li>
<li><p>多层神经网络参数优化是个高阶非凸优化问题，经常得到收敛较差的局部解；</p>
</li>
<li><p>梯度扩散问题，BP算法计算出的梯度随着深度向前而显著下降，导致前面网络参数贡献很小，更新速度慢。</p>
</li>
</ol>
<p><strong>解决方法：</strong></p>
<p>​    逐层贪婪训练，无监督预训练（unsupervised pre-training）即训练网络的第一个隐藏层，再训练第二个…最后用这些训练好的网络参数值作为整体网络参数的初始值。</p>
<p>经过预训练最终能得到比较好的局部最优解。</p>
<h3 id="3-7-2-什么是模型微调fine-tuning"><a href="#3-7-2-什么是模型微调fine-tuning" class="headerlink" title="3.7.2 什么是模型微调fine tuning"></a>3.7.2 什么是模型微调fine tuning</h3><p>​    用别人的参数、修改后的网络和自己的数据进行训练，使得参数适应自己的数据，这样一个过程，通常称之为微调（fine tuning). </p>
<p><strong>模型的微调举例说明：</strong></p>
<p>​    我们知道，CNN 在图像识别这一领域取得了巨大的进步。如果想将 CNN 应用到我们自己的数据集上，这时通常就会面临一个问题：通常我们的 dataset 都不会特别大，一般不会超过 1 万张，甚至更少，每一类图片只有几十或者十几张。这时候，直接应用这些数据训练一个网络的想法就不可行了，因为深度学习成功的一个关键性因素就是大量带标签数据组成的训练集。如果只利用手头上这点数据，即使我们利用非常好的网络结构，也达不到很高的 performance。这时候，fine-tuning 的思想就可以很好解决我们的问题：我们通过对 ImageNet 上训练出来的模型（如CaffeNet,VGGNet,ResNet) 进行微调，然后应用到我们自己的数据集上。</p>
<h3 id="3-7-3-微调时候网络参数是否更新？"><a href="#3-7-3-微调时候网络参数是否更新？" class="headerlink" title="3.7.3 微调时候网络参数是否更新？"></a>3.7.3 微调时候网络参数是否更新？</h3><p>答案：会更新。</p>
<ol>
<li>finetune 的过程相当于继续训练，跟直接训练的区别是初始化的时候。 </li>
<li>直接训练是按照网络定义指定的方式初始化。</li>
<li>finetune是用你已经有的参数文件来初始化。</li>
</ol>
<h3 id="3-7-4-fine-tuning-模型的三种状态"><a href="#3-7-4-fine-tuning-模型的三种状态" class="headerlink" title="3.7.4 fine-tuning 模型的三种状态"></a>3.7.4 fine-tuning 模型的三种状态</h3><ol>
<li><p>状态一：只预测，不训练。<br>特点：相对快、简单，针对那些已经训练好，现在要实际对未知数据进行标注的项目，非常高效；</p>
</li>
<li><p>状态二：训练，但只训练最后分类层。<br>特点：fine-tuning的模型最终的分类以及符合要求，现在只是在他们的基础上进行类别降维。</p>
</li>
<li><p>状态三：完全训练，分类层+之前卷积层都训练<br>特点：跟状态二的差异很小，当然状态三比较耗时和需要训练GPU资源，不过非常适合fine-tuning到自己想要的模型里面，预测精度相比状态二也提高不少。</p>
</li>
</ol>
<h2 id="3-8-权重偏差初始化"><a href="#3-8-权重偏差初始化" class="headerlink" title="3.8 权重偏差初始化"></a>3.8 权重偏差初始化</h2><h3 id="3-8-1-全都初始化为-0"><a href="#3-8-1-全都初始化为-0" class="headerlink" title="3.8.1 全都初始化为 0"></a>3.8.1 全都初始化为 0</h3><p><strong>偏差初始化陷阱</strong>： 都初始化为 0。</p>
<p><strong>产生陷阱原因</strong>：因为并不知道在训练神经网络中每一个权重最后的值，但是如果进行了恰当的数据归一化后，我们可以有理由认为有一半的权重是正的，另一半是负的。令所有权重都初始化为 0，如果神经网络计算出来的输出值是一样的，神经网络在进行反向传播算法计算出来的梯度值也一样，并且参数更新值也一样。更一般地说，如果权重初始化为同一个值，网络就是对称的。</p>
<p><strong>形象化理解</strong>：在神经网络中考虑梯度下降的时候，设想你在爬山，但身处直线形的山谷中，两边是对称的山峰。由于对称性，你所在之处的梯度只能沿着山谷的方向，不会指向山峰；你走了一步之后，情况依然不变。结果就是你只能收敛到山谷中的一个极大值，而走不到山峰上去。</p>
<h3 id="3-8-2-全都初始化为同样的值"><a href="#3-8-2-全都初始化为同样的值" class="headerlink" title="3.8.2 全都初始化为同样的值"></a>3.8.2 全都初始化为同样的值</h3><p>​    偏差初始化陷阱： 都初始化为一样的值。<br>​    以一个三层网络为例：<br>首先看下结构</p>
<p><img src="/img/ch3/3.8.2.1.png" alt=""></p>
<p>它的表达式为： </p>
<script type="math/tex; mode=display">
a_1^{(2)} = f(W_{11}^{(1)} x_1 + W_{12}^{(1)} x_2 + W_{13}^{(1)} x_3 + b_1^{(1)})</script><script type="math/tex; mode=display">
a_2^{(2)} = f(W_{21}^{(1)} x_1 + W_{22}^{(1)} x_2 + W_{23}^{(1)} x_3 + b_2^{(1)})</script><script type="math/tex; mode=display">
a_3^{(2)} = f(W_{31}^{(1)} x_1 + W_{32}^{(1)} x_2 + W_{33}^{(1)} x_3 + b_3^{(1)})</script><script type="math/tex; mode=display">
h_{W,b}(x) = a_1^{(3)} = f(W_{11}^{(2)} a_1^{(2)} + W_{12}^{(2)} a_2^{(2)} + W_{13}^{(2)} a_3^{(2)} + b_1^{(2)})</script><script type="math/tex; mode=display">
xa_1^{(2)} = f(W_{11}^{(1)} x_1 + W_{12}^{(1)} x_2 + W_{13}^{(1)} x_3 + b_1^{(1)})a_2^{(2)} = f(W_{21}^{(1)} x_1 + W_{22}^{(1)} x_2 + W_{23}^{(1)} x_3 +</script><p>如果每个权重都一样，那么在多层网络中，从第二层开始，每一层的输入值都是相同的了也就是$ a1=a2=a3=…. $，既然都一样，就相当于一个输入了，为啥呢？？</p>
<p>如果是反向传递算法（如果这里不明白请看上面的连接），其中的偏置项和权重项的迭代的偏导数计算公式如下</p>
<script type="math/tex; mode=display">
\frac{\partial}{\partial W_{ij}^{(l)}} J(W,b;x,y) = a_j^{(l)} \delta_i^{(l+1)}

\frac{\partial}{\partial b_{i}^{(l)}} J(W,b;x,y) = \delta_i^{(l+1)}</script><p>$ \delta $ 的计算公式</p>
<script type="math/tex; mode=display">
\delta_i^{(l)} = (\sum_{j=1}^{s_{t+1}} W_{ji}^{(l)} \delta_j^{(l+1)} ) f^{\prime}(z_i^{(l)})</script><p>如果用的是 sigmoid 函数</p>
<script type="math/tex; mode=display">
f^{\prime}(z_i^{(l)}) = a_i^{(l)}(1-a_i^{(l)})</script><p>把后两个公式代入，可以看出所得到的梯度下降法的偏导相同，不停的迭代，不停的相同，不停的迭代，不停的相同……，最后就得到了相同的值（权重和截距）。</p>
<h3 id="3-8-3-初始化为小的随机数"><a href="#3-8-3-初始化为小的随机数" class="headerlink" title="3.8.3 初始化为小的随机数"></a>3.8.3 初始化为小的随机数</h3><p>​    将权重初始化为很小的数字是一个普遍的打破网络对称性的解决办法。这个想法是，神经元在一开始都是随机的、独一无二的，所以它们会计算出不同的更新，并将自己整合到整个网络的各个部分。一个权重矩阵的实现可能看起来像 $ W=0.01∗np.random.randn(D,H) $，其中 randn 是从均值为 0 的单位标准高斯分布进行取样。通过这个公式(函数)，每个神经元的权重向量初始化为一个从多维高斯分布取样的随机向量，所以神经元在输入空间中指向随机的方向(so the neurons point in random direction in the input space). 应该是指输入空间对于随机方向有影响)。其实也可以从均匀分布中来随机选取小数，但是在实际操作中看起来似乎对最后的表现并没有太大的影响。</p>
<p>​    备注：并不是数字越小就会表现的越好。比如，如果一个神经网络层的权重非常小，那么在反向传播算法就会计算出很小的梯度(因为梯度 gradient 是与权重成正比的)。在网络不断的反向传播过程中将极大地减少“梯度信号”，并可能成为深层网络的一个需要注意的问题。</p>
<h3 id="3-8-4-用-1-sqrt-n-校准方差"><a href="#3-8-4-用-1-sqrt-n-校准方差" class="headerlink" title="3.8.4 用 $ 1/\sqrt n $ 校准方差"></a>3.8.4 用 $ 1/\sqrt n $ 校准方差</h3><p>​    上述建议的一个问题是，随机初始化神经元的输出的分布有一个随输入量增加而变化的方差。结果证明，我们可以通过将其权重向量按其输入的平方根(即输入的数量)进行缩放，从而将每个神经元的输出的方差标准化到 1。也就是说推荐的启发式方法 (heuristic) 是将每个神经元的权重向量按下面的方法进行初始化: $ w=np.random.randn(n)/\sqrt n $，其中 n 表示输入的数量。这保证了网络中所有的神经元最初的输出分布大致相同，并在经验上提高了收敛速度。</p>
<h3 id="3-8-5-稀疏初始化-Sparse-Initialazation"><a href="#3-8-5-稀疏初始化-Sparse-Initialazation" class="headerlink" title="3.8.5 稀疏初始化(Sparse Initialazation)"></a>3.8.5 稀疏初始化(Sparse Initialazation)</h3><p>​    另一种解决未校准方差问题的方法是把所有的权重矩阵都设为零，但是为了打破对称性，每个神经元都是随机连接地(从如上面所介绍的一个小的高斯分布中抽取权重)到它下面的一个固定数量的神经元。一个典型的神经元连接的数目可能是小到 10 个。</p>
<h3 id="3-8-6-初始化偏差"><a href="#3-8-6-初始化偏差" class="headerlink" title="3.8.6 初始化偏差"></a>3.8.6 初始化偏差</h3><p>​    将偏差初始化为零是可能的，也是很常见的，因为非对称性破坏是由权重的小随机数导致的。因为 ReLU 具有非线性特点，所以有些人喜欢使用将所有的偏差设定为小的常数值如 0.01，因为这样可以确保所有的 ReLU 单元在最开始就激活触发(fire)并因此能够获得和传播一些梯度值。然而，这是否能够提供持续的改善还不太清楚(实际上一些结果表明这样做反而使得性能更加糟糕)，所以更通常的做法是简单地将偏差初始化为 0.</p>
<h2 id="3-9-学习率"><a href="#3-9-学习率" class="headerlink" title="3.9 学习率"></a>3.9 学习率</h2><h3 id="3-9-1-学习率的作用"><a href="#3-9-1-学习率的作用" class="headerlink" title="3.9.1 学习率的作用"></a>3.9.1 学习率的作用</h3><p>​    在机器学习中，监督式学习通过定义一个模型，并根据训练集上的数据估计最优参数。梯度下降法是一个广泛被用来最小化模型误差的参数优化算法。梯度下降法通过多次迭代，并在每一步中最小化成本函数（cost 来估计模型的参数。学习率 (learning rate)，在迭代过程中会控制模型的学习进度。</p>
<p>​    在梯度下降法中，都是给定的统一的学习率，整个优化过程中都以确定的步长进行更新， 在迭代优化的前期中，学习率较大，则前进的步长就会较长，这时便能以较快的速度进行梯度下降，而在迭代优化的后期，逐步减小学习率的值，减小步长，这样将有助于算法的收敛，更容易接近最优解。故而如何对学习率的更新成为了研究者的关注点。<br>​    在模型优化中，常用到的几种学习率衰减方法有：分段常数衰减、多项式衰减、指数衰减、自然指数衰减、余弦衰减、线性余弦衰减、噪声线性余弦衰减</p>
<h3 id="3-9-2-学习率衰减常用参数有哪些"><a href="#3-9-2-学习率衰减常用参数有哪些" class="headerlink" title="3.9.2 学习率衰减常用参数有哪些"></a>3.9.2 学习率衰减常用参数有哪些</h3><div class="table-container">
<table>
<thead>
<tr>
<th>参数名称</th>
<th>参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>learning_rate</td>
<td>初始学习率</td>
</tr>
<tr>
<td>global_step</td>
<td>用于衰减计算的全局步数，非负，用于逐步计算衰减指数</td>
</tr>
<tr>
<td>decay_steps</td>
<td>衰减步数，必须是正值，决定衰减周期</td>
</tr>
<tr>
<td>decay_rate</td>
<td>衰减率</td>
</tr>
<tr>
<td>end_learning_rate</td>
<td>最低的最终学习率</td>
</tr>
<tr>
<td>cycle</td>
<td>学习率下降后是否重新上升</td>
</tr>
<tr>
<td>alpha</td>
<td>最小学习率</td>
</tr>
<tr>
<td>num_periods</td>
<td>衰减余弦部分的周期数</td>
</tr>
<tr>
<td>initial_variance</td>
<td>噪声的初始方差</td>
</tr>
<tr>
<td>variance_decay</td>
<td>衰减噪声的方差</td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-9-3-分段常数衰减"><a href="#3-9-3-分段常数衰减" class="headerlink" title="3.9.3 分段常数衰减"></a>3.9.3 分段常数衰减</h3><p>​    分段常数衰减需要事先定义好的训练次数区间，在对应区间置不同的学习率的常数值，一般情况刚开始的学习率要大一些，之后要越来越小，要根据样本量的大小设置区间的间隔大小，样本量越大，区间间隔要小一点。下图即为分段常数衰减的学习率变化图，横坐标代表训练次数，纵坐标代表学习率。</p>
<p><img src="/img/ch3/learnrate1.png" alt=""></p>
<h3 id="3-9-4-指数衰减"><a href="#3-9-4-指数衰减" class="headerlink" title="3.9.4 指数衰减"></a>3.9.4 指数衰减</h3><p>​    以指数衰减方式进行学习率的更新，学习率的大小和训练次数指数相关，其更新规则为：</p>
<script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =learning{\_}rate*decay{\_}rate^{\frac{global{\_step}}{decay{\_}steps}}</script><p>​    这种衰减方式简单直接，收敛速度快，是最常用的学习率衰减方式，如下图所示，绿色的为学习率随<br>训练次数的指数衰减方式，红色的即为分段常数衰减，它在一定的训练区间内保持学习率不变。</p>
<p><img src="/img/ch3/learnrate2.png" alt=""></p>
<h3 id="3-9-5-自然指数衰减"><a href="#3-9-5-自然指数衰减" class="headerlink" title="3.9.5 自然指数衰减"></a>3.9.5 自然指数衰减</h3><p>​    它与指数衰减方式相似，不同的在于它的衰减底数是$e$，故而其收敛的速度更快，一般用于相对比较<br>容易训练的网络，便于较快的收敛，其更新规则如下</p>
<script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =learning{\_}rate*e^{\frac{-decay{\_rate}}{global{\_}step}}</script><p>​    下图为为分段常数衰减、指数衰减、自然指数衰减三种方式的对比图，红色的即为分段常数衰减图，阶梯型曲线。蓝色线为指数衰减图，绿色即为自然指数衰减图，很明可以看到自然指数衰减方式下的学习率衰减程度要大于一般指数衰减方式，有助于更快的收敛。</p>
<p><img src="/img/ch3/learnrate3.png" alt=""></p>
<h3 id="3-9-6-多项式衰减"><a href="#3-9-6-多项式衰减" class="headerlink" title="3.9.6 多项式衰减"></a>3.9.6 多项式衰减</h3><p>​    应用多项式衰减的方式进行更新学习率，这里会给定初始学习率和最低学习率取值，然后将会按照<br>给定的衰减方式将学习率从初始值衰减到最低值,其更新规则如下式所示。</p>
<script type="math/tex; mode=display">
global{\_}step=min(global{\_}step,decay{\_}steps)</script><script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =(learning{\_}rate-end{\_}learning{\_}rate)* \left( 1-\frac{global{\_step}}{decay{\_}steps}\right)^{power} \\
 +end{\_}learning{\_}rate</script><p>​    需要注意的是，有两个机制，降到最低学习率后，到训练结束可以一直使用最低学习率进行更新，另一个是再次将学习率调高，使用 decay_steps 的倍数，取第一个大于 global_steps 的结果，如下式所示.它是用来防止神经网络在训练的后期由于学习率过小而导致的网络一直在某个局部最小值附近震荡，这样可以通过在后期增大学习率跳出局部极小值。</p>
<script type="math/tex; mode=display">
decay{\_}steps = decay{\_}steps*ceil \left( \frac{global{\_}step}{decay{\_}steps}\right)</script><p>​    如下图所示，红色线代表学习率降低至最低后，一直保持学习率不变进行更新，绿色线代表学习率衰减到最低后，又会再次循环往复的升高降低。</p>
<p><img src="/img/ch3/learnrate4.png" alt=""></p>
<h3 id="3-9-7-余弦衰减"><a href="#3-9-7-余弦衰减" class="headerlink" title="3.9.7 余弦衰减"></a>3.9.7 余弦衰减</h3><p>​    余弦衰减就是采用余弦的相关方式进行学习率的衰减，衰减图和余弦函数相似。其更新机制如下式所示：</p>
<script type="math/tex; mode=display">
global{\_}step=min(global{\_}step,decay{\_}steps)</script><script type="math/tex; mode=display">
cosine{\_}decay=0.5*\left( 1+cos\left( \pi* \frac{global{\_}step}{decay{\_}steps}\right)\right)</script><script type="math/tex; mode=display">
decayed=(1-\alpha)*cosine{\_}decay+\alpha</script><script type="math/tex; mode=display">
decayed{\_}learning{\_}rate=learning{\_}rate*decayed</script><p>​    如下图所示，红色即为标准的余弦衰减曲线，学习率从初始值下降到最低学习率后保持不变。蓝色的线是线性余弦衰减方式曲线，它是学习率从初始学习率以线性的方式下降到最低学习率值。绿色噪声线性余弦衰减方式。</p>
<p><img src="/img/ch3/learnrate5.png" alt=""></p>
<h2 id="3-12-Dropout-系列问题"><a href="#3-12-Dropout-系列问题" class="headerlink" title="3.12 Dropout 系列问题"></a>3.12 Dropout 系列问题</h2><h3 id="3-12-1-为什么要正则化？"><a href="#3-12-1-为什么要正则化？" class="headerlink" title="3.12.1 为什么要正则化？"></a>3.12.1 为什么要正则化？</h3><ol>
<li>深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少你的网络误差。  </li>
<li>如果你怀疑神经网络过度拟合了数据，即存在高方差问题，那么最先想到的方法可能是正则化，另一个解决高方差的方法就是准备更多数据，这也是非常可靠的办法，但你可能无法时时准备足够多的训练数据，或者，获取更多数据的成本很高，但正则化有助于避免过度拟合，或者减少网络误差。</li>
</ol>
<h3 id="3-12-2-为什么正则化有利于预防过拟合？"><a href="#3-12-2-为什么正则化有利于预防过拟合？" class="headerlink" title="3.12.2 为什么正则化有利于预防过拟合？"></a>3.12.2 为什么正则化有利于预防过拟合？</h3><p><img src="/img/ch3/3.12.2.1.png" alt=""><br><img src="/img/ch3/3.12.2.2.png" alt=""> </p>
<p>左图是高偏差，右图是高方差，中间是Just Right，这几张图我们在前面课程中看到过。  </p>
<h3 id="3-12-3-理解dropout正则化"><a href="#3-12-3-理解dropout正则化" class="headerlink" title="3.12.3 理解dropout正则化"></a>3.12.3 理解dropout正则化</h3><p>​    Dropout可以随机删除网络中的神经单元，它为什么可以通过正则化发挥如此大的作用呢？  </p>
<p>​    直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施dropout的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；L2对不同权重的衰减是不同的，它取决于激活函数倍增的大小。  </p>
<h3 id="3-12-4-dropout率的选择"><a href="#3-12-4-dropout率的选择" class="headerlink" title="3.12.4 dropout率的选择"></a>3.12.4 dropout率的选择</h3><ol>
<li>经过交叉验证，隐含节点 dropout 率等于 0.5 的时候效果最好，原因是 0.5 的时候 dropout 随机生成的网络结构最多。</li>
<li>dropout 也可以被用作一种添加噪声的方法，直接对 input 进行操作。输入层设为更接近 1 的数。使得输入变化不会太大（0.8） </li>
<li>对参数 $ w $ 的训练进行球形限制 (max-normalization)，对 dropout 的训练非常有用。</li>
<li>球形半径 $ c $ 是一个需要调整的参数，可以使用验证集进行参数调优。</li>
<li>dropout 自己虽然也很牛，但是 dropout、max-normalization、large decaying learning rates and high momentum 组合起来效果更好，比如 max-norm regularization 就可以防止大的learning rate 导致的参数 blow up。</li>
<li>使用 pretraining 方法也可以帮助 dropout 训练参数，在使用 dropout 时，要将所有参数都乘以 $ 1/p $。</li>
</ol>
<h3 id="3-12-5-dropout有什么缺点？"><a href="#3-12-5-dropout有什么缺点？" class="headerlink" title="3.12.5 dropout有什么缺点？"></a>3.12.5 dropout有什么缺点？</h3><p>​    dropout一大缺点就是代价函数J不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。定义明确的代价函数J每次迭代后都会下降，因为我们所优化的代价函数J实际上并没有明确定义，或者说在某种程度上很难计算，所以我们失去了调试工具来绘制这样的图片。我通常会关闭dropout函数，将keep-prob的值设为1，运行代码，确保J函数单调递减。然后打开dropout函数，希望在dropout过程中，代码并未引入bug。我觉得你也可以尝试其它方法，虽然我们并没有关于这些方法性能的数据统计，但你可以把它们与dropout方法一起使用。  </p>
<h2 id="3-13-深度学习中常用的数据增强方法？"><a href="#3-13-深度学习中常用的数据增强方法？" class="headerlink" title="3.13 深度学习中常用的数据增强方法？"></a>3.13 深度学习中常用的数据增强方法？</h2><p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<ul>
<li><p>Color Jittering：对颜色的数据增强：图像亮度、饱和度、对比度变化（此处对色彩抖动的理解不知是否得当）；</p>
</li>
<li><p>PCA  Jittering：首先按照RGB三个颜色通道计算均值和标准差，再在整个训练集上计算协方差矩阵，进行特征分解，得到特征向量和特征值，用来做PCA Jittering；</p>
</li>
<li><p>Random Scale：尺度变换；</p>
</li>
<li><p>Random Crop：采用随机图像差值方式，对图像进行裁剪、缩放；包括Scale Jittering方法（VGG及ResNet模型使用）或者尺度和长宽比增强变换；</p>
</li>
<li><p>Horizontal/Vertical Flip：水平/垂直翻转；</p>
</li>
<li><p>Shift：平移变换；</p>
</li>
<li><p>Rotation/Reflection：旋转/仿射变换；</p>
</li>
<li><p>Noise：高斯噪声、模糊处理；</p>
</li>
<li><p>Label Shuffle：类别不平衡数据的增广；</p>
</li>
</ul>
<h2 id="3-14-如何理解-Internal-Covariate-Shift？"><a href="#3-14-如何理解-Internal-Covariate-Shift？" class="headerlink" title="3.14 如何理解 Internal Covariate Shift？"></a>3.14 如何理解 Internal Covariate Shift？</h2><p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<p>​    深度神经网络模型的训练为什么会很困难？其中一个重要的原因是，深度神经网络涉及到很多层的叠加，而每一层的参数更新会导致上层的输入数据分布发生变化，通过层层叠加，高层的输入分布变化会非常剧烈，这就使得高层需要不断去重新适应底层的参数更新。为了训好模型，我们需要非常谨慎地去设定学习率、初始化权重、以及尽可能细致的参数更新策略。</p>
<p>​    Google 将这一现象总结为 Internal Covariate Shift，简称 ICS。 什么是 ICS 呢？</p>
<p>​    大家都知道在统计机器学习中的一个经典假设是“源空间（source domain）和目标空间（target domain）的数据分布（distribution）是一致的”。如果不一致，那么就出现了新的机器学习问题，如 transfer learning / domain adaptation 等。而 covariate shift 就是分布不一致假设之下的一个分支问题，它是指源空间和目标空间的条件概率是一致的，但是其边缘概率不同。</p>
<p>​    大家细想便会发现，的确，对于神经网络的各层输出，由于它们经过了层内操作作用，其分布显然与各层对应的输入信号分布不同，而且差异会随着网络深度增大而增大，可是它们所能“指示”的样本标记（label）仍然是不变的，这便符合了covariate shift的定义。由于是对层间信号的分析，也即是“internal”的来由。</p>
<p><strong>那么ICS会导致什么问题？</strong></p>
<p>简而言之，每个神经元的输入数据不再是“独立同分布”。</p>
<p>其一，上层参数需要不断适应新的输入数据分布，降低学习速度。</p>
<p>其二，下层输入的变化可能趋向于变大或者变小，导致上层落入饱和区，使得学习过早停止。</p>
<p>其三，每层的更新都会影响到其它层，因此每层的参数更新策略需要尽可能的谨慎。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Rosenblatt, F. The perceptron: A probabilistic model for information storage and organization in the brain.[J]. Psychological Review, 1958, 65(6):386-408.</p>
<p>[2] Duvenaud D , Rippel O , Adams R P , et al. Avoiding pathologies in very deep networks[J]. Eprint Arxiv, 2014:202-210.</p>
<p>[3] Rumelhart D E, Hinton G E, Williams R J. Learning representations by back-propagating errors[J]. Cognitive modeling, 1988, 5(3): 1.</p>
<p>[4] Hecht-Nielsen R. Theory of the backpropagation neural network[M]//Neural networks for perception. Academic Press, 1992: 65-93.</p>
<p>[5] Felice M. Which deep learning network is best for you?| CIO[J]. 2017.</p>
<p>[6] Conneau A, Schwenk H, Barrault L, et al. Very deep convolutional networks for natural language processing[J]. arXiv preprint arXiv:1606.01781, 2016, 2.</p>
<p>[7] Ba J, Caruana R. Do deep nets really need to be deep?[C]//Advances in neural information processing systems. 2014: 2654-2662.</p>
<p>[8] Nielsen M A. Neural networks and deep learning[M]. USA: Determination press, 2015.</p>
<p>[9] Goodfellow I, Bengio Y, Courville A. Deep learning[M]. MIT press, 2016.</p>
<p>[10] 周志华. 机器学习[M].清华大学出版社, 2016.</p>
<p>[11] Kim J, Kwon Lee J, Mu Lee K. Accurate image super-resolution using very deep convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 1646-1654.</p>
<p>[12] Chen Y, Lin Z, Zhao X, et al. Deep learning-based classification of hyperspectral data[J]. IEEE Journal of Selected topics in applied earth observations and remote sensing, 2014, 7(6): 2094-2107.</p>
<p>[13] Domhan T, Springenberg J T, Hutter F. Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves[C]//Twenty-Fourth International Joint Conference on Artificial Intelligence. 2015.</p>
<p>[14] Maclaurin D, Duvenaud D, Adams R. Gradient-based hyperparameter optimization through reversible learning[C]//International Conference on Machine Learning. 2015: 2113-2122.</p>
<p>[15] Srivastava R K, Greff K, Schmidhuber J. Training very deep networks[C]//Advances in neural information processing systems. 2015: 2377-2385.</p>
<p>[16] Bergstra J, Bengio Y. Random search for hyper-parameter optimization[J]. Journal of Machine Learning Research, 2012, 13(Feb): 281-305.</p>
<p>[17] Ngiam J, Khosla A, Kim M, et al. Multimodal deep learning[C]//Proceedings of the 28th international conference on machine learning (ICML-11). 2011: 689-696.</p>
<p>[18] Deng L, Yu D. Deep learning: methods and applications[J]. Foundations and Trends® in Signal Processing, 2014, 7(3–4): 197-387.</p>
<p>[19] Erhan D, Bengio Y, Courville A, et al. Why does unsupervised pre-training help deep learning?[J]. Journal of Machine Learning Research, 2010, 11(Feb): 625-660.</p>
<p>[20] Dong C, Loy C C, He K, et al. Learning a deep convolutional network for image super resolution[C]//European conference on computer vision. Springer, Cham, 2014: 184-199.</p>
<p>[21] 郑泽宇，梁博文，顾思宇.TensorFlow：实战Google深度学习框架（第2版）[M].电子工业出版社,2018.</p>
<p>[22] 焦李成. 深度学习优化与识别[M].清华大学出版社,2017.</p>
<p>[23] 吴岸城. 神经网络与深度学习[M].电子工业出版社,2016.</p>
<p>[24] Wei, W.G.H., Liu, T., Song, A., et al. (2018) An Adaptive Natural Gradient Method with Adaptive Step Size in Multilayer Perceptrons. Chinese Automation Congress, 1593-1597.</p>
<p>[25] Y Feng, Y Li.An Overview of Deep Learning Optimization Methods and Learning Rate Attenuation Methods[J].Hans Journal of Data Mining,2018,8(4),186-200.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/03/03/%E7%AC%AC%E4%B8%80%E7%AB%A0_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/03/%E7%AC%AC%E4%B8%80%E7%AB%A0_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">第一章_数学基础</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-03 12:21:02 / 修改时间：12:22:07" itemprop="dateCreated datePublished" datetime="2020-03-03T12:21:02+08:00">2020-03-03</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h1 id="第一章-数学基础"><a href="#第一章-数学基础" class="headerlink" title="第一章 数学基础"></a>第一章 数学基础</h1><p>深度学习通常又需要哪些数学基础？深度学习里的数学到底难在哪里？通常初学者都会有这些问题，在网络推荐及书本推荐里，经常看到会列出一系列数学科目，比如微积分、线性代数、概率论、复变函数、数值计算、优化理论、信息论等等。这些数学知识有相关性，但实际上按照这样的知识范围来学习，学习成本会很久，而且会很枯燥，本章我们通过选举一些数学基础里容易混淆的一些概念做以介绍，帮助大家更好的理清这些易混淆概念之间的关系。</p>
<h2 id="1-1-向量和矩阵"><a href="#1-1-向量和矩阵" class="headerlink" title="1.1 向量和矩阵"></a>1.1 向量和矩阵</h2><h3 id="1-1-1-标量、向量、矩阵、张量之间的联系"><a href="#1-1-1-标量、向量、矩阵、张量之间的联系" class="headerlink" title="1.1.1 标量、向量、矩阵、张量之间的联系"></a>1.1.1 标量、向量、矩阵、张量之间的联系</h3><p><strong>标量（scalar）</strong><br>一个标量表示一个单独的数，它不同于线性代数中研究的其他大部分对象（通常是多个数的数组）。我们用斜体表示标量。标量通常被赋予小写的变量名称。 </p>
<p><strong>向量（vector）</strong><br>​一个向量表示一组有序排列的数。通过次序中的索引，我们可以确定每个单独的数。通常我们赋予向量粗体的小写变量名称，比如xx。向量中的元素可以通过带脚标的斜体表示。向量$X$的第一个元素是$X_1$，第二个元素是$X_2$，以此类推。我们也会注明存储在向量中的元素的类型（实数、虚数等）。</p>
<p><strong>矩阵（matrix）</strong><br>​矩阵是具有相同特征和纬度的对象的集合，表现为一张二维数据表。其意义是一个对象表示为矩阵中的一行，一个特征表示为矩阵中的一列，每个特征都有数值型的取值。通常会赋予矩阵粗体的大写变量名称，比如$A$。</p>
<p><strong>张量（tensor）</strong><br>​在某些情况下，我们会讨论坐标超过两维的数组。一般地，一个数组中的元素分布在若干维坐标的规则网格中，我们将其称之为张量。使用 $A$ 来表示张量“A”。张量$A$中坐标为$(i,j,k)$的元素记作$A_{(i,j,k)}$。 </p>
<p><strong>四者之间关系</strong>  </p>
<blockquote>
<p>标量是0阶张量，向量是一阶张量。举例：<br>​标量就是知道棍子的长度，但是你不会知道棍子指向哪儿。<br>​向量就是不但知道棍子的长度，还知道棍子指向前面还是后面。<br>​张量就是不但知道棍子的长度，也知道棍子指向前面还是后面，还能知道这棍子又向上/下和左/右偏转了多少。</p>
</blockquote>
<h3 id="1-1-2-张量与矩阵的区别"><a href="#1-1-2-张量与矩阵的区别" class="headerlink" title="1.1.2 张量与矩阵的区别"></a>1.1.2 张量与矩阵的区别</h3><ul>
<li>从代数角度讲， 矩阵它是向量的推广。向量可以看成一维的“表格”（即分量按照顺序排成一排）， 矩阵是二维的“表格”（分量按照纵横位置排列）， 那么$n$阶张量就是所谓的$n$维的“表格”。 张量的严格定义是利用线性映射来描述。</li>
<li>从几何角度讲， 矩阵是一个真正的几何量，也就是说，它是一个不随参照系的坐标变换而变化的东西。向量也具有这种特性。</li>
<li>张量可以用3×3矩阵形式来表达。 </li>
<li>表示标量的数和表示向量的三维数组也可分别看作1×1，1×3的矩阵。 </li>
</ul>
<h3 id="1-1-3-矩阵和向量相乘结果"><a href="#1-1-3-矩阵和向量相乘结果" class="headerlink" title="1.1.3 矩阵和向量相乘结果"></a>1.1.3 矩阵和向量相乘结果</h3><p>若使用爱因斯坦求和约定（Einstein summation convention），矩阵$A$, $B$相乘得到矩阵$C$可以用下式表示：</p>
<script type="math/tex; mode=display">a_{ik}*b_{kj}=c_{ij} \tag{1.3-1}</script><p>其中，$a_{ik}$, $b_{kj}$, $c_{ij}$分别表示矩阵$A, B, C$的元素，$k$出现两次，是一个哑变量（Dummy Variables）表示对该参数进行遍历求和。<br>而矩阵和向量相乘可以看成是矩阵相乘的一个特殊情况，例如：矩阵$B$是一个$n \times 1$的矩阵。</p>
<h3 id="1-1-4-向量和矩阵的范数归纳"><a href="#1-1-4-向量和矩阵的范数归纳" class="headerlink" title="1.1.4 向量和矩阵的范数归纳"></a>1.1.4 向量和矩阵的范数归纳</h3><p><strong>向量的范数(norm)</strong><br>​    定义一个向量为：$\vec{a}=[-5, 6, 8, -10]$。任意一组向量设为$\vec{x}=(x_1,x_2,…,x_N)$。其不同范数求解如下：</p>
<ul>
<li>向量的1范数：向量的各个元素的绝对值之和，上述向量$\vec{a}$的1范数结果就是：29。</li>
</ul>
<script type="math/tex; mode=display">
\Vert\vec{x}\Vert_1=\sum_{i=1}^N\vert{x_i}\vert</script><ul>
<li>向量的2范数：向量的每个元素的平方和再开平方根，上述$\vec{a}$的2范数结果就是：15。</li>
</ul>
<script type="math/tex; mode=display">
\Vert\vec{x}\Vert_2=\sqrt{\sum_{i=1}^N{\vert{x_i}\vert}^2}</script><ul>
<li>向量的负无穷范数：向量的所有元素的绝对值中最小的：上述向量$\vec{a}$的负无穷范数结果就是：5。  </li>
</ul>
<script type="math/tex; mode=display">
\Vert\vec{x}\Vert_{-\infty}=\min{|{x_i}|}</script><ul>
<li>向量的正无穷范数：向量的所有元素的绝对值中最大的：上述向量$\vec{a}$的正无穷范数结果就是：10。 </li>
</ul>
<script type="math/tex; mode=display">
\Vert\vec{x}\Vert_{+\infty}=\max{|{x_i}|}</script><ul>
<li>向量的p范数：</li>
</ul>
<script type="math/tex; mode=display">
L_p=\Vert\vec{x}\Vert_p=\sqrt[p]{\sum_{i=1}^{N}|{x_i}|^p}</script><p><strong>矩阵的范数</strong>  </p>
<p>定义一个矩阵$A=[-1, 2, -3; 4, -6, 6]$。 任意矩阵定义为：$A_{m\times n}$，其元素为 $a_{ij}$。</p>
<p>矩阵的范数定义为</p>
<script type="math/tex; mode=display">
\Vert{A}\Vert_p :=\sup_{x\neq 0}\frac{\Vert{Ax}\Vert_p}{\Vert{x}\Vert_p}</script><p>当向量取不同范数时, 相应得到了不同的矩阵范数。</p>
<ul>
<li><strong>矩阵的1范数（列范数）</strong>：矩阵的每一列上的元</li>
</ul>
<p>  素绝对值先求和，再从中取个最大的,（列和最大），上述矩阵$A$的1范数先得到$[5,8,9]$，再取最大的最终结果就是：9。</p>
<script type="math/tex; mode=display">
\Vert A\Vert_1=\max_{1\le j\le n}\sum_{i=1}^m|{a_{ij}}|</script><ul>
<li><strong>矩阵的2范数</strong>：矩阵$A^TA$的最大特征值开平方根，上述矩阵$A$的2范数得到的最终结果是：10.0623。 </li>
</ul>
<script type="math/tex; mode=display">
\Vert A\Vert_2=\sqrt{\lambda_{max}(A^T A)}</script><p>其中， $\lambda_{max}(A^T A)$ 为 $A^T A​$ 的特征值绝对值的最大值。</p>
<ul>
<li><p><strong>矩阵的无穷范数（行范数）</strong>：矩阵的每一行上的元素绝对值先求和，再从中取个最大的，（行和最大），上述矩阵$A$的行范数先得到$[6；16]$，再取最大的最终结果就是：16。 </p>
<script type="math/tex; mode=display">
\Vert A\Vert_{\infty}=\max_{1\le i \le m}\sum_{j=1}^n |{a_{ij}}|</script></li>
<li><p><strong>矩阵的核范数</strong>：矩阵的奇异值（将矩阵svd分解）之和，这个范数可以用来低秩表示（因为最小化核范数，相当于最小化矩阵的秩——低秩），上述矩阵A最终结果就是：10.9287。  </p>
</li>
<li><p><strong>矩阵的L0范数</strong>：矩阵的非0元素的个数，通常用它来表示稀疏，L0范数越小0元素越多，也就越稀疏，上述矩阵$A$最终结果就是：6。</p>
</li>
<li><strong>矩阵的L1范数</strong>：矩阵中的每个元素绝对值之和，它是L0范数的最优凸近似，因此它也可以表示稀疏，上述矩阵$A$最终结果就是：22。  </li>
<li><strong>矩阵的F范数</strong>：矩阵的各个元素平方之和再开平方根，它通常也叫做矩阵的L2范数，它的优点在于它是一个凸函数，可以求导求解，易于计算，上述矩阵A最终结果就是：10.0995。  </li>
</ul>
<script type="math/tex; mode=display">
\Vert A\Vert_F=\sqrt{(\sum_{i=1}^m\sum_{j=1}^n{| a_{ij}|}^2)}</script><ul>
<li><strong>矩阵的L21范数</strong>：矩阵先以每一列为单位，求每一列的F范数（也可认为是向量的2范数），然后再将得到的结果求L1范数（也可认为是向量的1范数），很容易看出它是介于L1和L2之间的一种范数，上述矩阵$A$最终结果就是：17.1559。 </li>
<li><strong>矩阵的 p范数</strong> </li>
</ul>
<script type="math/tex; mode=display">
\Vert A\Vert_p=\sqrt[p]{(\sum_{i=1}^m\sum_{j=1}^n{| a_{ij}|}^p)}</script><h3 id="1-1-5-如何判断一个矩阵为正定"><a href="#1-1-5-如何判断一个矩阵为正定" class="headerlink" title="1.1.5 如何判断一个矩阵为正定"></a>1.1.5 如何判断一个矩阵为正定</h3><p>判定一个矩阵是否为正定，通常有以下几个方面：  </p>
<ul>
<li>顺序主子式全大于0；  </li>
<li>存在可逆矩阵$C$使$C^TC$等于该矩阵；</li>
<li>正惯性指数等于$n$；</li>
<li>合同于单位矩阵$E$（即：规范形为$E$）</li>
<li>标准形中主对角元素全为正；</li>
<li>特征值全为正；</li>
<li>是某基的度量矩阵。</li>
</ul>
<h2 id="1-2-导数和偏导数"><a href="#1-2-导数和偏导数" class="headerlink" title="1.2 导数和偏导数"></a>1.2 导数和偏导数</h2><h3 id="1-2-1-导数偏导计算"><a href="#1-2-1-导数偏导计算" class="headerlink" title="1.2.1 导数偏导计算"></a>1.2.1 导数偏导计算</h3><p><strong>导数定义</strong>:</p>
<p>导数(derivative)代表了在自变量变化趋于无穷小的时候，函数值的变化与自变量的变化的比值。几何意义是这个点的切线。物理意义是该时刻的（瞬时）变化率。<br>​</p>
<p><em>注意</em>：在一元函数中，只有一个自变量变动，也就是说只存在一个方向的变化率，这也就是为什么一元函数没有偏导数的原因。在物理学中有平均速度和瞬时速度之说。平均速度有</p>
<script type="math/tex; mode=display">
v=\frac{s}{t}</script><p>其中$v$表示平均速度，$s$表示路程，$t$表示时间。这个公式可以改写为</p>
<script type="math/tex; mode=display">
\bar{v}=\frac{\Delta s}{\Delta t}=\frac{s(t_0+\Delta t)-s(t_0)}{\Delta t}</script><p>其中$\Delta s$表示两点之间的距离，而$\Delta t$表示走过这段距离需要花费的时间。当$\Delta t$趋向于0（$\Delta t \to 0$）时，也就是时间变得很短时，平均速度也就变成了在$t_0$时刻的瞬时速度，表示成如下形式：</p>
<script type="math/tex; mode=display">
v(t_0)=\lim_{\Delta t \to 0}{\bar{v}}=\lim_{\Delta t \to 0}{\frac{\Delta s}{\Delta t}}=\lim_{\Delta t \to 0}{\frac{s(t_0+\Delta t)-s(t_0)}{\Delta t}}</script><p>实际上，上式表示的是路程$s$关于时间$t$的函数在$t=t_0$处的导数。一般的，这样定义导数：如果平均变化率的极限存在，即有</p>
<script type="math/tex; mode=display">
\lim_{\Delta x \to 0}{\frac{\Delta y}{\Delta x}}=\lim_{\Delta x \to 0}{\frac{f(x_0+\Delta x)-f(x_0)}{\Delta x}}</script><p>则称此极限为函数 $y=f(x)$ 在点 $x_0$ 处的导数。记作 $f’(x_0)$ 或 $y’\vert_{x=x_0}$ 或 $\frac{dy}{dx}\vert_{x=x_0}$ 或 $\frac{df(x)}{dx}\vert_{x=x_0}$。</p>
<p>通俗地说，导数就是曲线在某一点切线的斜率。</p>
<p><strong>偏导数</strong>:</p>
<p>既然谈到偏导数(partial derivative)，那就至少涉及到两个自变量。以两个自变量为例，$z=f(x,y)​$，从导数到偏导数，也就是从曲线来到了曲面。曲线上的一点，其切线只有一条。但是曲面上的一点，切线有无数条。而偏导数就是指多元函数沿着坐标轴的变化率。 </p>
<p><em>注意</em>：直观地说，偏导数也就是函数在某一点上沿坐标轴正方向的的变化率。</p>
<p>设函数$z=f(x,y)​$在点$(x_0,y_0)​$的领域内有定义，当$y=y_0​$时，$z​$可以看作关于$x​$的一元函数$f(x,y_0)​$，若该一元函数在$x=x_0​$处可导，即有</p>
<script type="math/tex; mode=display">
\lim_{\Delta x \to 0}{\frac{f(x_0+\Delta x,y_0)-f(x_0,y_0)}{\Delta x}}=A</script><p>函数的极限$A$存在。那么称$A$为函数$z=f(x,y)$在点$(x_0,y_0)$处关于自变量$x$的偏导数，记作$f_x(x_0,y_0)$或$\frac{\partial z}{\partial x}\vert_{y=y_0}^{x=x_0}$或$\frac{\partial f}{\partial x}\vert_{y=y_0}^{x=x_0}$或$z_x\vert_{y=y_0}^{x=x_0}$。</p>
<p>偏导数在求解时可以将另外一个变量看做常数，利用普通的求导方式求解，比如$z=3x^2+xy$关于$x$的偏导数就为$z_x=6x+y$，这个时候$y$相当于$x$的系数。</p>
<p>某点$(x_0,y_0)$处的偏导数的几何意义为曲面$z=f(x,y)$与面$x=x_0$或面$y=y_0$交线在$y=y_0$或$x=x_0$处切线的斜率。  </p>
<h3 id="1-2-2-导数和偏导数有什么区别？"><a href="#1-2-2-导数和偏导数有什么区别？" class="headerlink" title="1.2.2 导数和偏导数有什么区别？"></a>1.2.2 导数和偏导数有什么区别？</h3><p>导数和偏导没有本质区别，如果极限存在，都是当自变量的变化量趋于0时，函数值的变化量与自变量变化量比值的极限。  </p>
<blockquote>
<ul>
<li>一元函数，一个$y$对应一个$x$，导数只有一个。  </li>
<li>二元函数，一个$z$对应一个$x$和一个$y$，有两个导数：一个是$z$对$x$的导数，一个是$z$对$y$的导数，称之为偏导。  </li>
<li>求偏导时要注意，对一个变量求导，则视另一个变量为常数，只对改变量求导，从而将偏导的求解转化成了一元函数的求导。</li>
</ul>
</blockquote>
<h2 id="1-3-特征值和特征向量"><a href="#1-3-特征值和特征向量" class="headerlink" title="1.3 特征值和特征向量"></a>1.3 特征值和特征向量</h2><h3 id="1-3-1-特征值分解与特征向量"><a href="#1-3-1-特征值分解与特征向量" class="headerlink" title="1.3.1 特征值分解与特征向量"></a>1.3.1 特征值分解与特征向量</h3><ul>
<li><p>特征值分解可以得到特征值(eigenvalues)与特征向量(eigenvectors)；</p>
</li>
<li><p>特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么。  </p>
<p>如果说一个向量$\vec{v}$是方阵$A$的特征向量，将一定可以表示成下面的形式：</p>
</li>
</ul>
<script type="math/tex; mode=display">
A\nu = \lambda \nu</script><p>$\lambda$为特征向量$\vec{v}$对应的特征值。特征值分解是将一个矩阵分解为如下形式： </p>
<script type="math/tex; mode=display">
A=Q\sum Q^{-1}</script><p>其中，$Q$是这个矩阵$A$的特征向量组成的矩阵，$\sum$是一个对角矩阵，每一个对角线元素就是一个特征值，里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变化方向（从主要的变化到次要的变化排列）。也就是说矩阵$A$的信息可以由其特征值和特征向量表示。</p>
<h3 id="1-3-2-奇异值与特征值有什么关系"><a href="#1-3-2-奇异值与特征值有什么关系" class="headerlink" title="1.3.2 奇异值与特征值有什么关系"></a>1.3.2 奇异值与特征值有什么关系</h3><p>那么奇异值和特征值是怎么对应起来的呢？我们将一个矩阵$A$的转置乘以$A$，并对$A^TA​$求特征值，则有下面的形式：</p>
<script type="math/tex; mode=display">
(A^TA)V = \lambda V</script><p>这里$V​$就是上面的右奇异向量，另外还有：</p>
<script type="math/tex; mode=display">
\sigma_i = \sqrt{\lambda_i}, u_i=\frac{1}{\sigma_i}A\mu_i</script><p>这里的$\sigma​$就是奇异值，$u​$就是上面说的左奇异向量。【证明那个哥们也没给】<br>​奇异值$\sigma​$跟特征值类似，在矩阵$\sum​$中也是从大到小排列，而且$\sigma​$的减少特别的快，在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上了。也就是说，我们也可以用前$r​$（$r​$远小于$m、n​$）个的奇异值来近似描述矩阵，即部分奇异值分解：</p>
<script type="math/tex; mode=display">
A_{m\times n}\approx U_{m \times r}\sum_{r\times r}V_{r \times n}^T</script><p>右边的三个矩阵相乘的结果将会是一个接近于$A$的矩阵，在这儿，$r$越接近于$n$，则相乘的结果越接近于$A$。</p>
<h2 id="1-4-概率分布与随机变量"><a href="#1-4-概率分布与随机变量" class="headerlink" title="1.4 概率分布与随机变量"></a>1.4 概率分布与随机变量</h2><h3 id="1-4-1-机器学习为什么要使用概率"><a href="#1-4-1-机器学习为什么要使用概率" class="headerlink" title="1.4.1 机器学习为什么要使用概率"></a>1.4.1 机器学习为什么要使用概率</h3><p>事件的概率是衡量该事件发生的可能性的量度。虽然在一次随机试验中某个事件的发生是带有偶然性的，但那些可在相同条件下大量重复的随机试验却往往呈现出明显的数量规律。<br>​机器学习除了处理不确定量，也需处理随机量。不确定性和随机性可能来自多个方面，使用概率论来量化不确定性。<br>​概率论在机器学习中扮演着一个核心角色，因为机器学习算法的设计通常依赖于对数据的概率假设。  </p>
<blockquote>
<p>​    例如在机器学习（Andrew Ng）的课中，会有一个朴素贝叶斯假设就是条件独立的一个例子。该学习算法对内容做出假设，用来分辨电子邮件是否为垃圾邮件。假设无论邮件是否为垃圾邮件，单词x出现在邮件中的概率条件独立于单词y。很明显这个假设不是不失一般性的，因为某些单词几乎总是同时出现。然而，最终结果是，这个简单的假设对结果的影响并不大，且无论如何都可以让我们快速判别垃圾邮件。</p>
</blockquote>
<h3 id="1-4-2-变量与随机变量有什么区别"><a href="#1-4-2-变量与随机变量有什么区别" class="headerlink" title="1.4.2 变量与随机变量有什么区别"></a>1.4.2 变量与随机变量有什么区别</h3><p><strong>随机变量</strong>（random variable）</p>
<p>表示随机现象（在一定条件下，并不总是出现相同结果的现象称为随机现象）中各种结果的实值函数（一切可能的样本点）。例如某一时间内公共汽车站等车乘客人数，电话交换台在一定时间内收到的呼叫次数等，都是随机变量的实例。<br>​随机变量与模糊变量的不确定性的本质差别在于，后者的测定结果仍具有不确定性，即模糊性。</p>
<p><strong>变量与随机变量的区别：</strong><br>​当变量的取值的概率不是1时,变量就变成了随机变量；当随机变量取值的概率为1时,随机变量就变成了变量。</p>
<blockquote>
<p>比如：<br>​    当变量$x$值为100的概率为1的话,那么$x=100$就是确定了的,不会再有变化,除非有进一步运算.<br>​    当变量$x$的值为100的概率不为1,比如为50的概率是0.5,为100的概率是0.5,那么这个变量就是会随不同条件而变化的,是随机变量,取到50或者100的概率都是0.5,即50%。  </p>
</blockquote>
<h3 id="1-4-3-随机变量与概率分布的联系"><a href="#1-4-3-随机变量与概率分布的联系" class="headerlink" title="1.4.3 随机变量与概率分布的联系"></a>1.4.3 随机变量与概率分布的联系</h3><p>一个随机变量仅仅表示一个可能取得的状态，还必须给定与之相伴的概率分布来制定每个状态的可能性。用来描述随机变量或一簇随机变量的每一个可能的状态的可能性大小的方法，就是 <strong>概率分布(probability distribution)</strong>.</p>
<p>随机变量可以分为离散型随机变量和连续型随机变量。</p>
<p>相应的描述其概率分布的函数是 </p>
<p>概率质量函数(Probability Mass Function, PMF):描述离散型随机变量的概率分布，通常用大写字母 $P$表示。</p>
<p>概率密度函数(Probability Density Function, PDF):描述连续型随机变量的概率分布，通常用小写字母$p$表示。</p>
<h3 id="1-4-4-离散型随机变量和概率质量函数"><a href="#1-4-4-离散型随机变量和概率质量函数" class="headerlink" title="1.4.4 离散型随机变量和概率质量函数"></a>1.4.4 离散型随机变量和概率质量函数</h3><p>PMF 将随机变量能够取得的每个状态映射到随机变量取得该状态的概率。</p>
<ul>
<li>一般而言，$P(x)​$ 表示时$X=x​$的概率.</li>
<li>有时候为了防止混淆，要明确写出随机变量的名称$P(​$x$=x)​$ </li>
<li>有时候需要先定义一个随机变量，然后制定它遵循的概率分布x服从$P(​$x​$)​$ </li>
</ul>
<p>PMF 可以同时作用于多个随机变量，即联合概率分布(joint probability distribution) $P(X=x,Y=y)$*表示 $X=x$和$Y=y$同时发生的概率，也可以简写成 $P(x,y)$.</p>
<p>如果一个函数$P​$是随机变量 $X​$ 的 PMF， 那么它必须满足如下三个条件</p>
<ul>
<li>$P​$的定义域必须是的所有可能状态的集合</li>
<li>$∀x∈​$x, $0 \leq P(x) \leq 1 ​$. </li>
<li>$∑_{x∈X} P(x)=1$. 我们把这一条性质称之为 归一化的(normalized)</li>
</ul>
<h3 id="1-4-5-连续型随机变量和概率密度函数"><a href="#1-4-5-连续型随机变量和概率密度函数" class="headerlink" title="1.4.5 连续型随机变量和概率密度函数"></a>1.4.5 连续型随机变量和概率密度函数</h3><p>如果一个函数$p​$是x的PDF，那么它必须满足如下几个条件</p>
<ul>
<li>$p$的定义域必须是 xx 的所有可能状态的集合。</li>
<li>$∀x∈X,p(x)≥0$. 注意，我们并不要求$ p(x)≤1$，因为此处 $p(x)$不是表示的对应此状态具体的概率，而是概率的一个相对大小(密度)。具体的概率，需要积分去求。</li>
<li>$∫p(x)dx=1$, 积分下来，总和还是1，概率之和还是1.</li>
</ul>
<p>注：PDF$p(x)$并没有直接对特定的状态给出概率，给出的是密度，相对的，它给出了落在面积为 $δx$的无线小的区域内的概率为$ p(x)δx$. 由此，我们无法求得具体某个状态的概率，我们可以求得的是 某个状态 $x$ 落在 某个区间$[a,b]$内的概率为$ \int_{a}^{b}p(x)dx$.</p>
<h3 id="1-4-6-举例理解条件概率"><a href="#1-4-6-举例理解条件概率" class="headerlink" title="1.4.6 举例理解条件概率"></a>1.4.6 举例理解条件概率</h3><p>条件概率公式如下：</p>
<script type="math/tex; mode=display">
P(A|B) = P(A\cap B) / P(B)</script><p>说明：在同一个样本空间$\Omega$中的事件或者子集$A$与$B$，如果随机从$\Omega$中选出的一个元素属于$B$，那么下一个随机选择的元素属于$A$ 的概率就定义为在$B$的前提下$A$的条件概率。条件概率文氏图示意如图1.1所示。<br><img src="/img/ch1/conditional_probability.jpg" alt="条件概率"></p>
<p>图1.1 条件概率文氏图示意</p>
<p>根据文氏图，可以很清楚地看到在事件B发生的情况下，事件A发生的概率就是$P(A\bigcap B)$除以$P(B)$。<br>​举例：一对夫妻有两个小孩，已知其中一个是女孩，则另一个是女孩子的概率是多少？（面试、笔试都碰到过）<br>​<strong>穷举法</strong>：已知其中一个是女孩，那么样本空间为男女，女女，女男，则另外一个仍然是女生的概率就是1/3。<br>​<strong>条件概率法</strong>：$P(女|女)=P(女女)/P(女)$,夫妻有两个小孩，那么它的样本空间为女女，男女，女男，男男，则$P(女女)$为1/4，$P（女）= 1-P(男男)=3/4$,所以最后$1/3$。<br>这里大家可能会误解，男女和女男是同一种情况，但实际上类似姐弟和兄妹是不同情况。 </p>
<h3 id="1-4-7-联合概率与边缘概率联系区别"><a href="#1-4-7-联合概率与边缘概率联系区别" class="headerlink" title="1.4.7 联合概率与边缘概率联系区别"></a>1.4.7 联合概率与边缘概率联系区别</h3><p><strong>区别：</strong><br>​联合概率：联合概率指类似于$P(X=a,Y=b)$这样，包含多个条件，且所有条件同时成立的概率。联合概率是指在多元的概率分布中多个随机变量分别满足各自条件的概率。<br>​边缘概率：边缘概率是某个事件发生的概率，而与其它事件无关。边缘概率指类似于$P(X=a)$，$P(Y=b)$这样，仅与单个随机变量有关的概率。</p>
<p><strong>联系：</strong><br>​联合分布可求边缘分布，但若只知道边缘分布，无法求得联合分布。  </p>
<h3 id="1-4-8-条件概率的链式法则"><a href="#1-4-8-条件概率的链式法则" class="headerlink" title="1.4.8 条件概率的链式法则"></a>1.4.8 条件概率的链式法则</h3><p>由条件概率的定义，可直接得出下面的乘法公式：<br>​乘法公式 设$A, B$是两个事件，并且$P(A) &gt; 0$, 则有 </p>
<script type="math/tex; mode=display">
P(AB) = P(B|A)P(A)</script><p>推广 </p>
<script type="math/tex; mode=display">
P(ABC)=P(C|AB)P(B|A)P(A)</script><p>一般地，用归纳法可证：若$P(A_1A_2…A_n)&gt;0$，则有</p>
<script type="math/tex; mode=display">
P(A_1A_2...A_n)=P(A_n|A_1A_2...A_{n-1})P(A_{n-1}|A_1A_2...A_{n-2})...P(A_2|A_1)P(A_1)
=P(A_1)\prod_{i=2}^{n}P(A_i|A_1A_2...A_{i-1})</script><p>任何多维随机变量联合概率分布，都可以分解成只有一个变量的条件概率相乘形式。 </p>
<h3 id="1-4-9-独立性和条件独立性"><a href="#1-4-9-独立性和条件独立性" class="headerlink" title="1.4.9 独立性和条件独立性"></a>1.4.9 独立性和条件独立性</h3><p><strong>独立性</strong><br>​两个随机变量$x$和$y$，概率分布表示成两个因子乘积形式，一个因子只包含$x$，另一个因子只包含$y$，两个随机变量相互独立(independent)。<br>​条件有时为不独立的事件之间带来独立，有时也会把本来独立的事件，因为此条件的存在，而失去独立性。<br>​举例：$P(XY)=P(X)P(Y)$, 事件$X$和事件$Y$独立。此时给定$Z$，</p>
<script type="math/tex; mode=display">
P(X,Y|Z) \not = P(X|Z)P(Y|Z)</script><p>事件独立时，联合概率等于概率的乘积。这是一个非常好的数学性质，然而不幸的是，无条件的独立是十分稀少的，因为大部分情况下，事件之间都是互相影响的。 </p>
<p><strong>条件独立性</strong><br>​给定$Z$的情况下,$X$和$Y$条件独立，当且仅当</p>
<script type="math/tex; mode=display">
X\bot Y|Z \iff P(X,Y|Z) = P(X|Z)P(Y|Z)</script><p>$X$和$Y$的关系依赖于$Z$，而不是直接产生。  </p>
<blockquote>
<p><strong>举例</strong>定义如下事件：<br>$X$：明天下雨；<br>$Y$：今天的地面是湿的；<br>$Z$：今天是否下雨；<br>$Z$事件的成立，对$X$和$Y$均有影响，然而，在$Z$事件成立的前提下，今天的地面情况对明天是否下雨没有影响。 </p>
</blockquote>
<h2 id="1-5-常见概率分布"><a href="#1-5-常见概率分布" class="headerlink" title="1.5 常见概率分布"></a>1.5 常见概率分布</h2><h3 id="1-5-1-Bernoulli分布"><a href="#1-5-1-Bernoulli分布" class="headerlink" title="1.5.1 Bernoulli分布"></a>1.5.1 Bernoulli分布</h3><p><strong>Bernoulli分布</strong>是单个二值随机变量分布, 单参数$\phi​$∈[0,1]控制,$\phi​$给出随机变量等于1的概率. 主要性质有: </p>
<script type="math/tex; mode=display">
\begin{align*}
P(x=1) &= \phi \\
P(x=0) &= 1-\phi  \\
P(x=x) &= \phi^x(1-\phi)^{1-x} \\
\end{align*}</script><p>其期望和方差为：</p>
<script type="math/tex; mode=display">
\begin{align*}
E_x[x] &= \phi \\
Var_x(x) &= \phi{(1-\phi)}
\end{align*}</script><p><strong>Multinoulli分布</strong>也叫<strong>范畴分布</strong>, 是单个<em>k</em>值随机分布,经常用来表示<strong>对象分类的分布</strong>. 其中$k$是有限值.Multinoulli分布由向量$\vec{p}\in[0,1]^{k-1}$参数化,每个分量$p_i$表示第$i$个状态的概率, 且$p_k=1-1^Tp​$.</p>
<p><strong>适用范围</strong>: <strong>伯努利分布</strong>适合对<strong>离散型</strong>随机变量建模.</p>
<h3 id="1-5-2-高斯分布"><a href="#1-5-2-高斯分布" class="headerlink" title="1.5.2 高斯分布"></a>1.5.2 高斯分布</h3><p>高斯也叫正态分布(Normal Distribution), 概率度函数如下:  </p>
<script type="math/tex; mode=display">
N(x;\mu,\sigma^2) = \sqrt{\frac{1}{2\pi\sigma^2}}exp\left ( -\frac{1}{2\sigma^2}(x-\mu)^2 \right )</script><p>其中, $\mu​$和$\sigma​$分别是均值和方差, 中心峰值x坐标由$\mu​$给出, 峰的宽度受$\sigma​$控制, 最大点在$x=\mu​$处取得, 拐点为$x=\mu\pm\sigma​$</p>
<p>正态分布中，±1$\sigma$、±2$\sigma$、±3$\sigma$下的概率分别是68.3%、95.5%、99.73%，这3个数最好记住。 </p>
<p>此外, 令$\mu=0,\sigma=1​$高斯分布即简化为标准正态分布: </p>
<script type="math/tex; mode=display">
N(x;\mu,\sigma^2) = \sqrt{\frac{1}{2\pi}}exp\left ( -\frac{1}{2}x^2 \right )</script><p>对概率密度函数高效求值: </p>
<script type="math/tex; mode=display">
N(x;\mu,\beta^{-1})=\sqrt{\frac{\beta}{2\pi}}exp\left(-\frac{1}{2}\beta(x-\mu)^2\right)</script><p>其中，$\beta=\frac{1}{\sigma^2}$通过参数$\beta∈（0，\infty）​$来控制分布精度。</p>
<h3 id="1-5-3-何时采用正态分布"><a href="#1-5-3-何时采用正态分布" class="headerlink" title="1.5.3 何时采用正态分布"></a>1.5.3 何时采用正态分布</h3><p>问: 何时采用正态分布?<br>答: 缺乏实数上分布的先验知识, 不知选择何种形式时, 默认选择正态分布总是不会错的, 理由如下: </p>
<ol>
<li>中心极限定理告诉我们, 很多独立随机变量均近似服从正态分布, 现实中很多复杂系统都可以被建模成正态分布的噪声, 即使该系统可以被结构化分解. </li>
<li>正态分布是具有相同方差的所有概率分布中, 不确定性最大的分布, 换句话说, 正态分布是对模型加入先验知识最少的分布.</li>
</ol>
<p>正态分布的推广:<br>正态分布可以推广到$R^n$空间, 此时称为<strong>多位正态分布</strong>, 其参数是一个正定对称矩阵$\Sigma​$: </p>
<script type="math/tex; mode=display">
N(x;\vec\mu,\Sigma)=\sqrt{\frac{1}{(2\pi)^ndet(\Sigma)}}exp\left(-\frac{1}{2}(\vec{x}-\vec{\mu})^T\Sigma^{-1}(\vec{x}-\vec{\mu})\right)</script><p>对多为正态分布概率密度高效求值: </p>
<script type="math/tex; mode=display">
N(x;\vec{\mu},\vec\beta^{-1}) = \sqrt{det(\vec\beta)}{(2\pi)^n}exp\left(-\frac{1}{2}(\vec{x}-\vec\mu)^T\beta(\vec{x}-\vec\mu)\right)</script><p>此处，$\vec\beta$是一个精度矩阵。</p>
<h3 id="1-5-4-指数分布"><a href="#1-5-4-指数分布" class="headerlink" title="1.5.4 指数分布"></a>1.5.4 指数分布</h3><p>深度学习中, 指数分布用来描述在$x=0​$点处取得边界点的分布, 指数分布定义如下:</p>
<script type="math/tex; mode=display">
p(x;\lambda)=\lambda I_{x\geq 0}exp(-\lambda{x})</script><p>指数分布用指示函数$I_{x\geq 0}​$来使$x​$取负值时的概率为零。</p>
<h3 id="1-5-5-Laplace-分布"><a href="#1-5-5-Laplace-分布" class="headerlink" title="1.5.5 Laplace 分布"></a>1.5.5 Laplace 分布</h3><p>一个联系紧密的概率分布是 Laplace 分布（Laplace distribution），它允许我们在任意一点 $\mu$处设置概率质量的峰值</p>
<script type="math/tex; mode=display">
Laplace(x;\mu;\gamma)=\frac{1}{2\gamma}exp\left(-\frac{|x-\mu|}{\gamma}\right)</script><h3 id="1-5-6-Dirac分布和经验分布"><a href="#1-5-6-Dirac分布和经验分布" class="headerlink" title="1.5.6 Dirac分布和经验分布"></a>1.5.6 Dirac分布和经验分布</h3><p>Dirac分布可保证概率分布中所有质量都集中在一个点上. Diract分布的狄拉克$\delta​$函数(也称为<strong>单位脉冲函数</strong>)定义如下: </p>
<script type="math/tex; mode=display">
p(x)=\delta(x-\mu), x\neq \mu</script><script type="math/tex; mode=display">
\int_{a}^{b}\delta(x-\mu)dx = 1, a < \mu < b</script><p>Dirac 分布经常作为 经验分布（empirical distribution）的一个组成部分出现</p>
<script type="math/tex; mode=display">
\hat{p}(\vec{x})=\frac{1}{m}\sum_{i=1}^{m}\delta(\vec{x}-{\vec{x}}^{(i)})</script><p>, 其中, m个点$x^{1},…,x^{m}$是给定的数据集, <strong>经验分布</strong>将概率密度$\frac{1}{m}​$赋给了这些点.</p>
<p>当我们在训练集上训练模型时, 可以认为从这个训练集上得到的经验分布指明了<strong>采样来源</strong>.</p>
<p><strong>适用范围</strong>: 狄拉克δ函数适合对<strong>连续型</strong>随机变量的经验分布.</p>
<p>&gt;</p>
<h2 id="1-6-期望、方差、协方差、相关系数"><a href="#1-6-期望、方差、协方差、相关系数" class="headerlink" title="1.6 期望、方差、协方差、相关系数"></a>1.6 期望、方差、协方差、相关系数</h2><h3 id="1-6-1-期望"><a href="#1-6-1-期望" class="headerlink" title="1.6.1 期望"></a>1.6.1 期望</h3><p>在概率论和统计学中，数学期望（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和。它反映随机变量平均取值的大小。</p>
<ul>
<li>线性运算： $E(ax+by+c) = aE(x)+bE(y)+c$  </li>
<li>推广形式： $E(\sum_{k=1}^{n}{a_ix_i+c}) = \sum_{k=1}^{n}{a_iE(x_i)+c}$ </li>
<li>函数期望：设$f(x)$为$x$的函数，则$f(x)$的期望为<ul>
<li>离散函数： $E(f(x))=\sum_{k=1}^{n}{f(x_k)P(x_k)}$</li>
<li>连续函数： $E(f(x))=\int_{-\infty}^{+\infty}{f(x)p(x)dx}$</li>
</ul>
</li>
</ul>
<blockquote>
<p>注意：</p>
<ul>
<li>函数的期望大于等于期望的函数（Jensen不等式），即$E(f(x))\geqslant f(E(x))$  </li>
<li>一般情况下，乘积的期望不等于期望的乘积。  </li>
<li>如果$X$和$Y$相互独立，则$E(xy)=E(x)E(y)​$。  </li>
</ul>
</blockquote>
<h3 id="1-6-2-方差"><a href="#1-6-2-方差" class="headerlink" title="1.6.2 方差"></a>1.6.2 方差</h3><p>概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。方差是一种特殊的期望。定义为：</p>
<script type="math/tex; mode=display">
Var(x) = E((x-E(x))^2)</script><blockquote>
<p>方差性质：  </p>
<p>1）$Var(x) = E(x^2) -E(x)^2$<br>2）常数的方差为0;<br>3）方差不满足线性性质;<br>4）如果$X$和$Y$相互独立, $Var(ax+by)=a^2Var(x)+b^2Var(y)$   </p>
</blockquote>
<h3 id="1-6-3-协方差"><a href="#1-6-3-协方差" class="headerlink" title="1.6.3 协方差"></a>1.6.3 协方差</h3><p>协方差是衡量两个变量线性相关性强度及变量尺度。  两个随机变量的协方差定义为：</p>
<script type="math/tex; mode=display">
Cov(x,y)=E((x-E(x))(y-E(y)))</script><p>方差是一种特殊的协方差。当$X=Y$时，$Cov(x,y)=Var(x)=Var(y)$。</p>
<blockquote>
<p>协方差性质：  </p>
<p>1）独立变量的协方差为0。<br>2）协方差计算公式：</p>
</blockquote>
<script type="math/tex; mode=display">
Cov(\sum_{i=1}^{m}{a_ix_i}, \sum_{j=1}^{m}{b_jy_j}) = \sum_{i=1}^{m} \sum_{j=1}^{m}{a_ib_jCov(x_iy_i)}</script><p>&gt;</p>
<blockquote>
<p>3）特殊情况：</p>
</blockquote>
<script type="math/tex; mode=display">
Cov(a+bx, c+dy) = bdCov(x, y)</script><h3 id="1-6-4-相关系数"><a href="#1-6-4-相关系数" class="headerlink" title="1.6.4 相关系数"></a>1.6.4 相关系数</h3><p>相关系数是研究变量之间线性相关程度的量。两个随机变量的相关系数定义为：</p>
<script type="math/tex; mode=display">
Corr(x,y) = \frac{Cov(x,y)}{\sqrt{Var(x)Var(y)}}</script><blockquote>
<p>相关系数的性质：<br>1）有界性。相关系数的取值范围是 [-1,1]，可以看成无量纲的协方差。<br>2）值越接近1，说明两个变量正相关性（线性）越强。越接近-1，说明负相关性越强，当为0时，表示两个变量没有相关性。  </p>
</blockquote>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]Ian，Goodfellow，Yoshua，Bengio，Aaron…深度学习[M]，人民邮电出版，2017</p>
<p>[2]周志华.机器学习[M].清华大学出版社，2016.</p>
<p>[3]同济大学数学系.高等数学（第七版）[M]，高等教育出版社，2014.</p>
<p>[4]盛骤，试式千，潘承毅等编. 概率论与数理统计（第4版）[M]，高等教育出版社，2008</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/03/03/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/03/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">第二章_机器学习基础知识</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-03 12:13:21 / 修改时间：14:38:56" itemprop="dateCreated datePublished" datetime="2020-03-03T12:13:21+08:00">2020-03-03</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="第二章-机器学习基础"><a href="#第二章-机器学习基础" class="headerlink" title="第二章 机器学习基础"></a>第二章 机器学习基础</h1><p>​    机器学习起源于上世纪50年代，1959年在IBM工作的Arthur Samuel设计了一个下棋程序，这个程序具有学习的能力，它可以在不断的对弈中提高自己。由此提出了“机器学习”这个概念，它是一个结合了多个学科如概率论，优化理论，统计等，最终在计算机上实现自我获取新知识，学习改善自己的这样一个研究领域。机器学习是人工智能的一个子集，目前已经发展出许多有用的方法，比如支持向量机，回归，决策树，随机森林，强化方法，集成学习，深度学习等等，一定程度上可以帮助人们完成一些数据预测，自动化，自动决策，最优化等初步替代脑力的任务。本章我们主要介绍下机器学习的基本概念、监督学习、分类算法、逻辑回归、代价函数、损失函数、LDA、PCA、决策树、支持向量机、EM算法、聚类和降维以及模型评估有哪些方法、指标等等。</p>
<h2 id="2-1-基本概念"><a href="#2-1-基本概念" class="headerlink" title="2.1 基本概念"></a>2.1 基本概念</h2><h3 id="2-1-1-大话理解机器学习本质"><a href="#2-1-1-大话理解机器学习本质" class="headerlink" title="2.1.1 大话理解机器学习本质"></a>2.1.1 大话理解机器学习本质</h3><p>​    机器学习(Machine Learning, ML)，顾名思义，让机器去学习。这里，机器指的是计算机，是算法运行的物理载体，你也可以把各种算法本身当做一个有输入和输出的机器。那么到底让计算机去学习什么呢？对于一个任务及其表现的度量方法，设计一种算法，让算法能够提取中数据所蕴含的规律，这就叫机器学习。如果输入机器的数据是带有标签的，就称作有监督学习。如果数据是无标签的，就是无监督学习。</p>
<h3 id="2-1-2-什么是神经网络"><a href="#2-1-2-什么是神经网络" class="headerlink" title="2.1.2 什么是神经网络"></a>2.1.2 什么是神经网络</h3><p>​    神经网络就是按照一定规则将多个神经元连接起来的网络。不同的神经网络，具有不同的连接规则。例如全连接(Full Connected, FC)神经网络，它的规则包括：</p>
<p>（1）有三种层：输入层，输出层，隐藏层。</p>
<p>（2）同一层的神经元之间没有连接。</p>
<p>（3）fully connected的含义：第 N 层的每个神经元和第 N-1 层的所有神经元相连，第 N-1 层神经元的输出就是第 N 层神经元的输入。</p>
<p>（4）每个连接都有一个权值。</p>
<p><strong>神经网络架构</strong><br>​    图2-1就是一个神经网络系统，它由很多层组成。输入层负责接收信息，比如一只猫的图片。输出层是计算机对这个输入信息的判断结果，它是不是猫。隐藏层就是对输入信息的传递和加工处理。<br><img src="/img/ch2/2.5.1.png" alt="图2-2 神经网络系统"></p>
<p>​                                图2-1 神经网络系统</p>
<h3 id="2-1-3-各种常见算法图示"><a href="#2-1-3-各种常见算法图示" class="headerlink" title="2.1.3 各种常见算法图示"></a>2.1.3 各种常见算法图示</h3><p>​    日常使用机器学习的任务中，我们经常会遇见各种算法，图2-2是各种常见算法的图示。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">回归算法</th>
<th style="text-align:center">聚类算法</th>
<th style="text-align:center">正则化方法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/img/ch2/2.1/1.jpg" alt=""></td>
<td style="text-align:center"><img src="/img/ch2/2.1/2.jpg" alt=""></td>
<td style="text-align:center"><img src="/img/ch2/2.1/3.jpg" alt=""></td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">决策树学习</th>
<th style="text-align:center">贝叶斯方法</th>
<th style="text-align:center">基于核的算法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/img/ch2/2.2.4.png" alt=""></td>
<td style="text-align:center"><img src="/img/ch2/2.1/5.jpg" alt=""></td>
<td style="text-align:center"><img src="/img/ch2/2.1/6.jpg" alt=""></td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">聚类算法</th>
<th style="text-align:center">关联规则学习</th>
<th style="text-align:center">人工神经网络</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/img/ch2/2.1/7.jpg" alt=""></td>
<td style="text-align:center"><img src="/img/ch2/2.2.8.png" alt=""></td>
<td style="text-align:center"><img src="/img/ch2/2.2.09.png" alt=""></td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">深度学习</th>
<th style="text-align:center">降低维度算法</th>
<th style="text-align:center">集成算法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/img/ch2/2.2.10.png" alt=""></td>
<td style="text-align:center"><img src="/img/ch2/2.2.11.png" alt=""></td>
<td style="text-align:center"><img src="/img/ch2/2.2.12.png" alt=""></td>
</tr>
</tbody>
</table>
</div>
<p>​                                        图2-2 各种常见算法图示</p>
<h3 id="2-1-4-计算图的导数计算"><a href="#2-1-4-计算图的导数计算" class="headerlink" title="2.1.4 计算图的导数计算"></a>2.1.4 计算图的导数计算</h3><p>​    计算图导数计算是反向传播，利用链式法则和隐式函数求导。</p>
<p>​    假设 $z = f(u,v)$ 在点 $(u,v)$ 处偏导连续，$(u,v)$是关于 $t$ 的函数，在 $t$ 点可导，求 $z$ 在 $t$ 点的导数。</p>
<p>根据链式法则有</p>
<script type="math/tex; mode=display">
\frac{dz}{dt}=\frac{\partial z}{\partial u}.\frac{du}{dt}+\frac{\partial z}{\partial v}
                .\frac{dv}{dt}</script><p>​    链式法则用文字描述:“由两个函数凑起来的复合函数，其导数等于里边函数代入外边函数的值之导数，乘以里边函数的导数。<br>​    为了便于理解，下面举例说明：</p>
<script type="math/tex; mode=display">
f(x)=x^2,g(x)=2x+1</script><p>​    则:</p>
<script type="math/tex; mode=display">
{f[g(x)]}'=2[g(x)] \times g'(x)=2[2x+1] \times 2=8x+4</script><h3 id="2-1-5-理解局部最优与全局最优"><a href="#2-1-5-理解局部最优与全局最优" class="headerlink" title="2.1.5 理解局部最优与全局最优"></a>2.1.5 理解局部最优与全局最优</h3><p>​    笑谈局部最优和全局最优</p>
<blockquote>
<p>​    柏拉图有一天问老师苏格拉底什么是爱情？苏格拉底叫他到麦田走一次，摘一颗最大的麦穗回来，不许回头，只可摘一次。柏拉图空着手出来了，他的理由是，看见不错的，却不知道是不是最好的，一次次侥幸，走到尽头时，才发现还不如前面的，于是放弃。苏格拉底告诉他：“这就是爱情。”这故事让我们明白了一个道理，因为生命的一些不确定性，所以全局最优解是很难寻找到的，或者说根本就不存在，我们应该设置一些限定条件，然后在这个范围内寻找最优解，也就是局部最优解——有所斩获总比空手而归强，哪怕这种斩获只是一次有趣的经历。<br>​    柏拉图有一天又问什么是婚姻？苏格拉底叫他到树林走一次,选一棵最好的树做圣诞树，也是不许回头，只许选一次。这次他一身疲惫地拖了一棵看起来直挺、翠绿，却有点稀疏的杉树回来，他的理由是，有了上回的教训，好不容易看见一棵看似不错的，又发现时间、体力已经快不够用了，也不管是不是最好的，就拿回来了。苏格拉底告诉他：“这就是婚姻。”</p>
</blockquote>
<p>​    优化问题一般分为局部最优和全局最优。其中，</p>
<p>（1）局部最优，就是在函数值空间的一个有限区域内寻找最小值；而全局最优，是在函数值空间整个区域寻找最小值问题。</p>
<p>（2）函数局部最小点是它的函数值小于或等于附近点的点，但是有可能大于较远距离的点。</p>
<p>（3）全局最小点是那种它的函数值小于或等于所有的可行点。</p>
<h3 id="2-1-5-大数据与深度学习之间的关系"><a href="#2-1-5-大数据与深度学习之间的关系" class="headerlink" title="2.1.5 大数据与深度学习之间的关系"></a>2.1.5 大数据与深度学习之间的关系</h3><p>首先来看大数据、机器学习及数据挖掘三者简单的定义：</p>
<p><strong>大数据</strong>通常被定义为“超出常用软件工具捕获，管理和处理能力”的数据集。<br><strong>机器学习</strong>关心的问题是如何构建计算机程序使用经验自动改进。<br><strong>数据挖掘</strong>是从数据中提取模式的特定算法的应用，在数据挖掘中，重点在于算法的应用，而不是算法本身。</p>
<p><strong>机器学习和数据挖掘</strong>之间的关系如下：<br>数据挖掘是一个过程，在此过程中机器学习算法被用作提取数据集中的潜在有价值模式的工具。<br>大数据与深度学习关系总结如下：</p>
<p>（1）深度学习是一种模拟大脑的行为。可以从所学习对象的机制以及行为等等很多相关联的方面进行学习，模仿类型行为以及思维。</p>
<p>（2）深度学习对于大数据的发展有帮助。深度学习对于大数据技术开发的每一个阶段均有帮助，不管是数据的分析还是挖掘还是建模，只有深度学习，这些工作才会有可能一一得到实现。</p>
<p>（3）深度学习转变了解决问题的思维。很多时候发现问题到解决问题，走一步看一步不是一个主要的解决问题的方式了，在深度学习的基础上，要求我们从开始到最后都要基于一个目标，为了需要优化的那个最终目标去进行处理数据以及将数据放入到数据应用平台上去，这就是端到端（End to End）。</p>
<p>（4）大数据的深度学习需要一个框架。在大数据方面的深度学习都是从基础的角度出发的，深度学习需要一个框架或者一个系统。总而言之，将你的大数据通过深度分析变为现实，这就是深度学习和大数据的最直接关系。</p>
<h2 id="2-2-机器学习学习方式"><a href="#2-2-机器学习学习方式" class="headerlink" title="2.2 机器学习学习方式"></a>2.2 机器学习学习方式</h2><p>​    根据数据类型的不同，对一个问题的建模有不同的方式。依据不同的学习方式和输入数据，机器学习主要分为以下四种学习方式。</p>
<h3 id="2-2-1-监督学习"><a href="#2-2-1-监督学习" class="headerlink" title="2.2.1 监督学习"></a>2.2.1 监督学习</h3><p>​    特点：监督学习是使用已知正确答案的示例来训练网络。已知数据和其一一对应的标签，训练一个预测模型，将输入数据映射到标签的过程。</p>
<p>​    常见应用场景：监督式学习的常见应用场景如分类问题和回归问题。</p>
<p>​    算法举例：常见的有监督机器学习算法包括支持向量机(Support Vector Machine, SVM)，朴素贝叶斯(Naive Bayes)，逻辑回归(Logistic Regression)，K近邻(K-Nearest Neighborhood, KNN)，决策树(Decision Tree)，随机森林(Random Forest)，AdaBoost以及线性判别分析(Linear Discriminant Analysis, LDA)等。深度学习(Deep Learning)也是大多数以监督学习的方式呈现。</p>
<h3 id="2-2-2-非监督式学习"><a href="#2-2-2-非监督式学习" class="headerlink" title="2.2.2 非监督式学习"></a>2.2.2 非监督式学习</h3><p>​    定义：在非监督式学习中，数据并不被特别标识，适用于你具有数据集但无标签的情况。学习模型是为了推断出数据的一些内在结构。</p>
<p>​    常见应用场景：常见的应用场景包括关联规则的学习以及聚类等。</p>
<p>​    算法举例：常见算法包括Apriori算法以及k-Means算法。</p>
<h3 id="2-2-3-半监督式学习"><a href="#2-2-3-半监督式学习" class="headerlink" title="2.2.3 半监督式学习"></a>2.2.3 半监督式学习</h3><p>​    特点：在此学习方式下，输入数据部分被标记，部分没有被标记，这种学习模型可以用来进行预测。</p>
<p>​    常见应用场景：应用场景包括分类和回归，算法包括一些对常用监督式学习算法的延伸，通过对已标记数据建模，在此基础上，对未标记数据进行预测。</p>
<p>​    算法举例：常见算法如图论推理算法（Graph Inference）或者拉普拉斯支持向量机（Laplacian SVM）等。</p>
<h3 id="2-2-4-弱监督学习"><a href="#2-2-4-弱监督学习" class="headerlink" title="2.2.4 弱监督学习"></a>2.2.4 弱监督学习</h3><p>​    特点：弱监督学习可以看做是有多个标记的数据集合，次集合可以是空集，单个元素，或包含多种情况（没有标记，有一个标记，和有多个标记）的多个元素。 数据集的标签是不可靠的，这里的不可靠可以是标记不正确，多种标记，标记不充分，局部标记等。已知数据和其一一对应的弱标签，训练一个智能算法，将输入数据映射到一组更强的标签的过程。标签的强弱指的是标签蕴含的信息量的多少，比如相对于分割的标签来说，分类的标签就是弱标签。</p>
<p>​    算法举例：举例，给出一张包含气球的图片，需要得出气球在图片中的位置及气球和背景的分割线，这就是已知弱标签学习强标签的问题。</p>
<p>​    在企业数据应用的场景下， 人们最常用的可能就是监督式学习和非监督式学习的模型。 在图像识别等领域，由于存在大量的非标识的数据和少量的可标识数据， 目前半监督式学习是一个很热的话题。</p>
<h3 id="2-2-5-监督学习有哪些步骤"><a href="#2-2-5-监督学习有哪些步骤" class="headerlink" title="2.2.5 监督学习有哪些步骤"></a>2.2.5 监督学习有哪些步骤</h3><p>​    监督学习是使用已知正确答案的示例来训练网络，每组训练数据有一个明确的标识或结果。想象一下，我们可以训练一个网络，让其从照片库中（其中包含气球的照片）识别出气球的照片。以下就是我们在这个假设场景中所要采取的步骤。</p>
<p><strong>步骤1：数据集的创建和分类</strong><br>​    首先，浏览你的照片（数据集），确定所有包含气球的照片，并对其进行标注。然后，将所有照片分为训练集和验证集。目标就是在深度网络中找一函数，这个函数输入是任意一张照片，当照片中包含气球时，输出1，否则输出0。</p>
<p><strong>步骤2：数据增强（Data Augmentation）</strong><br>​    当原始数据搜集和标注完毕，一般搜集的数据并不一定包含目标在各种扰动下的信息。数据的好坏对于机器学习模型的预测能力至关重要，因此一般会进行数据增强。对于图像数据来说，数据增强一般包括，图像旋转，平移，颜色变换，裁剪，仿射变换等。</p>
<p><strong>步骤3：特征工程（Feature Engineering）</strong><br>​    一般来讲，特征工程包含特征提取和特征选择。常见的手工特征(Hand-Crafted Feature)有尺度不变特征变换(Scale-Invariant Feature Transform, SIFT)，方向梯度直方图(Histogram of Oriented Gradient, HOG)等。由于手工特征是启发式的，其算法设计背后的出发点不同，将这些特征组合在一起的时候有可能会产生冲突，如何将组合特征的效能发挥出来，使原始数据在特征空间中的判别性最大化，就需要用到特征选择的方法。在深度学习方法大获成功之后，人们很大一部分不再关注特征工程本身。因为，最常用到的卷积神经网络(Convolutional Neural Networks, CNNs)本身就是一种特征提取和选择的引擎。研究者提出的不同的网络结构、正则化、归一化方法实际上就是深度学习背景下的特征工程。</p>
<p><strong>步骤4：构建预测模型和损失</strong><br>​    将原始数据映射到特征空间之后，也就意味着我们得到了比较合理的输入。下一步就是构建合适的预测模型得到对应输入的输出。而如何保证模型的输出和输入标签的一致性，就需要构建模型预测和标签之间的损失函数，常见的损失函数(Loss Function)有交叉熵、均方差等。通过优化方法不断迭代，使模型从最初的初始化状态一步步变化为有预测能力的模型的过程，实际上就是学习的过程。</p>
<p><strong>步骤5：训练</strong><br>​    选择合适的模型和超参数进行初始化，其中超参数比如支持向量机中核函数、误差项惩罚权重等。当模型初始化参数设定好后，将制作好的特征数据输入到模型，通过合适的优化方法不断缩小输出与标签之间的差距，当迭代过程到了截止条件，就可以得到训练好的模型。优化方法最常见的就是梯度下降法及其变种，使用梯度下降法的前提是优化目标函数对于模型是可导的。</p>
<p><strong>步骤6：验证和模型选择</strong><br>​    训练完训练集图片后，需要进行模型测试。利用验证集来验证模型是否可以准确地挑选出含有气球在内的照片。<br>​    在此过程中，通常会通过调整和模型相关的各种事物（超参数）来重复步骤2和3，诸如里面有多少个节点，有多少层，使用怎样的激活函数和损失函数，如何在反向传播阶段积极有效地训练权值等等。</p>
<p><strong>步骤7：测试及应用</strong><br>​    当有了一个准确的模型，就可以将该模型部署到你的应用程序中。你可以将预测功能发布为API（Application Programming Interface, 应用程序编程接口）调用，并且你可以从软件中调用该API，从而进行推理并给出相应的结果。</p>
<h2 id="2-8-分类算法"><a href="#2-8-分类算法" class="headerlink" title="2.8 分类算法"></a>2.8 分类算法</h2><p>​    分类算法和回归算法是对真实世界不同建模的方法。分类模型是认为模型的输出是离散的，例如大自然的生物被划分为不同的种类，是离散的。回归模型的输出是连续的，例如人的身高变化过程是一个连续过程，而不是离散的。</p>
<p>​    因此，在实际建模过程时，采用分类模型还是回归模型，取决于你对任务（真实世界）的分析和理解。</p>
<h3 id="2-8-1-常用分类算法的优缺点？"><a href="#2-8-1-常用分类算法的优缺点？" class="headerlink" title="2.8.1 常用分类算法的优缺点？"></a>2.8.1 常用分类算法的优缺点？</h3><p>​    接下来我们介绍常用分类算法的优缺点，如表2-1所示。</p>
<p>​                                    表2-1 常用分类算法的优缺点</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">算法</th>
<th style="text-align:left">优点</th>
<th style="text-align:left">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Bayes 贝叶斯分类法</td>
<td style="text-align:left">1）所需估计的参数少，对于缺失数据不敏感。<br />2）有着坚实的数学基础，以及稳定的分类效率。</td>
<td style="text-align:left">1）需要假设属性之间相互独立，这往往并不成立。（喜欢吃番茄、鸡蛋，却不喜欢吃番茄炒蛋）。<br />2）需要知道先验概率。<br />3）分类决策存在错误率。</td>
</tr>
<tr>
<td style="text-align:left">Decision Tree决策树</td>
<td style="text-align:left">1）不需要任何领域知识或参数假设。<br />2）适合高维数据。<br />3）简单易于理解。<br />4）短时间内处理大量数据，得到可行且效果较好的结果。<br />5）能够同时处理数据型和常规性属性。</td>
<td style="text-align:left">1）对于各类别样本数量不一致数据，信息增益偏向于那些具有更多数值的特征。<br />2）易于过拟合。<br />3）忽略属性之间的相关性。<br />4）不支持在线学习。</td>
</tr>
<tr>
<td style="text-align:left">SVM支持向量机</td>
<td style="text-align:left">1）可以解决小样本下机器学习的问题。<br />2）提高泛化性能。<br />3）可以解决高维、非线性问题。超高维文本分类仍受欢迎。<br />4）避免神经网络结构选择和局部极小的问题。</td>
<td style="text-align:left">1）对缺失数据敏感。<br />2）内存消耗大，难以解释。<br />3）运行和调参略烦人。</td>
</tr>
<tr>
<td style="text-align:left">KNN K近邻</td>
<td style="text-align:left">1）思想简单，理论成熟，既可以用来做分类也可以用来做回归； <br />2）可用于非线性分类；<br /> 3）训练时间复杂度为O(n)； <br />4）准确度高，对数据没有假设，对outlier不敏感；</td>
<td style="text-align:left">1）计算量太大。<br />2）对于样本分类不均衡的问题，会产生误判。<br />3）需要大量的内存。<br />4）输出的可解释性不强。</td>
</tr>
<tr>
<td style="text-align:left">Logistic Regression逻辑回归</td>
<td style="text-align:left">1）速度快。<br />2）简单易于理解，直接看到各个特征的权重。<br />3）能容易地更新模型吸收新的数据。<br />4）如果想要一个概率框架，动态调整分类阀值。</td>
<td style="text-align:left">特征处理复杂。需要归一化和较多的特征工程。</td>
</tr>
<tr>
<td style="text-align:left">Neural Network 神经网络</td>
<td style="text-align:left">1）分类准确率高。<br />2）并行处理能力强。<br />3）分布式存储和学习能力强。<br />4）鲁棒性较强，不易受噪声影响。</td>
<td style="text-align:left">1）需要大量参数（网络拓扑、阀值、阈值）。<br />2）结果难以解释。<br />3）训练时间过长。</td>
</tr>
<tr>
<td style="text-align:left">Adaboosting</td>
<td style="text-align:left">1）adaboost是一种有很高精度的分类器。<br />2）可以使用各种方法构建子分类器，Adaboost算法提供的是框架。<br />3）当使用简单分类器时，计算出的结果是可以理解的。而且弱分类器构造极其简单。<br />4）简单，不用做特征筛选。<br />5）不用担心overfitting。</td>
<td style="text-align:left">对outlier比较敏感</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-8-2-分类算法的评估方法"><a href="#2-8-2-分类算法的评估方法" class="headerlink" title="2.8.2 分类算法的评估方法"></a>2.8.2 分类算法的评估方法</h3><p>​    分类评估方法主要功能是用来评估分类算法的好坏，而评估一个分类器算法的好坏又包括许多项指标。了解各种评估方法，在实际应用中选择正确的评估方法是十分重要的。</p>
<ul>
<li><p><strong>几个常用术语</strong><br>​    这里首先介绍几个常见的模型评价术语，现在假设我们的分类目标只有两类，计为正例（positive）和负例（negative）分别是：<br> 1) True positives(TP):  被正确地划分为正例的个数，即实际为正例且被分类器划分为正例的实例数；<br> 2) False positives(FP): 被错误地划分为正例的个数，即实际为负例但被分类器划分为正例的实例数；<br> 3) False negatives(FN):被错误地划分为负例的个数，即实际为正例但被分类器划分为负例的实例数；<br> 4) True negatives(TN): 被正确地划分为负例的个数，即实际为负例且被分类器划分为负例的实例数。　</p>
<p>​                                    表2-2 四个术语的混淆矩阵</p>
</li>
</ul>
<p><img src="/img/ch2/2.9/1.png" alt="图2-3 术语的混淆矩阵"></p>
<p>表2-2是这四个术语的混淆矩阵，做以下说明：<br>    1）P=TP+FN表示实际为正例的样本个数。<br>    2）True、False描述的是分类器是否判断正确。<br>    3）Positive、Negative是分类器的分类结果，如果正例计为1、负例计为-1，即positive=1、negative=-1。用1表示True，-1表示False，那么实际的类标=TF*PN，TF为true或false，PN为positive或negative。<br>    4）例如True positives(TP)的实际类标=1*1=1为正例，False positives(FP)的实际类标=(-1)*1=-1为负例，False negatives(FN)的实际类标=(-1)*(-1)=1为正例，True negatives(TN)的实际类标=1*(-1)=-1为负例。</p>
<ul>
<li><p><strong>评价指标</strong><br>1) 正确率（accuracy）</p>
<pre><code>正确率是我们最常见的评价指标，accuracy = (TP+TN)/(P+N)，正确率是被分对的样本数在所有样本数中的占比，通常来说，正确率越高，分类器越好。
</code></pre><p>2) 错误率（error rate)</p>
<pre><code>错误率则与正确率相反，描述被分类器错分的比例，error rate = (FP+FN)/(P+N)，对某一个实例来说，分对与分错是互斥事件，所以accuracy =1 -  error rate。
</code></pre><p>3) 灵敏度（sensitivity）</p>
<pre><code>sensitivity = TP/P，表示的是所有正例中被分对的比例，衡量了分类器对正例的识别能力。
</code></pre><p>4) 特异性（specificity)</p>
<pre><code>specificity = TN/N，表示的是所有负例中被分对的比例，衡量了分类器对负例的识别能力。
</code></pre><p>5) 精度（precision）</p>
<pre><code>precision=TP/(TP+FP)，精度是精确性的度量，表示被分为正例的示例中实际为正例的比例。
</code></pre><p>6) 召回率（recall）</p>
<pre><code>召回率是覆盖面的度量，度量有多个正例被分为正例，recall=TP/(TP+FN)=TP/P=sensitivity，可以看到召回率与灵敏度是一样的。
</code></pre><p>7) 其他评价指标</p>
<pre><code>计算速度：分类器训练和预测需要的时间；
鲁棒性：处理缺失值和异常值的能力；
可扩展性：处理大数据集的能力；
可解释性：分类器的预测标准的可理解性，像决策树产生的规则就是很容易理解的，而神经网络的一堆参数就不好理解，我们只好把它看成一个黑盒子。
</code></pre><p>8) 精度和召回率反映了分类器分类性能的两个方面。如果综合考虑查准率与查全率，可以得到新的评价指标F1-score，也称为综合分类率：$F1=\frac{2 \times precision \times recall}{precision + recall}​$。</p>
<pre><code>  为了综合多个类别的分类情况，评测系统整体性能，经常采用的还有微平均F1（micro-averaging）和宏平均F1（macro-averaging ）两种指标。

  （1）宏平均F1与微平均F1是以两种不同的平均方式求的全局F1指标。

  （2）宏平均F1的计算方法先对每个类别单独计算F1值，再取这些F1值的算术平均值作为全局指标。

  （3）微平均F1的计算方法是先累加计算各个类别的a、b、c、d的值，再由这些值求出F1值。

  （4）由两种平均F1的计算方式不难看出，宏平均F1平等对待每一个类别，所以它的值主要受到稀有类别的影响，而微平均F1平等考虑文档集中的每一个文档，所以它的值受到常见类别的影响比较大。
</code></pre></li>
</ul>
<ul>
<li><p><strong>ROC曲线和PR曲线</strong></p>
<pre><code>  如图2-3，ROC曲线是（Receiver Operating Characteristic Curve，受试者工作特征曲线）的简称，是以灵敏度（真阳性率）为纵坐标，以1减去特异性（假阳性率）为横坐标绘制的性能评价曲线。可以将不同模型对同一数据集的ROC曲线绘制在同一笛卡尔坐标系中，ROC曲线越靠近左上角，说明其对应模型越可靠。也可以通过ROC曲线下面的面积（Area Under Curve, AUC）来评价模型，AUC越大，模型越可靠。
</code></pre></li>
</ul>
<p><img src="/img/ch2/2.7.3.png" alt=""></p>
<p>​                                                                             图2-3 ROC曲线</p>
<p>​    PR曲线是Precision Recall Curve的简称，描述的是precision和recall之间的关系，以recall为横坐标，precision为纵坐标绘制的曲线。该曲线的所对应的面积AUC实际上是目标检测中常用的评价指标平均精度（Average Precision, AP）。AP越高，说明模型性能越好。</p>
<h3 id="2-8-3-正确率能很好的评估分类算法吗"><a href="#2-8-3-正确率能很好的评估分类算法吗" class="headerlink" title="2.8.3 正确率能很好的评估分类算法吗"></a>2.8.3 正确率能很好的评估分类算法吗</h3><p>​    不同算法有不同特点，在不同数据集上有不同的表现效果，根据特定的任务选择不同的算法。如何评价分类算法的好坏，要做具体任务具体分析。对于决策树，主要用正确率去评估，但是其他算法，只用正确率能很好的评估吗？<br>​    答案是否定的。<br>​    正确率确实是一个很直观很好的评价指标，但是有时候正确率高并不能完全代表一个算法就好。比如对某个地区进行地震预测，地震分类属性分为0：不发生地震、1发生地震。我们都知道，不发生的概率是极大的，对于分类器而言，如果分类器不加思考，对每一个测试样例的类别都划分为0，达到99%的正确率，但是，问题来了，如果真的发生地震时，这个分类器毫无察觉，那带来的后果将是巨大的。很显然，99%正确率的分类器并不是我们想要的。出现这种现象的原因主要是数据分布不均衡，类别为1的数据太少，错分了类别1但达到了很高的正确率缺忽视了研究者本身最为关注的情况。</p>
<h3 id="2-8-4-什么样的分类器是最好的"><a href="#2-8-4-什么样的分类器是最好的" class="headerlink" title="2.8.4 什么样的分类器是最好的"></a>2.8.4 什么样的分类器是最好的</h3><p>​    对某一个任务，某个具体的分类器不可能同时满足或提高所有上面介绍的指标。<br>​    如果一个分类器能正确分对所有的实例，那么各项指标都已经达到最优，但这样的分类器往往不存在。比如之前说的地震预测，既然不能百分百预测地震的发生，但实际情况中能容忍一定程度的误报。假设在1000次预测中，共有5次预测发生了地震，真实情况中有一次发生了地震，其他4次则为误报。正确率由原来的999/1000=99.9下降为996/1000=99.6。召回率由0/1=0%上升为1/1=100%。对此解释为，虽然预测失误了4次，但真的地震发生前，分类器能预测对，没有错过，这样的分类器实际意义更为重大，正是我们想要的。在这种情况下，在一定正确率前提下，要求分类器的召回率尽量高。</p>
<h2 id="2-9-逻辑回归"><a href="#2-9-逻辑回归" class="headerlink" title="2.9 逻辑回归"></a>2.9 逻辑回归</h2><h3 id="2-9-1-回归划分"><a href="#2-9-1-回归划分" class="headerlink" title="2.9.1 回归划分"></a>2.9.1 回归划分</h3><p>广义线性模型家族里，依据因变量不同，可以有如下划分：</p>
<p>（1）如果是连续的，就是多重线性回归。</p>
<p>（2）如果是二项分布，就是逻辑回归。</p>
<p>（3）如果是泊松（Poisson）分布，就是泊松回归。</p>
<p>（4）如果是负二项分布，就是负二项回归。</p>
<p>（5）逻辑回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的逻辑回归。</p>
<h3 id="2-9-2-逻辑回归适用性"><a href="#2-9-2-逻辑回归适用性" class="headerlink" title="2.9.2 逻辑回归适用性"></a>2.9.2 逻辑回归适用性</h3><p>逻辑回归可用于以下几个方面：</p>
<p>（1）用于概率预测。用于可能性预测时，得到的结果有可比性。比如根据模型进而预测在不同的自变量情况下，发生某病或某种情况的概率有多大。</p>
<p>（2）用于分类。实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。进行分类时，仅需要设定一个阈值即可，可能性高于阈值是一类，低于阈值是另一类。</p>
<p>（3）寻找危险因素。寻找某一疾病的危险因素等。</p>
<p>（4）仅能用于线性问题。只有当目标和特征是线性关系时，才能用逻辑回归。在应用逻辑回归时注意两点：一是当知道模型是非线性时，不适用逻辑回归；二是当使用逻辑回归时，应注意选择和目标为线性关系的特征。</p>
<p>（5）各特征之间不需要满足条件独立假设，但各个特征的贡献独立计算。</p>
<h3 id="2-9-3-逻辑回归与朴素贝叶斯有什么区别"><a href="#2-9-3-逻辑回归与朴素贝叶斯有什么区别" class="headerlink" title="2.9.3 逻辑回归与朴素贝叶斯有什么区别"></a>2.9.3 逻辑回归与朴素贝叶斯有什么区别</h3><p>逻辑回归与朴素贝叶斯区别有以下几个方面：</p>
<p>（1）逻辑回归是判别模型， 朴素贝叶斯是生成模型，所以生成和判别的所有区别它们都有。</p>
<p>（2）朴素贝叶斯属于贝叶斯，逻辑回归是最大似然，两种概率哲学间的区别。</p>
<p>（3）朴素贝叶斯需要条件独立假设。</p>
<p>（4）逻辑回归需要求特征参数间是线性的。</p>
<h3 id="2-9-4-线性回归与逻辑回归的区别"><a href="#2-9-4-线性回归与逻辑回归的区别" class="headerlink" title="2.9.4 线性回归与逻辑回归的区别"></a>2.9.4 线性回归与逻辑回归的区别</h3><p>线性回归与逻辑回归的区别如下描述：</p>
<p>（1）线性回归的样本的输出，都是连续值，$ y\in (-\infty ,+\infty )$，而逻辑回归中$y\in (0,1)$，只能取0和1。</p>
<p>（2）对于拟合函数也有本质上的差别： </p>
<p>​    线性回归：$f(x)=\theta ^{T}x=\theta _{1}x _{1}+\theta _{2}x _{2}+…+\theta _{n}x _{n}$</p>
<p>​    逻辑回归：$f(x)=P(y=1|x;\theta )=g(\theta ^{T}x)$，其中，$g(z)=\frac{1}{1+e^{-z}}$</p>
<p>​    可以看出，线性回归的拟合函数，是对f(x)的输出变量y的拟合，而逻辑回归的拟合函数是对为1类样本的概率的拟合。</p>
<p>​    那么，为什么要以1类样本的概率进行拟合呢，为什么可以这样拟合呢？ </p>
<p>​    $\theta ^{T}x=0$就相当于是1类和0类的决策边界： </p>
<p>​    当$\theta ^{T}x&gt;0$，则y&gt;0.5；若$\theta ^{T}x\rightarrow +\infty $，则$y \rightarrow  1 $，即y为1类; </p>
<p>​    当$\theta ^{T}x&lt;0$，则y&lt;0.5；若$\theta ^{T}x\rightarrow -\infty $，则$y \rightarrow  0 $，即y为0类; </p>
<p>这个时候就能看出区别，在线性回归中$\theta ^{T}x$为预测值的拟合函数；而在逻辑回归中$\theta ^{T}x$为决策边界。下表2-3为线性回归和逻辑回归的区别。</p>
<p>​                                    表2-3 线性回归和逻辑回归的区别</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">线性回归</th>
<th style="text-align:center">逻辑回归</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">目的</td>
<td style="text-align:center">预测</td>
<td style="text-align:center">分类</td>
</tr>
<tr>
<td style="text-align:center">$y^{(i)}$</td>
<td style="text-align:center">未知</td>
<td style="text-align:center">（0,1）</td>
</tr>
<tr>
<td style="text-align:center">函数</td>
<td style="text-align:center">拟合函数</td>
<td style="text-align:center">预测函数</td>
</tr>
<tr>
<td style="text-align:center">参数计算方式</td>
<td style="text-align:center">最小二乘法</td>
<td style="text-align:center">极大似然估计</td>
</tr>
</tbody>
</table>
</div>
<p>下面具体解释一下： </p>
<ol>
<li>拟合函数和预测函数什么关系呢？简单来说就是将拟合函数做了一个逻辑函数的转换，转换后使得$y^{(i)} \in (0,1)$;</li>
<li>最小二乘和最大似然估计可以相互替代吗？回答当然是不行了。我们来看看两者依仗的原理：最大似然估计是计算使得数据出现的可能性最大的参数，依仗的自然是Probability。而最小二乘是计算误差损失。</li>
</ol>
<h2 id="2-10-代价函数"><a href="#2-10-代价函数" class="headerlink" title="2.10 代价函数"></a>2.10 代价函数</h2><h3 id="2-10-1-为什么需要代价函数"><a href="#2-10-1-为什么需要代价函数" class="headerlink" title="2.10.1 为什么需要代价函数"></a>2.10.1 为什么需要代价函数</h3><ol>
<li>为了得到训练逻辑回归模型的参数，需要一个代价函数，通过训练代价函数来得到参数。</li>
<li>用于找到最优解的目的函数。</li>
</ol>
<h3 id="2-10-2-代价函数作用原理"><a href="#2-10-2-代价函数作用原理" class="headerlink" title="2.10.2 代价函数作用原理"></a>2.10.2 代价函数作用原理</h3><p>​    在回归问题中，通过代价函数来求解最优解，常用的是平方误差代价函数。假设函数图像如图2-4所示，当参数发生变化时，假设函数状态也会随着变化。</p>
<p><img src="/img/ch2/2.16/1.jpg" alt=""></p>
<p>​                                        图2-4  $h(x) = A + Bx$函数示意图</p>
<p>​    想要拟合图中的离散点，我们需要尽可能找到最优的$A$和$B$来使这条直线更能代表所有数据。如何找到最优解呢，这就需要使用代价函数来求解，以平方误差代价函数为例，假设函数为$h(x)=\theta_0x$。<br>​    <strong>平方误差代价函数的主要思想</strong>就是将实际数据给出的值与拟合出的线的对应值做差，求出拟合出的直线与实际的差距。在实际应用中，为了避免因个别极端数据产生的影响，采用类似方差再取二分之一的方式来减小个别数据的影响。因此，引出代价函数：</p>
<script type="math/tex; mode=display">
J(\theta_0, \theta_1) = \frac{1}{m}\sum_{i=1}^m(h(x^{(i)})-y^{(i)})^2</script><p>​    <strong>最优解即为代价函数的最小值</strong>$\min J(\theta_0, \theta_1)$。如果是1个参数，代价函数一般通过二维曲线便可直观看出。如果是2个参数，代价函数通过三维图像可看出效果，参数越多，越复杂。<br>当参数为2个时，代价函数是三维图像，如下图2-5所示。</p>
<p><img src="/img/ch2/2.16/2.jpg" alt=""></p>
<p>​                                        图2-5  代价函数三维图像</p>
<h3 id="2-10-3-为什么代价函数要非负"><a href="#2-10-3-为什么代价函数要非负" class="headerlink" title="2.10.3 为什么代价函数要非负"></a>2.10.3 为什么代价函数要非负</h3><p>​    目标函数存在一个下界，在优化过程当中，如果优化算法能够使目标函数不断减小，根据单调有界准则，这个优化算法就能证明是收敛有效的。<br>​    只要设计的目标函数有下界，基本上都可以，代价函数非负更为方便。</p>
<h3 id="2-10-4-常见代价函数"><a href="#2-10-4-常见代价函数" class="headerlink" title="2.10.4 常见代价函数"></a>2.10.4 常见代价函数</h3><p>（1）<strong>二次代价函数（quadratic cost）</strong>：</p>
<script type="math/tex; mode=display">
J = \frac{1}{2n}\sum_x\Vert y(x)-a^L(x)\Vert^2</script><p>​    其中，$J$表示代价函数，$x$表示样本，$y$表示实际值，$a$表示输出值，$n$表示样本的总数。使用一个样本为例简单说明，此时二次代价函数为：</p>
<script type="math/tex; mode=display">
J = \frac{(y-a)^2}{2}</script><p>​    假如使用梯度下降法（Gradient descent）来调整权值参数的大小，权值$w$和偏置$b$的梯度推导如下：</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial b}=(a-y)\sigma'(z)</script><p>其中，$z​$表示神经元的输入，$\sigma​$表示激活函数。权值$w​$和偏置$b​$的梯度跟激活函数的梯度成正比，激活函数的梯度越大，权值$w​$和偏置$b​$的大小调整得越快，训练收敛得就越快。</p>
<p><em>注</em>：神经网络常用的激活函数为sigmoid函数，该函数的曲线如下图2-6所示：</p>
<p><img src="/img/ch2/2.18/1.jpg" alt=""></p>
<p>​                                                图2-6 sigmoid函数曲线</p>
<p>如上图所示，对0.88和0.98两个点进行比较：<br>​    假设目标是收敛到1.0。0.88离目标1.0比较远，梯度比较大，权值调整比较大。0.98离目标1.0比较近，梯度比较小，权值调整比较小。调整方案合理。<br>​    假如目标是收敛到0。0.88离目标0比较近，梯度比较大，权值调整比较大。0.98离目标0比较远，梯度比较小，权值调整比较小。调整方案不合理。<br>​    原因：在使用sigmoid函数的情况下, 初始的代价（误差）越大，导致训练越慢。</p>
<p>（2）<strong>交叉熵代价函数（cross-entropy）</strong>：</p>
<script type="math/tex; mode=display">
J = -\frac{1}{n}\sum_x[y\ln a + (1-y)\ln{(1-a)}]</script><p>其中，$J$表示代价函数，$x$表示样本，$y$表示实际值，$a$表示输出值，$n$表示样本的总数。<br>    权值$w$和偏置$b​$的梯度推导如下：</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial w_j}=\frac{1}{n}\sum_{x}x_j(\sigma{(z)}-y)\;，
\frac{\partial J}{\partial b}=\frac{1}{n}\sum_{x}(\sigma{(z)}-y)</script><p>当误差越大时，梯度就越大，权值$w$和偏置$b$调整就越快，训练的速度也就越快。<br><strong>二次代价函数适合输出神经元是线性的情况，交叉熵代价函数适合输出神经元是S型函数的情况。</strong></p>
<p>（3）<strong>对数似然代价函数（log-likelihood cost）</strong>：<br>对数似然函数常用来作为softmax回归的代价函数。深度学习中普遍的做法是将softmax作为最后一层，此时常用的代价函数是对数似然代价函数。<br>    对数似然代价函数与softmax的组合和交叉熵与sigmoid函数的组合非常相似。对数似然代价函数在二分类时可以化简为交叉熵代价函数的形式。<br>在tensorflow中：<br>    与sigmoid搭配使用的交叉熵函数：<code>tf.nn.sigmoid_cross_entropy_with_logits()</code>。<br>    与softmax搭配使用的交叉熵函数：<code>tf.nn.softmax_cross_entropy_with_logits()</code>。<br>在pytorch中：<br>        与sigmoid搭配使用的交叉熵函数：<code>torch.nn.BCEWithLogitsLoss()</code>。<br>    与softmax搭配使用的交叉熵函数：<code>torch.nn.CrossEntropyLoss()</code>。</p>
<h3 id="2-10-5-为什么用交叉熵代替二次代价函数"><a href="#2-10-5-为什么用交叉熵代替二次代价函数" class="headerlink" title="2.10.5 为什么用交叉熵代替二次代价函数"></a>2.10.5 为什么用交叉熵代替二次代价函数</h3><p>（1）<strong>为什么不用二次方代价函数</strong><br>由上一节可知，权值$w$和偏置$b$的偏导数为$\frac{\partial J}{\partial w}=(a-y)\sigma’(z)x$，$\frac{\partial J}{\partial b}=(a-y)\sigma’(z)$， 偏导数受激活函数的导数影响，sigmoid函数导数在输出接近0和1时非常小，会导致一些实例在刚开始训练时学习得非常慢。</p>
<p>（2）<strong>为什么要用交叉熵</strong><br>交叉熵函数权值$w$和偏置$b$的梯度推导为：</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial w_j}=\frac{1}{n}\sum_{x}x_j(\sigma{(z)}-y)\;，
\frac{\partial J}{\partial b}=\frac{1}{n}\sum_{x}(\sigma{(z)}-y)</script><p>由以上公式可知，权重学习的速度受到$\sigma{(z)}-y$影响，更大的误差，就有更快的学习速度，避免了二次代价函数方程中因$\sigma’{(z)}$导致的学习缓慢的情况。</p>
<h2 id="2-11-损失函数"><a href="#2-11-损失函数" class="headerlink" title="2.11 损失函数"></a>2.11 损失函数</h2><h3 id="2-11-1-什么是损失函数"><a href="#2-11-1-什么是损失函数" class="headerlink" title="2.11.1 什么是损失函数"></a>2.11.1 什么是损失函数</h3><p>​    损失函数（Loss Function）又叫做误差函数，用来衡量算法的运行情况，估量模型的预测值与真实值的不一致程度，是一个非负实值函数，通常使用$<br>L(Y, f(x))​$来表示。损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。</p>
<h3 id="2-11-2-常见的损失函数"><a href="#2-11-2-常见的损失函数" class="headerlink" title="2.11.2 常见的损失函数"></a>2.11.2 常见的损失函数</h3><p>​    机器学习通过对算法中的目标函数进行不断求解优化，得到最终想要的结果。分类和回归问题中，通常使用损失函数或代价函数作为目标函数。<br>​    损失函数用来评价预测值和真实值不一样的程度。通常损失函数越好，模型的性能也越好。<br>​    损失函数可分为经验风险损失函数和结构风险损失函数。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是在经验风险损失函数上加上正则项。<br>​    下面介绍常用的损失函数：</p>
<p>（1）<strong>0-1损失函数</strong><br>如果预测值和目标值相等，值为0，如果不相等，值为1。</p>
<script type="math/tex; mode=display">
L(Y, f(x)) =
\begin{cases}
1,& Y\ne f(x)\\
0,& Y = f(x)
\end{cases}</script><p>一般的在实际使用中，相等的条件过于严格，可适当放宽条件：</p>
<script type="math/tex; mode=display">
L(Y, f(x)) =
\begin{cases}
1,& |Y-f(x)|\geqslant T\\
0,& |Y-f(x)|< T
\end{cases}</script><p>（2）<strong>绝对值损失函数</strong><br>和0-1损失函数相似，绝对值损失函数表示为：</p>
<script type="math/tex; mode=display">
L(Y, f(x)) = |Y-f(x)|​</script><p>（3）<strong>平方损失函数</strong></p>
<script type="math/tex; mode=display">
L(Y, f(x)) = \sum_N{(Y-f(x))}^2</script><p>这点可从最小二乘法和欧几里得距离角度理解。最小二乘法的原理是，最优拟合曲线应该使所有点到回归直线的距离和最小。</p>
<p>（4）<strong>对数损失函数</strong></p>
<script type="math/tex; mode=display">
L(Y, P(Y|X)) = -\log{P(Y|X)}</script><p>​    常见的逻辑回归使用的就是对数损失函数，有很多人认为逻辑回归的损失函数是平方损失，其实不然。逻辑回归它假设样本服从伯努利分布（0-1分布），进而求得满足该分布的似然函数，接着取对数求极值等。逻辑回归推导出的经验风险函数是最小化负的似然函数，从损失函数的角度看，就是对数损失函数。</p>
<p>（6）<strong>指数损失函数</strong><br>指数损失函数的标准形式为：</p>
<script type="math/tex; mode=display">
L(Y, f(x)) = \exp(-Yf(x))</script><p>例如AdaBoost就是以指数损失函数为损失函数。</p>
<p>（7）<strong>Hinge损失函数</strong><br>Hinge损失函数的标准形式如下：</p>
<script type="math/tex; mode=display">
L(y) = \max{(0, 1-ty)}</script><p>统一的形式：</p>
<script type="math/tex; mode=display">
L(Y, f(x)) = \max{(0, Yf(x))}</script><p>其中y是预测值，范围为(-1,1)，t为目标值，其为-1或1。</p>
<p>在线性支持向量机中，最优化问题可等价于</p>
<script type="math/tex; mode=display">
\underset{\min}{w,b}\sum_{i=1}^N (1-y_i(wx_i+b))+\lambda\Vert w\Vert ^2</script><p>上式相似于下式</p>
<script type="math/tex; mode=display">
\frac{1}{m}\sum_{i=1}^{N}l(wx_i+by_i) + \Vert w\Vert ^2</script><p>其中$l(wx_i+by_i)$是Hinge损失函数，$\Vert w\Vert ^2$可看做为正则化项。</p>
<h3 id="2-11-3-逻辑回归为什么使用对数损失函数"><a href="#2-11-3-逻辑回归为什么使用对数损失函数" class="headerlink" title="2.11.3 逻辑回归为什么使用对数损失函数"></a>2.11.3 逻辑回归为什么使用对数损失函数</h3><p>假设逻辑回归模型</p>
<script type="math/tex; mode=display">
P(y=1|x;\theta)=\frac{1}{1+e^{-\theta^{T}x}}</script><p>假设逻辑回归模型的概率分布是伯努利分布，其概率质量函数为：</p>
<script type="math/tex; mode=display">
P(X=n)=
\begin{cases}
1-p, n=0\\
 p,n=1
\end{cases}</script><p>其似然函数为：</p>
<script type="math/tex; mode=display">
L(\theta)=\prod_{i=1}^{m}
P(y=1|x_i)^{y_i}P(y=0|x_i)^{1-y_i}</script><p>对数似然函数为：</p>
<script type="math/tex; mode=display">
\ln L(\theta)=\sum_{i=1}^{m}[y_i\ln{P(y=1|x_i)}+(1-y_i)\ln{P(y=0|x_i)}]\\
  =\sum_{i=1}^m[y_i\ln{P(y=1|x_i)}+(1-y_i)\ln(1-P(y=1|x_i))]</script><p>对数函数在单个数据点上的定义为：</p>
<script type="math/tex; mode=display">
cost(y,p(y|x))=-y\ln{p(y|x)-(1-y)\ln(1-p(y|x))}</script><p>则全局样本损失函数为：</p>
<script type="math/tex; mode=display">
cost(y,p(y|x)) = -\sum_{i=1}^m[y_i\ln p(y_i|x_i)+(1-y_i)\ln(1-p(y_i|x_i))]</script><p>由此可看出，对数损失函数与极大似然估计的对数似然函数本质上是相同的。所以逻辑回归直接采用对数损失函数。</p>
<h3 id="2-11-4-对数损失函数是如何度量损失的"><a href="#2-11-4-对数损失函数是如何度量损失的" class="headerlink" title="2.11.4 对数损失函数是如何度量损失的"></a>2.11.4 对数损失函数是如何度量损失的</h3><p>​    例如，在高斯分布中，我们需要确定均值和标准差。<br>​    如何确定这两个参数？最大似然估计是比较常用的方法。最大似然的目标是找到一些参数值，这些参数值对应的分布可以最大化观测到数据的概率。<br>​    因为需要计算观测到所有数据的全概率，即所有观测到的数据点的联合概率。现考虑如下简化情况：</p>
<p>（1）假设观测到每个数据点的概率和其他数据点的概率是独立的。</p>
<p>（2）取自然对数。<br>假设观测到单个数据点$x_i(i=1,2,…n)$的概率为：</p>
<script type="math/tex; mode=display">
P(x_i;\mu,\sigma)=\frac{1}{\sigma \sqrt{2\pi}}\exp 
        \left( - \frac{(x_i-\mu)^2}{2\sigma^2} \right)</script><p>（3）其联合概率为：</p>
<script type="math/tex; mode=display">
P(x_1,x_2,...,x_n;\mu,\sigma)=\frac{1}{\sigma \sqrt{2\pi}}\exp 
        \left( - \frac{(x_1-\mu)^2}{2\sigma^2} \right) \\ \times
         \frac{1}{\sigma \sqrt{2\pi}}\exp 
        \left( - \frac{(x_2-\mu)^2}{2\sigma^2} \right) \times ... \times
        \frac{1}{\sigma \sqrt{2\pi}}\exp 
        \left( - \frac{(x_n-\mu)^2}{2\sigma^2} \right)</script><p>​    对上式取自然对数，可得：</p>
<script type="math/tex; mode=display">
 \ln(P(x_1,x_2,...x_n;\mu,\sigma))=
         \ln \left(\frac{1}{\sigma \sqrt{2\pi}} \right) 
          - \frac{(x_1-\mu)^2}{2\sigma^2}  \\ +
          \ln \left( \frac{1}{\sigma \sqrt{2\pi}} \right) 
          - \frac{(x_2-\mu)^2}{2\sigma^2} +...+
          \ln \left( \frac{1}{\sigma \sqrt{2\pi}} \right) 
          - \frac{(x_n-\mu)^2}{2\sigma^2}</script><p>根据对数定律，上式可以化简为：</p>
<script type="math/tex; mode=display">
\ln(P(x_1,x_2,...x_n;\mu,\sigma))=-n\ln(\sigma)-\frac{n}{2} \ln(2\pi)\\
         -\frac{1}{2\sigma^2}[(x_1-\mu)^2+(x_2-\mu)^2+...+(x_n-\mu)^2]</script><p>然后求导为：</p>
<script type="math/tex; mode=display">
\frac{\partial\ln(P(x_1,x_2,...,x_n;\mu,\sigma))}{\partial\mu}=
                 \frac{n}{\sigma^2}[\mu - (x_1+x_2+...+x_n)]</script><p>​     上式左半部分为对数损失函数。损失函数越小越好，因此我们令等式左半的对数损失函数为0，可得：</p>
<script type="math/tex; mode=display">
\mu=\frac{x_1+x_2+...+x_n}{n}</script><p>同理，可计算$\sigma ​$。</p>
<h2 id="2-12-梯度下降"><a href="#2-12-梯度下降" class="headerlink" title="2.12 梯度下降"></a>2.12 梯度下降</h2><h3 id="2-12-1-机器学习中为什么需要梯度下降"><a href="#2-12-1-机器学习中为什么需要梯度下降" class="headerlink" title="2.12.1 机器学习中为什么需要梯度下降"></a>2.12.1 机器学习中为什么需要梯度下降</h3><p>梯度下降是机器学习中常见优化算法之一，梯度下降法有以下几个作用：</p>
<p>（1）梯度下降是迭代法的一种，可以用于求解最小二乘问题。</p>
<p>（2）在求解机器学习算法的模型参数，即无约束优化问题时，主要有梯度下降法（Gradient Descent）和最小二乘法。</p>
<p>（3）在求解损失函数的最小值时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数和模型参数值。</p>
<p>（4）如果我们需要求解损失函数的最大值，可通过梯度上升法来迭代。梯度下降法和梯度上升法可相互转换。</p>
<p>（5）在机器学习中，梯度下降法主要有随机梯度下降法和批量梯度下降法。</p>
<h3 id="2-12-2-梯度下降法缺点"><a href="#2-12-2-梯度下降法缺点" class="headerlink" title="2.12.2 梯度下降法缺点"></a>2.12.2 梯度下降法缺点</h3><p>梯度下降法缺点有以下几点：</p>
<p>（1）靠近极小值时收敛速度减慢。</p>
<p>（2）直线搜索时可能会产生一些问题。</p>
<p>（3）可能会“之字形”地下降。</p>
<p>梯度概念也有需注意的地方：</p>
<p>（1）梯度是一个向量，即有方向有大小。 </p>
<p>（2）梯度的方向是最大方向导数的方向。 </p>
<p>（3）梯度的值是最大方向导数的值。</p>
<h3 id="2-12-3-梯度下降法直观理解"><a href="#2-12-3-梯度下降法直观理解" class="headerlink" title="2.12.3 梯度下降法直观理解"></a>2.12.3 梯度下降法直观理解</h3><p>梯度下降法经典图示如下图2.7所示：</p>
<p><img src="/img/ch2/2.25/1.png" alt=""></p>
<p>​                                    图2.7 梯度下降法经典图示</p>
<p>​    形象化举例，由上图2.7所示，假如最开始，我们在一座大山上的某处位置，因为到处都是陌生的，不知道下山的路，所以只能摸索着根据直觉，走一步算一步，在此过程中，每走到一个位置的时候，都会求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。不断循环求梯度，就这样一步步地走下去，一直走到我们觉得已经到了山脚。当然这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山势低处。<br>​    由此，从上面的解释可以看出，梯度下降不一定能够找到全局的最优解，有可能是一个局部的最优解。当然，如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。</p>
<p><strong>核心思想归纳</strong>：</p>
<p>（1）初始化参数，随机选取取值范围内的任意数；</p>
<p>（2）迭代操作：<br>    a）计算当前梯度；<br>    b）修改新的变量；<br>    c）计算朝最陡的下坡方向走一步；<br>    d）判断是否需要终止，如否，返回a）；</p>
<p>（3）得到全局最优解或者接近全局最优解。</p>
<h3 id="2-12-4-梯度下降法算法描述"><a href="#2-12-4-梯度下降法算法描述" class="headerlink" title="2.12.4 梯度下降法算法描述"></a>2.12.4 梯度下降法算法描述</h3><p>梯度下降法算法步骤如下：</p>
<p>（1）确定优化模型的假设函数及损失函数。<br>​    举例，对于线性回归，假设函数为：</p>
<script type="math/tex; mode=display">
  h_\theta(x_1,x_2,...,x_n)=\theta_0+\theta_1x_1+...+\theta_nx_n</script><p>  其中，$\theta_i,x_i(i=0,1,2,…,n)$分别为模型参数、每个样本的特征值。<br>  对于假设函数，损失函数为：</p>
<script type="math/tex; mode=display">
  J(\theta_0,\theta_1,...,\theta_n)=\frac{1}{2m}\sum^{m}_{j=0}(h_\theta (x^{(j)}_0
      ,x^{(j)}_1,...,x^{(j)}_n)-y_j)^2</script><p>（2）相关参数初始化。<br>​    主要初始化${\theta}_i$、算法迭代步长${\alpha} $、终止距离${\zeta} $。初始化时可以根据经验初始化，即${\theta} $初始化为0，步长${\alpha} $初始化为1。当前步长记为${\varphi}_i $。当然，也可随机初始化。</p>
<p>（3）迭代计算。</p>
<p>​    1）计算当前位置时损失函数的梯度，对${\theta}_i $，其梯度表示为：</p>
<script type="math/tex; mode=display">
\frac{\partial}{\partial \theta_i}J({\theta}_0,{\theta}_1,...,{\theta}_n)=\frac{1}{2m}\sum^{m}_{j=0}(h_\theta (x^{(j)}_0
    ,x^{(j)}_1,...,x^{(j)}_n)-y_j)^2</script><p>​    2）计算当前位置下降的距离。</p>
<script type="math/tex; mode=display">
{\varphi}_i={\alpha} \frac{\partial}{\partial \theta_i}J({\theta}_0,{\theta}_1,...,{\theta}_n)</script><p>​    3）判断是否终止。<br>​    确定是否所有${\theta}_i$梯度下降的距离${\varphi}_i$都小于终止距离${\zeta}$，如果都小于${\zeta}$，则算法终止，当然的值即为最终结果，否则进入下一步。<br>​    4）更新所有的${\theta}_i$，更新后的表达式为：</p>
<script type="math/tex; mode=display">
{\theta}_i={\theta}_i-\alpha \frac{\partial}{\partial \theta_i}J({\theta}_0,{\theta}_1,...,{\theta}_n)</script><script type="math/tex; mode=display">
\theta_i=\theta_i - \alpha \frac{1}{m} \sum^{m}_{j=0}(h_\theta (x^{(j)}_0
    ,x^{(j)}_1,...,x^{(j)}_n)-y_j)x^{(j)}_i</script><p>​    5）令上式$x^{(j)}_0=1$，更新完毕后转入1)。<br>​    由此，可看出，当前位置的梯度方向由所有样本决定，上式中 $\frac{1}{m}​$、$\alpha \frac{1}{m}​$ 的目的是为了便于理解。</p>
<h3 id="2-12-5-如何对梯度下降法进行调优"><a href="#2-12-5-如何对梯度下降法进行调优" class="headerlink" title="2.12.5 如何对梯度下降法进行调优"></a>2.12.5 如何对梯度下降法进行调优</h3><p>实际使用梯度下降法时，各项参数指标不能一步就达到理想状态，对梯度下降法调优主要体现在以下几个方面：</p>
<p>（1）<strong>算法迭代步长$\alpha$选择。</strong><br>    在算法参数初始化时，有时根据经验将步长初始化为1。实际取值取决于数据样本。可以从大到小，多取一些值，分别运行算法看迭代效果，如果损失函数在变小，则取值有效。如果取值无效，说明要增大步长。但步长太大，有时会导致迭代速度过快，错过最优解。步长太小，迭代速度慢，算法运行时间长。</p>
<p>（2）<strong>参数的初始值选择。</strong><br>    初始值不同，获得的最小值也有可能不同，梯度下降有可能得到的是局部最小值。如果损失函数是凸函数，则一定是最优解。由于有局部最优解的风险，需要多次用不同初始值运行算法，关键损失函数的最小值，选择损失函数最小化的初值。</p>
<p>（3）<strong>标准化处理。</strong><br>    由于样本不同，特征取值范围也不同，导致迭代速度慢。为了减少特征取值的影响，可对特征数据标准化，使新期望为0，新方差为1，可节省算法运行时间。</p>
<h3 id="2-12-6-随机梯度和批量梯度区别"><a href="#2-12-6-随机梯度和批量梯度区别" class="headerlink" title="2.12.6 随机梯度和批量梯度区别"></a>2.12.6 随机梯度和批量梯度区别</h3><p>​    随机梯度下降（SDG）和批量梯度下降（BDG）是两种主要梯度下降法，其目的是增加某些限制来加速运算求解。<br>下面通过介绍两种梯度下降法的求解思路，对其进行比较。<br>假设函数为：</p>
<script type="math/tex; mode=display">
h_\theta (x_0,x_1,...,x_3) = \theta_0 x_0 + \theta_1 x_1 + ... + \theta_n x_n</script><p>损失函数为：</p>
<script type="math/tex; mode=display">
J(\theta_0, \theta_1, ... , \theta_n) = 
            \frac{1}{2m} \sum^{m}_{j=0}(h_\theta (x^{j}_0
    ,x^{j}_1,...,x^{j}_n)-y^j)^2</script><p>其中，$m​$为样本个数，$j​$为参数个数。</p>
<p>1、 <strong>批量梯度下降的求解思路如下：</strong><br>a) 得到每个$ \theta ​$对应的梯度：</p>
<script type="math/tex; mode=display">
\frac{\partial}{\partial \theta_i}J({\theta}_0,{\theta}_1,...,{\theta}_n)=\frac{1}{m}\sum^{m}_{j=0}(h_\theta (x^{j}_0
    ,x^{j}_1,...,x^{j}_n)-y^j)x^{j}_i</script><p>b) 由于是求最小化风险函数，所以按每个参数 $ \theta ​$ 的梯度负方向更新 $ \theta_i ​$ ：</p>
<script type="math/tex; mode=display">
\theta_i=\theta_i - \frac{1}{m} \sum^{m}_{j=0}(h_\theta (x^{j}_0
    ,x^{j}_1,...,x^{j}_n)-y^j)x^{j}_i</script><p>c) 从上式可以注意到，它得到的虽然是一个全局最优解，但每迭代一步，都要用到训练集所有的数据，如果样本数据很大，这种方法迭代速度就很慢。<br>相比而言，随机梯度下降可避免这种问题。</p>
<p>2、<strong>随机梯度下降的求解思路如下：</strong><br>a) 相比批量梯度下降对应所有的训练样本，随机梯度下降法中损失函数对应的是训练集中每个样本的粒度。<br>损失函数可以写成如下这种形式，</p>
<script type="math/tex; mode=display">
J(\theta_0, \theta_1, ... , \theta_n) = 
            \frac{1}{m} \sum^{m}_{j=0}(y^j - h_\theta (x^{j}_0
            ,x^{j}_1,...,x^{j}_n))^2 = 
            \frac{1}{m} \sum^{m}_{j=0} cost(\theta,(x^j,y^j))</script><p>b）对每个参数 $ \theta​$ 按梯度方向更新 $ \theta​$：</p>
<script type="math/tex; mode=display">
\theta_i = \theta_i + (y^j - h_\theta (x^{j}_0, x^{j}_1, ... ,x^{j}_n))</script><p>c) 随机梯度下降是通过每个样本来迭代更新一次。<br>随机梯度下降伴随的一个问题是噪音较批量梯度下降要多，使得随机梯度下降并不是每次迭代都向着整体最优化方向。</p>
<p><strong>小结：</strong><br>随机梯度下降法、批量梯度下降法相对来说都比较极端，简单对比如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">方法</th>
<th style="text-align:left">特点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">批量梯度下降</td>
<td style="text-align:left">a）采用所有数据来梯度下降。<br/>b）批量梯度下降法在样本量很大的时候，训练速度慢。</td>
</tr>
<tr>
<td style="text-align:center">随机梯度下降</td>
<td style="text-align:left">a）随机梯度下降用一个样本来梯度下降。<br/>b）训练速度很快。<br />c）随机梯度下降法仅仅用一个样本决定梯度方向，导致解有可能不是全局最优。<br />d）收敛速度来说，随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。</td>
</tr>
</tbody>
</table>
</div>
<p>下面介绍能结合两种方法优点的小批量梯度下降法。</p>
<p>3、 <strong>小批量（Mini-Batch）梯度下降的求解思路如下</strong><br>对于总数为$m$个样本的数据，根据样本的数据，选取其中的$n(1&lt; n&lt; m)$个子样本来迭代。其参数$\theta$按梯度方向更新$\theta_i$公式如下：</p>
<script type="math/tex; mode=display">
\theta_i = \theta_i - \alpha \sum^{t+n-1}_{j=t}
        ( h_\theta (x^{j}_{0}, x^{j}_{1}, ... , x^{j}_{n} ) - y^j ) x^{j}_{i}</script><h3 id="2-12-7-各种梯度下降法性能比较"><a href="#2-12-7-各种梯度下降法性能比较" class="headerlink" title="2.12.7 各种梯度下降法性能比较"></a>2.12.7 各种梯度下降法性能比较</h3><p>​    下表简单对比随机梯度下降（SGD）、批量梯度下降（BGD）、小批量梯度下降（Mini-batch GD）、和Online GD的区别：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">BGD</th>
<th style="text-align:center">SGD</th>
<th style="text-align:center">Mini-batch GD</th>
<th style="text-align:center">Online GD</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">训练集</td>
<td style="text-align:center">固定</td>
<td style="text-align:center">固定</td>
<td style="text-align:center">固定</td>
<td style="text-align:center">实时更新</td>
</tr>
<tr>
<td style="text-align:center">单次迭代样本数</td>
<td style="text-align:center">整个训练集</td>
<td style="text-align:center">单个样本</td>
<td style="text-align:center">训练集的子集</td>
<td style="text-align:center">根据具体算法定</td>
</tr>
<tr>
<td style="text-align:center">算法复杂度</td>
<td style="text-align:center">高</td>
<td style="text-align:center">低</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">低</td>
</tr>
<tr>
<td style="text-align:center">时效性</td>
<td style="text-align:center">低</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">高</td>
</tr>
<tr>
<td style="text-align:center">收敛性</td>
<td style="text-align:center">稳定</td>
<td style="text-align:center">不稳定</td>
<td style="text-align:center">较稳定</td>
<td style="text-align:center">不稳定</td>
</tr>
</tbody>
</table>
</div>
<p>BGD、SGD、Mini-batch GD，前面均已讨论过，这里介绍一下Online GD。</p>
<p>​    Online GD于Mini-batch GD/SGD的区别在于，所有训练数据只用一次，然后丢弃。这样做的优点在于可预测最终模型的变化趋势。</p>
<p>​    Online GD在互联网领域用的较多，比如搜索广告的点击率（CTR）预估模型，网民的点击行为会随着时间改变。用普通的BGD算法（每天更新一次）一方面耗时较长（需要对所有历史数据重新训练）；另一方面，无法及时反馈用户的点击行为迁移。而Online GD算法可以实时的依据网民的点击行为进行迁移。</p>
<h2 id="2-14-线性判别分析（LDA）"><a href="#2-14-线性判别分析（LDA）" class="headerlink" title="2.14 线性判别分析（LDA）"></a>2.14 线性判别分析（LDA）</h2><h3 id="2-14-1-LDA思想总结"><a href="#2-14-1-LDA思想总结" class="headerlink" title="2.14.1 LDA思想总结"></a>2.14.1 LDA思想总结</h3><p>​    线性判别分析（Linear Discriminant Analysis，LDA）是一种经典的降维方法。和主成分分析PCA不考虑样本类别输出的无监督降维技术不同，LDA是一种监督学习的降维技术，数据集的每个样本有类别输出。  </p>
<p>LDA分类思想简单总结如下：  </p>
<ol>
<li>多维空间中，数据处理分类问题较为复杂，LDA算法将多维空间中的数据投影到一条直线上，将d维数据转化成1维数据进行处理。  </li>
<li>对于训练数据，设法将多维数据投影到一条直线上，同类数据的投影点尽可能接近，异类数据点尽可能远离。  </li>
<li>对数据进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定样本的类别。  </li>
</ol>
<p>如果用一句话概括LDA思想，即“投影后类内方差最小，类间方差最大”。</p>
<h3 id="2-14-2-图解LDA核心思想"><a href="#2-14-2-图解LDA核心思想" class="headerlink" title="2.14.2 图解LDA核心思想"></a>2.14.2 图解LDA核心思想</h3><p>​    假设有红、蓝两类数据，这些数据特征均为二维，如下图所示。我们的目标是将这些数据投影到一维，让每一类相近的数据的投影点尽可能接近，不同类别数据尽可能远，即图中红色和蓝色数据中心之间的距离尽可能大。</p>
<p><img src="/img/ch2/2.29/1.png" alt=""></p>
<p>左图和右图是两种不同的投影方式。</p>
<p>​    左图思路：让不同类别的平均点距离最远的投影方式。</p>
<p>​    右图思路：让同类别的数据挨得最近的投影方式。</p>
<p>​    从上图直观看出，右图红色数据和蓝色数据在各自的区域来说相对集中，根据数据分布直方图也可看出，所以右图的投影效果好于左图，左图中间直方图部分有明显交集。</p>
<p>​    以上例子是基于数据是二维的，分类后的投影是一条直线。如果原始数据是多维的，则投影后的分类面是一低维的超平面。</p>
<h3 id="2-14-3-二类LDA算法原理"><a href="#2-14-3-二类LDA算法原理" class="headerlink" title="2.14.3 二类LDA算法原理"></a>2.14.3 二类LDA算法原理</h3><p>​    输入：数据集 $D=\{(\boldsymbol x_1,\boldsymbol y_1),(\boldsymbol x_2,\boldsymbol y_2),…,(\boldsymbol x_m,\boldsymbol y_m)\}​$，其中样本 $\boldsymbol x_i ​$ 是n维向量，$\boldsymbol y_i  \epsilon \{0, 1\}​$，降维后的目标维度 $d​$。定义</p>
<p>​    $N_j(j=0,1)$ 为第 $j$ 类样本个数；</p>
<p>​    $X_j(j=0,1)$ 为第 $j$ 类样本的集合；</p>
<p>​    $u_j(j=0,1)​$ 为第 $j​$ 类样本的均值向量；</p>
<p>​    $\sum_j(j=0,1)$ 为第 $j$ 类样本的协方差矩阵。</p>
<p>​    其中</p>
<script type="math/tex; mode=display">
u_j = \frac{1}{N_j} \sum_{\boldsymbol x\epsilon X_j}\boldsymbol x(j=0,1)， 
\sum_j = \sum_{\boldsymbol x\epsilon X_j}(\boldsymbol x-u_j)(\boldsymbol x-u_j)^T(j=0,1)</script><p>​    假设投影直线是向量 $\boldsymbol w$，对任意样本 $\boldsymbol x_i$，它在直线 $w$上的投影为 $\boldsymbol w^Tx_i$，两个类别的中心点 $u_0$, $u_1 $在直线 $w$ 的投影分别为 $\boldsymbol w^Tu_0$ 、$\boldsymbol w^Tu_1$。</p>
<p>​    LDA的目标是让两类别的数据中心间的距离 $| \boldsymbol w^Tu_0 - \boldsymbol w^Tu_1 |^2_2$ 尽量大，与此同时，希望同类样本投影点的协方差$\boldsymbol w^T \sum_0 \boldsymbol w$、$\boldsymbol w^T \sum_1 \boldsymbol w$ 尽量小，最小化 $\boldsymbol w^T \sum_0 \boldsymbol w + \boldsymbol w^T \sum_1 \boldsymbol w​$ 。<br>​    定义<br>​    类内散度矩阵</p>
<script type="math/tex; mode=display">
S_w = \sum_0 + \sum_1 = 
    \sum_{\boldsymbol x\epsilon X_0}(\boldsymbol x-u_0)(\boldsymbol x-u_0)^T + 
    \sum_{\boldsymbol x\epsilon X_1}(\boldsymbol x-u_1)(\boldsymbol x-u_1)^T</script><p>​    类间散度矩阵 $S_b = (u_0 - u_1)(u_0 - u_1)^T$</p>
<p>​    据上分析，优化目标为</p>
<script type="math/tex; mode=display">
\mathop{\arg\max}_\boldsymbol w J(\boldsymbol w) = \frac{\| \boldsymbol w^Tu_0 - \boldsymbol w^Tu_1 \|^2_2}{\boldsymbol w^T \sum_0\boldsymbol w + \boldsymbol w^T \sum_1\boldsymbol w} = 
\frac{\boldsymbol w^T(u_0-u_1)(u_0-u_1)^T\boldsymbol w}{\boldsymbol w^T(\sum_0 + \sum_1)\boldsymbol w} =
\frac{\boldsymbol w^TS_b\boldsymbol w}{\boldsymbol w^TS_w\boldsymbol w}</script><p>​    根据广义瑞利商的性质，矩阵 $S^{-1}_{w} S_b$ 的最大特征值为 $J(\boldsymbol w)$ 的最大值，矩阵 $S^{-1}_{w} S_b$ 的最大特征值对应的特征向量即为 $\boldsymbol w$。</p>
<h3 id="2-14-4-LDA算法流程总结"><a href="#2-14-4-LDA算法流程总结" class="headerlink" title="2.14.4 LDA算法流程总结"></a>2.14.4 LDA算法流程总结</h3><p>LDA算法降维流程如下：</p>
<p>​    输入：数据集 $D = \{ (x_1,y_1),(x_2,y_2), … ,(x_m,y_m) \}$，其中样本 $x_i $ 是n维向量，$y_i  \epsilon \{C_1, C_2, …, C_k\}$，降维后的目标维度 $d$ 。</p>
<p>​    输出：降维后的数据集 $\overline{D} $ 。</p>
<p>步骤：</p>
<ol>
<li>计算类内散度矩阵 $S_w$。</li>
<li>计算类间散度矩阵 $S_b​$ 。</li>
<li>计算矩阵 $S^{-1}_wS_b​$ 。</li>
<li>计算矩阵 $S^{-1}_wS_b$ 的最大的 d 个特征值。</li>
<li>计算 d 个特征值对应的 d 个特征向量，记投影矩阵为 W 。</li>
<li>转化样本集的每个样本，得到新样本 $P_i = W^Tx_i​$ 。</li>
<li>输出新样本集 $\overline{D} = \{ (p_1,y_1),(p_2,y_2),…,(p_m,y_m) \}​$</li>
</ol>
<h3 id="2-14-5-LDA和PCA区别"><a href="#2-14-5-LDA和PCA区别" class="headerlink" title="2.14.5 LDA和PCA区别"></a>2.14.5 LDA和PCA区别</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">异同点</th>
<th style="text-align:left">LDA</th>
<th style="text-align:left">PCA</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">相同点</td>
<td style="text-align:left">1. 两者均可以对数据进行降维；<br />2. 两者在降维时均使用了矩阵特征分解的思想；<br />3. 两者都假设数据符合高斯分布；</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:center">不同点</td>
<td style="text-align:left">有监督的降维方法；</td>
<td style="text-align:left">无监督的降维方法；</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:left">降维最多降到k-1维；</td>
<td style="text-align:left">降维多少没有限制；</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:left">可以用于降维，还可以用于分类；</td>
<td style="text-align:left">只用于降维；</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:left">选择分类性能最好的投影方向；</td>
<td style="text-align:left">选择样本点投影具有最大方差的方向；</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:left">更明确，更能反映样本间差异；</td>
<td style="text-align:left">目的较为模糊；</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-14-6-LDA优缺点"><a href="#2-14-6-LDA优缺点" class="headerlink" title="2.14.6 LDA优缺点"></a>2.14.6 LDA优缺点</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">优缺点</th>
<th style="text-align:left">简要说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">优点</td>
<td style="text-align:left">1. 可以使用类别的先验知识；<br />2. 以标签、类别衡量差异性的有监督降维方式，相对于PCA的模糊性，其目的更明确，更能反映样本间的差异；</td>
</tr>
<tr>
<td style="text-align:center">缺点</td>
<td style="text-align:left">1. LDA不适合对非高斯分布样本进行降维；<br />2. LDA降维最多降到分类数k-1维；<br />3. LDA在样本分类信息依赖方差而不是均值时，降维效果不好；<br />4. LDA可能过度拟合数据。</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-15-主成分分析（PCA）"><a href="#2-15-主成分分析（PCA）" class="headerlink" title="2.15  主成分分析（PCA）"></a>2.15  主成分分析（PCA）</h2><h3 id="2-15-1-主成分分析（PCA）思想总结"><a href="#2-15-1-主成分分析（PCA）思想总结" class="headerlink" title="2.15.1 主成分分析（PCA）思想总结"></a>2.15.1 主成分分析（PCA）思想总结</h3><ol>
<li>PCA就是将高维的数据通过线性变换投影到低维空间上去。</li>
<li>投影思想：找出最能够代表原始数据的投影方法。被PCA降掉的那些维度只能是那些噪声或是冗余的数据。</li>
<li>去冗余：去除可以被其他向量代表的线性相关向量，这部分信息量是多余的。</li>
<li>去噪声，去除较小特征值对应的特征向量，特征值的大小反映了变换后在特征向量方向上变换的幅度，幅度越大，说明这个方向上的元素差异也越大，要保留。</li>
<li>对角化矩阵，寻找极大线性无关组，保留较大的特征值，去除较小特征值，组成一个投影矩阵，对原始样本矩阵进行投影，得到降维后的新样本矩阵。</li>
<li>完成PCA的关键是——协方差矩阵。协方差矩阵，能同时表现不同维度间的相关性以及各个维度上的方差。协方差矩阵度量的是维度与维度之间的关系，而非样本与样本之间。</li>
<li>之所以对角化，因为对角化之后非对角上的元素都是0，达到去噪声的目的。对角化后的协方差矩阵，对角线上较小的新方差对应的就是那些该去掉的维度。所以我们只取那些含有较大能量(特征值)的维度，其余的就舍掉，即去冗余。</li>
</ol>
<h3 id="2-15-2-图解PCA核心思想"><a href="#2-15-2-图解PCA核心思想" class="headerlink" title="2.15.2 图解PCA核心思想"></a>2.15.2 图解PCA核心思想</h3><p>​    PCA可解决训练数据中存在数据特征过多或特征累赘的问题。核心思想是将m维特征映射到n维（n &lt; m），这n维形成主元，是重构出来最能代表原始数据的正交特征。</p>
<p>​    假设数据集是m个n维，$(\boldsymbol x^{(1)}, \boldsymbol x^{(2)}, \cdots, \boldsymbol x^{(m)})$。如果$n=2$，需要降维到$n’=1$，现在想找到某一维度方向代表这两个维度的数据。下图有$u_1, u_2$两个向量方向，但是哪个向量才是我们所想要的，可以更好代表原始数据集的呢？</p>
<p><img src="/img/ch2/2.34/1.png" alt=""></p>
<p>从图可看出，$u_1$比$u_2$好，为什么呢？有以下两个主要评价指标：</p>
<ol>
<li>样本点到这个直线的距离足够近。</li>
<li>样本点在这个直线上的投影能尽可能的分开。</li>
</ol>
<p>如果我们需要降维的目标维数是其他任意维，则：</p>
<ol>
<li>样本点到这个超平面的距离足够近。</li>
<li>样本点在这个超平面上的投影能尽可能的分开。</li>
</ol>
<h3 id="2-15-3-PCA算法推理"><a href="#2-15-3-PCA算法推理" class="headerlink" title="2.15.3 PCA算法推理"></a>2.15.3 PCA算法推理</h3><p>下面以基于最小投影距离为评价指标推理：</p>
<p>​    假设数据集是m个n维，$(x^{(1)}, x^{(2)},…,x^{(m)})$，且数据进行了中心化。经过投影变换得到新坐标为 ${w_1,w_2,…,w_n}$，其中 $w$ 是标准正交基，即 $| w |_2 = 1$，$w^T_iw_j = 0$。</p>
<p>​    经过降维后，新坐标为 $\{ w_1,w_2,…,w_n \}$，其中 $n’$ 是降维后的目标维数。样本点 $x^{(i)}$ 在新坐标系下的投影为 $z^{(i)} = \left(z^{(i)}_1, z^{(i)}_2, …, z^{(i)}_{n’}   \right)$，其中 $z^{(i)}_j = w^T_j x^{(i)}$ 是 $x^{(i)} ​$ 在低维坐标系里第 j 维的坐标。</p>
<p>​    如果用 $z^{(i)} $ 去恢复 $x^{(i)} $ ，则得到的恢复数据为 $\widehat{x}^{(i)} = \sum^{n’}_{j=1} x^{(i)}_j w_j = Wz^{(i)}$，其中 $W$为标准正交基组成的矩阵。</p>
<p>​    考虑到整个样本集，样本点到这个超平面的距离足够近，目标变为最小化 $\sum^m_{i=1} | \hat{x}^{(i)} - x^{(i)} |^2_2$ 。对此式进行推理，可得：</p>
<script type="math/tex; mode=display">
\sum^m_{i=1} \| \hat{x}^{(i)} - x^{(i)} \|^2_2 = 
    \sum^m_{i=1} \| Wz^{(i)} - x^{(i)} \|^2_2 \\
    = \sum^m_{i=1} \left( Wz^{(i)} \right)^T \left( Wz^{(i)} \right)
    - 2\sum^m_{i=1} \left( Wz^{(i)} \right)^T x^{(i)}
    + \sum^m_{i=1} \left( x^{(i)} \right)^T x^{(i)} \\
    = \sum^m_{i=1} \left( z^{(i)} \right)^T \left( z^{(i)} \right)
    - 2\sum^m_{i=1} \left( z^{(i)} \right)^T x^{(i)}
    + \sum^m_{i=1} \left( x^{(i)} \right)^T x^{(i)} \\
    = - \sum^m_{i=1} \left( z^{(i)} \right)^T \left( z^{(i)} \right)
    + \sum^m_{i=1} \left( x^{(i)} \right)^T x^{(i)} \\
    = -tr \left( W^T \left( \sum^m_{i=1} x^{(i)} \left( x^{(i)} \right)^T \right)W \right)
    + \sum^m_{i=1} \left( x^{(i)} \right)^T x^{(i)} \\
    = -tr \left( W^TXX^TW \right)
    + \sum^m_{i=1} \left( x^{(i)} \right)^T x^{(i)}</script><p>​    在推导过程中，分别用到了 $\overline{x}^{(i)} = Wz^{(i)}$ ，矩阵转置公式 $(AB)^T = B^TA^T$，$W^TW = I$，$z^{(i)} = W^Tx^{(i)}$ 以及矩阵的迹，最后两步是将代数和转为矩阵形式。<br>​    由于 $W$ 的每一个向量 $w_j$ 是标准正交基，$\sum^m_{i=1} x^{(i)} \left(  x^{(i)} \right)^T$ 是数据集的协方差矩阵，$\sum^m_{i=1} \left(  x^{(i)} \right)^T x^{(i)} $ 是一个常量。最小化 $\sum^m_{i=1} | \hat{x}^{(i)} - x^{(i)} |^2_2$ 又可等价于</p>
<script type="math/tex; mode=display">
\underbrace{\arg \min}_W - tr \left( W^TXX^TW \right) s.t.W^TW = I</script><p>利用拉格朗日函数可得到</p>
<script type="math/tex; mode=display">
J(W) = -tr(W^TXX^TW) + \lambda(W^TW - I)</script><p>​    对 $W$ 求导，可得 $-XX^TW + \lambda W = 0 $ ，也即 $ XX^TW = \lambda W $ 。 $ XX^T $ 是 $ n’ $ 个特征向量组成的矩阵，$\lambda$ 为$ XX^T $ 的特征值。$W$ 即为我们想要的矩阵。<br>​    对于原始数据，只需要 $z^{(i)} = W^TX^{(i)}$ ，就可把原始数据集降维到最小投影距离的 $n’$ 维数据集。</p>
<p>​    基于最大投影方差的推导，这里就不再赘述，有兴趣的同仁可自行查阅资料。</p>
<h3 id="2-15-4-PCA算法流程总结"><a href="#2-15-4-PCA算法流程总结" class="headerlink" title="2.15.4 PCA算法流程总结"></a>2.15.4 PCA算法流程总结</h3><p>输入：$n​$ 维样本集 $D = \left( x^{(1)},x^{(2)},…,x^{(m)} \right)​$ ，目标降维的维数 $n’​$ 。</p>
<p>输出：降维后的新样本集 $D’  = \left( z^{(1)},z^{(2)},…,z^{(m)} \right)$ 。</p>
<p>主要步骤如下：</p>
<ol>
<li>对所有的样本进行中心化，$ x^{(i)} = x^{(i)} - \frac{1}{m} \sum^m_{j=1} x^{(j)} $ 。</li>
<li>计算样本的协方差矩阵 $XX^T​$ 。</li>
<li>对协方差矩阵 $XX^T$ 进行特征值分解。</li>
<li>取出最大的 $n’ $ 个特征值对应的特征向量 $\{ w_1,w_2,…,w_{n’} \}$ 。</li>
<li>标准化特征向量，得到特征向量矩阵 $W$ 。</li>
<li>转化样本集中的每个样本 $z^{(i)} = W^T x^{(i)}$ 。</li>
<li>得到输出矩阵 $D’ = \left( z^{(1)},z^{(2)},…,z^{(n)} \right)​$ 。<br><em>注</em>：在降维时，有时不明确目标维数，而是指定降维到的主成分比重阈值 $k(k \epsilon(0,1])​$ 。假设 $n​$ 个特征值为 $\lambda_1 \geqslant \lambda_2 \geqslant … \geqslant \lambda_n​$ ，则 $n’​$ 可从 $\sum^{n’}_{i=1} \lambda_i \geqslant k \times \sum^n_{i=1} \lambda_i ​$ 得到。</li>
</ol>
<h3 id="2-15-5-PCA算法主要优缺点"><a href="#2-15-5-PCA算法主要优缺点" class="headerlink" title="2.15.5 PCA算法主要优缺点"></a>2.15.5 PCA算法主要优缺点</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">优缺点</th>
<th style="text-align:left">简要说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">优点</td>
<td style="text-align:left">1. 仅仅需要以方差衡量信息量，不受数据集以外的因素影响。　2.各主成分之间正交，可消除原始数据成分间的相互影响的因素。3. 计算方法简单，主要运算是特征值分解，易于实现。</td>
</tr>
<tr>
<td style="text-align:center">缺点</td>
<td style="text-align:left">1.主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强。2. 方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-15-6-降维的必要性及目的"><a href="#2-15-6-降维的必要性及目的" class="headerlink" title="2.15.6 降维的必要性及目的"></a>2.15.6 降维的必要性及目的</h3><p><strong>降维的必要性</strong>：</p>
<ol>
<li>多重共线性和预测变量之间相互关联。多重共线性会导致解空间的不稳定，从而可能导致结果的不连贯。</li>
<li>高维空间本身具有稀疏性。一维正态分布有68%的值落于正负标准差之间，而在十维空间上只有2%。</li>
<li>过多的变量，对查找规律造成冗余麻烦。</li>
<li>仅在变量层面上分析可能会忽略变量之间的潜在联系。例如几个预测变量可能落入仅反映数据某一方面特征的一个组内。</li>
</ol>
<p><strong>降维的目的</strong>：</p>
<ol>
<li>减少预测变量的个数。</li>
<li>确保这些变量是相互独立的。</li>
<li>提供一个框架来解释结果。相关特征，特别是重要特征更能在数据中明确的显示出来；如果只有两维或者三维的话，更便于可视化展示。</li>
<li>数据在低维下更容易处理、更容易使用。</li>
<li>去除数据噪声。</li>
<li>降低算法运算开销。</li>
</ol>
<h3 id="2-15-7-KPCA与PCA的区别"><a href="#2-15-7-KPCA与PCA的区别" class="headerlink" title="2.15.7 KPCA与PCA的区别"></a>2.15.7 KPCA与PCA的区别</h3><p>​    应用PCA算法前提是假设存在一个线性超平面，进而投影。那如果数据不是线性的呢？该怎么办？这时候就需要KPCA，数据集从 $n$ 维映射到线性可分的高维 $N &gt;n$，然后再从 $N$ 维降维到一个低维度 $n’(n’&lt;n&lt;N)$ 。</p>
<p>​    KPCA用到了核函数思想，使用了核函数的主成分分析一般称为核主成分分析(Kernelized PCA, 简称KPCA）。</p>
<p>假设高维空间数据由 $n​$ 维空间的数据通过映射 $\phi​$ 产生。</p>
<p>​    $n$ 维空间的特征分解为：</p>
<script type="math/tex; mode=display">
\sum^m_{i=1} x^{(i)} \left( x^{(i)} \right)^T W = \lambda W</script><p>​    其映射为</p>
<script type="math/tex; mode=display">
\sum^m_{i=1} \phi \left( x^{(i)} \right) \phi \left( x^{(i)} \right)^T W = \lambda W</script><p>​    通过在高维空间进行协方差矩阵的特征值分解，然后用和PCA一样的方法进行降维。由于KPCA需要核函数的运算，因此它的计算量要比PCA大很多。</p>
<h2 id="2-16-模型评估"><a href="#2-16-模型评估" class="headerlink" title="2.16 模型评估"></a>2.16 模型评估</h2><h3 id="2-16-1-模型评估常用方法？"><a href="#2-16-1-模型评估常用方法？" class="headerlink" title="2.16.1 模型评估常用方法？"></a>2.16.1 模型评估常用方法？</h3><p>​    一般情况来说，单一评分标准无法完全评估一个机器学习模型。只用good和bad偏离真实场景去评估某个模型，都是一种欠妥的评估方式。下面介绍常用的分类模型和回归模型评估方法。</p>
<p><strong>分类模型常用评估方法：</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">指标</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Accuracy</td>
<td style="text-align:center">准确率</td>
</tr>
<tr>
<td style="text-align:center">Precision</td>
<td style="text-align:center">精准度/查准率</td>
</tr>
<tr>
<td style="text-align:center">Recall</td>
<td style="text-align:center">召回率/查全率</td>
</tr>
<tr>
<td style="text-align:center">P-R曲线</td>
<td style="text-align:center">查准率为纵轴，查全率为横轴，作图</td>
</tr>
<tr>
<td style="text-align:center">F1</td>
<td style="text-align:center">F1值</td>
</tr>
<tr>
<td style="text-align:center">Confusion Matrix</td>
<td style="text-align:center">混淆矩阵</td>
</tr>
<tr>
<td style="text-align:center">ROC</td>
<td style="text-align:center">ROC曲线</td>
</tr>
<tr>
<td style="text-align:center">AUC</td>
<td style="text-align:center">ROC曲线下的面积</td>
</tr>
</tbody>
</table>
</div>
<p><strong>回归模型常用评估方法：</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">指标</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Mean Square Error (MSE, RMSE)</td>
<td style="text-align:center">平均方差</td>
</tr>
<tr>
<td style="text-align:center">Absolute Error (MAE, RAE)</td>
<td style="text-align:center">绝对误差</td>
</tr>
<tr>
<td style="text-align:center">R-Squared</td>
<td style="text-align:center">R平方值</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-16-2-误差、偏差和方差有什么区别和联系"><a href="#2-16-2-误差、偏差和方差有什么区别和联系" class="headerlink" title="2.16.2 误差、偏差和方差有什么区别和联系"></a>2.16.2 误差、偏差和方差有什么区别和联系</h3><p>在机器学习中，Bias(偏差)，Error(误差)，和Variance(方差)存在以下区别和联系：</p>
<p><strong>对于Error </strong>：</p>
<ul>
<li><p>误差（error）：一般地，我们把学习器的实际预测输出与样本的真是输出之间的差异称为“误差”。</p>
</li>
<li><p>Error = Bias + Variance + Noise，Error反映的是整个模型的准确度。</p>
</li>
</ul>
<p><strong>对于Noise:</strong></p>
<p>噪声：描述了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。</p>
<p><strong>对于Bias：</strong></p>
<ul>
<li>Bias衡量模型拟合训练数据的能力（训练数据不一定是整个 training dataset，而是只用于训练它的那一部分数据，例如：mini-batch），Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度。</li>
<li>Bias 越小，拟合能力越高（可能产生overfitting）；反之，拟合能力越低（可能产生underfitting）。</li>
<li>偏差越大，越偏离真实数据，如下图第二行所示。</li>
</ul>
<p><strong>对于Variance：</strong></p>
<ul>
<li><p>方差公式：$S_{N}^{2}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}$</p>
</li>
<li><p>Variance描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，模型的稳定程度越差。</p>
</li>
<li>Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。</li>
<li>Variance越小，模型的泛化的能力越高；反之，模型的泛化的能力越低。</li>
<li>如果模型在训练集上拟合效果比较优秀，但是在测试集上拟合效果比较差劣，则方差较大，说明模型的稳定程度较差，出现这种现象可能是由于模型对训练集过拟合造成的。 如下图右列所示。</li>
</ul>
<blockquote>
<p><img src="/img/ch2/2.16.20.1.png" alt=""></p>
</blockquote>
<h3 id="2-16-3-经验误差与泛化误差"><a href="#2-16-3-经验误差与泛化误差" class="headerlink" title="2.16.3 经验误差与泛化误差"></a>2.16.3 经验误差与泛化误差</h3><p>经验误差（empirical error）：也叫训练误差（training error），模型在训练集上的误差。 </p>
<p>泛化误差（generalization error）：模型在新样本集（测试集）上的误差称为“泛化误差”。</p>
<h3 id="2-16-4-图解欠拟合、过拟合"><a href="#2-16-4-图解欠拟合、过拟合" class="headerlink" title="2.16.4 图解欠拟合、过拟合"></a>2.16.4 图解欠拟合、过拟合</h3><p>根据不同的坐标方式，欠拟合与过拟合图解不同。</p>
<ol>
<li><strong>横轴为训练样本数量，纵轴为误差</strong></li>
</ol>
<p><img src="/img/ch2/2.16.4.1.jpg" alt=""></p>
<p>如上图所示，我们可以直观看出欠拟合和过拟合的区别：</p>
<p>​    模型欠拟合：在训练集以及测试集上同时具有较高的误差，此时模型的偏差较大；</p>
<p>​    模型过拟合：在训练集上具有较低的误差，在测试集上具有较高的误差，此时模型的方差较大。</p>
<p>​    模型正常：在训练集以及测试集上，同时具有相对较低的偏差以及方差。</p>
<ol>
<li><strong>横轴为模型复杂程度，纵轴为误差</strong></li>
</ol>
<p><img src="/img/ch2/2.16.4.2.png" alt=""></p>
<p>​                    红线为测试集上的Error,蓝线为训练集上的Error</p>
<p>​    模型欠拟合：模型在点A处，在训练集以及测试集上同时具有较高的误差，此时模型的偏差较大。</p>
<p>​    模型过拟合：模型在点C处，在训练集上具有较低的误差，在测试集上具有较高的误差，此时模型的方差较大。 </p>
<p>​    模型正常：模型复杂程度控制在点B处为最优。</p>
<ol>
<li><strong>横轴为正则项系数，纵轴为误差</strong></li>
</ol>
<p><img src="/img/ch2/2.16.4.3.png" alt=""></p>
<p>​                                             红线为测试集上的Error,蓝线为训练集上的Error</p>
<p>​    模型欠拟合：模型在点C处，在训练集以及测试集上同时具有较高的误差，此时模型的偏差较大。</p>
<p>​    模型过拟合：模型在点A处，在训练集上具有较低的误差，在测试集上具有较高的误差，此时模型的方差较大。 它通常发生在模型过于复杂的情况下，如参数过多等，会使得模型的预测性能变弱，并且增加数据的波动性。虽然模型在训练时的效果可以表现的很完美，基本上记住了数据的全部特点，但这种模型在未知数据的表现能力会大减折扣，因为简单的模型泛化能力通常都是很弱的。</p>
<p>​    模型正常：模型复杂程度控制在点B处为最优。</p>
<h3 id="2-16-5-如何解决过拟合与欠拟合"><a href="#2-16-5-如何解决过拟合与欠拟合" class="headerlink" title="2.16.5 如何解决过拟合与欠拟合"></a>2.16.5 如何解决过拟合与欠拟合</h3><p><strong>如何解决欠拟合：</strong></p>
<ol>
<li>添加其他特征项。组合、泛化、相关性、上下文特征、平台特征等特征是特征添加的重要手段，有时候特征项不够会导致模型欠拟合。</li>
<li>添加多项式特征。例如将线性模型添加二次项或三次项使模型泛化能力更强。例如，FM（Factorization Machine）模型、FFM（Field-aware Factorization Machine）模型，其实就是线性模型，增加了二阶多项式，保证了模型一定的拟合程度。</li>
<li>可以增加模型的复杂程度。</li>
<li>减小正则化系数。正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。</li>
</ol>
<p><strong>如何解决过拟合：</strong></p>
<ol>
<li>重新清洗数据，数据不纯会导致过拟合，此类情况需要重新清洗数据。 </li>
<li>增加训练样本数量。 </li>
<li>降低模型复杂程度。 </li>
<li>增大正则项系数。 </li>
<li>采用dropout方法，dropout方法，通俗的讲就是在训练的时候让神经元以一定的概率不工作。 </li>
<li>early stopping。 </li>
<li>减少迭代次数。 </li>
<li>增大学习率。 </li>
<li>添加噪声数据。 </li>
<li>树结构中，可以对树进行剪枝。 </li>
<li>减少特征项。</li>
</ol>
<p>欠拟合和过拟合这些方法，需要根据实际问题，实际模型，进行选择。</p>
<h3 id="2-16-6-交叉验证的主要作用"><a href="#2-16-6-交叉验证的主要作用" class="headerlink" title="2.16.6 交叉验证的主要作用"></a>2.16.6 交叉验证的主要作用</h3><p>​    为了得到更为稳健可靠的模型，对模型的泛化误差进行评估，得到模型泛化误差的近似值。当有多个模型可以选择时，我们通常选择“泛化误差”最小的模型。 </p>
<p>​    交叉验证的方法有许多种，但是最常用的是：留一交叉验证、k折交叉验证。</p>
<h3 id="2-16-7-理解k折交叉验证"><a href="#2-16-7-理解k折交叉验证" class="headerlink" title="2.16.7 理解k折交叉验证"></a>2.16.7 理解k折交叉验证</h3><ol>
<li>将含有N个样本的数据集，分成K份，每份含有N/K个样本。选择其中1份作为测试集，另外K-1份作为训练集，测试集就有K种情况。 </li>
<li>在每种情况中，用训练集训练模型，用测试集测试模型，计算模型的泛化误差。 </li>
<li>交叉验证重复K次，每份验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测，得到模型最终的泛化误差。 </li>
<li>将K种情况下，模型的泛化误差取均值，得到模型最终的泛化误差。  </li>
<li>一般$2\leqslant K \leqslant10$。 k折交叉验证的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10折交叉验证是最常用的。 </li>
<li>训练集中样本数量要足够多，一般至少大于总样本数的50%。 </li>
<li>训练集和测试集必须从完整的数据集中均匀取样。均匀取样的目的是希望减少训练集、测试集与原数据集之间的偏差。当样本数量足够多时，通过随机取样，便可以实现均匀取样的效果。 </li>
</ol>
<h3 id="2-16-8-混淆矩阵"><a href="#2-16-8-混淆矩阵" class="headerlink" title="2.16.8 混淆矩阵"></a>2.16.8 混淆矩阵</h3><p>第一种混淆矩阵:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">真实情况T or F</th>
<th style="text-align:left">预测为正例1，P</th>
<th style="text-align:left">预测为负例0，N</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">本来label标记为1，预测结果真为T、假为F</td>
<td style="text-align:left">TP(预测为1，实际为1)</td>
<td style="text-align:left">FN(预测为0，实际为1)</td>
</tr>
<tr>
<td style="text-align:center">本来label标记为0，预测结果真为T、假为F</td>
<td style="text-align:left">FP(预测为1，实际为0)</td>
<td style="text-align:left">TN(预测为0，实际也为0)</td>
</tr>
</tbody>
</table>
</div>
<p>第二种混淆矩阵:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">预测情况P or N</th>
<th style="text-align:left">实际label为1,预测对了为T</th>
<th style="text-align:left">实际label为0,预测对了为T</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">预测为正例1，P</td>
<td style="text-align:left">TP(预测为1，实际为1)</td>
<td style="text-align:left">FP(预测为1，实际为0)</td>
</tr>
<tr>
<td style="text-align:center">预测为负例0，N</td>
<td style="text-align:left">FN(预测为0，实际为1)</td>
<td style="text-align:left">TN(预测为0，实际也为0)</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-16-9-错误率及精度"><a href="#2-16-9-错误率及精度" class="headerlink" title="2.16.9 错误率及精度"></a>2.16.9 错误率及精度</h3><ol>
<li>错误率（Error Rate）：分类错误的样本数占样本总数的比例。</li>
<li>精度（accuracy）：分类正确的样本数占样本总数的比例。</li>
</ol>
<h3 id="2-16-10-查准率与查全率"><a href="#2-16-10-查准率与查全率" class="headerlink" title="2.16.10 查准率与查全率"></a>2.16.10 查准率与查全率</h3><p>将算法预测的结果分成四种情况： </p>
<ol>
<li>正确肯定（True Positive,TP）：预测为真，实际为真 </li>
<li>正确否定（True Negative,TN）：预测为假，实际为假 </li>
<li>错误肯定（False Positive,FP）：预测为真，实际为假 </li>
<li>错误否定（False Negative,FN）：预测为假，实际为真</li>
</ol>
<p>则： </p>
<p>查准率（Precision）=TP/（TP+FP）</p>
<p><strong>理解</strong>：预测出为阳性的样本中，正确的有多少。区别准确率（正确预测出的样本，包括正确预测为阳性、阴性，占总样本比例）。<br>例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。 </p>
<p>查全率（Recall）=TP/（TP+FN）</p>
<p><strong>理解</strong>：正确预测为阳性的数量占总样本中阳性数量的比例。<br>例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。 </p>
<h3 id="2-16-11-ROC与AUC"><a href="#2-16-11-ROC与AUC" class="headerlink" title="2.16.11 ROC与AUC"></a>2.16.11 ROC与AUC</h3><p>​    ROC全称是“受试者工作特征”（Receiver Operating Characteristic）。</p>
<p>​    ROC曲线的面积就是AUC（Area Under Curve）。</p>
<p>​    AUC用于衡量“二分类问题”机器学习算法性能（泛化能力）。</p>
<p>​    ROC曲线，通过将连续变量设定出多个不同的临界值，从而计算出一系列真正率和假正率，再以假正率为横坐标、真正率为纵坐标绘制成曲线，曲线下面积越大，推断准确性越高。在ROC曲线上，最靠近坐标图左上方的点为假正率和真正率均较高的临界值。 </p>
<p>​    对于分类器，或者说分类算法，评价指标主要有Precision，Recall，F-score。下图是一个ROC曲线的示例。</p>
<p><img src="/img/ch2/2.40.10/1.png" alt=""></p>
<p>ROC曲线的横坐标为False Positive Rate（FPR），纵坐标为True Positive Rate（TPR）。其中</p>
<script type="math/tex; mode=display">
TPR = \frac{TP}{TP+FN} ,FPR = \frac{FP}{FP+TN}</script><p>​    下面着重介绍ROC曲线图中的四个点和一条线。<br>​    第一个点(0,1)，即FPR=0, TPR=1，这意味着FN（False Negative）=0，并且FP（False Positive）=0。意味着这是一个完美的分类器，它将所有的样本都正确分类。<br>​    第二个点(1,0)，即FPR=1，TPR=0，意味着这是一个最糟糕的分类器，因为它成功避开了所有的正确答案。<br>​    第三个点(0,0)，即FPR=TPR=0，即FP（False Positive）=TP（True Positive）=0，可以发现该分类器预测所有的样本都为负样本（Negative）。<br>​    第四个点(1,1)，即FPR=TPR=1，分类器实际上预测所有的样本都为正样本。<br>​    经过以上分析，ROC曲线越接近左上角，该分类器的性能越好。</p>
<p>​    ROC曲线所覆盖的面积称为AUC（Area Under Curve），可以更直观的判断学习器的性能，AUC越大则性能越好。  </p>
<h3 id="2-16-12-如何画ROC曲线"><a href="#2-16-12-如何画ROC曲线" class="headerlink" title="2.16.12 如何画ROC曲线"></a>2.16.12 如何画ROC曲线</h3><p>​    下图是一个示例，图中共有20个测试样本，“Class”一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），“Score”表示每个测试样本属于正样本的概率。</p>
<p>步骤：<br>    1、假设已经得出一系列样本被划分为正类的概率，按照大小排序。<br>    2、从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。<br>    3、每次选取一个不同的threshold，得到一组FPR和TPR，即ROC曲线上的一点。以此共得到20组FPR和TPR的值。<br>    4、根据3、中的每个坐标点，画图。</p>
<p><img src="/img/ch2/2.40.11/1.jpg" alt=""></p>
<h3 id="2-16-13-如何计算TPR，FPR"><a href="#2-16-13-如何计算TPR，FPR" class="headerlink" title="2.16.13 如何计算TPR，FPR"></a>2.16.13 如何计算TPR，FPR</h3><p>1、分析数据<br>y_true = [0, 0, 1, 1]；scores = [0.1, 0.4, 0.35, 0.8]；<br>2、列表</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>样本</th>
<th>预测属于P的概率(score)</th>
<th>真实类别</th>
</tr>
</thead>
<tbody>
<tr>
<td>y[0]</td>
<td>0.1</td>
<td>N</td>
</tr>
<tr>
<td>y[1]</td>
<td>0.4</td>
<td>N</td>
</tr>
<tr>
<td>y[2]</td>
<td>0.35</td>
<td>P</td>
</tr>
<tr>
<td>y[3]</td>
<td>0.8</td>
<td>P</td>
</tr>
</tbody>
</table>
</div>
<p>3、将截断点依次取为score值，计算TPR和FPR。<br>当截断点为0.1时：<br>说明只要score&gt;=0.1，它的预测类别就是正例。 因为4个样本的score都大于等于0.1，所以，所有样本的预测类别都为P。<br>scores = [0.1, 0.4, 0.35, 0.8]；y_true = [0, 0, 1, 1]；y_pred = [1, 1, 1, 1]；<br>正例与反例信息如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>正例</th>
<th>反例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>正例</strong></td>
<td>TP=2</td>
<td>FN=0</td>
</tr>
<tr>
<td><strong>反例</strong></td>
<td>FP=2</td>
<td>TN=0</td>
</tr>
</tbody>
</table>
</div>
<p>由此可得：<br>TPR = TP/(TP+FN) = 1； FPR = FP/(TN+FP) = 1；</p>
<p>当截断点为0.35时：<br>scores = [0.1, 0.4, 0.35, 0.8]；y_true = [0, 0, 1, 1]；y_pred = [0, 1, 1, 1];<br>正例与反例信息如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>正例</th>
<th>反例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>正例</strong></td>
<td>TP=2</td>
<td>FN=0</td>
</tr>
<tr>
<td><strong>反例</strong></td>
<td>FP=1</td>
<td>TN=1</td>
</tr>
</tbody>
</table>
</div>
<p>由此可得：<br>TPR = TP/(TP+FN) = 1； FPR = FP/(TN+FP) = 0.5；</p>
<p>当截断点为0.4时：<br>scores = [0.1, 0.4, 0.35, 0.8]；y_true = [0, 0, 1, 1]；y_pred = [0, 1, 0, 1]；<br>正例与反例信息如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>正例</th>
<th>反例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>正例</strong></td>
<td>TP=1</td>
<td>FN=1</td>
</tr>
<tr>
<td><strong>反例</strong></td>
<td>FP=1</td>
<td>TN=1</td>
</tr>
</tbody>
</table>
</div>
<p>由此可得：<br>TPR = TP/(TP+FN) = 0.5； FPR = FP/(TN+FP) = 0.5；</p>
<p>当截断点为0.8时：<br>scores = [0.1, 0.4, 0.35, 0.8]；y_true = [0, 0, 1, 1]；y_pred = [0, 0, 0, 1]；</p>
<p>正例与反例信息如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>正例</th>
<th>反例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>正例</strong></td>
<td>TP=1</td>
<td>FN=1</td>
</tr>
<tr>
<td><strong>反例</strong></td>
<td>FP=0</td>
<td>TN=2</td>
</tr>
</tbody>
</table>
</div>
<p>由此可得：<br>TPR = TP/(TP+FN) = 0.5； FPR = FP/(TN+FP) = 0；</p>
<p>4、根据TPR、FPR值，以FPR为横轴，TPR为纵轴画图。</p>
<h3 id="2-16-14-如何计算AUC"><a href="#2-16-14-如何计算AUC" class="headerlink" title="2.16.14 如何计算AUC"></a>2.16.14 如何计算AUC</h3><ul>
<li>将坐标点按照横坐标FPR排序 。</li>
<li>计算第$i$个坐标点和第$i+1$个坐标点的间距$dx$ 。 </li>
<li>获取第$i$或者$i+1$个坐标点的纵坐标y。</li>
<li>计算面积微元$ds=ydx$。</li>
<li>对面积微元进行累加，得到AUC。</li>
</ul>
<h3 id="2-16-15-为什么使用Roc和Auc评价分类器"><a href="#2-16-15-为什么使用Roc和Auc评价分类器" class="headerlink" title="2.16.15 为什么使用Roc和Auc评价分类器"></a>2.16.15 为什么使用Roc和Auc评价分类器</h3><p>​    模型有很多评估方法，为什么还要使用ROC和AUC呢？<br>​    因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。</p>
<h3 id="2-16-16-直观理解AUC"><a href="#2-16-16-直观理解AUC" class="headerlink" title="2.16.16 直观理解AUC"></a>2.16.16 直观理解AUC</h3><p>​    下图展现了三种AUC的值： </p>
<p><img src="/img/ch2/2.40.15/1.png" alt=""></p>
<p>​    AUC是衡量二分类模型优劣的一种评价指标，表示正例排在负例前面的概率。其他评价指标有精确度、准确率、召回率，而AUC比这三者更为常用。<br>​    一般在分类模型中，预测结果都是以概率的形式表现，如果要计算准确率，通常都会手动设置一个阈值来将对应的概率转化成类别，这个阈值也就很大程度上影响了模型准确率的计算。<br>​    举例：<br>​    现在假设有一个训练好的二分类器对10个正负样本（正例5个，负例5个）预测，得分按高到低排序得到的最好预测结果为[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]，即5个正例均排在5个负例前面，正例排在负例前面的概率为100%。然后绘制其ROC曲线，由于是10个样本，除去原点我们需要描10个点，如下：</p>
<p><img src="/img/ch2/2.16.17-1.png" alt=""></p>
<p>​    描点方式按照样本预测结果的得分高低从左至右开始遍历。从原点开始，每遇到1便向y轴正方向移动y轴最小步长1个单位，这里是1/5=0.2；每遇到0则向x轴正方向移动x轴最小步长1个单位，这里也是0.2。不难看出，上图的AUC等于1，印证了正例排在负例前面的概率的确为100%。</p>
<p>​    假设预测结果序列为[1, 1, 1, 1, 0, 1, 0, 0, 0, 0]。</p>
<p><img src="/img/ch2/2.16.17-2.png" alt=""></p>
<p>​    计算上图的AUC为0.96与计算正例与排在负例前面的概率0.8 × 1 + 0.2 × 0.8 = 0.96相等，而左上角阴影部分的面积则是负例排在正例前面的概率0.2 × 0.2 = 0.04。</p>
<p>​    假设预测结果序列为[1, 1, 1, 0, 1, 0, 1, 0, 0, 0]。</p>
<p><img src="/img/ch2/2.16.17-3.png" alt=""></p>
<p>​    计算上图的AUC为0.88与计算正例与排在负例前面的概率0.6 × 1 + 0.2 × 0.8 + 0.2 × 0.6 = 0.88相等，左上角阴影部分的面积是负例排在正例前面的概率0.2 × 0.2 × 3 = 0.12。</p>
<h3 id="2-16-17-代价敏感错误率与代价曲线"><a href="#2-16-17-代价敏感错误率与代价曲线" class="headerlink" title="2.16.17 代价敏感错误率与代价曲线"></a>2.16.17 代价敏感错误率与代价曲线</h3><p>不同的错误会产生不同代价。以二分法为例，设置代价矩阵如下：</p>
<p><img src="/img/ch2/2-1.png" alt=""></p>
<p>当判断正确的时候，值为0，不正确的时候，分别为$Cost_{01}​$和$Cost_{10}​$ 。</p>
<p>$Cost_{10}$:表示实际为反例但预测成正例的代价。</p>
<p>$Cost_{01}$:表示实际为正例但是预测为反例的代价。</p>
<p><strong>代价敏感错误率</strong>=样本中由模型得到的错误值与代价乘积之和 / 总样本。<br>其数学表达式为：</p>
<script type="math/tex; mode=display">
E(f;D;cost)=\frac{1}{m}\left( \sum_{x_{i} \in D^{+}}({f(x_i)\neq y_i})\times Cost_{01}+ \sum_{x_{i} \in D^{-}}({f(x_i)\neq y_i})\times Cost_{10}\right)</script><p>$D^{+}、D^{-}​$分别代表样例集的正例子集和反例子集，x是预测值，y是真实值。</p>
<p><strong>代价曲线</strong>：<br>    在均等代价时，ROC曲线不能直接反应出模型的期望总体代价，而代价曲线可以。<br>代价曲线横轴为[0,1]的正例函数代价：</p>
<script type="math/tex; mode=display">
P(+)Cost=\frac{p*Cost_{01}}{p*Cost_{01}+(1-p)*Cost_{10}}</script><p>其中p是样本为正例的概率。</p>
<p>代价曲线纵轴维[0,1]的归一化代价：</p>
<script type="math/tex; mode=display">
Cost_{norm}=\frac{FNR*p*Cost_{01}+FNR*(1-p)*Cost_{10}}{p*Cost_{01}+(1-p)*Cost_{10}}</script><p>其中FPR为假阳率，FNR=1-TPR为假阴率。</p>
<p>注：ROC每个点，对应代价平面上一条线。</p>
<p>例如，ROC上(TPR,FPR),计算出FNR=1-TPR，在代价平面上绘制一条从(0,FPR)到(1,FNR)的线段，面积则为该条件下期望的总体代价。所有线段下界面积，所有条件下学习器的期望总体代价。</p>
<p><img src="/img/ch2/2.16.18.1.png" alt=""></p>
<h3 id="2-16-18-模型有哪些比较检验方法"><a href="#2-16-18-模型有哪些比较检验方法" class="headerlink" title="2.16.18 模型有哪些比较检验方法"></a>2.16.18 模型有哪些比较检验方法</h3><p>正确性分析：模型稳定性分析，稳健性分析，收敛性分析，变化趋势分析，极值分析等。<br>有效性分析：误差分析，参数敏感性分析，模型对比检验等。<br>有用性分析：关键数据求解，极值点，拐点，变化趋势分析，用数据验证动态模拟等。<br>高效性分析：时空复杂度分析与现有进行比较等。</p>
<h3 id="2-16-19-为什么使用标准差"><a href="#2-16-19-为什么使用标准差" class="headerlink" title="2.16.19 为什么使用标准差"></a>2.16.19 为什么使用标准差</h3><p>方差公式为：$S^2_{N}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}​$</p>
<p>标准差公式为：$S_{N}=\sqrt{\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}​$</p>
<p>样本标准差公式为：$S_{N}=\sqrt{\frac{1}{N-1}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}​$</p>
<p>与方差相比，使用标准差来表示数据点的离散程度有3个好处：<br>1、表示离散程度的数字与样本数据点的数量级一致，更适合对数据样本形成感性认知。</p>
<p>2、表示离散程度的数字单位与样本数据的单位一致，更方便做后续的分析运算。</p>
<p>3、在样本数据大致符合正态分布的情况下，标准差具有方便估算的特性：68%的数据点落在平均值前后1个标准差的范围内、95%的数据点落在平均值前后2个标准差的范围内，而99%的数据点将会落在平均值前后3个标准差的范围内。</p>
<h3 id="2-16-20-类别不平衡产生原因"><a href="#2-16-20-类别不平衡产生原因" class="headerlink" title="2.16.20 类别不平衡产生原因"></a>2.16.20 类别不平衡产生原因</h3><p>​    类别不平衡（class-imbalance）是指分类任务中不同类别的训练样例数目差别很大的情况。 </p>
<p>产生原因：</p>
<p>​    分类学习算法通常都会假设不同类别的训练样例数目基本相同。如果不同类别的训练样例数目差别很大，则会影响学习结果，测试结果变差。例如二分类问题中有998个反例，正例有2个，那学习方法只需返回一个永远将新样本预测为反例的分类器，就能达到99.8%的精度；然而这样的分类器没有价值。</p>
<h3 id="2-16-21-常见的类别不平衡问题解决方法"><a href="#2-16-21-常见的类别不平衡问题解决方法" class="headerlink" title="2.16.21 常见的类别不平衡问题解决方法"></a>2.16.21 常见的类别不平衡问题解决方法</h3><p>  防止类别不平衡对学习造成的影响，在构建分类模型之前，需要对分类不平衡性问题进行处理。主要解决方法有：</p>
<p>1、扩大数据集</p>
<p>​    增加包含小类样本数据的数据，更多的数据能得到更多的分布信息。</p>
<p>2、对大类数据欠采样</p>
<p>​    减少大类数据样本个数，使与小样本个数接近。<br>​    缺点：欠采样操作时若随机丢弃大类样本，可能会丢失重要信息。<br>​    代表算法：EasyEnsemble。其思想是利用集成学习机制，将大类划分为若干个集合供不同的学习器使用。相当于对每个学习器都进行欠采样，但对于全局则不会丢失重要信息。</p>
<p>3、对小类数据过采样</p>
<p>​    过采样：对小类的数据样本进行采样来增加小类的数据样本个数。 </p>
<p>​    代表算法：SMOTE和ADASYN。 </p>
<p>​    SMOTE：通过对训练集中的小类数据进行插值来产生额外的小类样本数据。</p>
<p>​    新的少数类样本产生的策略：对每个少数类样本a，在a的最近邻中随机选一个样本b，然后在a、b之间的连线上随机选一点作为新合成的少数类样本。<br>​    ADASYN：根据学习难度的不同，对不同的少数类别的样本使用加权分布，对于难以学习的少数类的样本，产生更多的综合数据。 通过减少类不平衡引入的偏差和将分类决策边界自适应地转移到困难的样本两种手段，改善了数据分布。</p>
<p>4、使用新评价指标</p>
<p>​    如果当前评价指标不适用，则应寻找其他具有说服力的评价指标。比如准确度这个评价指标在类别不均衡的分类任务中并不适用，甚至进行误导。因此在类别不均衡分类任务中，需要使用更有说服力的评价指标来对分类器进行评价。</p>
<p>5、选择新算法</p>
<p>​    不同的算法适用于不同的任务与数据，应该使用不同的算法进行比较。</p>
<p>6、数据代价加权</p>
<p>​    例如当分类任务是识别小类，那么可以对分类器的小类样本数据增加权值，降低大类样本的权值，从而使得分类器将重点集中在小类样本身上。</p>
<p>7、转化问题思考角度</p>
<p>​    例如在分类问题时，把小类的样本作为异常点，将问题转化为异常点检测或变化趋势检测问题。 异常点检测即是对那些罕见事件进行识别。变化趋势检测区别于异常点检测在于其通过检测不寻常的变化趋势来识别。    </p>
<p>8、将问题细化分析</p>
<p>​    对问题进行分析与挖掘，将问题划分成多个更小的问题，看这些小问题是否更容易解决。 </p>
<h2 id="2-17-决策树"><a href="#2-17-决策树" class="headerlink" title="2.17 决策树"></a>2.17 决策树</h2><h3 id="2-17-1-决策树的基本原理"><a href="#2-17-1-决策树的基本原理" class="headerlink" title="2.17.1 决策树的基本原理"></a>2.17.1 决策树的基本原理</h3><p>​    决策树（Decision Tree）是一种分而治之的决策过程。一个困难的预测问题，通过树的分支节点，被划分成两个或多个较为简单的子集，从结构上划分为不同的子问题。将依规则分割数据集的过程不断递归下去（Recursive Partitioning）。随着树的深度不断增加，分支节点的子集越来越小，所需要提的问题数也逐渐简化。当分支节点的深度或者问题的简单程度满足一定的停止规则（Stopping Rule）时, 该分支节点会停止分裂，此为自上而下的停止阈值（Cutoff Threshold）法；有些决策树也使用自下而上的剪枝（Pruning）法。</p>
<h3 id="2-17-2-决策树的三要素？"><a href="#2-17-2-决策树的三要素？" class="headerlink" title="2.17.2 决策树的三要素？"></a>2.17.2 决策树的三要素？</h3><p>​    一棵决策树的生成过程主要分为下3个部分：  </p>
<p>​    1、特征选择：从训练数据中众多的特征中选择一个特征作为当前节点的分裂标准，如何选择特征有着很多不同量化评估标准，从而衍生出不同的决策树算法。 </p>
<p>​    2、决策树生成：根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分则决策树停止生长。树结构来说，递归结构是最容易理解的方式。 </p>
<p>​    3、剪枝：决策树容易过拟合，一般来需要剪枝，缩小树结构规模、缓解过拟合。剪枝技术有预剪枝和后剪枝两种。</p>
<h3 id="2-17-3-决策树学习基本算法"><a href="#2-17-3-决策树学习基本算法" class="headerlink" title="2.17.3 决策树学习基本算法"></a>2.17.3 决策树学习基本算法</h3><p><img src="/img/ch2/2-5.png" alt=""></p>
<h3 id="2-17-4-决策树算法优缺点"><a href="#2-17-4-决策树算法优缺点" class="headerlink" title="2.17.4 决策树算法优缺点"></a>2.17.4 决策树算法优缺点</h3><p><strong>决策树算法的优点</strong>：  </p>
<p>1、决策树算法易理解，机理解释起来简单。 </p>
<p>2、决策树算法可以用于小数据集。</p>
<p>3、决策树算法的时间复杂度较小，为用于训练决策树的数据点的对数。</p>
<p>4、相比于其他算法智能分析一种类型变量，决策树算法可处理数字和数据的类别。</p>
<p>5、能够处理多输出的问题。 </p>
<p>6、对缺失值不敏感。</p>
<p>7、可以处理不相关特征数据。</p>
<p>8、效率高，决策树只需要一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。</p>
<p><strong>决策树算法的缺点</strong>： </p>
<p>1、对连续性的字段比较难预测。</p>
<p>2、容易出现过拟合。</p>
<p>3、当类别太多时，错误可能就会增加的比较快。</p>
<p>4、在处理特征关联性比较强的数据时表现得不是太好。</p>
<p>5、对于各类别样本数量不一致的数据，在决策树当中，信息增益的结果偏向于那些具有更多数值的特征。</p>
<h3 id="2-17-5-熵的概念以及理解"><a href="#2-17-5-熵的概念以及理解" class="headerlink" title="2.17.5 熵的概念以及理解"></a>2.17.5 熵的概念以及理解</h3><p>​    熵：度量随机变量的不确定性。<br>​    定义：假设随机变量X的可能取值有$x_{1},x_{2},…,x_{n}$，对于每一个可能的取值$x_{i}$，其概率为$P(X=x_{i})=p_{i},i=1,2…,n$。随机变量的熵为：</p>
<script type="math/tex; mode=display">
H(X)=-\sum_{i=1}^{n}p_{i}log_{2}p_{i}</script><p>​       对于样本集合，假设样本有k个类别，每个类别的概率为$\frac{|C_{k}|}{|D|}$，其中 ${|C_{k}|}{|D|}$为类别为k的样本个数，$|D|​$为样本总数。样本集合D的熵为：</p>
<script type="math/tex; mode=display">
H(D)=-\sum_{k=1}^{k}\frac{|C_{k}|}{|D|}log_{2}\frac{|C_{k}|}{|D|}</script><h3 id="2-17-6-信息增益的理解"><a href="#2-17-6-信息增益的理解" class="headerlink" title="2.17.6 信息增益的理解"></a>2.17.6 信息增益的理解</h3><p>​    定义：以某特征划分数据集前后的熵的差值。<br>​    熵可以表示样本集合的不确定性，熵越大，样本的不确定性就越大。因此可以使用划分前后集合熵的差值来衡量使用当前特征对于样本集合D划分效果的好坏。  ​    假设划分前样本集合D的熵为H(D)。使用某个特征A划分数据集D，计算划分后的数据子集的熵为H(D|A)。<br>​    则信息增益为：</p>
<script type="math/tex; mode=display">
g(D,A)=H(D)-H(D|A)</script><p>​    <em>注：</em>在决策树构建的过程中我们总是希望集合往最快到达纯度更高的子集合方向发展，因此我们总是选择使得信息增益最大的特征来划分当前数据集D。<br>​    思想：计算所有特征划分数据集D，得到多个特征划分数据集D的信息增益，从这些信息增益中选择最大的，因而当前结点的划分特征便是使信息增益最大的划分所使用的特征。<br>​    另外这里提一下信息增益比相关知识：<br>​    $信息增益比=惩罚参数\times信息增益$<br>​    信息增益比本质：在信息增益的基础之上乘上一个惩罚参数。特征个数较多时，惩罚参数较小；特征个数较少时，惩罚参数较大。<br>​    惩罚参数：数据集D以特征A作为随机变量的熵的倒数。</p>
<h3 id="2-17-7-剪枝处理的作用及策略"><a href="#2-17-7-剪枝处理的作用及策略" class="headerlink" title="2.17.7 剪枝处理的作用及策略"></a>2.17.7 剪枝处理的作用及策略</h3><p>​    剪枝处理是决策树学习算法用来解决过拟合问题的一种办法。</p>
<p>​    在决策树算法中，为了尽可能正确分类训练样本， 节点划分过程不断重复， 有时候会造成决策树分支过多，以至于将训练样本集自身特点当作泛化特点， 而导致过拟合。 因此可以采用剪枝处理来去掉一些分支来降低过拟合的风险。 </p>
<p>​    剪枝的基本策略有预剪枝（pre-pruning）和后剪枝（post-pruning）。</p>
<p>​    预剪枝：在决策树生成过程中，在每个节点划分前先估计其划分后的泛化性能， 如果不能提升，则停止划分，将当前节点标记为叶结点。 </p>
<p>​    后剪枝：生成决策树以后，再自下而上对非叶结点进行考察， 若将此节点标记为叶结点可以带来泛化性能提升，则修改之。</p>
<h2 id="2-18-支持向量机"><a href="#2-18-支持向量机" class="headerlink" title="2.18 支持向量机"></a>2.18 支持向量机</h2><h3 id="2-18-1-什么是支持向量机"><a href="#2-18-1-什么是支持向量机" class="headerlink" title="2.18.1 什么是支持向量机"></a>2.18.1 什么是支持向量机</h3><p>​    支持向量：在求解的过程中，会发现只根据部分数据就可以确定分类器，这些数据称为支持向量。</p>
<p>​    支持向量机（Support Vector Machine，SVM）：其含义是通过支持向量运算的分类器。</p>
<p>​    在一个二维环境中，其中点R，S，G点和其它靠近中间黑线的点可以看作为支持向量，它们可以决定分类器，即黑线的具体参数。</p>
<p><img src="/img/ch2/2-6.png" alt=""></p>
<p>​    支持向量机是一种二分类模型，它的目的是寻找一个超平面来对样本进行分割，分割的原则是边界最大化，最终转化为一个凸二次规划问题来求解。由简至繁的模型包括：</p>
<p>​    当训练样本线性可分时，通过硬边界（hard margin）最大化，学习一个线性可分支持向量机；</p>
<p>​    当训练样本近似线性可分时，通过软边界（soft margin）最大化，学习一个线性支持向量机；</p>
<p>​    当训练样本线性不可分时，通过核技巧和软边界最大化，学习一个非线性支持向量机；</p>
<h3 id="2-18-2-支持向量机能解决哪些问题"><a href="#2-18-2-支持向量机能解决哪些问题" class="headerlink" title="2.18.2 支持向量机能解决哪些问题"></a>2.18.2 支持向量机能解决哪些问题</h3><p><strong>线性分类</strong></p>
<p>​    在训练数据中，每个数据都有n个的属性和一个二分类类别标志，我们可以认为这些数据在一个n维空间里。我们的目标是找到一个n-1维的超平面，这个超平面可以将数据分成两部分，每部分数据都属于同一个类别。</p>
<p>​    这样的超平面有很多，假如我们要找到一个最佳的超平面。此时，增加一个约束条件：要求这个超平面到每边最近数据点的距离是最大的，成为最大边距超平面。这个分类器即为最大边距分类器。</p>
<p><strong>非线性分类</strong></p>
<p>​    SVM的一个优势是支持非线性分类。它结合使用拉格朗日乘子法（Lagrange Multiplier）和KKT（Karush Kuhn Tucker）条件，以及核函数可以生成非线性分类器。</p>
<h3 id="2-18-3-核函数特点及其作用"><a href="#2-18-3-核函数特点及其作用" class="headerlink" title="2.18.3 核函数特点及其作用"></a>2.18.3 核函数特点及其作用</h3><p>​    引入核函数目的：把原坐标系里线性不可分的数据用核函数Kernel投影到另一个空间，尽量使得数据在新的空间里线性可分。<br>​    核函数方法的广泛应用，与其特点是分不开的：  </p>
<p>1）核函数的引入避免了“维数灾难”，大大减小了计算量。而输入空间的维数n对核函数矩阵无影响。因此，核函数方法可以有效处理高维输入。</p>
<p>2）无需知道非线性变换函数Φ的形式和参数。</p>
<p>3）核函数的形式和参数的变化会隐式地改变从输入空间到特征空间的映射，进而对特征空间的性质产生影响，最终改变各种核函数方法的性能。</p>
<p>4）核函数方法可以和不同的算法相结合，形成多种不同的基于核函数技术的方法，且这两部分的设计可以单独进行，并可以为不同的应用选择不同的核函数和算法。</p>
<h3 id="2-18-4-SVM为什么引入对偶问题"><a href="#2-18-4-SVM为什么引入对偶问题" class="headerlink" title="2.18.4 SVM为什么引入对偶问题"></a>2.18.4 SVM为什么引入对偶问题</h3><p>1，对偶问题将原始问题中的约束转为了对偶问题中的等式约束，对偶问题往往更加容易求解。</p>
<p>2，可以很自然的引用核函数（拉格朗日表达式里面有内积，而核函数也是通过内积进行映射的）。</p>
<p>3，在优化理论中，目标函数 f(x) 会有多种形式：如果目标函数和约束条件都为变量 x 的线性函数，称该问题为线性规划；如果目标函数为二次函数，约束条件为线性函数，称该最优化问题为二次规划；如果目标函数或者约束条件均为非线性函数，称该最优化问题为非线性规划。每个线性规划问题都有一个与之对应的对偶问题，对偶问题有非常良好的性质，以下列举几个：</p>
<p>​    a, 对偶问题的对偶是原问题；</p>
<p>​    b, 无论原始问题是否是凸的，对偶问题都是凸优化问题；</p>
<p>​    c, 对偶问题可以给出原始问题一个下界；</p>
<p>​    d, 当满足一定条件时，原始问题与对偶问题的解是完全等价的。</p>
<h3 id="2-18-5-如何理解SVM中的对偶问题"><a href="#2-18-5-如何理解SVM中的对偶问题" class="headerlink" title="2.18.5 如何理解SVM中的对偶问题"></a>2.18.5 如何理解SVM中的对偶问题</h3><p>在硬边界支持向量机中，问题的求解可以转化为凸二次规划问题。</p>
<p>​    假设优化目标为</p>
<script type="math/tex; mode=display">
\begin{align}
&\min_{\boldsymbol w, b}\frac{1}{2}||\boldsymbol w||^2\\
&s.t. y_i(\boldsymbol w^T\boldsymbol x_i+b)\geqslant 1, i=1,2,\cdots,m.\\
\end{align}  \tag{1}</script><p><strong>step 1</strong>. 转化问题：</p>
<script type="math/tex; mode=display">
\min_{\boldsymbol w, b} \max_{\alpha_i \geqslant 0}  \left\{\frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))\right\}  \tag{2}</script><p>上式等价于原问题，因为若满足(1)中不等式约束，则(2)式求max时,$\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))$必须取0，与(1)等价；若不满足(1)中不等式约束，(2)中求max会得到无穷大。 交换min和max获得其对偶问题:</p>
<script type="math/tex; mode=display">
\max_{\alpha_i \geqslant 0} \min_{\boldsymbol w, b}  \left\{\frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))\right\}</script><p>交换之后的对偶问题和原问题并不相等，上式的解小于等于原问题的解。</p>
<p><strong>step 2</strong>.现在的问题是如何找到问题(1) 的最优值的一个最好的下界? </p>
<script type="math/tex; mode=display">
\frac{1}{2}||\boldsymbol w||^2 < v\\
1 - y_i(\boldsymbol w^T\boldsymbol x_i+b) \leqslant 0\tag{3}</script><p>若方程组(3)无解， 则v是问题(1)的一个下界。若(3)有解， 则 </p>
<script type="math/tex; mode=display">
\forall \boldsymbol \alpha >  0 , \ \min_{\boldsymbol w, b}  \left\{\frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))\right\} < v</script><p>由逆否命题得：若 </p>
<script type="math/tex; mode=display">
\exists \boldsymbol \alpha >  0 , \ \min_{\boldsymbol w, b}  \left\{\frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))\right\} \geqslant v</script><p>则(3)无解。</p>
<p>那么v是问题</p>
<p>(1)的一个下界。<br> 要求得一个好的下界，取最大值即可 </p>
<script type="math/tex; mode=display">
\max_{\alpha_i \geqslant 0}  \min_{\boldsymbol w, b} \left\{\frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))\right\}</script><p><strong>step 3</strong>. 令</p>
<script type="math/tex; mode=display">
L(\boldsymbol w, b,\boldsymbol a) =   \frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))</script><p>$p^<em>$为原问题的最小值，对应的$w,b$分别为$w^</em>,b^*$,则对于任意的$a&gt;0$:</p>
<script type="math/tex; mode=display">
p^* = \frac{1}{2}||\boldsymbol w^*||^2 \geqslant  L(\boldsymbol w^*, b,\boldsymbol a) \geqslant \min_{\boldsymbol w, b} L(\boldsymbol w, b,\boldsymbol a)</script><p>则 $\min_{\boldsymbol w, b} L(\boldsymbol w, b,\boldsymbol a)$是问题（1）的一个下界。</p>
<p>此时，取最大值即可求得好的下界，即</p>
<script type="math/tex; mode=display">
\max_{\alpha_i \geqslant 0} \min_{\boldsymbol w, b} L(\boldsymbol w, b,\boldsymbol a)</script><h3 id="2-18-7-常见的核函数有哪些"><a href="#2-18-7-常见的核函数有哪些" class="headerlink" title="2.18.7 常见的核函数有哪些"></a>2.18.7 常见的核函数有哪些</h3><div class="table-container">
<table>
<thead>
<tr>
<th>核函数</th>
<th>表达式</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linear Kernel线性核</td>
<td>$k(x,y)=x^{t}y+c$</td>
<td></td>
</tr>
<tr>
<td>Polynomial Kernel多项式核</td>
<td>$k(x,y)=(ax^{t}y+c)^{d}$</td>
<td>$d\geqslant1$为多项式的次数</td>
</tr>
<tr>
<td>Exponential Kernel指数核</td>
<td>$k(x,y)=exp(-\frac{\left \</td>
<td>x-y \right \</td>
<td>}{2\sigma ^{2}})$</td>
<td>$\sigma&gt;0$</td>
</tr>
<tr>
<td>Gaussian Kernel高斯核</td>
<td>$k(x,y)=exp(-\frac{\left \</td>
<td>x-y \right \</td>
<td>^{2}}{2\sigma ^{2}})$</td>
<td>$\sigma$为高斯核的带宽，$\sigma&gt;0$,</td>
</tr>
<tr>
<td>Laplacian Kernel拉普拉斯核</td>
<td>$k(x,y)=exp(-\frac{\left \</td>
<td>x-y \right \</td>
<td>}{\sigma})$</td>
<td>$\sigma&gt;0$</td>
</tr>
<tr>
<td>ANOVA Kernel</td>
<td>$k(x,y)=exp(-\sigma(x^{k}-y^{k})^{2})^{d}$</td>
<td></td>
</tr>
<tr>
<td>Sigmoid Kernel</td>
<td>$k(x,y)=tanh(ax^{t}y+c)$</td>
<td>$tanh$为双曲正切函数，$a&gt;0,c&lt;0$</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-18-9-SVM主要特点"><a href="#2-18-9-SVM主要特点" class="headerlink" title="2.18.9 SVM主要特点"></a>2.18.9 SVM主要特点</h3><p>特点：</p>
<p>(1)  SVM方法的理论基础是非线性映射，SVM利用内积核函数代替向高维空间的非线性映射。<br>(2)  SVM的目标是对特征空间划分得到最优超平面，SVM方法核心是最大化分类边界。<br>(3)  支持向量是SVM的训练结果，在SVM分类决策中起决定作用的是支持向量。<br>(4)  SVM是一种有坚实理论基础的新颖的适用小样本学习方法。它基本上不涉及概率测度及大数定律等，也简化了通常的分类和回归等问题。<br>(5)  SVM的最终决策函数只由少数的支持向量所确定，计算的复杂性取决于支持向量的数目，而不是样本空间的维数，这在某种意义上避免了“维数灾难”。<br>(6)  少数支持向量决定了最终结果，这不但可以帮助我们抓住关键样本、“剔除”大量冗余样本,而且注定了该方法不但算法简单，而且具有较好的“鲁棒性”。这种鲁棒性主要体现在：<br>​        ①增、删非支持向量样本对模型没有影响;<br>​        ②支持向量样本集具有一定的鲁棒性;<br>​        ③有些成功的应用中，SVM方法对核的选取不敏感<br>(7)  SVM学习问题可以表示为凸优化问题，因此可以利用已知的有效算法发现目标函数的全局最小值。而其他分类方法（如基于规则的分类器和人工神经网络）都采用一种基于贪心学习的策略来搜索假设空间，这种方法一般只能获得局部最优解。<br>(8)  SVM通过最大化决策边界的边缘来控制模型的能力。尽管如此，用户必须提供其他参数，如使用核函数类型和引入松弛变量等。<br>(9)  SVM在小样本训练集上能够得到比其它算法好很多的结果。SVM优化目标是结构化风险最小，而不是经验风险最小，避免了过拟合问题，通过margin的概念，得到对数据分布的结构化描述，减低了对数据规模和数据分布的要求，有优秀的泛化能力。<br>(10)  它是一个凸优化问题，因此局部最优解一定是全局最优解的优点。  </p>
<h3 id="2-18-10-SVM主要缺点"><a href="#2-18-10-SVM主要缺点" class="headerlink" title="2.18.10 SVM主要缺点"></a>2.18.10 SVM主要缺点</h3><p>(1) SVM算法对大规模训练样本难以实施<br>​        SVM的空间消耗主要是存储训练样本和核矩阵，由于SVM是借助二次规划来求解支持向量，而求解二次规划将涉及m阶矩阵的计算（m为样本的个数），当m数目很大时该矩阵的存储和计算将耗费大量的机器内存和运算时间。<br>​        如果数据量很大，SVM的训练时间就会比较长，如垃圾邮件的分类检测，没有使用SVM分类器，而是使用简单的朴素贝叶斯分类器，或者是使用逻辑回归模型分类。</p>
<p>(2) 用SVM解决多分类问题存在困难</p>
<p>​        经典的支持向量机算法只给出了二类分类的算法，而在实际应用中，一般要解决多类的分类问题。可以通过多个二类支持向量机的组合来解决。主要有一对多组合模式、一对一组合模式和SVM决策树；再就是通过构造多个分类器的组合来解决。主要原理是克服SVM固有的缺点，结合其他算法的优势，解决多类问题的分类精度。如：与粗糙集理论结合，形成一种优势互补的多类问题的组合分类器。</p>
<p>(3) 对缺失数据敏感，对参数和核函数的选择敏感</p>
<p>​        支持向量机性能的优劣主要取决于核函数的选取，所以对于一个实际问题而言，如何根据实际的数据模型选择合适的核函数从而构造SVM算法。目前比较成熟的核函数及其参数的选择都是人为的，根据经验来选取的，带有一定的随意性。在不同的问题领域，核函数应当具有不同的形式和参数，所以在选取时候应该将领域知识引入进来，但是目前还没有好的方法来解决核函数的选取问题。</p>
<h3 id="2-18-11-逻辑回归与SVM的异同"><a href="#2-18-11-逻辑回归与SVM的异同" class="headerlink" title="2.18.11 逻辑回归与SVM的异同"></a>2.18.11 逻辑回归与SVM的异同</h3><p>相同点：</p>
<ul>
<li>LR和SVM都是<strong>分类</strong>算法。</li>
<li>LR和SVM都是<strong>监督学习</strong>算法。</li>
<li>LR和SVM都是<strong>判别模型</strong>。</li>
<li>如果不考虑核函数，LR和SVM都是<strong>线性分类</strong>算法，也就是说他们的分类决策面都是线性的。<br> 说明：LR也是可以用核函数的.但LR通常不采用核函数的方法。（<strong>计算量太大</strong>）</li>
</ul>
<p>不同点：</p>
<p><strong>1、LR采用log损失，SVM采用合页(hinge)损失。</strong><br>逻辑回归的损失函数：</p>
<script type="math/tex; mode=display">
J(\theta)=-\frac{1}{m}\sum^m_{i=1}\left[y^{i}logh_{\theta}(x^{i})+ (1-y^{i})log(1-h_{\theta}(x^{i}))\right]</script><p>支持向量机的目标函数:</p>
<script type="math/tex; mode=display">
L(w,n,a)=\frac{1}{2}||w||^2-\sum^n_{i=1}\alpha_i \left( y_i(w^Tx_i+b)-1\right)</script><p>​    逻辑回归方法基于概率理论，假设样本为1的概率可以用sigmoid函数来表示，然后通过<strong>极大似然估计</strong>的方法估计出参数的值。<br>​    支持向量机基于几何<strong>边界最大化</strong>原理，认为存在最大几何边界的分类面为最优分类面。</p>
<p>2、<strong>LR对异常值敏感，SVM对异常值不敏感</strong>。</p>
<p>​    支持向量机只考虑局部的边界线附近的点，而逻辑回归考虑全局。LR模型找到的那个超平面，是尽量让所有点都远离他，而SVM寻找的那个超平面，是只让最靠近中间分割线的那些点尽量远离，即只用到那些支持向量的样本。<br>​    支持向量机改变非支持向量样本并不会引起决策面的变化。<br>​    逻辑回归中改变任何样本都会引起决策面的变化。  </p>
<p>3、<strong>计算复杂度不同。对于海量数据，SVM的效率较低，LR效率比较高</strong></p>
<p>​    当样本较少，特征维数较低时，SVM和LR的运行时间均比较短，SVM较短一些。准确率的话，LR明显比SVM要高。当样本稍微增加些时，SVM运行时间开始增长，但是准确率赶超了LR。SVM时间虽长，但在可接受范围内。当数据量增长到20000时，特征维数增长到200时，SVM的运行时间剧烈增加，远远超过了LR的运行时间。但是准确率却和LR相差无几。(这其中主要原因是大量非支持向量参与计算，造成SVM的二次规划问题)</p>
<p>4、<strong>对非线性问题的处理方式不同</strong></p>
<p>​    LR主要靠特征构造，必须组合交叉特征，特征离散化。SVM也可以这样，还可以通过核函数kernel（因为只有支持向量参与核计算，计算复杂度不高）。由于可以利用核函数，SVM则可以通过对偶求解高效处理。LR则在特征空间维度很高时，表现较差。</p>
<p>5、<strong>SVM的损失函数就自带正则</strong>。<br>​    损失函数中的1/2||w||^2项，这就是为什么SVM是结构风险最小化算法的原因！！！而LR必须另外在损失函数上添加正则项！！！**</p>
<p>6、SVM自带<strong>结构风险最小化</strong>，LR则是<strong>经验风险最小化</strong>。</p>
<p>7、SVM会用核函数而LR一般不用核函数。</p>
<h2 id="2-19-贝叶斯分类器"><a href="#2-19-贝叶斯分类器" class="headerlink" title="2.19 贝叶斯分类器"></a>2.19 贝叶斯分类器</h2><h3 id="2-19-1-图解极大似然估计"><a href="#2-19-1-图解极大似然估计" class="headerlink" title="2.19.1 图解极大似然估计"></a>2.19.1 图解极大似然估计</h3><p>极大似然估计的原理，用一张图片来说明，如下图所示：</p>
<p><img src="/img/ch2/2.19.1.1.png" alt=""></p>
<p>​    例：有两个外形完全相同的箱子，1号箱有99只白球，1只黑球；2号箱有1只白球，99只黑球。在一次实验中，取出的是黑球，请问是从哪个箱子中取出的？</p>
<p>​    一般的根据经验想法，会猜测这只黑球最像是从2号箱取出，此时描述的“最像”就有“最大似然”的意思，这种想法常称为“最大似然原理”。</p>
<h3 id="2-19-2-极大似然估计原理"><a href="#2-19-2-极大似然估计原理" class="headerlink" title="2.19.2 极大似然估计原理"></a>2.19.2 极大似然估计原理</h3><p>​    总结起来，最大似然估计的目的就是：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。</p>
<p>​    极大似然估计是建立在极大似然原理的基础上的一个统计方法。极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。通过若干次试验，观察其结果，利用试验结果得到某个参数值能够使样本出现的概率为最大，则称为极大似然估计。</p>
<p>​    由于样本集中的样本都是独立同分布，可以只考虑一类样本集$D$，来估计参数向量$\vec\theta$。记已知的样本集为：</p>
<script type="math/tex; mode=display">
D=\vec x_{1},\vec x_{2},...,\vec x_{n}</script><p>似然函数（likelihood function）：联合概率密度函数$p(D|\vec\theta )$称为相对于$\vec x_{1},\vec x_{2},…,\vec x_{n}$的$\vec\theta$的似然函数。</p>
<script type="math/tex; mode=display">
l(\vec\theta )=p(D|\vec\theta ) =p(\vec x_{1},\vec x_{2},...,\vec x_{n}|\vec\theta )=\prod_{i=1}^{n}p(\vec x_{i}|\vec \theta )</script><p>如果$\hat{\vec\theta}$是参数空间中能使似然函数$l(\vec\theta)$最大的$\vec\theta$值，则$\hat{\vec\theta}$应该是“最可能”的参数值，那么$\hat{\vec\theta}​$就是$\theta$的极大似然估计量。它是样本集的函数，记作：</p>
<script type="math/tex; mode=display">
\hat{\vec\theta}=d(D)= \mathop {\arg \max}_{\vec\theta} l(\vec\theta )</script><p>$\hat{\vec\theta}(\vec x_{1},\vec x_{2},…,\vec x_{n})$称为极大似然函数估计值。</p>
<h3 id="2-19-3-贝叶斯分类器基本原理"><a href="#2-19-3-贝叶斯分类器基本原理" class="headerlink" title="2.19.3 贝叶斯分类器基本原理"></a>2.19.3 贝叶斯分类器基本原理</h3><p>​    贝叶斯决策论通过<strong>相关概率已知</strong>的情况下利用<strong>误判损失</strong>来选择最优的类别分类。<br>假设有$N$种可能的分类标记，记为$Y=\{c_1,c_2,…,c_N\}$，那对于样本$\boldsymbol{x}$，它属于哪一类呢？</p>
<p>计算步骤如下：</p>
<p>step 1. 算出样本$\boldsymbol{x}$属于第i个类的概率，即$P(c_i|x)​$；</p>
<p>step 2. 通过比较所有的$P(c_i|\boldsymbol{x})$，得到样本$\boldsymbol{x}$所属的最佳类别。</p>
<p>step 3. 将类别$c_i$和样本$\boldsymbol{x}$代入到贝叶斯公式中，得到：</p>
<script type="math/tex; mode=display">
P(c_i|\boldsymbol{x})=\frac{P(\boldsymbol{x}|c_i)P(c_i)}{P(\boldsymbol{x})}.</script><p>​    一般来说，$P(c_i)$为先验概率，$P(\boldsymbol{x}|c_i)$为条件概率，$P(\boldsymbol{x})$是用于归一化的证据因子。对于$P(c_i)$可以通过训练样本中类别为$c_i$的样本所占的比例进行估计；此外，由于只需要找出最大的$P(\boldsymbol{x}|c_i)$，因此我们并不需要计算$P(\boldsymbol{x})$。<br>​    为了求解条件概率，基于不同假设提出了不同的方法，以下将介绍朴素贝叶斯分类器和半朴素贝叶斯分类器。</p>
<h3 id="2-19-4-朴素贝叶斯分类器"><a href="#2-19-4-朴素贝叶斯分类器" class="headerlink" title="2.19.4 朴素贝叶斯分类器"></a>2.19.4 朴素贝叶斯分类器</h3><p>​    假设样本$\boldsymbol{x}$包含$d$个属性，即$\boldsymbol{x}=\{ x_1,x_2,…,x_d\}$。于是有：</p>
<script type="math/tex; mode=display">
P(\boldsymbol{x}|c_i)=P(x_1,x_2,\cdots,x_d|c_i)</script><p>这个联合概率难以从有限的训练样本中直接估计得到。于是，朴素贝叶斯（Naive Bayesian，简称NB）采用了“属性条件独立性假设”：对已知类别，假设所有属性相互独立。于是有：</p>
<script type="math/tex; mode=display">
P(x_1,x_2,\cdots,x_d|c_i)=\prod_{j=1}^d P(x_j|c_i)</script><p>这样的话，我们就可以很容易地推出相应的判定准则了：</p>
<script type="math/tex; mode=display">
h_{nb}(\boldsymbol{x})=\mathop{\arg \max}_{c_i\in Y} P(c_i)\prod_{j=1}^dP(x_j|c_i)</script><p><strong>条件概率$P(x_j|c_i)​$的求解</strong></p>
<p>如果$x_j$是标签属性，那么我们可以通过计数的方法估计$P(x_j|c_i)$</p>
<script type="math/tex; mode=display">
P(x_j|c_i)=\frac{P(x_j,c_i)}{P(c_i)}\approx\frac{\#(x_j,c_i)}{\#(c_i)}</script><p>其中，$#(x_j,c_i)$表示在训练样本中$x_j$与$c_{i}$共同出现的次数。</p>
<p>如果$x_j​$是数值属性，通常我们假设类别中$c_{i}​$的所有样本第$j​$个属性的值服从正态分布。我们首先估计这个分布的均值$μ​$和方差$σ​$，然后计算$x_j​$在这个分布中的概率密度$P(x_j|c_i)​$。</p>
<h3 id="2-19-5-举例理解朴素贝叶斯分类器"><a href="#2-19-5-举例理解朴素贝叶斯分类器" class="headerlink" title="2.19.5 举例理解朴素贝叶斯分类器"></a>2.19.5 举例理解朴素贝叶斯分类器</h3><p>使用经典的西瓜训练集如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">编号</th>
<th style="text-align:center">色泽</th>
<th style="text-align:center">根蒂</th>
<th style="text-align:center">敲声</th>
<th style="text-align:center">纹理</th>
<th style="text-align:center">脐部</th>
<th style="text-align:center">触感</th>
<th style="text-align:center">密度</th>
<th style="text-align:center">含糖率</th>
<th style="text-align:center">好瓜</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.697</td>
<td style="text-align:center">0.460</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.774</td>
<td style="text-align:center">0.376</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.634</td>
<td style="text-align:center">0.264</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.608</td>
<td style="text-align:center">0.318</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">浅白</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.556</td>
<td style="text-align:center">0.215</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">软粘</td>
<td style="text-align:center">0.403</td>
<td style="text-align:center">0.237</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">稍糊</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">软粘</td>
<td style="text-align:center">0.481</td>
<td style="text-align:center">0.149</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.437</td>
<td style="text-align:center">0.211</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">9</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">稍糊</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.666</td>
<td style="text-align:center">0.091</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">10</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">硬挺</td>
<td style="text-align:center">清脆</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">平坦</td>
<td style="text-align:center">软粘</td>
<td style="text-align:center">0.243</td>
<td style="text-align:center">0.267</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">11</td>
<td style="text-align:center">浅白</td>
<td style="text-align:center">硬挺</td>
<td style="text-align:center">清脆</td>
<td style="text-align:center">模糊</td>
<td style="text-align:center">平坦</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.245</td>
<td style="text-align:center">0.057</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">12</td>
<td style="text-align:center">浅白</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">模糊</td>
<td style="text-align:center">平坦</td>
<td style="text-align:center">软粘</td>
<td style="text-align:center">0.343</td>
<td style="text-align:center">0.099</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">13</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">稍糊</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.639</td>
<td style="text-align:center">0.161</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">14</td>
<td style="text-align:center">浅白</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">稍糊</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.657</td>
<td style="text-align:center">0.198</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">15</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">软粘</td>
<td style="text-align:center">0.360</td>
<td style="text-align:center">0.370</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">16</td>
<td style="text-align:center">浅白</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">模糊</td>
<td style="text-align:center">平坦</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.593</td>
<td style="text-align:center">0.042</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">17</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">稍糊</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.719</td>
<td style="text-align:center">0.103</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
</div>
<p>对下面的测试例“测1”进行 分类：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">编号</th>
<th style="text-align:center">色泽</th>
<th style="text-align:center">根蒂</th>
<th style="text-align:center">敲声</th>
<th style="text-align:center">纹理</th>
<th style="text-align:center">脐部</th>
<th style="text-align:center">触感</th>
<th style="text-align:center">密度</th>
<th style="text-align:center">含糖率</th>
<th style="text-align:center">好瓜</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">测1</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.697</td>
<td style="text-align:center">0.460</td>
<td style="text-align:center">？</td>
</tr>
</tbody>
</table>
</div>
<p>首先，估计类先验概率$P(c_j)$，有</p>
<script type="math/tex; mode=display">
\begin{align} 
&P(好瓜=是)=\frac{8}{17}=0.471 \newline 
&P(好瓜=否)=\frac{9}{17}=0.529 
\end{align}</script><p>然后，为每个属性估计条件概率（这里，对于连续属性，假定它们服从正态分布）</p>
<script type="math/tex; mode=display">
P_{青绿|是}=P（色泽=青绿|好瓜=是）=\frac{3}{8}=0.375</script><script type="math/tex; mode=display">
P_{青绿|否}=P（色泽=青绿|好瓜=否）=\frac{3}{9}\approx0.333</script><script type="math/tex; mode=display">
P_{蜷缩|是}=P（根蒂=蜷缩|好瓜=是）=\frac{5}{8}=0.625</script><script type="math/tex; mode=display">
P_{蜷缩|否}=P（根蒂=蜷缩|好瓜=否）=\frac{3}{9}=0.333</script><script type="math/tex; mode=display">
P_{浊响|是}=P（敲声=浊响|好瓜=是）=\frac{6}{8}=0.750</script><script type="math/tex; mode=display">
P_{浊响|否}=P（敲声=浊响|好瓜=否）=\frac{4}{9}\approx 0.444</script><script type="math/tex; mode=display">
P_{清晰|是}=P（纹理=清晰|好瓜=是）=\frac{7}{8}= 0.875</script><script type="math/tex; mode=display">
P_{清晰|否}=P（纹理=清晰|好瓜=否）=\frac{2}{9}\approx 0.222</script><script type="math/tex; mode=display">
P_{凹陷|是}=P（脐部=凹陷|好瓜=是）=\frac{6}{8}= 0.750</script><script type="math/tex; mode=display">
P_{凹陷|否}=P（脐部=凹陷|好瓜=否）=\frac{2}{9} \approx 0.222</script><script type="math/tex; mode=display">
P_{硬滑|是}=P（触感=硬滑|好瓜=是）=\frac{6}{8}= 0.750</script><script type="math/tex; mode=display">
P_{硬滑|否}=P（触感=硬滑|好瓜=否）=\frac{6}{9} \approx 0.667</script><script type="math/tex; mode=display">
\begin{aligned}
\rho_{密度：0.697|是}&=\rho（密度=0.697|好瓜=是）\\&=\frac{1}{\sqrt{2 \pi}\times0.129}exp\left( -\frac{(0.697-0.574)^2}{2\times0.129^2}\right) \approx 1.959
\end{aligned}</script><script type="math/tex; mode=display">
\begin{aligned}
\rho_{密度：0.697|否}&=\rho（密度=0.697|好瓜=否）\\&=\frac{1}{\sqrt{2 \pi}\times0.195}exp\left( -\frac{(0.697-0.496)^2}{2\times0.195^2}\right) \approx 1.203
\end{aligned}</script><script type="math/tex; mode=display">
\begin{aligned}
\rho_{含糖：0.460|是}&=\rho（密度=0.460|好瓜=是）\\&=\frac{1}{\sqrt{2 \pi}\times0.101}exp\left( -\frac{(0.460-0.279)^2}{2\times0.101^2}\right) \approx 0.788
\end{aligned}</script><script type="math/tex; mode=display">
\begin{aligned}
\rho_{含糖：0.460|否}&=\rho（密度=0.460|好瓜=是）\\&=\frac{1}{\sqrt{2 \pi}\times0.108}exp\left( -\frac{(0.460-0.154)^2}{2\times0.108^2}\right) \approx 0.066
\end{aligned}</script><p>于是有</p>
<script type="math/tex; mode=display">
\begin{align} 
P(&好瓜=是)\times P_{青绿|是} \times P_{蜷缩|是} \times P_{浊响|是} \times P_{清晰|是} \times P_{凹陷|是}\newline 
&\times P_{硬滑|是} \times p_{密度：0.697|是} \times p_{含糖：0.460|是} \approx 0.063 \newline\newline 
P(&好瓜=否)\times P_{青绿|否} \times P_{蜷缩|否} \times P_{浊响|否} \times P_{清晰|否} \times P_{凹陷|否}\newline 
&\times P_{硬滑|否} \times p_{密度：0.697|否} \times p_{含糖：0.460|否} \approx 6.80\times 10^{-5} 
\end{align}</script><p>由于$0.063&gt;6.80\times 10^{-5}$，因此，朴素贝叶斯分类器将测试样本“测1”判别为“好瓜”。</p>
<h3 id="2-19-6-半朴素贝叶斯分类器"><a href="#2-19-6-半朴素贝叶斯分类器" class="headerlink" title="2.19.6 半朴素贝叶斯分类器"></a>2.19.6 半朴素贝叶斯分类器</h3><p>​    朴素贝叶斯采用了“属性条件独立性假设”，半朴素贝叶斯分类器的基本想法是适当考虑一部分属性间的相互依赖信息。<strong>独依赖估计</strong>（One-Dependence Estimator，简称ODE）是半朴素贝叶斯分类器最常用的一种策略。顾名思义，独依赖是假设每个属性在类别之外最多依赖一个其他属性，即：</p>
<script type="math/tex; mode=display">
P(\boldsymbol{x}|c_i)=\prod_{j=1}^d P(x_j|c_i,{\rm pa}_j)</script><p>其中$pa_j$为属性$x_i$所依赖的属性，成为$x_i$的父属性。假设父属性$pa_j$已知，那么可以使用下面的公式估计$P(x_j|c_i,{\rm pa}_j)$</p>
<script type="math/tex; mode=display">
P(x_j|c_i,{\rm pa}_j)=\frac{P(x_j,c_i,{\rm pa}_j)}{P(c_i,{\rm pa}_j)}</script><h2 id="2-20-EM算法"><a href="#2-20-EM算法" class="headerlink" title="2.20 EM算法"></a>2.20 EM算法</h2><h3 id="2-20-1-EM算法基本思想"><a href="#2-20-1-EM算法基本思想" class="headerlink" title="2.20.1 EM算法基本思想"></a>2.20.1 EM算法基本思想</h3><p>​    最大期望算法（Expectation-Maximization algorithm, EM），是一类通过迭代进行极大似然估计的优化算法，通常作为牛顿迭代法的替代，用于对包含隐变量或缺失数据的概率模型进行参数估计。</p>
<p>​    最大期望算法基本思想是经过两个步骤交替进行计算：</p>
<p>​    第一步是计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值<strong>；</strong></p>
<p>​    第二步是最大化（M），最大化在E步上求得的最大似然值来计算参数的值。</p>
<p>​    M步上找到的参数估计值被用于下一个E步计算中，这个过程不断交替进行。</p>
<h3 id="2-20-2-EM算法推导"><a href="#2-20-2-EM算法推导" class="headerlink" title="2.20.2 EM算法推导"></a>2.20.2 EM算法推导</h3><p>​    对于$m$个样本观察数据$x=(x^{1},x^{2},…,x^{m})$，现在想找出样本的模型参数$\theta$，其极大化模型分布的对数似然函数为：</p>
<script type="math/tex; mode=display">
\theta = \mathop{\arg\max}_\theta\sum\limits_{i=1}^m logP(x^{(i)};\theta)</script><p>如果得到的观察数据有未观察到的隐含数据$z=(z^{(1)},z^{(2)},…z^{(m)})$，极大化模型分布的对数似然函数则为：</p>
<script type="math/tex; mode=display">
\theta =\mathop{\arg\max}_\theta\sum\limits_{i=1}^m logP(x^{(i)};\theta) = \mathop{\arg\max}_\theta\sum\limits_{i=1}^m log\sum\limits_{z^{(i)}}P(x^{(i)}, z^{(i)};\theta)  \tag{a}</script><p>由于上式不能直接求出$\theta$，采用缩放技巧：</p>
<script type="math/tex; mode=display">
\begin{align} \sum\limits_{i=1}^m log\sum\limits_{z^{(i)}}P(x^{(i)}, z^{(i)};\theta)   & = \sum\limits_{i=1}^m log\sum\limits_{z^{(i)}}Q_i(z^{(i)})\frac{P(x^{(i)}, z^{(i)};\theta)}{Q_i(z^{(i)})} \\ & \geqslant  \sum\limits_{i=1}^m \sum\limits_{z^{(i)}}Q_i(z^{(i)})log\frac{P(x^{(i)}, z^{(i)};\theta)}{Q_i(z^{(i)})} \end{align}   \tag{1}</script><p>上式用到了Jensen不等式：</p>
<script type="math/tex; mode=display">
log\sum\limits_j\lambda_jy_j \geqslant \sum\limits_j\lambda_jlogy_j\;\;,  \lambda_j \geqslant 0, \sum\limits_j\lambda_j =1</script><p>并且引入了一个未知的新分布$Q_i(z^{(i)})$。</p>
<p>此时，如果需要满足Jensen不等式中的等号，所以有：</p>
<script type="math/tex; mode=display">
\frac{P(x^{(i)}, z^{(i)};\theta)}{Q_i(z^{(i)})} =c, c为常数</script><p>由于$Q_i(z^{(i)})$是一个分布，所以满足</p>
<script type="math/tex; mode=display">
\sum\limits_{z}Q_i(z^{(i)}) =1</script><p>综上，可得：</p>
<script type="math/tex; mode=display">
Q_i(z^{(i)})  = \frac{P(x^{(i)}， z^{(i)};\theta)}{\sum\limits_{z}P(x^{(i)}, z^{(i)};\theta)} =  \frac{P(x^{(i)}, z^{(i)};\theta)}{P(x^{(i)};\theta)} = P( z^{(i)}|x^{(i)};\theta)</script><p>如果$Q_i(z^{(i)}) = P( z^{(i)}|x^{(i)};\theta)$ ，则第(1)式是我们的包含隐藏数据的对数似然的一个下界。如果我们能极大化这个下界，则也在尝试极大化我们的对数似然。即我们需要最大化下式：</p>
<script type="math/tex; mode=display">
\mathop{\arg\max}_\theta \sum\limits_{i=1}^m \sum\limits_{z^{(i)}}Q_i(z^{(i)})log\frac{P(x^{(i)}， z^{(i)};\theta)}{Q_i(z^{(i)})}</script><p>简化得：</p>
<script type="math/tex; mode=display">
\mathop{\arg\max}_\theta \sum\limits_{i=1}^m \sum\limits_{z^{(i)}}Q_i(z^{(i)})log{P(x^{(i)}, z^{(i)};\theta)}</script><p>以上即为EM算法的M步，$\sum\limits_{z^{(i)}}Q_i(z^{(i)})log{P(x^{(i)}, z^{(i)};\theta)}​$可理解为$logP(x^{(i)}, z^{(i)};\theta) $基于条件概率分布$Q_i(z^{(i)}) $的期望。以上即为EM算法中E步和M步的具体数学含义。</p>
<h3 id="2-20-3-图解EM算法"><a href="#2-20-3-图解EM算法" class="headerlink" title="2.20.3 图解EM算法"></a>2.20.3 图解EM算法</h3><p>​    考虑上一节中的（a）式，表达式中存在隐变量，直接找到参数估计比较困难，通过EM算法迭代求解下界的最大值到收敛为止。</p>
<p><img src="/img/ch2/2.20.1.jpg" alt=""></p>
<p>​    图片中的紫色部分是我们的目标模型$p(x|\theta)$，该模型复杂，难以求解析解，为了消除隐变量$z^{(i)}$的影响，我们可以选择一个不包含$z^{(i)}$的模型$r(x|\theta)$，使其满足条件$r(x|\theta) \leqslant p(x|\theta) $。</p>
<p>求解步骤如下：</p>
<p>（1）选取$\theta_1$，使得$r(x|\theta_1) = p(x|\theta_1)$，然后对此时的$r$求取最大值，得到极值点$\theta_2$，实现参数的更新。</p>
<p>（2）重复以上过程到收敛为止，在更新过程中始终满足$r \leqslant p $.</p>
<h3 id="2-20-4-EM算法流程"><a href="#2-20-4-EM算法流程" class="headerlink" title="2.20.4 EM算法流程"></a>2.20.4 EM算法流程</h3><p>输入：观察数据$x=(x^{(1)},x^{(2)},…x^{(m)})$，联合分布$p(x,z ;\theta)$，条件分布$p(z|x; \theta)$，最大迭代次数$J$</p>
<p>1）随机初始化模型参数$\theta$的初值$\theta^0$。</p>
<p>2）$for  j   from  1   to   j$：</p>
<p>​    a） E步。计算联合分布的条件概率期望：</p>
<script type="math/tex; mode=display">
Q_i(z^{(i)}) = P( z^{(i)}|x^{(i)}, \theta^{j})</script><script type="math/tex; mode=display">
L(\theta, \theta^{j}) = \sum\limits_{i=1}^m\sum\limits_{z^{(i)}}P( z^{(i)}|x^{(i)}, \theta^{j})log{P(x^{(i)}, z^{(i)};\theta)}</script><p>​    b） M步。极大化$L(\theta, \theta^{j})$，得到$\theta^{j+1}$:</p>
<script type="math/tex; mode=display">
\theta^{j+1} = \mathop{\arg\max}_\theta L(\theta, \theta^{j})</script><p>​    c） 如果$\theta^{j+1}$收敛，则算法结束。否则继续回到步骤a）进行E步迭代。</p>
<p>输出：模型参数$\theta​$。</p>
<h2 id="2-21-降维和聚类"><a href="#2-21-降维和聚类" class="headerlink" title="2.21 降维和聚类"></a>2.21 降维和聚类</h2><h3 id="2-21-1-图解为什么会产生维数灾难"><a href="#2-21-1-图解为什么会产生维数灾难" class="headerlink" title="2.21.1 图解为什么会产生维数灾难"></a>2.21.1 图解为什么会产生维数灾难</h3><p>​    假如数据集包含10张照片，照片中包含三角形和圆两种形状。现在来设计一个分类器进行训练，让这个分类器对其他的照片进行正确分类（假设三角形和圆的总数是无限大），简单的，我们用一个特征进行分类：</p>
<p><img src="/img/ch2/2.21.1.1.png" alt=""></p>
<p>​                                            图2.21.1.a</p>
<p>​    从上图可看到，如果仅仅只有一个特征进行分类，三角形和圆几乎是均匀分布在这条线段上，很难将10张照片线性分类。那么，增加一个特征后的情况会怎么样：</p>
<p><img src="/img/ch2/2.21.1.2.png" alt=""></p>
<p>​                                            图2.21.1.b</p>
<p>增加一个特征后，我们发现仍然无法找到一条直线将猫和狗分开。所以，考虑需要再增加一个特征：</p>
<p><img src="/img/ch2/2.21.1.3.png" alt=""></p>
<p>​                                            图2.21.1.c</p>
<p><img src="/img/ch2/2.21.1.4.png" alt=""></p>
<p>​                                            图2.21.1.d</p>
<p>​    此时，可以找到一个平面将三角形和圆分开。</p>
<p>​    现在计算一下不同特征数是样本的密度：</p>
<p>​    （1）一个特征时，假设特征空间时长度为5的线段，则样本密度为$10 \div 5 = 2$。</p>
<p>​    （2）两个特征时，特征空间大小为$ 5\times5 = 25$，样本密度为$10 \div 25 = 0.4$。</p>
<p>​    （3）三个特征时，特征空间大小是$ 5\times5\times5 = 125$，样本密度为$10 \div 125 = 0.08$。</p>
<p>​    以此类推，如果继续增加特征数量，样本密度会越来越稀疏，此时，更容易找到一个超平面将训练样本分开。当特征数量增长至无限大时，样本密度就变得非常稀疏。</p>
<p>​    下面看一下将高维空间的分类结果映射到低维空间时，会出现什么情况？</p>
<p><img src="/img/ch2/2.21.1.5.png" alt=""></p>
<p>​                                        图2.21.1.e</p>
<p>​    上图是将三维特征空间映射到二维特征空间后的结果。尽管在高维特征空间时训练样本线性可分，但是映射到低维空间后，结果正好相反。事实上，增加特征数量使得高维空间线性可分，相当于在低维空间内训练一个复杂的非线性分类器。不过，这个非线性分类器太过“聪明”，仅仅学到了一些特例。如果将其用来辨别那些未曾出现在训练样本中的测试样本时，通常结果不太理想，会造成过拟合问题。</p>
<p><img src="/img/ch2/2.21.1.6a.png" alt=""></p>
<p>​                                        图2.21.1.f</p>
<p>​    上图所示的只采用2个特征的线性分类器分错了一些训练样本，准确率似乎没有图2.21.1.e的高，但是，采用2个特征的线性分类器的泛化能力比采用3个特征的线性分类器要强。因为，采用2个特征的线性分类器学习到的不只是特例，而是一个整体趋势，对于那些未曾出现过的样本也可以比较好地辨别开来。换句话说，通过减少特征数量，可以避免出现过拟合问题，从而避免“维数灾难”。</p>
<p><img src="/img/ch2/2.21.1.6.png" alt=""></p>
<p>​    上图从另一个角度诠释了“维数灾难”。假设只有一个特征时，特征的值域是0到1，每一个三角形和圆的特征值都是唯一的。如果我们希望训练样本覆盖特征值值域的20%，那么就需要三角形和圆总数的20%。我们增加一个特征后，为了继续覆盖特征值值域的20%就需要三角形和圆总数的45%($0.452^2\approx0.2$)。继续增加一个特征后，需要三角形和圆总数的58%($0.583^3\approx0.2$)。随着特征数量的增加，为了覆盖特征值值域的20%，就需要更多的训练样本。如果没有足够的训练样本，就可能会出现过拟合问题。</p>
<p>​    通过上述例子，我们可以看到特征数量越多，训练样本就会越稀疏，分类器的参数估计就会越不准确，更加容易出现过拟合问题。“维数灾难”的另一个影响是训练样本的稀疏性并不是均匀分布的。处于中心位置的训练样本比四周的训练样本更加稀疏。</p>
<p><img src="/img/ch2/2.21.1.7.png" alt=""></p>
<p>​    假设有一个二维特征空间，如上图所示的矩形，在矩形内部有一个内切的圆形。由于越接近圆心的样本越稀疏，因此，相比于圆形内的样本，那些位于矩形四角的样本更加难以分类。当维数变大时，特征超空间的容量不变，但单位圆的容量会趋于0，在高维空间中，大多数训练数据驻留在特征超空间的角落。散落在角落的数据要比处于中心的数据难于分类。</p>
<h3 id="2-21-2-怎样避免维数灾难"><a href="#2-21-2-怎样避免维数灾难" class="headerlink" title="2.21.2 怎样避免维数灾难"></a>2.21.2 怎样避免维数灾难</h3><p><strong>有待完善！！！</strong></p>
<p>解决维度灾难问题：</p>
<p>主成分分析法PCA，线性判别法LDA</p>
<p>奇异值分解简化数据、拉普拉斯特征映射</p>
<p>Lassio缩减系数法、小波分析法、</p>
<h3 id="2-21-3-聚类和降维有什么区别与联系"><a href="#2-21-3-聚类和降维有什么区别与联系" class="headerlink" title="2.21.3 聚类和降维有什么区别与联系"></a>2.21.3 聚类和降维有什么区别与联系</h3><p>​    聚类用于找寻数据内在的分布结构，既可以作为一个单独的过程，比如异常检测等等。也可作为分类等其他学习任务的前驱过程。聚类是标准的无监督学习。</p>
<p>​    1）在一些推荐系统中需确定新用户的类型，但定义“用户类型”却可能不太容易，此时往往可先对原有的用户数据进行聚类，根据聚类结果将每个簇定义为一个类,然后再基于这些类训练分类模型,用于判别新用户的类型。</p>
<p><img src="/img/ch2/2.21.3.1.png" alt=""></p>
<p>​    2）而降维则是为了缓解维数灾难的一个重要方法，就是通过某种数学变换将原始高维属性空间转变为一个低维“子空间”。其基于的假设就是，虽然人们平时观测到的数据样本虽然是高维的，但是实际上真正与学习任务相关的是个低维度的分布。从而通过最主要的几个特征维度就可以实现对数据的描述，对于后续的分类很有帮助。比如对于Kaggle（数据分析竞赛平台之一）上的泰坦尼克号生还问题。通过给定一个乘客的许多特征如年龄、姓名、性别、票价等，来判断其是否能在海难中生还。这就需要首先进行特征筛选，从而能够找出主要的特征，让学习到的模型有更好的泛化性。</p>
<p>​    聚类和降维都可以作为分类等问题的预处理步骤。</p>
<p><img src="/img/ch2/2-19.jpg" alt=""></p>
<p>​    但是他们虽然都能实现对数据的约减。但是二者适用的对象不同，聚类针对的是数据点，而降维则是对于数据的特征。另外它们有着很多种实现方法。聚类中常用的有K-means、层次聚类、基于密度的聚类等；降维中常用的则PCA、Isomap、LLE等。</p>
<h3 id="2-21-4-有哪些聚类算法优劣衡量标准"><a href="#2-21-4-有哪些聚类算法优劣衡量标准" class="headerlink" title="2.21.4 有哪些聚类算法优劣衡量标准"></a>2.21.4 有哪些聚类算法优劣衡量标准</h3><p>不同聚类算法有不同的优劣和不同的适用条件。可从以下方面进行衡量判断：<br>    1、算法的处理能力：处理大的数据集的能力，即算法复杂度；处理数据噪声的能力；处理任意形状，包括有间隙的嵌套的数据的能力；<br>    2、算法是否需要预设条件：是否需要预先知道聚类个数，是否需要用户给出领域知识； </p>
<p>​    3、算法的数据输入属性：算法处理的结果与数据输入的顺序是否相关，也就是说算法是否独立于数据输入顺序；算法处理有很多属性数据的能力，也就是对数据维数是否敏感，对数据的类型有无要求。</p>
<h3 id="2-21-5-聚类和分类有什么区别"><a href="#2-21-5-聚类和分类有什么区别" class="headerlink" title="2.21.5 聚类和分类有什么区别"></a>2.21.5 聚类和分类有什么区别</h3><p><strong>聚类（Clustering） </strong><br>    聚类，简单地说就是把相似的东西分到一组，聚类的时候，我们并不关心某一类是什么，我们需要实现的目标只是把相似的东西聚到一起。一个聚类算法通常只需要知道如何计算相似度就可以开始工作了，因此聚类通常并不需要使用训练数据进行学习，在机器学习中属于无监督学习。 </p>
<p><strong>分类（Classification） </strong></p>
<p>​     分类，对于一个分类器，通常需要你告诉它“这个东西被分为某某类”。一般情况下，一个分类器会从它得到的训练集中进行学习，从而具备对未知数据进行分类的能力，在机器学习中属于监督学习。</p>
<h3 id="2-21-6-不同聚类算法特点性能比较"><a href="#2-21-6-不同聚类算法特点性能比较" class="headerlink" title="2.21.6 不同聚类算法特点性能比较"></a>2.21.6 不同聚类算法特点性能比较</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">算法名称</th>
<th style="text-align:center">可伸缩性</th>
<th style="text-align:center">适合的数据类型</th>
<th style="text-align:center">高维性</th>
<th style="text-align:center">异常数据抗干扰性</th>
<th style="text-align:center">聚类形状</th>
<th style="text-align:center">算法效率</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">WAVECLUSTER</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">很高</td>
</tr>
<tr>
<td style="text-align:center">ROCK</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">混合型</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">一般</td>
</tr>
<tr>
<td style="text-align:center">BIRCH</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">球形</td>
<td style="text-align:center">很高</td>
</tr>
<tr>
<td style="text-align:center">CURE</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">较高</td>
</tr>
<tr>
<td style="text-align:center">K-PROTOTYPES</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">混合型</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">一般</td>
</tr>
<tr>
<td style="text-align:center">DENCLUE</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">较高</td>
</tr>
<tr>
<td style="text-align:center">OPTIGRID</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">一般</td>
</tr>
<tr>
<td style="text-align:center">CLIQUE</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">较低</td>
</tr>
<tr>
<td style="text-align:center">DBSCAN</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">一般</td>
</tr>
<tr>
<td style="text-align:center">CLARANS</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">球形</td>
<td style="text-align:center">较低</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-21-7-四种常用聚类方法之比较"><a href="#2-21-7-四种常用聚类方法之比较" class="headerlink" title="2.21.7 四种常用聚类方法之比较"></a>2.21.7 四种常用聚类方法之比较</h3><p>​    聚类就是按照某个特定标准把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不在同一个簇中的数据对象的差异性也尽可能地大。即聚类后同一类的数据尽可能聚集到一起，不同类数据尽量分离。<br>​    主要的聚类算法可以划分为如下几类：划分方法、层次方法、基于密度的方法、基于网格的方法以及基于模型的方法。下面主要对k-means聚类算法、凝聚型层次聚类算法、神经网络聚类算法之SOM,以及模糊聚类的FCM算法通过通用测试数据集进行聚类效果的比较和分析。</p>
<h3 id="2-21-8-k-means聚类算法"><a href="#2-21-8-k-means聚类算法" class="headerlink" title="2.21.8 k-means聚类算法"></a>2.21.8 k-means聚类算法</h3><p>k-means是划分方法中较经典的聚类算法之一。由于该算法的效率高，所以在对大规模数据进行聚类时被广泛应用。目前，许多算法均围绕着该算法进行扩展和改进。<br>k-means算法以k为参数，把n个对象分成k个簇，使簇内具有较高的相似度，而簇间的相似度较低。k-means算法的处理过程如下：首先，随机地 选择k个对象，每个对象初始地代表了一个簇的平均值或中心;对剩余的每个对象，根据其与各簇中心的距离，将它赋给最近的簇;然后重新计算每个簇的平均值。 这个过程不断重复，直到准则函数收敛。通常，采用平方误差准则，其定义如下：</p>
<script type="math/tex; mode=display">
E=\sum_{i=1}^{k}\sum_{p\in C_i}\left\|p-m_i\right\|^2</script><p>　这里E是数据中所有对象的平方误差的总和，p是空间中的点，$m_i$是簇$C_i$的平均值[9]。该目标函数使生成的簇尽可能紧凑独立，使用的距离度量是欧几里得距离，当然也可以用其他距离度量。</p>
<p><strong>算法流程</strong>：<br>​    输入：包含n个对象的数据和簇的数目k；<br>​    输出：n个对象到k个簇，使平方误差准则最小。<br>​    步骤：<br>　　(1) 任意选择k个对象作为初始的簇中心；<br>　　(2) 根据簇中对象的平均值，将每个对象(重新)赋予最类似的簇；<br>　　(3) 更新簇的平均值，即计算每个簇中对象的平均值；<br>　　(4) 重复步骤(2)、(3)直到簇中心不再变化；</p>
<h3 id="2-21-9-层次聚类算法"><a href="#2-21-9-层次聚类算法" class="headerlink" title="2.21.9 层次聚类算法"></a>2.21.9 层次聚类算法</h3><p>​    根据层次分解的顺序是自底向上的还是自上向下的，层次聚类算法分为凝聚的层次聚类算法和分裂的层次聚类算法。<br>　凝聚型层次聚类的策略是先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到所有对象都在一个簇中，或者某个终结条件被满足。绝大多数层次聚类属于凝聚型层次聚类，它们只是在簇间相似度的定义上有所不同。</p>
<p><strong>算法流程</strong>：</p>
<p>注：以采用最小距离的凝聚层次聚类算法为例：</p>
<p>　(1) 将每个对象看作一类，计算两两之间的最小距离；<br>　(2) 将距离最小的两个类合并成一个新类；<br>　(3) 重新计算新类与所有类之间的距离；<br>　(4) 重复(2)、(3)，直到所有类最后合并成一类。</p>
<h3 id="2-21-10-SOM聚类算法"><a href="#2-21-10-SOM聚类算法" class="headerlink" title="2.21.10 SOM聚类算法"></a>2.21.10 SOM聚类算法</h3><p>​    SOM神经网络[11]是由芬兰神经网络专家Kohonen教授提出的，该算法假设在输入对象中存在一些拓扑结构或顺序，可以实现从输入空间(n维)到输出平面(2维)的降维映射，其映射具有拓扑特征保持性质,与实际的大脑处理有很强的理论联系。</p>
<p>​    SOM网络包含输入层和输出层。输入层对应一个高维的输入向量，输出层由一系列组织在2维网格上的有序节点构成，输入节点与输出节点通过权重向量连接。 学习过程中，找到与之距离最短的输出层单元，即获胜单元，对其更新。同时，将邻近区域的权值更新，使输出节点保持输入向量的拓扑特征。</p>
<p><strong>算法流程</strong>：</p>
<p>​    (1) 网络初始化，对输出层每个节点权重赋初值；<br>​    (2) 从输入样本中随机选取输入向量并且归一化，找到与输入向量距离最小的权重向量；<br>​    (3) 定义获胜单元，在获胜单元的邻近区域调整权重使其向输入向量靠拢；<br>​    (4) 提供新样本、进行训练；<br>​    (5) 收缩邻域半径、减小学习率、重复，直到小于允许值，输出聚类结果。</p>
<h3 id="2-21-11-FCM聚类算法"><a href="#2-21-11-FCM聚类算法" class="headerlink" title="2.21.11 FCM聚类算法"></a>2.21.11 FCM聚类算法</h3><p>​    1965年美国加州大学柏克莱分校的扎德教授第一次提出了‘集合’的概念。经过十多年的发展，模糊集合理论渐渐被应用到各个实际应用方面。为克服非此即彼的分类缺点，出现了以模糊集合论为数学基础的聚类分析。用模糊数学的方法进行聚类分析，就是模糊聚类分析[12]。<br>​    FCM算法是一种以隶属度来确定每个数据点属于某个聚类程度的算法。该聚类算法是传统硬聚类算法的一种改进。<br>​    设数据集$X={x_1,x_2,…,x_n}$,它的模糊$c$划分可用模糊矩阵$U=[u_{ij}]$表示，矩阵$U$的元素$u_{ij}$表示第$j(j=1,2,…,n)$个数据点属于第$i(i=1,2,…,c)$类的隶属度，$u_{ij}$满足如下条件：  </p>
<script type="math/tex; mode=display">
\begin{equation}
\left\{
\begin{array}{lr}
\sum_{i=1}^c u_{ij}=1 \quad\forall~j
\\u_{ij}\in[0,1] \quad\forall ~i,j
\\\sum_{j=1}^c u_{ij}>0 \quad\forall ~i
\end{array}
\right.
\end{equation}</script><p>目前被广泛使用的聚类准则是取类内加权误差平方和的极小值。即：</p>
<script type="math/tex; mode=display">
(min)J_m(U,V)=\sum^n_{j=1}\sum^c_{i=1}u^m_{ij}d^2_{ij}(x_j,v_i)</script><p>其中$V$为聚类中心，$m$为加权指数，$d_{ij}(x_j,v_i)=||v_i-x_j||$。</p>
<p><strong>算法流程</strong>：</p>
<p>　(1) 标准化数据矩阵；<br>　(2) 建立模糊相似矩阵，初始化隶属矩阵；<br>　(3) 算法开始迭代，直到目标函数收敛到极小值；<br>　(4) 根据迭代结果，由最后的隶属矩阵确定数据所属的类，显示最后的聚类结果。</p>
<h3 id="2-21-12-四种聚类算法试验"><a href="#2-21-12-四种聚类算法试验" class="headerlink" title="2.21.12 四种聚类算法试验"></a>2.21.12 四种聚类算法试验</h3><p>​    选取专门用于测试分类、聚类算法的国际通用的UCI数据库中的IRIS数据集，IRIS数据集包含150个样本数据，分别取自三种不同 的莺尾属植物setosa、versicolor和virginica的花朵样本,每个数据含有4个属性，即萼片长度、萼片宽度、花瓣长度、花瓣宽度，单位为cm。 在数据集上执行不同的聚类算法，可以得到不同精度的聚类结果。基于前面描述的各算法原理及流程，可初步得如下聚类结果。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>聚类方法</th>
<th>聚错样本数</th>
<th>运行时间/s</th>
<th>平均准确率/（%）</th>
</tr>
</thead>
<tbody>
<tr>
<td>K-means</td>
<td>17</td>
<td>0.146001</td>
<td>89</td>
</tr>
<tr>
<td>层次聚类</td>
<td>51</td>
<td>0.128744</td>
<td>66</td>
</tr>
<tr>
<td>SOM</td>
<td>22</td>
<td>5.267283</td>
<td>86</td>
</tr>
<tr>
<td>FCM</td>
<td>12</td>
<td>0.470417</td>
<td>92</td>
</tr>
</tbody>
</table>
</div>
<p><strong>注</strong>：</p>
<p>(1) 聚错样本数：总的聚错的样本数，即各类中聚错的样本数的和；<br>(2) 运行时间：即聚类整个过程所耗费的时间，单位为s；<br>(3) 平均准确度：设原数据集有k个类,用$c_i$表示第i类，$n_i$为$c_i$中样本的个数，$m_i$为聚类正确的个数,则$m_i/n_i$为 第i类中的精度，则平均精度为：$avg=\frac{1}{k}\sum_{i=1}^{k}\frac{m_{i}}{n_{i}}$。  </p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]   Goodfellow I, Bengio Y, Courville A. Deep learning[M]. MIT press, 2016.<br>[2]   周志华. 机器学习[M].清华大学出版社, 2016.<br>[3]   Michael A. Nielsen. “Neural Networks and Deep Learning”, Determination Press, 2015.<br>[4]   Suryansh S. Gradient Descent: All You Need to Know, 2018.<br>[5]   刘建平. 梯度下降小结,EM算法的推导, 2018<br>[6]   杨小兵．聚类分析中若干关键技术的研究[D]． 杭州：浙江大学, 2005.<br>[7]   XU Rui, Donald Wunsch 1 1． survey of clustering algorithm[J]．IEEE．Transactions on Neural Networks, 2005, 16(3)：645-67 8.<br>[8]   YI Hong, SAM K． Learning assignment order of instances for the constrained k-means clustering algorithm[J]．IEEE Transactions on Systems, Man, and Cybernetics, Part B：Cybernetics,2009,39 (2)：568-574.<br>[9]   贺玲, 吴玲达, 蔡益朝．数据挖掘中的聚类算法综述[J]．计算机应用研究, 2007, 24(1):10-13．<br>[10]  孙吉贵, 刘杰, 赵连宇．聚类算法研究[J]．软件学报, 2008, 19(1)：48-61．<br>[11]  孔英会, 苑津莎, 张铁峰等．基于数据流管理技术的配变负荷分类方法研究．中国国际供电会议, CICED2006．<br>[12]  马晓艳, 唐雁．层次聚类算法研究[J]．计算机科学, 2008, 34(7)：34-36．<br>[13]  FISHER R A． Iris Plants Database <a href="https://www.ics.uci.edu/vmlearn/MLRepository.html" target="_blank" rel="noopener">https://www.ics.uci.edu/vmlearn/MLRepository.html</a>, Authorized license．<br>[14]  Quinlan J R. Induction of decision trees[J]. Machine learning, 1986, 1(1): 81-106.<br>[15]  Breiman L. Random forests[J]. Machine learning, 2001, 45(1): 5-32.  </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/26/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/26/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">算法分析：双指针</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-26 22:57:52" itemprop="dateCreated datePublished" datetime="2020-02-26T22:57:52+08:00">2020-02-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-07 22:44:58" itemprop="dateModified" datetime="2020-03-07T22:44:58+08:00">2020-03-07</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h1><p>什么是滑动窗口？其实就是一个队列，比如题目无重复字符的最长子串中的abcabcbb，进入这个队列（窗口）为abc满足题目，当再进入a，队列就变成了abca，这时候不满足要求。所以，我们就要移动这个队列。我们只要把队列的左边元素移出就行，直到满足题目要求。<br>例题1：leetcode3.无重复字符的最长子串(滑窗模板)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(s)</span>:</span></span><br><span class="line">    <span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> s:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> len(s)==<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    left, right, counter= <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    maxLen = <span class="number">0</span></span><br><span class="line">    windows = defaultdict(int)</span><br><span class="line">    <span class="keyword">while</span> right&lt;len(s):</span><br><span class="line">        <span class="keyword">if</span> windows[s[right]]&gt;<span class="number">0</span>:</span><br><span class="line">            counter += <span class="number">1</span></span><br><span class="line">        windows[s[right]] += <span class="number">1</span></span><br><span class="line">        right += <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> counter&gt;<span class="number">0</span>:        <span class="comment"># 窗口条件决定左边元素是否移出</span></span><br><span class="line">            <span class="keyword">if</span> windows[s[left]]&gt;<span class="number">1</span>:</span><br><span class="line">                counter -= <span class="number">1</span></span><br><span class="line">            windows[s[left]] -= <span class="number">1</span></span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line">        maxLen = max(maxLen, right-left)</span><br><span class="line">    <span class="keyword">return</span> maxLen</span><br></pre></td></tr></table></figure><br>例题：<br><a href="https://leetcode-cn.com/problems/minimum-window-substring/" target="_blank" rel="noopener">76.最小覆盖子串</a><br><a href="https://leetcode-cn.com/problems/minimum-size-subarray-sum/" target="_blank" rel="noopener">209.长度最小的子数组</a><br><a href="https://leetcode-cn.com/problems/permutation-in-string/" target="_blank" rel="noopener">567.字符串的排列</a></p>
<h1 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h1><h2 id="前序"><a href="#前序" class="headerlink" title="前序"></a>前序</h2><p>递归<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preOrder</span><span class="params">(node)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    print(node.val)</span><br><span class="line">    preOrder(node.left)</span><br><span class="line">    preOrder(node.right)</span><br></pre></td></tr></table></figure><br>非递归<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preOrder</span><span class="params">(node)</span>:</span></span><br><span class="line">    stack = [node]</span><br><span class="line">    <span class="keyword">while</span> stack:</span><br><span class="line">        print(node.val)</span><br><span class="line">        <span class="keyword">if</span> node.right:</span><br><span class="line">            stack.append(node.right)</span><br><span class="line">        <span class="keyword">if</span> node.left:</span><br><span class="line">            stack.append(node.left)</span><br><span class="line">        node = stack.pop()</span><br></pre></td></tr></table></figure></p>
<h2 id="中序遍历"><a href="#中序遍历" class="headerlink" title="中序遍历"></a>中序遍历</h2><p>递归<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inorder</span><span class="params">(node)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    inorder(node.left)</span><br><span class="line">    print(node.val)</span><br><span class="line">    inorder(node.right)</span><br></pre></td></tr></table></figure><br>非递归<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inorder</span><span class="params">(node)</span>:</span></span><br><span class="line">    stack = []</span><br><span class="line">    <span class="keyword">while</span> node <span class="keyword">or</span> len(stack)&gt;<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">while</span> node:</span><br><span class="line">            stack.append(node)</span><br><span class="line">            node = node.left</span><br><span class="line">        node = stack.pop()</span><br><span class="line">        print(node.val)</span><br><span class="line">        node = node.right</span><br></pre></td></tr></table></figure></p>
<h2 id="后序遍历"><a href="#后序遍历" class="headerlink" title="后序遍历"></a>后序遍历</h2><p>递归<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postOrder</span><span class="params">(node)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    postOrder(node.left)</span><br><span class="line">    postOrder(node.right)</span><br><span class="line">    print(node.val)</span><br></pre></td></tr></table></figure><br>非递归：使用两个栈结构，第一个栈进栈顺序：左节点-&gt;右节点-&gt;根节点，第一个栈弹出顺序：根节点-&gt;右节点-&gt;左节点，第二个栈存储为第一个栈的每个弹出依次入栈，最后第二个栈依次出栈。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postOrder</span><span class="params">(node)</span>:</span></span><br><span class="line">    stack = [node]</span><br><span class="line">    stack2 = []</span><br><span class="line">    <span class="keyword">while</span> len(stack)&gt;<span class="number">0</span>:</span><br><span class="line">        node = stack.pop()</span><br><span class="line">        stack2.append(node)</span><br><span class="line">        <span class="keyword">if</span> node.left:</span><br><span class="line">            stack.append(node.left)</span><br><span class="line">        <span class="keyword">if</span> node.right:</span><br><span class="line">            stack.append(node.right)</span><br><span class="line">    <span class="keyword">while</span> len(stack2)&gt;<span class="number">0</span>:</span><br><span class="line">        print(stack2.pop().val)</span><br></pre></td></tr></table></figure></p>
<h2 id="层次遍历"><a href="#层次遍历" class="headerlink" title="层次遍历"></a>层次遍历</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">queue = []</span><br><span class="line">queue.append(node)</span><br><span class="line"><span class="keyword">while</span> len(queue)&gt;<span class="number">0</span>:</span><br><span class="line">    node = queue.pop(<span class="number">0</span>)</span><br><span class="line">    print(node.val)</span><br><span class="line">    <span class="keyword">if</span> node.left:</span><br><span class="line">        queue.append(node.left)</span><br><span class="line">    <span class="keyword">if</span> node.right:</span><br><span class="line">        queue.append(node.right)</span><br></pre></td></tr></table></figure>
<h1 id="买卖股票"><a href="#买卖股票" class="headerlink" title="买卖股票"></a>买卖股票</h1><p>1）给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。<br>如果你最多只允许完成一笔交易（即买入和卖出一支股票），求获得的最大利润。<br>思路1：dp[i][j]表示第i天用户持股为j所获最大利润。<br>j只有两个值：0表示不持股，1表示持股。<br>则dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])<br>dp[i][1] = max(dp[i-1][1], -prices[i])，因为题目只允许一次交易，因此不能加上dp[i-1][0]<br>初始值：第0天不持股，dp[0][0]=0；第0天持股，dp[0][1]=-prices[0]<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxProfit</span><span class="params">(prices)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(prices)&lt;<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    n = len(prices)</span><br><span class="line">    dp = [[<span class="number">0</span>]*n <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">2</span>)]</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n):</span><br><span class="line">        dp[i][<span class="number">0</span>] = max(dp[i<span class="number">-1</span>][<span class="number">0</span>], dp[i<span class="number">-1</span>][<span class="number">1</span>]+prices[i])</span><br><span class="line">        dp[i][<span class="number">1</span>] = max(dp[i<span class="number">-1</span>][<span class="number">1</span>], -prices[i])</span><br><span class="line">    <span class="keyword">return</span> dp[<span class="number">-1</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><br>考虑状态压缩，dp[i]仅仅依赖于dp[i-1]<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxProfit2</span><span class="params">(prices)</span>:</span></span><br><span class="line">    n = len(prices)</span><br><span class="line">    <span class="keyword">if</span> n&lt;<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    dp = [<span class="number">0</span>]*<span class="number">2</span></span><br><span class="line">    dp[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    dp[<span class="number">1</span>] = -prices[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n):</span><br><span class="line">        dp[<span class="number">0</span>] = max(dp[<span class="number">0</span>], dp[<span class="number">1</span>]+prices[i])</span><br><span class="line">        dp[<span class="number">1</span>] = max(dp[<span class="number">1</span>], -prices[i])</span><br><span class="line">    <span class="keyword">return</span> dp[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><br>2）可以尽可能地完成更多的交易（多次买卖一支股票），但不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）<br>思路：dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])<br>dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])<br>dp[0][0] = 0, dp[0][1] = -prices[0]<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxProfitII</span><span class="params">(prices)</span>:</span></span><br><span class="line">    n = len(prices)</span><br><span class="line">    <span class="keyword">if</span> n&lt;<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    dp = [[<span class="number">0</span>]*<span class="number">2</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(n)]</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n):</span><br><span class="line">        dp[i][<span class="number">0</span>] = max(dp[i<span class="number">-1</span>][<span class="number">0</span>], dp[i<span class="number">-1</span>][<span class="number">1</span>]+prices[i])</span><br><span class="line">        dp[i][<span class="number">1</span>] = max(dp[i<span class="number">-1</span>][<span class="number">1</span>], dp[i<span class="number">-1</span>][<span class="number">0</span>]-prices[i])</span><br><span class="line">    <span class="keyword">return</span> dp[<span class="number">-1</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><br>考虑状态压缩 dp[i]也仅仅依赖dp[i-1]</p>
<p>3）最多可以完成两笔交易。<br>注：必须在再次购买前出售掉之前的股票<br>思路：重新定义状态方程<br>dp[i][0]表示未交易<br>dp[i][1]表示第一次买入一支股票<br>dp[i][2]表示第一次卖出一支股票<br>dp[i][3]表示第二次买入一支股票<br>dp[i][4]表示第二次卖出一支股票<br>状态转移方程见代码<br>初始化：第0天初始化为前两个状态，而状态3（第二次持股）只能赋值为一个不可能的数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxProfitIII</span><span class="params">(prices)</span>:</span></span><br><span class="line">    n = len(prices)</span><br><span class="line">    <span class="keyword">if</span> n&lt;<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    dp = [[<span class="number">0</span>]*<span class="number">5</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(n)]</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        dp[i][<span class="number">3</span>] = float(<span class="string">"-inf"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n):</span><br><span class="line">        dp[i][<span class="number">1</span>] = max(dp[i<span class="number">-1</span>][<span class="number">1</span>], dp[i<span class="number">-1</span>][<span class="number">0</span>]-prices[i])</span><br><span class="line">        dp[i][<span class="number">2</span>] = max(dp[i<span class="number">-1</span>][<span class="number">2</span>], dp[i<span class="number">-1</span>][<span class="number">1</span>]+prices[i])</span><br><span class="line">        dp[i][<span class="number">3</span>] = max(dp[i<span class="number">-1</span>][<span class="number">3</span>], dp[i<span class="number">-1</span>][<span class="number">2</span>]-prices[i])</span><br><span class="line">        dp[i][<span class="number">4</span>] = max(dp[i<span class="number">-1</span>][<span class="number">4</span>], dp[i<span class="number">-1</span>][<span class="number">3</span>]+prices[i])</span><br><span class="line">    <span class="comment"># 最大值只发生在不持股的时候</span></span><br><span class="line">    <span class="keyword">return</span> max(<span class="number">0</span>, dp[<span class="number">-1</span>][<span class="number">2</span>], dp[<span class="number">-1</span>][<span class="number">4</span>])</span><br></pre></td></tr></table></figure><br>状态压缩，dp[i]仅仅依赖于dp[i-1]</p>
<p>4）最多可以完成 k 笔交易<br>注：必须在再次购买前出售掉之前的股票</p>
<p>5）在满足以下约束条件下，你可以尽可能地完成更多的交易（多次买卖一支股票）:<br>a) 必须在再次购买前出售掉之前的股票;<br>b) 卖出股票后，你无法在第二天买入股票 (即冷冻期为 1 天)<br>思路：增加一个状态，j取三个值：<br>0表示不持股，1表示持股，2表示冷冻期<br>状态转移方程：<br>dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])<br>dp[i][1] = max(dp[i-1][1], dp[i-1][2]-prices[i])<br>dp[i][2] = dp[i-1][0]<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxProfitV</span><span class="params">(prices)</span>:</span></span><br><span class="line">    n = len(prices)</span><br><span class="line">    <span class="keyword">if</span> n&lt;<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    dp = [[<span class="number">0</span>]*<span class="number">3</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(n)]</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n):</span><br><span class="line">        dp[i][<span class="number">0</span>] = max(dp[i<span class="number">-1</span>][<span class="number">0</span>], dp[i<span class="number">-1</span>][<span class="number">1</span>]+prices[i])</span><br><span class="line">        dp[i][<span class="number">1</span>] = max(dp[i<span class="number">-1</span>][<span class="number">1</span>], dp[i<span class="number">-1</span>][<span class="number">2</span>]-prices[i])</span><br><span class="line">        dp[i][<span class="number">2</span>] = dp[i<span class="number">-1</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> max(dp[<span class="number">-1</span>][<span class="number">0</span>], dp[<span class="number">-1</span>][<span class="number">2</span>])</span><br></pre></td></tr></table></figure><br>考虑状态压缩，dp[i]仅仅只依赖于dp[i-1]<br>6）你可以无限次地完成交易，但是你每次交易都需要付手续费fee。<br>如果你已经购买了一个股票，在卖出它之前你就不能再继续购买股票了。<br>思路：规定手续费在买入股票时扣除<br>状态转移方程：<br>dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])<br>dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i]-fee)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxProfitVI</span><span class="params">(prices, fee)</span>:</span></span><br><span class="line">    n = len(prices)</span><br><span class="line">    <span class="keyword">if</span> n&lt;<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    dp = [[<span class="number">0</span>]*<span class="number">2</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(n)]</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>]-fee</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n):</span><br><span class="line">        dp[i][<span class="number">0</span>] = max(dp[i<span class="number">-1</span>][<span class="number">0</span>], dp[i<span class="number">-1</span>][<span class="number">1</span>]+prices[i])</span><br><span class="line">        dp[i][<span class="number">1</span>] = max(dp[i<span class="number">-1</span>][<span class="number">1</span>], dp[i<span class="number">-1</span>][<span class="number">0</span>]-prices[i]-fee)</span><br><span class="line">    <span class="keyword">return</span> dp[<span class="number">-1</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/25/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/25/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD%E7%9F%A5%E8%AF%86/" class="post-title-link" itemprop="url">基础技能知识</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-25 21:29:48" itemprop="dateCreated datePublished" datetime="2020-02-25T21:29:48+08:00">2020-02-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-06 11:07:24" itemprop="dateModified" datetime="2020-03-06T11:07:24+08:00">2020-03-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><p><a href="https://juejin.im/post/5b6bc1d16fb9a04f9c43edc3" target="_blank" rel="noopener">Python常问问题</a></p>
<h1 id="Pytorch、Tensorflow"><a href="#Pytorch、Tensorflow" class="headerlink" title="Pytorch、Tensorflow"></a>Pytorch、Tensorflow</h1><p><a href="https://blog.csdn.net/weixin_31866177/article/details/87974664" target="_blank" rel="noopener">tensorflow</a></p>
<h1 id="Linux系统"><a href="#Linux系统" class="headerlink" title="Linux系统"></a>Linux系统</h1><p><a href="https://blog.csdn.net/qq_40910541/article/details/80686362?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">linux常用指令</a></p>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><p><a href="https://blog.csdn.net/qq_26768741/article/details/66975516" target="_blank" rel="noopener">git常见问题</a></p>
<h1 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h1><p><a href="https://www.jianshu.com/p/0fc161b9bcc7" target="_blank" rel="noopener">Java常见问题</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/25/%E9%9D%A2%E7%BB%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/25/%E9%9D%A2%E7%BB%8F/" class="post-title-link" itemprop="url">面经</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-25 08:52:11" itemprop="dateCreated datePublished" datetime="2020-02-25T08:52:11+08:00">2020-02-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-10 14:55:10" itemprop="dateModified" datetime="2020-03-10T14:55:10+08:00">2020-03-10</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="2020年快手Y-tech面经"><a href="#2020年快手Y-tech面经" class="headerlink" title="2020年快手Y-tech面经"></a>2020年快手Y-tech面经</h1><h2 id="一面"><a href="#一面" class="headerlink" title="一面:"></a>一面:</h2><p>1、PCA原理，应用<br>PCA原理是在原有n维特征的基础上重新构造出k维全新的正交特征，PCA的工作就是从原始空间顺序中到一组互相正交的坐标轴，第一个坐标轴选择就是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使方差最大的，第三个轴是与第1、2个轴正交的平面中方差最大的。依次类推可以得到n个这样的坐标轴。通过这种方式获得的新坐标轴，我们发现大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。于是我们可以忽略余下的坐标轴，只保留前面k个含有大部分方差的坐标轴。<br>PCA的应用范围有：1）数据压缩。数据压缩或者数据降维首先能够减少内存的使用，其次，数据降维能够加快机器学习的速度。2）数据可视化。在很多情况下，可能我们需要查看样本特征，但是高维度的特征根本无法观察，这个时候我们可以将样本的特征维数降到2个特征或3个特征，这样就可以采用可视化观察数据。3）去除数据噪声。<br>如何得到这些包含最大差异性的主成分方向呢？通过计算数据矩阵的协方差矩阵，然后得到协方差矩阵的特征值特征向量，选择特征值最大（即方差最大）的k个特征所对应的特征向量组成的矩阵。这样就可以将数据矩阵转换到新的空间中，实现数据特征的降维。得到协方差矩阵的特征值向量有两种方法：特征值分解协方差矩阵、奇异值分解协方差矩阵。<br>2、SVD原理，应用<br><a href="https://blog.csdn.net/weixin_31866177/article/details/88079612?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">SVD推导过程</a><br>3、SVM<br>SVM是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔大使它有别于普通的感知机，通过核技巧隐式的在输入空间直接求解映射空间中特征向量的内积，使其成为一个非线性分类器。SVM的学习策略是间隔最大化，可形式化为一个求解凸二次规划问题。<br>（重点）<a href="https://blog.csdn.net/cppjava_/article/details/68060439" target="_blank" rel="noopener">SVM算法推导过程</a><br>4、BN 优缺点 IN<br>BN的基本思想相当直观：因为深层神经网络在做非线性变换前的激活输入值随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或变动，之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区域的上下限两端靠近，所以这导致反向传播时低层神经网络的梯度消失，这是训练深层神经网络收敛越来越慢的本质原因。而BN就是通过一定的规范化手段，把层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，其实就是把越来越偏的分布强制拉回到标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就是导致损失函数较大的变化。<br>BatchNorm的优点：1）极大提升了训练速度，使得收敛过程大大加快；2）还能增加分类效果，一种解释是这类似于Dropout的一种防止过拟合的正则化表达方式，所以不用Dropout也能达到相当的效果；3）调参过程也简单了，对于初始化要求没那么高，可以使用大的学习率。4）可以代替LRN<br>缺点：需要计算均值与方差，不适合动态网络或者RNN。计算均值方差依赖每批次，因此数据最好足够打乱。<br>IN的计算就是把每张图片的HW维度单独拿出来归一化处理，不受通道和batchsize 的影响<br>5、cross entropy和mse区别，求导<br>交叉熵是用来评估当前训练得到的概率分布于真实分布的差异情况，减少交叉熵损失就是在提高模型的预测准确率。交叉熵通常用作分类问题的代价函数。<br>均方误差是指参数估计值与真实值之差的平方的期望值，MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精度。通常用来做回归问题的代价函数。<br>6、sigmoid, softmax用途，区别<br>Sigmoid函数或Softmax函数可以将分类器的原始输出值映射为概率。Sigmoid函数会分别处理各个原始输出值，因此其结果相互独立，概率总和不一定为1。相反，Softmax函数的输出值相互关联，其概率的总和始终为1。<br>Sigmoid = 多标签分类问题 = 多个正确答案 = 非独占输出<br>Softmax = 多类别分类问题 = 只有一个正确答案 = 互斥输出<br>如果模型输出为非互斥类别，且可以同时选择多个类别，则采用Sigmoid函数计算该网络的原始输出值。<br>如果模型输出为互斥类别，且只能选择一个类别，则采用Softmax函数计算该网络的原始输出值。<br>7、单链表快排思想<br>8、概率题，a服从均匀分布(0,1)，b服从均匀分布(0,1),求max(a,b)的期望，拓展为n个独立变量，求max期望</p>
<h2 id="二面"><a href="#二面" class="headerlink" title="二面:"></a>二面:</h2><p>1、cross entropy和mse能否互相替换？<br>不能。参见问题（为什么分类问题用 cross entropy，而回归问题用 MSE?）<br>2、多标签分类是否了解, 多标签分类激活函数?<br><a href="https://blog.csdn.net/rocling/article/details/89165463" target="_blank" rel="noopener">解答</a><br>3、单链表快排实现</p>
<h1 id="2019-海康威视"><a href="#2019-海康威视" class="headerlink" title="2019 海康威视"></a>2019 海康威视</h1><h2 id="一面-1"><a href="#一面-1" class="headerlink" title="一面"></a>一面</h2><p>1、faster-rcnn的整个从输入到输出的框架流程？<br>参见深度学习基础知识.faster rcnn<br>2、说一下rpn的原理<br>参见深度学习基础知识.faster rcnn<br>3、针对小目标的解决措施<br>（待解决）<br>4、如何解决类内的检测<br>（待解决）<br>5、focal loss原理<br><a href="https://blog.csdn.net/hejin_some/article/details/100600663" target="_blank" rel="noopener">参考解答</a></p>
<h1 id="2019-矿视"><a href="#2019-矿视" class="headerlink" title="2019 矿视"></a>2019 矿视</h1><h2 id="一面-2"><a href="#一面-2" class="headerlink" title="一面"></a>一面</h2><p>1、讲一下SENet的模块，为什么有性能提升，有什么好处<br>2、讲一下Focal loss 的2个参数有什么作用<br>3、讲一下FPN为什么能提升小目标的准确率<br>4、对One-stage的模型有没有了解<br>5、说一说One-stage和Two-stage两者有什么特点<br>6、说一说SSD具体是怎么操作的<br>7、算法题：leetcode.754。一个人从原点出发，可以往左走可以往右走，每次走的步数递增1，问能不能到达一个位置x？如果能，给出走的步数最少的方案？</p>
<h1 id="蚂蚁金服"><a href="#蚂蚁金服" class="headerlink" title="蚂蚁金服"></a>蚂蚁金服</h1><h2 id="二面-1"><a href="#二面-1" class="headerlink" title="二面"></a>二面</h2><p>1、分类和定位的不一致具体是什么<br>2、Faster-RCNN比起RCNN有什么改进的地方<br>3、Faster-RCNN如何进行一次计算<br>4、RoI Pooling如何操作<br>5、如果有很长，很小，或者很宽的目标，应该如何处理<br>（待解决）<br>6、FPN具体是怎么操作的<br>（待解决）<br>7、FPN的特征融合具体是怎么做的<br>8、FPN的特征融合为什么是相加操作呢<br>9、Soft-NMS是如何操作的<br>10、Softmax是什么，公式是什么样的<br>11、Softmax的梯度是什么<br>12、BN原理<br>13、Pytorch的卷积是如何实现的<br><a href="https://blog.csdn.net/qq_37541097/article/details/102926037" target="_blank" rel="noopener">解答</a><br>14、还知道哪些传统计算机视觉的算法<br>(待解决)<br>15、SIFT原理，SIFT如何保持尺度不变性的<br>(待解决)</p>
<h2 id="三面"><a href="#三面" class="headerlink" title="三面"></a>三面</h2><p>1、说一个比较熟悉的网络<br>（项目中需准备）<br>2、对移动端的网络有没有什么了解<br>（待解决）<br>3、Focal loss怎么操作的<br>4、IoUNet怎么操作的<br>（待解决）<br>5、Soft-NMS怎么操作的<br>6、FPN的相加操作有没有尝试其他操作<br>7、对SSD和YOLO有没有什么了解？对SSD做过什么实验<br>8、对attention有什么了解<br>9、对跟踪有没有什么了解</p>
<h2 id="四面"><a href="#四面" class="headerlink" title="四面"></a>四面</h2><p>1、说一下focal loss的原理<br>2、介绍一下目标检测有哪些方向，最近的一些新的进展<br>3、说一下Soft-NMS的原理<br>4、说一下视觉的attention<br>5、平常是如何学习的<br>6、python多线程有了解吗<br>（待解决）<br>7、引用和指针的区别<br>（待解决）整理python相关问题<br>8、有什么想问的</p>
<h2 id="五面"><a href="#五面" class="headerlink" title="五面"></a>五面</h2><p>1、说比赛<br>2、比赛的数据集数量是怎么分布的<br>3、小目标占比如何<br>4、为什么说SENet泛化性好<br>5、SENet为什么效果好<br>6、FPN是怎么提升小目标检出率的<br>7、项目是一个什么问题呢<br>8、大目标如果有2个候选框和gt重合应该怎么处理<br>9、BN是解决什么问题的<br>10、BN为什么有效<br>11、什么时候开始接触这个方向的<br>12、学过哪些课程<br>13、学过机器学习吗</p>
<h1 id="商汤"><a href="#商汤" class="headerlink" title="商汤"></a>商汤</h1><h2 id="一面-3"><a href="#一面-3" class="headerlink" title="一面"></a>一面</h2><p>1、InceptionV1为什么能提升性能<br>2、RPN哪里也可以提升小目标检出率<br>3、为什么说resnet101不适用于目标检测<br>4、小目标在FPN的什么位置检测<br>5、sigmoid和softmax的区别<br>6、detnet原理<br>7、一道算法题：输入一个文件，等概率输出某一行，只能顺序遍历<br>8、手写nms<br>(参考答案)[<a href="https://zhuanlan.zhihu.com/p/64423753" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/64423753</a>]</p>
<h2 id="二面-2"><a href="#二面-2" class="headerlink" title="二面"></a>二面</h2><p>1、项目：最大的创新点是什么<br>2、SENet原理<br>3、Focal Loss 原理<br>4、Faster RCNN原理<br>5、用的roi pooling 还是roi align<br>6、IoUNet的原理<br>7、有了解过单阶段的检测器<br>8、说一下SSD的原理<br>9、还知道哪些轻量级的检测器<br>10、知道大网络用来学习小网络的方法吗<br>11、对分割有没有了解<br>12、用的什么机器(GPU)<br>13、比赛排名多少<br>14、用的什么模型</p>
<h2 id="三面-1"><a href="#三面-1" class="headerlink" title="三面"></a>三面</h2><p>1、什么时候开始接触CV课程<br>2、有没有上过CV的相关课程<br>3、SENet原理<br>4、SENet接在ResNet还有Inception的什么位置呢<br>5、IOUNet能有多少提升<br>6、NMS和soft-NMS原理<br>7、比赛遇到了什么不work的地方<br>8、假如一个图片中有一个很大的目标还有一个很小的目标，你会怎么处理呢<br>9、多尺度训练如何设置<br>10、为什么设置长边为固定的1600呢<br>11、介绍一下SSD和Faster-RCNN，说一下异同点<br>12、Faster-RCNN的回归目标是如何定义的<br>13、Faster-RCNN用的什么loss<br>14、smooth L1 loss为什么更有效<br>15、SGD、Adam之类优化的原理<br>16、BN、IN、LN、GN原理，BN为什么有效<br>17、Python有哪些常用的库报一遍<br>18、说一下使用Pytorch对cifar10数据集分类的整个代码流程，构建模型的过程是怎么样的<br>19、会C++吗<br>20、github的常用操作：上传、合并、分支之类的<br>（待整理）<br>21、linux的常用操作：查看文件大小、删除文件、查看文件行数、假如文件中有很多文件，每个文件中又有很多文件，如何删除全部文件<br>（待整理）<br>22、SiamRPN原理<br>23、轻量级模型<br>（待解决）</p>
<h1 id="精锐视觉上海研究院"><a href="#精锐视觉上海研究院" class="headerlink" title="精锐视觉上海研究院"></a>精锐视觉上海研究院</h1><h2 id="二面-3"><a href="#二面-3" class="headerlink" title="二面"></a>二面</h2><p>算法题：1、给定一个乱序的数组，给定一个整数target，要求找出数组中所有和为该target的两个数。2、给定一张100元纸币，兑换为20，5，1元的纸币，要求将100元纸币正好兑换为上述面额的纸币，且每种面额不少于一张，写代码实现总共有多少种兑换方法。<br>2、生成式模型和判别式模型<br>（待解决）<br>3、解释最大似然估计和最大后验概率以及区别<br>4、神经网络中激活层的作用<br>5、faster rcnn中为什么要用3x3的巻积核代替5x5和7x7的巻积核。<br>6、防止过拟合的方式有哪些，请写出不少于五种。<br>7、请用深度学习的方法设计一套手写签名的识别方案。（不会）<br>8、请自主设计一套人脸识别方案，详述数据集、backbone、训练策略、模型测试等。<br>9、opencv的cascade级联分类器的工作原理以及具体的实现方式，训练级联分类器的注意事项。<br>（待解决）<br>10、HOG，LBP，Haar特征<br>（待解决）<br>11、简单介绍一下deep_sort算法</p>
<h2 id="三面-2"><a href="#三面-2" class="headerlink" title="三面"></a>三面</h2><p>1、问了一个深度学习的项目，项目简介，自己负责的部分，技术原理细节，创新点，难点。后续改进方案。<br>2、详细介绍一下deepsort算法，以及和传统跟踪方法的区别。<br>3、faster rcnn原理<br>4、详细解释deep_sort算法，与online track的方法有什么区别，目标跟踪丢失怎么办</p>
<h1 id="聚时科技"><a href="#聚时科技" class="headerlink" title="聚时科技"></a>聚时科技</h1><h2 id="一面-4"><a href="#一面-4" class="headerlink" title="一面"></a>一面</h2><p>1、图像处理，中值滤波和平滑滤波的区别<br>2、说几个机器学习常用的算法，SVM的目标函数是什么，是如何实现分类的，KNN的原理以及分类流程<br>3、常见的目标分类的基础网络有哪些，mobilenet和shufflenet是如何实现卷积加速的。</p>
<h2 id="二面-4"><a href="#二面-4" class="headerlink" title="二面"></a>二面</h2><p>1、给了一个7x7的灰度图像和一个2x2的卷积核，分别写出腐蚀和膨胀运算后的图像。<br>2、手写代码实现二维卷积过程，不得调用TF、Keras等深度学习库。<br>3、手写代码实现一个8邻接连通域算法，不得调用opencv等图像处理库。<br>4、写出三个常用的机器学习算法，并介绍其原理和使用场景。<br>5、请写出如些解决样本不平衡问题。</p>
<h1 id="腾讯"><a href="#腾讯" class="headerlink" title="腾讯"></a>腾讯</h1><p>1、YOLO V2 V3你对哪个熟悉，讲一下细节实现<br>2、多尺度问题<br>3、anchor基础知识<br>4、人脸识别现在常用算法<br>5、语义分割到实例分割怎么做<br>6、GAN是否了解，如何通俗的讲其原理<br>7、PCA原理LDA原理<br>8、SVM+HOG<br>9、XGBoost<br>10、CNN、RCNN、FRCNN，有可能问你其中一个细节的关键<br>11、TensorFlow这些框架你谈一下看法以及对其他框架的了解<br>12、现在机器学习、深度学习这么火，你有什么看法<br>13、机器学习、深度学习你对他们的理解是什么<br>14、Relu比Sigmoid使用多的原因<br>15、Loss不升反降的原因，如何解决<br>16、SSD细节<br>17、Linux 权限的意义<br>18、块操作的操作的步骤以及快捷方式</p>
<h1 id="搜狗"><a href="#搜狗" class="headerlink" title="搜狗"></a>搜狗</h1><h2 id="一面-5"><a href="#一面-5" class="headerlink" title="一面"></a>一面</h2><p>1、RCNN系列的算法流程和区别；<br>2、Fast RCNN中 bbox 回归的损失函数什么；<br>3、解释 ROI Pooling 和 ROI Align；<br>4、Mask RCNN中 mask branch 如何接入 Faster RCNN中；<br>5、解释 FPN （没细看，面完补的）；<br>6、优化算法举例和他们的区别（SGD、SGDM、RMSprop、Adam）；<br>7、训练不收敛的原因有哪些；<br>8、简述 Inception v1-v4；<br>9、简述 CNN 的演变；<br>10、BN 的作用和缺陷，以及针对batch_size小的情况的改进（GN）</p>
<h1 id="旷世CV岗"><a href="#旷世CV岗" class="headerlink" title="旷世CV岗"></a>旷世CV岗</h1><p>1.自我介绍，项目介绍<br>2.FCN结构介绍，上采样的具体操作<br>3.空洞卷积原理，deeplab v1 v2的改进<br>4.focal loss介绍, lovasz loss数学原理<br>5.一道题，计算卷积操作的浮点计算量，比较简单<br>6.介绍下RPN的原理<br>7.mobile net<br>8.unet的缺点</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/21/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/21/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">排序算法</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-21 19:41:40" itemprop="dateCreated datePublished" datetime="2020-02-21T19:41:40+08:00">2020-02-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-24 23:38:43" itemprop="dateModified" datetime="2020-02-24T23:38:43+08:00">2020-02-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><img src="/images/排序算法.png" alt="排序算法比较"></p>
<h1 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h1><p>算法过程：首先，找到数组中最小的那个元素，其次，将它和数组的第一个元素交换位置（如果第一个元素就是最小元素就和自己交换）。然后在剩下的元素中找到最小的元素，将它与数组的第二个元素交换位置。如此往复，知道整个数组排序。<br><img src="https://images2017.cnblogs.com/blog/849589/201710/849589-20171015224719590-1433219824.gif" alt="选择排序过程"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectionSort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)<span class="number">-1</span>):</span><br><span class="line">        minIndex = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, len(nums)):</span><br><span class="line">            <span class="keyword">if</span> nums[j]&lt;nums[minIndex]:</span><br><span class="line">                minIndex = j</span><br><span class="line">        nums[i], nums[minIndex] = nums[minIndex], nums[i]</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><br>性质：时间复杂度：$O(n^2)$，空间复杂度：$O(1)$，非稳定排序，原地排序</p>
<h1 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h1><p>算法过程：1）从数组第2个元素开始抽取元素。2）把它与左边第一个元素比较，如果左边第一个元素比它大，则继续与左边第二个元素比较，知道遇到不必它大的元素，然后插入到这个元素的右边。3）继续选取第3,4,…,n个元素，重复步骤2，选择适当的位置插入。<br><img src="http://wuchong.me/img/Insertion-sort-example-300px.gif" alt="插入排序过程"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertionSort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)<span class="number">-1</span>):</span><br><span class="line">        curNum, preIndex = nums[i+<span class="number">1</span>], i</span><br><span class="line">        <span class="keyword">while</span> preIndex&gt;=<span class="number">0</span> <span class="keyword">and</span> curNum&lt;nums[preIndex]:</span><br><span class="line">            nums[preIndex+<span class="number">1</span>] = nums[preIndex]</span><br><span class="line">            preIndex -= <span class="number">1</span></span><br><span class="line">        nums[preIndex+<span class="number">1</span>] = curNum</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><br>性质：时间复杂度：$O(n^2)$，空间复杂度：$O(1)$，稳定排序，原地排序。</p>
<h1 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h1><p>算法过程：1）把第一个元素和第二个元素比较，如果第一个比第二个大，则交换他们的位置。接着比较第二个与第三个元素，如果第二个比第三个大，则交换它们的位置…。这样一趟比较交换之后，排在最右的就会是最大的数。2）除去最右的数，我们对剩余的元素做同样的工作，如此重复下去，直到排序完成。<br><img src="https://images2017.cnblogs.com/blog/849589/201710/849589-20171015223238449-2146169197.gif" alt="冒泡排序过程"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubblesort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)<span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, i):</span><br><span class="line">            <span class="keyword">if</span> nums[j]&gt;nums[j+<span class="number">1</span>]:</span><br><span class="line">                nums[j], nums[j+<span class="number">1</span>] = nums[j+<span class="number">1</span>], nums[j]</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><br>性质：时间复杂度：$O(n^2)$，空间复杂度：$O(1)$，稳定排序，原地排序。<br><strong>优化冒泡排序算法:</strong>假如开始的第一队到结尾的最后一对，相邻的元素之间都没有发生交换的操作，这意味着右边的元素总是大于等于左边的元素，此时数组已经是有序的，无须再对剩余的元素重复比较下去。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubblesort2</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> nums:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)<span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        swapped = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, i):</span><br><span class="line">            <span class="keyword">if</span> nums[j]&gt;nums[j+<span class="number">1</span>]:</span><br><span class="line">                nums[j], nums[j+<span class="number">1</span>] = nums[j+<span class="number">1</span>], nums[j]</span><br><span class="line">                swapped = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> swapped:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure></p>
<h1 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h1><p>希尔排序可以说是插入排序的一种变种，无论是插入排序还是冒泡排序，如果数组的最大值刚好是在第一位，要将它挪到正确的位置就需要n-1次移动。也就是说原数组的一个元素如果距离它正确的位置很远，则需要与相邻元素交换很多次才能到达正确的位置，这是相对比较花时间了。<br>希尔排序就是为了加快速度简单地改进插入排序，交换不相邻的元素对数组的局部进行排序。基本思想是：先将整个待排序列分割成为若干子序列分别进行插入排序，待整个序列中的记录基本有序时再对全体记录进行一次直接插入排序。希尔排序的核心在于间隔序列的设定，既可以提前设定好间隔序列，也可以动态地定义间隔序列。<br><img src="https://images2018.cnblogs.com/blog/849589/201803/849589-20180331170017421-364506073.gif" alt="希尔排序过程"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shellSort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    gap = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> gap&lt;len(nums)//<span class="number">3</span>:</span><br><span class="line">        gap = gap*<span class="number">3</span>+<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> gap&gt;<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(gap, len(nums)):</span><br><span class="line">            curNum, preIndex = nums[i], i-gap</span><br><span class="line">            <span class="keyword">while</span> preIndex&gt;=<span class="number">0</span> <span class="keyword">and</span> curNum&lt;nums[preIndex]:</span><br><span class="line">                nums[preIndex+gap] = nums[preIndex]</span><br><span class="line">                preIndex -= gap</span><br><span class="line">            nums[preIndex+gap] = curNum</span><br><span class="line">        gap //= <span class="number">3</span></span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><br>性质：时间复杂度：$O(nlogn)$，空间复杂度：$O(1)$，非稳定排序，原地排序。</p>
<h1 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h1><p>归并排序使用递归分治的思想，其基本思想是：把待排序列看成两个有序的子序列，然后合并两个子序列，接着把子序列再看成两个有序的子子序列，…，以此类推。<br><img src="http://wuchong.me/img/Insertion-sort-example-300px.gif" alt="归并排序过程"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mergeSort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(nums)&lt;=<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> nums</span><br><span class="line">    <span class="comment"># 归并过程</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge</span><span class="params">(left, right)</span>:</span></span><br><span class="line">        result = []</span><br><span class="line">        i = j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i&lt;len(left) <span class="keyword">and</span> j&lt;len(right):</span><br><span class="line">            <span class="keyword">if</span> left[i]&lt;=right[j]:</span><br><span class="line">                result.append(left[i])</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                result.append(right[j])</span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">        result = result + left[i:] + right[j:]</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="comment"># 递归过程</span></span><br><span class="line">    mid = len(nums)//<span class="number">2</span></span><br><span class="line">    left = mergeSort(nums[:mid])</span><br><span class="line">    right = mergeSort(nums[mid:])</span><br><span class="line">    <span class="keyword">return</span> merge(left, right)</span><br></pre></td></tr></table></figure><br>非递归做法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mergeSort2</span><span class="params">(nums)</span>:</span></span><br><span class="line">    i = <span class="number">1</span>  <span class="comment"># i是步长</span></span><br><span class="line">    <span class="keyword">while</span> i&lt;len(nums):</span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> left&lt;len(nums):</span><br><span class="line">            mid = left+i</span><br><span class="line">            right = min(left+<span class="number">2</span>*i, len(nums))</span><br><span class="line">            <span class="keyword">if</span> mid&lt;right:</span><br><span class="line">                nums[left:right]=merge(nums[left:mid], nums[mid:right])</span><br><span class="line">            left += <span class="number">2</span>*i</span><br><span class="line">        i *= <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure></p>
<h1 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h1><p>快速排序通常明显比同为$O(nlogn)$的其他算法更快，因此常被采用，而且快排采用了分治的思想，所以在面试中经常看到快排的影子。<br>步骤：<br>1）从数列中跳出一个元素作为基准数。<br>2）分区过程，将比基准数大的放在右边，小于或等于它的数都放在左边。<br>3）再对左右分区递归执行第二步，直至各区间只有一个数。<br><a href="http://wuchong.me/img/Quicksort-example.gif" target="_blank" rel="noopener">快排过程</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 划分策略，适用于链表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partition</span><span class="params">(nums, left, right)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> left == right:</span><br><span class="line">        <span class="keyword">return</span> left</span><br><span class="line">    pivot = left</span><br><span class="line">    slow, fast = left, left+<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> fast&lt;=right:</span><br><span class="line">        <span class="keyword">if</span> nums[fast]&lt;nums[pivot]:</span><br><span class="line">            slow += <span class="number">1</span></span><br><span class="line">            nums[slow], nums[fast] = nums[fast], nums[slow]</span><br><span class="line">        fast += <span class="number">1</span></span><br><span class="line">    nums[pivot], nums[slow] = nums[slow], nums[pivot]</span><br><span class="line">    <span class="keyword">return</span> slow</span><br><span class="line"></span><br><span class="line"><span class="comment"># 递归方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quickSort</span><span class="params">(nums, left, right)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> left&lt;=right:</span><br><span class="line">        midIndex = partition(nums, left, right)</span><br><span class="line">        quickSort(nums, left, midIndex<span class="number">-1</span>)</span><br><span class="line">        quickSort(nums, midIndex+<span class="number">1</span>, right)</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><br>非递归方式，利用栈的思想将需要继续排序的首尾下标存入栈中，不断弹栈进行分区操作。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partition2</span><span class="params">(nums, left, right)</span>:</span></span><br><span class="line">    mid = nums[left]</span><br><span class="line">    <span class="keyword">while</span> left&lt;right:</span><br><span class="line">        <span class="keyword">while</span> left&lt;right <span class="keyword">and</span> nums[right]&gt;mid:</span><br><span class="line">            right -= <span class="number">1</span></span><br><span class="line">        nums[left] = nums[right]</span><br><span class="line">        <span class="keyword">while</span> left&lt;right <span class="keyword">and</span> nums[left]&lt;=mid:</span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line">        nums[right] = nums[left]</span><br><span class="line">    nums[left] = mid</span><br><span class="line">    <span class="keyword">return</span> left</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quickSort2</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(nums)&lt;=<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> nums</span><br><span class="line">    stack = []</span><br><span class="line">    left, right = <span class="number">0</span>, len(nums)<span class="number">-1</span></span><br><span class="line">    stack.append(left)</span><br><span class="line">    stack.append(right)</span><br><span class="line">    <span class="keyword">while</span> stack:</span><br><span class="line">        r = stack.pop()</span><br><span class="line">        l = stack.pop()</span><br><span class="line">        midIndex = partition2(nums, l, r)</span><br><span class="line">        <span class="keyword">if</span> l&lt;midIndex:</span><br><span class="line">            stack.append(l)</span><br><span class="line">            stack.append(midIndex<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">if</span> r&gt;midIndex:</span><br><span class="line">            stack.append(midIndex+<span class="number">1</span>)</span><br><span class="line">            stack.append(r)</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure></p>
<h1 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h1><p>堆排序是借助堆来实现的选择排序，思想同选择排序，以下以大根堆为例。注意：如果想升序排序就使用大根堆，反之使用小根堆。原因是堆顶元素需要交换到序列尾部。<br>首先，实现堆排序需要解决两个问题：<br>1）如何由一个无序序列建成一个堆？<br>2）如何在输出堆顶元素之后，调整剩余元素成为一个新的堆？<br>第一个问题，可以直接使用线性数组来表示一个堆，由初始的无序序列建成一个堆就需要自底向上从第一个非叶元素开始按个调整成一个堆。<br>第二个问题，怎么调整成堆？首先是将堆顶元素和最后一个元素交换，然后比较当前堆顶元素的左右孩子节点，因为除了当前的堆顶元素，左右孩子均满足条件，这时需要选择当前堆顶元素与左右孩子节点的较大者（大根堆）交换，直到叶子节点。我们称这个自堆顶至叶子节点的调整为筛选。<br>从一个无序序列建堆的过程就是一个反复筛选的过程。若将此序列看成是一个完全二叉树，则最后一个非终端节点是n/2（取底）个元素，由此筛选即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 大根堆</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapSort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">adjustHeap</span><span class="params">(nums, i, size)</span>:</span></span><br><span class="line">        lchild = <span class="number">2</span>*i+<span class="number">1</span></span><br><span class="line">        rchild = <span class="number">2</span>*i+<span class="number">2</span></span><br><span class="line">        largest = i</span><br><span class="line">        <span class="keyword">if</span> lchild&lt;size <span class="keyword">and</span> nums[lchild]&gt;nums[largest]:</span><br><span class="line">            largest = lchild</span><br><span class="line">        <span class="keyword">if</span> rchild&lt;size <span class="keyword">and</span> nums[rchild]&gt;nums[largest]:</span><br><span class="line">            largest = rchild</span><br><span class="line">        <span class="keyword">if</span> largest != i:</span><br><span class="line">            nums[largest], nums[i] = nums[i], nums[largest]</span><br><span class="line">            adjustHeap(nums, largest, size)</span><br><span class="line">    <span class="comment"># 建立堆</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">buildHeap</span><span class="params">(nums, size)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)//<span class="number">2</span>)[::<span class="number">-1</span>]:  <span class="comment"># 从倒数第一个非叶子节点开始建立大根堆</span></span><br><span class="line">            adjustHeap(nums, i, size)        <span class="comment"># 对所有非叶子节点进行堆的调整</span></span><br><span class="line">    <span class="comment"># 堆排序</span></span><br><span class="line">    size = len(nums)</span><br><span class="line">    buildHeap(nums, size)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums))[::<span class="number">-1</span>]:</span><br><span class="line">        nums[<span class="number">0</span>], nums[i] = nums[i], nums[<span class="number">0</span>]</span><br><span class="line">        adjustHeap(nums, <span class="number">0</span>, i)</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure></p>
<h1 id="计数排序"><a href="#计数排序" class="headerlink" title="计数排序"></a>计数排序</h1><p>（待补充）</p>
<h1 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h1><p>（待补充）</p>
<h1 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h1><p>（待补充）</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="post-title-link" itemprop="url">深度学习基础知识</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-18 21:13:44" itemprop="dateCreated datePublished" datetime="2020-02-18T21:13:44+08:00">2020-02-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-10 17:02:11" itemprop="dateModified" datetime="2020-03-10T17:02:11+08:00">2020-03-10</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><h2 id="SGD-Momentum-Adagard-Adam原理"><a href="#SGD-Momentum-Adagard-Adam原理" class="headerlink" title="SGD,Momentum,Adagard,Adam原理"></a>SGD,Momentum,Adagard,Adam原理</h2><h3 id="1-SGD、BGD和Mini-BGD"><a href="#1-SGD、BGD和Mini-BGD" class="headerlink" title="1. SGD、BGD和Mini-BGD:"></a>1. SGD、BGD和Mini-BGD:</h3><p>SGD(stochastic gradient descent):随机梯度下降，算法在每读入一个数据都会立刻计算loss function的梯度来更新参数，假设loss function为L(w),下同。</p>
<script type="math/tex; mode=display">w-=\eta \bigtriangledown_{w_{i}}L(w_{i})</script><p>优点：收敛的速度快，可以实现在线更新<br>缺点：很容易陷入到局部最优，困在马鞍点<br>BGD(batch gradient decent):批量梯度下降，算法在读取整个数据集后累加来计算损失函数的梯度。</p>
<script type="math/tex; mode=display">w-=\eta \bigtriangledown_{w}L(w)</script><p>优点：如果loss function为convex(凸函数)，则基本可以找到全局最优解<br>缺点：数据处理量大，导致梯度下降慢；不能实时增加实例，在线更新；训练占内存<br>Mini-BGD(mini-batch gradient descent):选择小批量数据进行梯度下降，这是一个折中的方法，采用训练集的子集(mini-batch)来计算loss function的梯度：</p>
<script type="math/tex; mode=display">w-=\eta \bigtriangledown_{w_{i:i+n}}L(w_{i:i+n})</script><p>这个优化方法用的比较多，计算效率高且收敛稳定，是现在深度学习的主流方法。<br>上面的方法都存在一个问题，就是update更新的方向完全依赖计算出来的梯度，很容易陷入局部最优的马鞍点。能不能改变其走向，又保证原本的梯度方向，就像向量变换一样，我们模拟物理中物体流动的动量概念（惯性），引入Momentum的概念。</p>
<h3 id="2-Momentum"><a href="#2-Momentum" class="headerlink" title="2. Momentum"></a>2. Momentum</h3><p>在更新方向的时候保留之前的方向，增加稳定性而且还有摆脱局部最优的能力。</p>
<script type="math/tex; mode=display">\Delta w=\alpha \Delta w- \eta \bigtriangledown L(w)</script><script type="math/tex; mode=display">w=w+\Delta w</script><p>若当前梯度的方向与历史梯度方向一致（表明当前样本不太可能为异常点），则会增强这个方向的梯度，若当前梯度与历史梯度方向不一致，则梯度会衰减。一种形象的解释是：我们把一个球推下山，球在下坡时积聚动量，在途中变得越来越快，<script type="math/tex">\eta</script>可视为空气阻力，若球的方向发生变化，则动量会衰减。</p>
<h3 id="3-Adagrad"><a href="#3-Adagrad" class="headerlink" title="3. Adagrad"></a>3. Adagrad</h3><p>Adagrad(adaptive gradient)自适应梯度算法，是一种改进的随机梯度下降算法。以前的算法中，每一个参数都使用相同的学习率<script type="math/tex">\alpha</script>,而Adagrad算法能够在训练中自动对learning_rate进行调整，出现频率较低参数采用较大的<script type="math/tex">\alpha</script>更新，出现频率较高的参数采用较小的<script type="math/tex">\alpha</script>更新，根据描述这个优化方法很适合处理稀疏数据。</p>
<script type="math/tex; mode=display">G=\sum ^{t}_{\tau=1}g_{\tau} g_{\tau}^{T} \quad s.t. \ g_{\tau}=\bigtriangledown L(w_{i})</script><script type="math/tex; mode=display">G_{j,j}=\sum _{\tau=1}^{t} g_{\tau,j\cdot}^{2}</script><p>这个对角线矩阵的元素代表的是参数的出现频率，每个参数的更新：</p>
<script type="math/tex; mode=display">w_{j}=w_{j}-\frac{\eta}{\sqrt{G_{j,j}}}g_{j}</script><h3 id="4-RMSprop"><a href="#4-RMSprop" class="headerlink" title="4. RMSprop"></a>4. RMSprop</h3><p>RMSprop(root mean square propagation)也是一种自适应学习率方法，不同之处在于，Adagrad会累加之前所有的梯度平方，RMSprop仅仅是计算对应的平均值，可以缓解Adagrad算法学习率下降较快的问题。</p>
<script type="math/tex; mode=display">v(w,t)=\gamma v(w,t-1)+(1-\gamma)(\bigtriangledown L(w_{i}))^{2}</script><p>其中 $\gamma$ 是遗忘因子</p>
<p>参数更新</p>
<script type="math/tex; mode=display">w=w-\frac{\eta}{\sqrt{v(w,t)}}\bigtriangledown L(w_{i})</script><h3 id="5-Adam"><a href="#5-Adam" class="headerlink" title="5. Adam"></a>5. Adam</h3><p>Adam(adaptive moment estimation)是对RMSprop优化器的更新，利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。优点：每一次迭代学习率都有一个明确的范围，使得参数变化很平稳。</p>
<script type="math/tex; mode=display">m_{w}^{t+1}=\beta_{1}m_{w}^{t}+(1-\beta_{1}) \bigtriangledown L^{t}</script><script type="math/tex; mode=display">v_{w}^{t+1}=\beta_{2}m_{w}^{t}+(1-\beta_{2}) (\bigtriangledown L^{t})^{2}</script><p>其中，m为一阶矩估计，v为二阶矩估计，然后进行估计校正，实现无偏估计</p>
<script type="math/tex; mode=display">\hat{m}_{w}=\frac{m_{w}^{t+1}}{1-\beta_{1}^{t+1}}</script><script type="math/tex; mode=display">\hat{v}_{w}=\frac{v_{w}^{t+1}}{1-\beta_{2}^{t+1}}</script><script type="math/tex; mode=display">w^{t+1} \leftarrow=w^{t}-\eta \frac{\hat{m}_{w}}{\sqrt{\hat{v}_{w}}+\epsilon}</script><p>Adam是实际中最常用的算法</p>
<h2 id="L1、L2范数"><a href="#L1、L2范数" class="headerlink" title="L1、L2范数"></a>L1、L2范数</h2><p>在机器学习中几乎可以看到在损失函数后面都会添加一个额外项，常用的额外项一般有两种，称为L1正则化和L2正则化，或者L1范数和L2范数。L1范数和L2范数可以看做是损失函数的惩罚项，所谓“惩罚”是指对损失函数中的某些参数做些限制。对于现在的回归模型，使用L1范数的模型叫做Lasso回归，使用L2范数的模型叫做Ridge回归（岭回归）。</p>
<h3 id="L1范数"><a href="#L1范数" class="headerlink" title="L1范数"></a>L1范数</h3><p>L1范数是指向量中各个元素绝对值之和，也叫“稀疏规则算子”(Lasso regularization)。稀疏的意思是可以让权重矩阵的一部分值等于0。为什么L1范数会使权值稀疏？有一种回答“它是L0范数的最优凸近似”，还存在一种更优雅的回答：任何的规则算子，如果他在$w_{i}=0$处不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子可以实现稀疏。</p>
<script type="math/tex; mode=display">||x||_{1}=\sum_{i}|x_{i}|</script><p>L1范数可以实现稀疏，而实现稀疏的作用为：<br>1) 可解释性：可以看到到底是哪些特征和预测的信息有关<br>2) 特征选择：输入的x的大部分特征与输出y是没有关系的，如果让参数矩阵w中出现许多0，则可以直接干掉与y无关的元素，也就是选择出于y真正相关的特征。如果不这么做，那么x中本来与y无关的特征也加入到模型中，虽然会更好的减小训练误差，但是在预测新样本时会考虑到无关的信息，干扰了预测。</p>
<h3 id="L2范数"><a href="#L2范数" class="headerlink" title="L2范数"></a>L2范数</h3><p>L2范数是指向量中各元素的平方和然后再求平方根，也叫做“岭回归(Ridge Regression)”，或叫做“权值衰减(weight decay)”。</p>
<script type="math/tex; mode=display">||x||_{2}=\sqrt{\sum_{i}x_{i}^2}</script><p>L2范数与L1范数不同，它不会让参数等于0，而是让每个参数都接近于0。L2范数的优点是：<br>1) 防止过拟合。一般的用法是在损失函数后面加上w的L2范数，即$||x||_{2}$，这是一种规则。<br>2) 优化求解变得稳定快速。简单地说它可以让$w$在接近全局最优点$w^*$的时候，还保持较大的梯度。这样可以跳出局部最优，也使得收敛速度变快。<br>总之，L1会趋向产生少量的特征，而其他的特征都是0，L2会产生更多地特征但都会接近于0。L1在特征选择时候非常有用，而L2就是一种规则化而已</p>
<h3 id="L1不可导的时候该怎么办"><a href="#L1不可导的时候该怎么办" class="headerlink" title="L1不可导的时候该怎么办"></a>L1不可导的时候该怎么办</h3><p>当损失函数不可导，梯度下降不再有效，可以使用坐标轴下降法。梯度下降是沿着当前点的负梯度方向进行参数更新，而坐标轴下降法是沿着坐标轴的方向。假设有m个特征个数，坐标轴下降法进行参数更新的时候，先固定m-1个值，然后再求另外一个的局部最优解，从而避免损失函数不可导问题。坐标轴下降法每轮迭代都需要O(mn)的计算，和梯度下降算法相同。</p>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>神经网络的每个神经元接受上一层神经元的输出值作为本神经元的输入值，并将输入值传递给下一层，输入神经元节点会将输入属性值直接传递给下一层（隐藏层或输出层）。上层函数的输出和下层节点的输入之间具有一个函数关系，这个函数称为激活函数。如果不用激活函数，在这种情况下每一层节点的输入都是上一层输出的线性函数，很容易验证，无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，这种情况就是最原始的感知机（Perceptron），那么网络的逼近能力就相当有限。我们引入非线性函数作为激励函数，这样深层神经网络表达能力就更加强大，几乎可以逼近任意函数。</p>
<h3 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h3><p>Signoid是常用的非线性的激活函数，它的数学形式如下：</p>
<script type="math/tex; mode=display">f(z)=\frac{1}{1+e^{-z}}</script><p>Sigmoid的几何如下：<br><img src="/images/Sigmoid.png" alt="Sigmoid函数"><br>特点：它能够把输入的连续实值变换为0和1之间的输出，对于非常大的负数则输出为0，非常大的正数则输出为1.<br>缺点：<br>1) 在深度神经网络中梯度反向传递时导致梯度爆炸和梯度消失，其中梯度爆炸发生的概率非常小，而梯度消失发生的概率比较大。Sigmoid函数的倒数如下所示：<br><img src="/images/Sigmoid导数.png" alt="Sigmoid的导数"><br>如果我们初始化神经网络的权值为[0,1]之间的随机值，由反向传播算法的数学推导可知，梯度从后向前传播时，每传递一层梯度值都会减少为原来的0.25倍，如果神经网络隐藏层特别多时，那么梯度在多层传递之后就变得非常小接近于0，即出现梯度消失现象；当网络权值初始化为$(1,+\infty)$区间的值，则会出现梯度爆炸情况。<br>2) Sigmoid的输出不是0均值，这会导致后一层的神经元将上一层的神经元输出的非0均值的信号作为输入。产生的结果是：如果$x&gt;0, f=w^Tx+b$，那么对$w$求局部梯度则都为正，这样反向传播的过程中$w$要么都向正方向更新，要么都往负方向更新，使得收敛缓慢。当然，如果按batch训练，那么那个batch可能会得到不同的信号，这个问题可以缓解一下。非0均值问题虽然会产生一些不好的影响，不过跟梯度消失问题相比还是要好很多。<br>3) 其解析式中含有幂运算，计算求解时相对比较耗时。对于规模较大的深度网络，这回较大地增加训练时间。</p>
<h3 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h3><p>tanh函数的解析式：</p>
<script type="math/tex; mode=display">tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}</script><p>tanh函数及其导数的几何图像如下：<br><img src="/images/tanh函数.png" alt="tanh函数及其导数"><br>tanh函数解决了Sigmoid函数不是zero-centered输出的问题，然而，梯度消失的问题和幂运算的问题仍然存在。</p>
<h3 id="Relu函数"><a href="#Relu函数" class="headerlink" title="Relu函数"></a>Relu函数</h3><p>Relu函数的解析式：</p>
<script type="math/tex; mode=display">Relu=max(0, x)</script><p>Relu函数及其导数的图像如下图所示：<br><img src="/images/Relu函数.png" alt="Relu函数及其导数"><br>ReLU其实是一个取最大值函数，注意这并不是全区间可导的，但是我们可以取sub-gradient，如上图所示。<br>优点：1）解决了梯度消失问题(gradient vanishing)问题（在正区间）。 2）计算速度非常快，只需要判断输入是否大于0。 3）收敛速度远快于sigmoid和tanh函数。<br>ReLU也有几个需要注意的问题：<br>1) ReLU的输出不是zero-centered。<br>2) Dead ReLU Problem，指的是某些神经元可能永远不会被激活，导致相应的参数永远不会被更新。有两个主要原因可能会导致这种情况：参数的初始化或learning_rate太大导致训练过程中参数更新太大进入这种状态。<br>解决的方法是采用Xavier初始化方法，以及避免将learning rate设置太大或使用adagrad等自动调节learning rate的算法。Xavier初始化方法是一种很有效的神经网络初始化方法，为了使得网络中信息更好的流动，每一层输出的方法应该尽量相等。</p>
<h3 id="Leaky-ReLU函数"><a href="#Leaky-ReLU函数" class="headerlink" title="Leaky ReLU函数"></a>Leaky ReLU函数</h3><p>函数表达式：</p>
<script type="math/tex; mode=display">f(x)=max(\alpha x, x)</script><p>Leaky Relu函数及其导数的图像如下图所示：<br><img src="/images/LeakyRelu函数.png" alt="Leaky ReLU函数及其导数"><br>图中左半边直线斜率非常接近于0，所以看起来像是平的。为了解决Dead ReLU Problem，通过将ReLU的前半段设为$\alpha x$而不是0，通常$\alpha =0.01$。理论上讲，Leaky ReLU有ReLU的所有优点，外加不会有Dead ReLU问题，但在实际操作中，并没有完全证明Leaky ReLU总是好于ReLU。</p>
<h3 id="ELU函数"><a href="#ELU函数" class="headerlink" title="ELU函数"></a>ELU函数</h3><p>函数表达式为：</p>
<script type="math/tex; mode=display">
f(x)=
\begin{cases}
x &\text(if\ x>0)\\
\alpha(e^x-1) &\text{otherwise}
\end{cases}</script><p>函数及其导数的图像如下：<br><img src="/images/ELU函数.png" alt="ELU函数及导数图像"><br>显然，ELU有ReLU的基本所有优点，以及不会有Dead ReLU问题，输出的均值接近于0，是zero-centered。它的一个小问题在于计算量稍大。</p>
<h2 id="神经网络权重初始化方式"><a href="#神经网络权重初始化方式" class="headerlink" title="神经网络权重初始化方式"></a>神经网络权重初始化方式</h2><p>在深度学习找那个，神经网络的权重初始化方法(weight initialization)对模型的收敛速度和性能有着至关重要的影响。神经网络其实就是对权重参数w的不停迭代更新，以期达到较好的性能。在深度神经网络中，随着层数的增多，在梯度下降的过程中，极易出现梯度消失或者梯度爆炸。因此，对权重w的初始化显得至关重要，一个好的权重初始化虽然不能完全解决梯度消失和梯度爆炸问题，但是对于处理这两个问题是由很大的帮助的，并且十分有利于模型性能和收敛速度。</p>
<h3 id="初始化为0"><a href="#初始化为0" class="headerlink" title="初始化为0"></a>初始化为0</h3><p>在线性回归和logistics回归中可以使用，因为隐藏层只有一层。在超过一层的神经网络中就不能够使用了。因为如果所有的权重参数都为0，那么所有的神经元输出都是一样的，在反向传播时向后传递的梯度也是一致，将无法发挥多层的效果，实际上相当于一层隐藏层。</p>
<h3 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h3><p>卷积层的方差为：</p>
<script type="math/tex; mode=display">Var(w_ix_i)=E[w_i]^2Var(x_i)+E[x_i]^2Var(w_i)+Var(w_i)Var(x_i)</script><p>使用高斯随机初始化时要把W随机初始化到一个相对较小的值，因为如果X很大的话，W又相对较大，会导致输出值特别大，这样如果激活函数是sigmoid，就会导致sigmoid的输出值为1或0，导致更多的问题。但是随机初始化也有缺点，在均值为0，方差为1的高斯分布中，当神经网络层数增加时，会发现越往高层的激活函数（tanh函数）的输出值几乎都接近于0，使得神经元不被激活。</p>
<h3 id="Xavier初始化"><a href="#Xavier初始化" class="headerlink" title="Xavier初始化"></a>Xavier初始化</h3><p>每层的权重初始化为：</p>
<script type="math/tex; mode=display">W\sim U[-\frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}}, \frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}}]</script><p>服从均匀分布，$n_j$为输入层的参数，$n_{j+1}$为输出层参数。<br>Xavier是为了解决随机初始化问题而提出的一种初始化方式，其思想是尽可能让输入和输出服从相同的分布，这样能够避免高层的激活函数的输出值趋向于0。虽然Xavier初始化能很好地用于tanh函数，但是对于目前最常用的ReLU激活函数，还是无能为力，因此引出He initialization。</p>
<h3 id="MSRA-He-initialization"><a href="#MSRA-He-initialization" class="headerlink" title="MSRA/He initialization"></a>MSRA/He initialization</h3><p>Xavier初始化对于Relu激活函数表现非常不好，因此何恺明针对ReLU重新推导，每层的初始化公式为：</p>
<script type="math/tex; mode=display">W\sim U[0, \sqrt{\frac{2}{n}}]</script><p>是一个均值为0，方差为$\frac{2}{n}$的高斯分布。<br>缺点是：MSRA方法只考虑一个方向，无法使得正向反向传播时方差变化都很小。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><h3 id="损失函数、代价函数与目标函数"><a href="#损失函数、代价函数与目标函数" class="headerlink" title="损失函数、代价函数与目标函数"></a>损失函数、代价函数与目标函数</h3><p>损失函数(Loss Function)：是定义在单个样本上的，是指一个样本的误差。<br>代价函数(Cost Function)：是定义在整个训练集上，是所有样本误差的平均值，也就是所有损失函数值的平均。<br>目标函数(Object Function)：是指最终需要优化的函数，一般来说是代价函数+正则化项。</p>
<h3 id="常用的损失函数"><a href="#常用的损失函数" class="headerlink" title="常用的损失函数"></a>常用的损失函数</h3><p>（1）0-1损失函数(0-1 loss function)</p>
<script type="math/tex; mode=display">
L(y, f(x))=
\begin{cases}
1, &\text{y}\ne\text{f(x)}\\
0, &\text{y}=\text{f(x)}
\end{cases}</script><p>即，当预测错误时，损失函数为1，当预测正确时，损失函数值为0.该损失函数不考虑预测值与真实值之间的误差程度。<br>（2）平方损失函数（quadratic loss function）</p>
<script type="math/tex; mode=display">L(y,f(x))=(y-f(x))^2</script><p>是指预测值与实际值差的平方。<br>（3）绝对值损失函数（absolute loss function）</p>
<script type="math/tex; mode=display">L(y,f(x))=|y-f(x)|</script><p>该损失函数只是取了绝对值而不是求平方值，差距不会被平方放大。<br>（4）对数损失函数(logarithmic loss function)</p>
<script type="math/tex; mode=display">L(y, p(y|x))=-logp(y|x)</script><p>该损失函数用到了极大似然估计思想。P(Y|X)通俗的解释是：在当前模型的基础上，对于样本X，其预测值为Y，也就是预测正确的概率。由于概率之间同时满足需要使用乘法，为了将其转化为加法，我们将其取对数。最后由于是损失函数，所以预测正确的概率越高，其损失值应该越小，因此再加个符号取反。<br>（5）Hinge loss<br>Hinge loss一般分类算法中的损失函数，尤其是SVM，其定义为：</p>
<script type="math/tex; mode=display">L(w,b)=max(0, 1-yf(x))</script><p>其中$y=+1$或$y=-1$，$f(x)=wx+b$，当为SVM的线性核时。</p>
<h3 id="常用的代价函数"><a href="#常用的代价函数" class="headerlink" title="常用的代价函数"></a>常用的代价函数</h3><p>（1）均方误差(Mean Squared Error)</p>
<script type="math/tex; mode=display">MSE=\frac{1}{N}\sum_{i=1}^N(y^{(i)}-f(x^{(i)}))^2</script><p>均方误差是指参数估计值与真实值之差的平方的期望值，MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精度。（i表示第i个样本，N表示样本总数）。<br>通常用来做回归问题的代价函数。<br>（2）均方根误差</p>
<script type="math/tex; mode=display">RMSE=\sqrt{\frac{1}{N}\sum_{i=1}^N(y^{(i)}-f(x^{(i)}))^2}</script><p>均方根误差是均方误差的算术平方根，能够直观观测预测值与真实值的离散程度。通常用来作为回归算法的性能指标。<br>（3）平均绝对误差（Mean Absolute Error）</p>
<script type="math/tex; mode=display">MAE=\frac{1}{N}\sum_{i=1}^N|y^{(i)}-f(x^{(i)})|</script><p>平均绝对误差是绝对误差的平均值，平均绝对误差能更好地反映预测值误差的实际情况。通常用来作为回归算法的性能指标。<br>（4）交叉熵代价函数(Cross Entry)</p>
<script type="math/tex; mode=display">H(p,q)=-\frac{1}{N}\sum_{i=1}^Np(x^{(i)})log(x^{(-i)})</script><p>交叉熵是用来评估当前训练得到的概率分布于真实分布的差异情况，减少交叉熵损失就是在提高模型的预测准确率。其中p(x)是指真实分布的概率，q(x)是模型通过数据计算出来的概率估计。<br>对于二分类模型的交叉熵代价函数：</p>
<script type="math/tex; mode=display">L(w,b)=-\frac{1}{N}\sum_{i=1}^N(y^{(i)}logf(x^{(i)})+(1-y^{(i)})log(1-f(x^{(i)})))</script><p>其中f(x)可以是sigmoid函数或深度学习中的其他激活函数，而$y{(i)}\in 0,1$。<br>交叉熵通常用作分类问题的代价函数。<br><a href="https://zhuanlan.zhihu.com/p/37217242" target="_blank" rel="noopener">常用损失函数</a></p>
<h3 id="为什么分类问题用-cross-entropy，而回归问题用-MSE"><a href="#为什么分类问题用-cross-entropy，而回归问题用-MSE" class="headerlink" title="为什么分类问题用 cross entropy，而回归问题用 MSE?"></a>为什么分类问题用 cross entropy，而回归问题用 MSE?</h3><p><a href="https://blog.csdn.net/weixin_41888969/article/details/89450163" target="_blank" rel="noopener">优秀解答</a><br>对于多分类的标签，从本质上看，通过One-hot操作，就是把具体的标签（Label）空间，变换到一个概率测度空间（设为 p）。而对于多分类问题，在Softmax函数的“加工”下，神经网络的实际输出值就是一个概率向量，设其概率分布为q。现在我们想衡量p和q之间的差异（即损失），一种简单粗暴的方式，自然是可以比较p和q的差值，如MSE（不过效果不好而已）。一种更好的方式是衡量这二者的概率分布的差异，就是交叉熵，因为它的设计初衷，就是要衡量两个概率分布之间的差异。总之分类标签可以看做是概率分布（由one-hot变换而来），神经网络输出（经过softmax加工）也是一个概率分布，现在想衡量二者的差异（即损失），自然用交叉熵最好了。<br>当MSE和交叉熵同时应用到多分类场景下时，（标签的值为1时表示属于此分类，标签值为0时表示不属于此分类），MSE对于每一个输出的结果都非常看重，而交叉熵只对正确分类的结果看重。交叉熵的损失函数只和分类正确的预测结果有关系，而MSE的损失函数还和错误的分类有关系，该分类函数除了让正确的分类尽量变大，还会让错误的分类变得平均，但实际在分类问题中这个调整是没有必要的。但是对于回归问题来说，这样的考虑就显得很重要了。所以，回归问题熵使用交叉熵并不合适。</p>
<h2 id="Batch-Normalization原理"><a href="#Batch-Normalization原理" class="headerlink" title="Batch Normalization原理"></a>Batch Normalization原理</h2><p><a href="https://blog.csdn.net/e01528/article/details/89313518" target="_blank" rel="noopener">BN归纳</a><br>Batch Normalization就是在训练过程中使得每一层神经网络的输入保持相同分布的。BN的基本思想相当直观：随着网络深度加深或者在训练过程中，神经元的输入值分布逐渐发生偏移或变动，使得整体分布逐渐往非线性函数的取值区域的上下限两端靠近，所以这导致反向传播时低层神经网络的梯度消失，这是训练深层神经网络收敛越来越慢的本质原因。而BN就是通过一定的规范化手段，把该层任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，其实就是把越来越偏的分布强制拉回到标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就是导致损失函数较大的变化，使得梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。<br>如果都通过BN，那么不就跟把非线性函数替换成线性函数效果相同吗？这意味着什么？我们知道，如果是多层的线性函数变换其实这个深层网络就没有意义，因为多层线性网络跟一层线性网络是等价的。这意味着网络的表达能力又下降了。所以BN为了保证非线性的获得，对变换后的满足均值为0方差为1的$x$又进行了scale加上shift操作($y=scale*x+shift$)，每个神经元增加了两个参数scale和shift参数，这两个参数是通过训练学习到的，意思是通过scale和shift把输入值从标准正太分布左移或右移一点并拉伸或缩短一点，每个实例的挪动情况不一样，这样等价于非线性函数的值从正中心的线性区域往非线性区域动了动。核心思想是想找到一个线性和非线性的较好平衡点，既能享受非线性的较强表达能力的好处，又避免太靠近非线性区两头使得网络的收敛速度太慢。<br>BatchNorm在网络中的作用：BN层添加在激活函数前，对输入激活函数的输入进行归一化，这样解决了输入数据发生偏移和增大的影响。<br>BatchNorm的优点：1）极大提升了训练速度，使得收敛过程大大加快；2）还能增加分类效果，一种解释是这类似于Dropout的一种防止过拟合的正则化表达方式，所以不用Dropout也能达到相当的效果；3）调参过程也简单了，对于初始化要求没那么高，可以使用大的学习率。</p>
<h2 id="LRN-局部归一化响应"><a href="#LRN-局部归一化响应" class="headerlink" title="LRN 局部归一化响应"></a>LRN 局部归一化响应</h2><p>为什么要有LRN 局部归一化响应？<br>在神经生物学有一概念叫 “侧抑制”，指的是被激活的神经元会抑制相邻的神经元。局部响应归一化借鉴了“侧抑制”的思想来实现局部抑制，对局部神经元的活动创建竞争机制，使得相应比较大的值相对大，小的更小。<br>优点：可提高模型泛化能力，当使用Relu时这种“侧抑制”的方法很管用。</p>
<h2 id="深度学习几种归一化（BN、LN、IN、GN）"><a href="#深度学习几种归一化（BN、LN、IN、GN）" class="headerlink" title="深度学习几种归一化（BN、LN、IN、GN）"></a>深度学习几种归一化（BN、LN、IN、GN）</h2><p> BN、LN、IN和GN这四个归一化的计算流程几乎是一样的，可以分为四步：1）计算出均值；2）计算出方差；3）归一化处理到均值为0，方差为1；4）变化重构，恢复出这一层网络所要学到的分布。<br> 我们先用一个示意图来形象的表现BN、LN、IN和GN的区别，在输入图片的维度为（NCHW）中，HW是被合成一个维度，这个是方便画出示意图，C和N各占一个维度。<br> <img src="/images/归一化区别.png" alt="BN,LN,IN,GN的区别"><br> Batch Normalization：<br>1)BN的计算就是把每个通道的NHW单独拿出来归一化处理<br>2)针对每个channel我们都有一组γ,β，所以可学习的参数为2*C<br>3)当batch size越小，BN的表现效果也越不好，因为计算过程中所得到的均值和方差不能代表全局。<br>Layer Normalizaiton：<br>1)LN的计算就是把每个CHW单独拿出来归一化处理，不受batchsize 的影响<br>2)常用在RNN网络，但如果输入的特征区别很大，那么就不建议使用它做归一化处理<br>Instance Normalization:<br>1)IN的计算就是把每个HW单独拿出来归一化处理，不受通道和batchsize 的影响<br>2)常用在风格化迁移，但如果特征图可以用到通道之间的相关性，那么就不建议使用它做归一化处理<br>Group Normalization:<br>1)GN的计算就是把先把通道C分成G组，然后把每个gHW单独拿出来归一化处理，最后把G组归一化之后的数据合并成CHW<br>2)GN介于LN和IN之间，当然可以说LN和IN就是GN的特列，比如G的大小为1或者为C</p>
<h2 id="反向传播原理"><a href="#反向传播原理" class="headerlink" title="反向传播原理"></a>反向传播原理</h2><p><a href="https://blog.csdn.net/u014313009/article/details/51039334?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">推导过程</a></p>
<h1 id="卷积神经网络模型"><a href="#卷积神经网络模型" class="headerlink" title="卷积神经网络模型"></a>卷积神经网络模型</h1><h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>输入图像的维数通常很高，例如，1000x1000大小的彩色图像对应于三百万维特征。因此，继续沿用多层感知机中全连接层会导致庞大的参数量。大参数量需要繁重的计算，而更重要的是大参数量会有更高的过拟合风险。卷积是局部连接、共享参数的全连接层。这两个特征使参数量大大降低。卷积层中的权值通常被称为滤波器(filter)或卷积核(convolution kernel)。<br><strong>局部连接</strong>：所谓局部连接，就是卷积层的节点仅仅和前一层的部分节点相连接，只用来学习局部特征，而全连接层中，每个输出通过权值(weight)和所有输入相连。在计算机视觉中，图像中的某一块区域中，像素之间的相关性与像素之间的距离同样相关，距离较近的像素之间相关性强，距离较远则相关性比较弱，所以局部相关性理论同样适用于计算机视觉的图像处理领域。在卷积层中，每个输出神经元在通道方向保持全连接，在空间方向上只和上一层一部分输入神经元相连。局部感知采用部分神经元接收图像信息，再通过综合全部的图像信息达到增强图像信息的目的。这种局部连接的方式大大减少了参数数量，加快了学习速率，同时也在一定程度上减少过拟合的可能。<br><strong>共享参数</strong>：如果一组权值可以在图像中某个区域提取出有效的表示，那么它们也能在图像中的另外区域提取出有效的表示。也就是说，如果一个模式(pattern)出现在图像中的某个区域，那么它们也可以出现在图像中的其他任何区域。因此，卷积层不同空间位置的神经元共享权值，用于发现图像中不同空间位置的模式。权值共享其实就是整张图片在使用同一个卷积核内的参数提取特征，但是不同的卷积核提取的是不同特征，因此不同卷积核间的神经元权值是不共享的。卷积层在空间方向共享参数，而循环神经网络在时间方向共享参数。<br><strong>描述卷积的四个量</strong>：一个卷积层的配置由如下四个量确定。1）卷积核个数。使用一个卷积核进行卷积可以得到一个二维的特征图(feature map)。使用多个卷积核进行卷积，可以得到不同特征的feature map。2）感受野（receptive field）F，即卷积核的大小。3）零填充(zero-padding)P，随着卷积的进行，图像的大小将缩小，图像边缘的信息将逐渐丢失，因此在卷积前，我们在图像上下左右填补一些0，使得我们可以控制输出特征图的大小。4）步长(stride)S，卷积核在输入图像上每移动S个位置计算一个输出神经元。<br>假设输入图片大小为$I\times I$，卷积核大小为$K\times K$，步长为S，填充的像素为P，则卷积层输出的特征图大小为：</p>
<script type="math/tex; mode=display">O=(I-K+2P)/S+1</script><h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>池化层根据特征图上的局部统计信息进行下采样，在保留有用信息的同时减少特征图的大小。和卷积层不同，池化层不包含需要学习的参数，最大池化层(max-pooling)在一个局部区域选最大值输出，而平均池化(average pooling)计算一个区域的均值作为输出。<br><img src="/images/pooling.png" alt="池化层"><br><strong>池化层的作用</strong>：1）增加特征平移不变性，池化可以提高网络对微小位移的容忍能力。2）减小特征图大小，池化层对空间局部区域进行下采样，使下一层需要的参数量和计算量减少，并降低过拟合风险。3）最大池化可以带来非线性，这是目前最大池化更常使用的原因。</p>
<h3 id="召回率、精确率、准确率"><a href="#召回率、精确率、准确率" class="headerlink" title="召回率、精确率、准确率"></a>召回率、精确率、准确率</h3><p>精确率是针对预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能，一种是把正类预测为正类（TP），另一种就是把负类预测为正类（FP），也就是：</p>
<script type="math/tex; mode=display">P=\frac{TP}{TP+FP}</script><p>而召回率是针对原来的样本而言，它表示的是样本中的正例有多少被预测正确，也有两种可能，一种是把原来的正类预测成正类（TP），另一种就是把原来的正类预测为负类（FN）。</p>
<script type="math/tex; mode=display">R=\frac{TP}{TP+FN}</script><p>准确率就是所有样本中预测出正例的概率。</p>
<script type="math/tex; mode=display">A=\frac{TP+TN}{TP+FN+FP+TN}</script><h2 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h2><p>给定一张图像，图像分类任务旨在判断该图像所属类别。</p>
<h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><p>LeCun等将BP算法应用到多层神经网络中，提出了LeNet5模型，并将其用于手写数字识别，卷积神经网络才算正式提出。<br><img src="/images/LeNet5.png" alt="LeNet5网络模型"><br><img src="/images/LeNet5参数.png" alt="LeNet5网络模型参数"><br>网络输入32*32的手写字体图片，这些手写字体包含0~9数字，也就是相当于10个类别的图片；输出：分类结果在0~9之间。LeNet的网络结构十分简单且单一，卷积层C1、C3和C5除了输出维数外采用的是相同的参数，池化层S2和S4采用的也是相同的参数。</p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>2012年Krizhevsky使用卷积神经网络在ILSRC 2012图像分类大赛上夺冠，提出了AlexNet模型。AlexNet网络的提出对于卷积神经网络具有里程碑式的意义，相较于LeNet5的改进有以下几点：<br>1）数据增强：水平翻转、随机裁剪（平移变换）、颜色光照变换<br>2）Dropout:Dropout方法和数据增强一样，都是防止过拟合。dropout能按照一定的概率将神经元从网络中丢弃，dropout能在一定程度上防止过拟合，并且加快网络的训练速度。<br>3）ReLU激活函数：ReLU具有一些优良的特性，在为网络引入非线性的同时，也能引入稀疏性。稀疏性可以选择性激活和分布式激活神经元，能学习到相对稀疏的特征，起到自动化解离的效果。此外，ReLU的导数曲线在输入大于0时，函数的导数为1，这种特性能保证在其输入大于0时梯度不衰减，从而避免或抑制网络训练时梯度消失现象，网络模型的收敛速度会相对稳定。4）Local Response Normalization:局部响应归一化，简称LRN，实际就是利用临近的数据做归一化。5）Overlapping Pooling：即Pooling的步长比Pooling Kernel对应边要小。6）多GPU并行：极大加快网络训练。<br><img src="/images/AlexNet.png" alt="AlexNet网络模型"><br><img src="/images/AlexNet.png" alt="AlexNet网络模型参数"></p>
<h3 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h3><p>VGGNet是由牛津大学计算机视觉组合Google DeepMind项目的研究员共同研发的卷积神经网络模型，包含VGG16和VGG19两种模型。<br><img src="/images/VGG16.png" alt="VGG16网络模型"><br>从网络模型中可以看出，VGG16相比于AlexNet类的模型具有较深的深度，通过反复堆叠$3\times 3$的卷积层和$2\times 2$的池化层，VGG16构建了较深层次的网络结构。与AlexNet主要有以下不同：<br>1）Vgg16有16层网络，AlexNet只有8层；<br>2）在训练和测试时使用了多尺度做数据增强。</p>
<h3 id="GoogleNet-22层"><a href="#GoogleNet-22层" class="headerlink" title="GoogleNet(22层)"></a>GoogleNet(22层)</h3><p>GoogleNet进一步增加了网络模型的深度，但是单纯的在VGG16的基础上增加网络的宽度会带来以下的缺陷：1）过多的参数容易引起过拟合；2）层数的过深，容易引起梯度消息现象。<br>GoogleNet的提出受到论文Network in Network(NIN)的启发，NIN有两个贡献：1）提出多层感知卷积层，使用卷积层后加上多层感知机，增强网络提取特征的能力。普通的卷积层和多层感知卷积层结构如图所示，Mlpconv相当于在一般卷积层后加一个1*1的卷积层。2）提出了全局平均池化代替全连接层，全连接层具有大量的参数，使用全局平均池化代替全连接层，能很大程度减少参数空间，便于加深网络，还能防止过拟合。<br><img src="/images/多层感知卷积层.png" alt="普通卷积层和多层感知卷积层结构图"><br>GoogleNet根据Mlpconv的思想提出了Inception结构，该结构有两个版本，下图是Inception的naive版，该结构巧妙的将$1\times 1$、$3\times 3$和$5\times 5$三种卷积核和最大池化层结合起来作为一层结构。<br><img src="/images/Inception1.png" alt="Inception结构的native版"><br>而Inception的native版中$5\times 5$的卷积核会带来很大的计算量，因此采用了与NIN类似的结构，在原始的卷积层之后加上$1\times 1$卷积层，最终版本的Inception如下图所示：<br><img src="/images/Inception.png" alt="降维后的Inception模块"></p>
<h3 id="Inception-v3-v4"><a href="#Inception-v3-v4" class="headerlink" title="Inception v3/v4"></a>Inception v3/v4</h3><p>在GoogleNet的基础上进一步降低参数，其和GoogleNet有相似的Inception模块，但将$7\times 7$和$5\times 5$卷积分解为若干等效$3\times 3$卷积，并在网络中后部分把$3\times 3$卷积分解为$1\times 3$和$3\times 1$卷积，这使得在相似的网络参数下网络可以部署到42层。此外，Inception v3使用了批量归一化层。Inception v3是GoogleNet计算量的2.5倍，而错误率较后者下降了3%。Inception v4在Inception模块基础上结合residual模块，进一步降低了0.4%的错误率。<br><img src="/images/Inceptionv3.png" alt="Inceptionv3模块"></p>
<h3 id="Inception-v1-v2-v3-v4"><a href="#Inception-v1-v2-v3-v4" class="headerlink" title="Inception v1/v2/v3/v4"></a>Inception v1/v2/v3/v4</h3><p><a href="https://blog.csdn.net/langb2014/article/details/52787095?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">Inception v1/v2/v3/v4对比</a></p>
<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p>卷积神经网络模型的发展历程一次次证明加深网络的深度和宽度能得到更好的效果，但是后来的研究发现，网络层次较深的网络模型的效果反而不如较浅层的网络，称为“退化”现象。退化现象产生的原因在于当模型的结构变得复杂随机梯度下降的优化变得更加困难，导致网络模型的效果反而不如浅层网络。针对这个问题，MSRA何凯明团队提出Residual Network，该网络具有Residual结构如下所示：<br><img src="/images/Residual.png" alt="Residual结构"><br>ResNet的基本思想是引入了能够跳过一层或多层的“shortcut connection”，即增加一个identity mapping（恒等映射），将原始所需要学的函数H(x)转换为F(x)+x，作者认为这两种表达的效果相同，但是优化的难度却并不相同。这个Residual block通过将shortcut connection实现，通过shortcut将这个block的输入和输出进行一个element-wise的叠加，这个简单地加法并不会给网络增加额外的参数和计算量，同时却可以大大增加模型的训练速度，提高训练效果，并且当模型的层数加深时，这个简单的结构能够很好的解决退化问题。对于shortcut的方式，作者提出了三个策略：1）使用恒等映射，如果residual block的输入和输出维度不一致，对增加的维度用0来填充；2）在block输入输出维度一致时使用恒等映射，不一致时使用线性投影以保证维度一致；3）对于所有的block使用线性投影。论文最后用三个$1\times 1,3\times 3, 1\times 1$的卷积层代替前面说的两个$3\times 3$卷积层，第一个$1\times 1$用来降低维度，第三个$1\times 1$用来增加维度，这样可以保证中间的$3\times 3$卷积层拥有比较小的输入输出维度。<br><img src="/images/bottleneck.png" alt="更深的residual block"></p>
<h3 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h3><p><a href="https://blog.csdn.net/xiaohu2022/article/details/85560788" target="_blank" rel="noopener">DenseNet网络介绍</a><br>DenseNet脱离了加深网络层数(ResNet)和旁路网络结构(Inception)来提升网络性能的定式思维，从特征的家督考虑，通过特征重用和旁路（Bypass）设置，既大幅度减少了网络的参数量，又在一定程度上缓解了gradient vanishing问题的产生。DenseNet作为另一种较深层数的卷积神经网络，具有如下优点：<br>1）相比于ResNet拥有更少的参数数量；2）旁路加强了特征的重用；3）网络更容易训练，并具有一定的正则效果；4）缓解了gradient vanishing和model degradation的问题。<br><img src="/images/DenseNet.jpg" alt="DenseNet网络结构图"><br>如图所示，第i层的输入不仅与i-1层的输出相关，还与所有之前层的输出相关。记作：<br>$X_l=H_l([X_0,X_1,…,X_{l-1}])$<br>其中[]代表concatenation（拼接），既将$X_0$到$X_{l-1}$层的所有输出feature map按Channel组合在一起，这里所用到的非线性变换H为BN+ReLU+Conv(3x3)的组合。<br>由于在DenseNet中需要对不同层的feature map进行cat操作，所以需要不同层的feature map保持相同的feature size，这就限制了网络中的down sampling的实现。为了使用down sampling在实验中transition layer由BN+Conv(1x1)+average-pooling(2x2)组成。<br><img src="/images/Denseblock.jpg" alt="Denseblock网络图"></p>
<h3 id="SENet"><a href="#SENet" class="headerlink" title="SENet"></a>SENet</h3><p>Squeeze-and-Excitation Networks（SENet）是由自动驾驶公司Momenta在2017年公布的一种全新的图像识别结构，它通过对特征通道间的相关性进行建模，把重要的特征进行强化来提升准确率。<br><img src="/images/SEblock.jpg" alt="SE Bolck结构"><br>上图是SENet的Block单元，图中的$F_{tr}$是传统的卷积结构，X和U是$F_{tr}$的输入（C’xH’xW’）和输出（CxHxW），这些都是以往结构中已存在的。SENet增加的部分是U后的结构：对U先做一个Global Average Pooling（图中的$F_{sq(.)}$，作者称为Squeeze过程），输出的1x1xC数据再经过两级全连接（图中的$F_{ex(.)}$，作者称为Excitation过程），最后用sigmoid限制到[0，1]的范围，把这个值作为scale乘到U的C个通道上， 作为下一级的输入数据。这种结构的原理是想通过控制scale的大小，把重要的特征增强，不重要的特征减弱，从而让提取的特征指向性更强。<br>先是Squeeze部分。GAP有很多算法，作者用了最简单的求平均的方法，将空间上所有点的信息都平均成了一个值。这么做是因为最终的scale是对整个通道作用的，这就得基于通道的整体信息来计算scale。另外作者要利用的是通道间的相关性，而不是空间分布中的相关性，用GAP屏蔽掉空间上的分布信息能让scale的计算更加准确。</p>
<script type="math/tex; mode=display">z_c=F_{sq}(u_c)=\frac{1}{W\times H}\sum_{i=1}^W\sum_{j=1}^Hu_c(i,j)</script><p>Excitation部分是用2个全连接来实现 ，第一个全连接把C个通道压缩成了C/r个通道来降低计算量（后面跟了RELU），第二个全连接再恢复回C个通道（后面跟了Sigmoid），r是指压缩的比例。作者尝试了r在各种取值下的性能 ，最后得出结论r=16时整体性能和计算量最平衡。<br>为什么要加全连接层呢？这是为了利用通道间的相关性来训练出真正的scale。一次mini-batch个样本的squeeze输出并不代表通道真实要调整的scale值，真实的scale要基于全部数据集来训练得出，而不是基于单个batch，所以后面要加个全连接层来进行训练。<br>可以拿SE Block和下面3种错误的结构比较来进一步理解：<br>下图最上方的结构，squeeze的输出直接scale到输入上，没有了全连接层，某个通道的调整值完全基于单个通道GAP的结果，事实上只有GAP的分支是完全没有反向计算、没有训练的过程的，就无法基于全部数据集来训练得出通道增强、减弱的规律。<br>下图中间是经典的卷积结构，有人会说卷积训练出的权值就含有了scale的成分在里面，也利用了通道间的相关性，为啥还要多个SE Block？那是因为这种卷积有空间的成分在里面，为了排除空间上的干扰就得先用GAP压缩成一个点后再作卷积，压缩后因为没有了Height、Width的成分，这种卷积就是全连接了。<br>下图最下面的结构，SE模块和传统的卷积间采用并联而不是串联的方式，这时SE利用的是$F_{tr}$输入X的相关性来计算scale，X和U的相关性是不同的，把根据X的相关性计算出的scale应用到U上明显不合适。<br><img src="/images/SEnet2.jpg" alt="三种错误的SE结构"><br>下图是两个SENet实际应用的例子，左侧是SE-Inception的结构，即Inception模块和SENet组和在一起；右侧是SE-ResNet，ResNet和SENet的组合，这种结构scale放到了直连相加之前。<br><img src="/images/SENet3.jpg" alt="SE-Inception和SE-ResNet结构"></p>
<h2 id="图像检测"><a href="#图像检测" class="headerlink" title="图像检测"></a>图像检测</h2><p>分类任务关系整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。相比于分类，检测给出的是对图片前景和背景的理解，我们需要从背景中分离出感兴趣的目标，并确定这一目标的描述（类别和位置）。因此，检测模型的输出是一个列表，列表的每一项使用一个数据组给出检测目标的类别和位置（常用矩形检测框的坐标表示）。<br>目前主流的目标检测算法主要是基于深度模型，大致可以分成两大类别：（1）One-Stage目标检测算法，这类检测算法不需要Region Proposal阶段，可以通过一个Stage直接产生物体的类别概率和位置坐标值，比较典型的算法有YOLO、SSD和CornerNet；（2）Two-Stage目标检测算法，这类检测算法将检测问题划分为两个阶段，第一个阶段首先产生候选区域（Region Proposals），包含目标大概的位置信息，然后第二个阶段对候选区域进行分类和位置精修，这类算法的典型代表有R-CNN、Fast R-CNN、Faster R-CNN等。目标检测模型的主要性能是检测准确度和速度，其中准确度主要考虑物体的定位及分类准确度。一般情况下，Two-Stage算法在准确度上有优势，而One-Stage算法在速度上有优势。不过随着研究的发展，两类算法都在两个方面做改进，均能在准确度及速度上取得较好结果。</p>
<h3 id="IOU的定义"><a href="#IOU的定义" class="headerlink" title="IOU的定义"></a>IOU的定义</h3><p><a href="https://blog.csdn.net/sinat_34474705/article/details/80045294?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">手写IOU</a><br>物体检测需要定位出物体的bounding box，对于bounding box的定位精度，存在一个定位精度评价公式：IOU。<br>IOU定义了两个bounding box的重叠度，如下图所示：<br><img src="/images/IOU.png" alt="IOU图像"><br>矩形框A、B的一个重合度计算公式为：</p>
<script type="math/tex; mode=display">IOU=\frac{A\cap B}{A\cup B}</script><p>就是矩形框A、B的重叠面积$S_I$占A、B并集的面积的比例：</p>
<script type="math/tex; mode=display">IOU=\frac{S_I}{S_A+S_B-S_I}</script><h3 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h3><p>在目标检测时一般会采取窗口滑动的方式，在图像上生成很多的候选框，把这些候选框进行特征提取送入到分类器，一般会得到一个得分，然后把这些得分全部排序。选取得分最高的那个框，接下来计算其他框与当前框的重合程度(IOU)，如果重合程度大于一定的阈值就删除，这样不停的迭代下去就会得到所有想要找到的目标物体的区域。</p>
<h3 id="Soft-NMS"><a href="#Soft-NMS" class="headerlink" title="Soft-NMS"></a>Soft-NMS</h3><p><a href="https://blog.csdn.net/lcczzu/article/details/86518615" target="_blank" rel="noopener">非极大值抑制算法改进</a></p>
<h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h3><p>算法摘要：首先输入一张图片，我们先定位出2000个物体候选框，然后采用CNN提取每个候选框中图片的特征向量，特征向量的维度是4096维，接着采用SVM算法对各个候选框中的物体进行分类识别。<br><img src="/images/RCNN.png" alt="R-CNN算法流程"><br>我们采用selective search算法搜索出候选框，由于搜索到的候选框是矩形的，而且大小各不相同，而CNN对输入的图片大小是固定的，因此需要对每个输入的候选框都要缩放到固定的大小。然而人工标注的图片中就只标注了一个正确的bounding box，我们搜索出来的2000个矩形框也不可能会出现一个与人工标注完全匹配的候选框。因此我们需要用IOU为2000个bounding box打标签，以便下一步CNN训练使用。在CNN阶段，如果用selective search挑选出来的候选框与物体的人工标注矩形框的重叠区域大于0.5，我们就把这个候选框标注成物体类别，否则我们就把它当做背景类别。最后，我们需要对上面预训练的CNN模型进行fine-tuning训练。假设需要检测的物体类别有N类，那么我们就需要将上面与训练的CNN模型的最后一层给替换点，替换成N+1个输出的神经元（还有一个背景），然后这一层直接采用参数随机初始化的方法，其他的网络层数不变。<br>R-CNN缺点：<br>1）耗时的selective search，对一帧图像，需要花费2s。<br>2）耗时的串行式CNN前向传播，对于每一个ROI，都需要经过一个AlexNet提取特征，为所有的ROI提供特征需要花费47s。<br>3）三个模块分别训练，并且在训练的时候，对于存储空间的消耗很大。<br><img src="/images/rcnn2.png" alt="RCNN算法流程框图"></p>
<h3 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP-Net"></a>SPP-Net</h3><p><img src="/images/sppnet.png" alt="SPPNet网络流程框图"><br>算法特点：1）通过Spatial Pyramid Pooling解决了深度网络固定输入层尺寸的这个限制，使得网络可以享受不限制输入尺寸带来的好处。2）解决了RCNN速度慢的问题，不需要对每个Proposal(2000个左右)进行wrap或crop输入CNN提取feature map，只需要对整图提一次feature map，然后将proposal区域映射到卷积特征层得到全连接层的输入特征。<br><img src="/images/rcnn_vs_spp.png" alt="RCNN与SPPNet对比"><br>一、ROI在特征图上的对应的特征区域的维度不满足全连接层的输入要求怎么办？<br>事实上，CNN的卷积层不需要固定尺寸的图像，而是全连接层是需要固定大小的输入。根据Pooling规则，每个Pooling bin对应一个输出，所以最终的Pooling后的输出特征由bin的个数来决定。SPP网络就是分级固定bin的个数，调整bin的尺寸来实现多级Pooling固定输出。如图所示，SPP网络中最后一个卷积层的feature map维数为16x24，按照图中所示分为3级：<br><img src="/images/SPP.png" alt="SPP网络结构"><br>其中，第一级bin个数为1，最终对应的window大小为16x24；第二级bin个数为4个，最终对应的window大小为4x8；第三级bin个数为16个，最终对应的window大小为1x1.5(小数需要舍入处理)。通过融合各级bin的输出，最终每一个feature map经过SPP处理后，得到1+4+16维的feature map，经过融合后输入分类器。这样就可以在任意输入size和scale下获得固定的输出；不同的scale下网络可以提取不同尺度的特征，有利于分类。<br>二、原始图像的ROI如何映射到特征图？<br>下面将从感受野、感受野上坐标映射及原始图像的ROI如何映射三方面阐述。<br>1）感受野<br>在卷积神经网络中，感受野的定义是卷积神经网络每一层输出的特征图(feature map)的像素点在原始图像上映射的区域大小。</p>
<script type="math/tex; mode=display">output\ field\ size = (input\ field\ size - kernel size + 2*padding) / stride + 1</script><p>其中output field size是卷积层的输出，input field size是卷积层的输入，反过来卷积层的输入为:</p>
<script type="math/tex; mode=display">input\ field\ size = (output\ field\ size - 1) * stride - 2*padding + kernel size</script><p>2）感受野上的坐标映射<br>对于Convolution/Pooling Layer:</p>
<script type="math/tex; mode=display">p_i=s_i \cdot p_{i+1}+[(k_i-1)/2-padding]</script><p>对于Neuronlayer（ReLU/Sigmoid/…）:</p>
<script type="math/tex; mode=display">p_i=p_{i+1}</script><p>其中$p_i$为第$i$层感受野上的坐标，$s_i$为Stride的大小，$k_i$为感受野的大小。<br>何凯明在SPP-NET中使用的是简化版本，将公式中的Padding都设为$\left \lfloor k_i/2 \right \rfloor$，公式可进一步简化为：<script type="math/tex">p_i=s_i \cdot p_{i+1}</script><br>3）原始图像的ROI如何映射<br>SPP-NET是把原始ROI的左上角和右下角 映射到Feature Map上的两个对应点。 有了Feature Map上的两队角点就确定了对应的Feature Map 区域（下图中橙色）。<br><img src="/images/ROImap.png" alt="ROI映射过程"><br>左上角取$x’=\left \lfloor x/S \right \rfloor+1, y’=\left \lfloor y/S \right \rfloor+1$；右下角的点取$x’=\left \lceil x/S \right \rceil-1, y’=\left \lceil y/S \right \rceil-1$。其中S为坐标映射的简化计算版本，即$S=\prod_{0}^{i}s_i$。<br><a href="https://zhuanlan.zhihu.com/p/73654026" target="_blank" rel="noopener">ROI原理</a></p>
<h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><p>Fast R-CNN针对R-CNN在训练时multi-state pipeline和训练的过程很耗时间和空间的问题进行了改进，主要改进为：<br>1）在最后一个卷积层加了一个ROI pooling layer。ROI Pooling layer首先可以将image中的ROI定位到feature map，然后用一个单层的SPP layer将这个feature map池化到固定大小的feature map后再传入全连接层。<br>2）损失函数使用多任务损失函数（multi-task loss），将边框回归直接加入到CNN网络进行训练。<br><img src="/images/frcnn.png" alt="Fast R-CNN流程框图"><br>首先还是采用selective search提取2000个候选框，然后对全图进行特征提取，接着使用一个ROI pooling layer在全体特征上获取每一个ROI对应的特征，再通过全连接层进行分类和检测框修正。即最后得到的ROI feature vector被分开，一个经过全连接层后用作softmax回归，用来分类，另一个经过全连接后用作bbox回归。需要注意的是，输入到后面ROI Pooling layer的feature map是在卷积层上的feature map上提取的，故整个特征提取过程只计算一次卷积。虽然在最开始也提取了大量的ROI，但他们还是作为整体输入到卷积网络的，最开始提取的ROI区域只是为了最后的bounding box回归时使用。<br><strong>联合训练</strong>：联合训练（Joint Training）指如何将分类和边框回归联合到一起在CNN阶段训练，主要难点是损失函数的设计。Fast-RCNN中，有两个输出层：第一个是针对每个ROI区域的分类概率预测，$p=(p_0, p_1, \cdots, p_K)$；第二个则是针对每个ROI区域坐标的偏移优化，$t^k = (t^k_x, t^k_y, t^k_w, t^k_h)$，$0 \le k \le K$是多类检测的类别序号。每个训练ROI都对应着真实类别$u$和边框回归目标$v=(v_x,v_y,v_w,v_h)$，对于类别$u$预测边框为$t^u=(t_x^u,t_y^u,t_w^u,t_h^u)$，使用多任务损失$L$来定义ROI上分类和边框回归的损失：</p>
<script type="math/tex; mode=display">L(p,u,t^u,v)=L_{cls}(p,u)+\lambda [u \ge 1]L_{loc}(t^u,v)</script><p>其中$L_{cls}(p,u)=-\log p_u$表示真实类别的log损失，当$u \ge 1$时，$[u \ge 1]$的值为1，否则为0。下面将重点介绍多任务损失中的边框回归部分（对应坐标偏移优化部分）。<br><strong>边框回归</strong>：假设对于类别$u$，在图片中标注的真实坐标和对应的预测值理论上两者越接近越好，相应的损失函数为：</p>
<script type="math/tex; mode=display">L_{loc}(t^u, v) = \sum_{i \in {x, y, w, h}} \text{smooth}_{L_1}(t_i^u- v_i)</script><script type="math/tex; mode=display">\text{smooth}_{L_1}(x) = \left \{ \begin{aligned} & 0.5x^2 & |x| \le 1 \\ &|x|-0.5 & \text{otherwise}\end{aligned} \right.</script><p>Fast-RCNN在上面用到的鲁棒$L_1$函数对外点比RCNN和SPP-NET中用的$L_2$函数更为鲁棒，该函数在$(-1, 1)$之间为二次函数，其他区域为线性函数。<br>存在问题：使用Selective Search提取Region Proposals，没有实现真正意义上的端到端，操作耗时。<br>采用$\text{smooth}_{L_1}$的原因：边框的预测是一个回归问题，通常可以选择平方损失函数（L2损失）$f(x)=x^2$，但这个损失对于比较大的误差的惩罚很高。可以采用稍微缓和一点绝对损失函数（L1损失）$f(x)=|x|$，这个函数在0点处导数不存在，因此可能会影响收敛。因此采用分段函数，在0点附近使用平方函数使得它更加平滑。</p>
<h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><p><img src="/images/faster rcnn.png" alt="Faster R-CNN流程图"><br>算法特点：1）提出了Region Proposal Network(RPN)，将Proposal阶段和CNN分类融合到一起，实现了一个完全的End-To-End的CNN目标检测模型。RPN可以快速提取高质量的Proposal，不仅加快了目标检测速度，还提高了目标检测性能。2）将Fast R-CNN和RPN放在同一个网络结构中训练，共享网络参数。</p>
<h4 id="Region-Proposal-Network"><a href="#Region-Proposal-Network" class="headerlink" title="Region Proposal Network"></a>Region Proposal Network</h4><p>Region Proposal Network(RPN)的核心思想是使用卷积神经网络直接产生Region Proposal，使用的方法本质上就是滑动窗口。RPN的设计比较巧妙，RPN只需要在最后的卷积层上滑动以便，借助Anchor机制和边框回归就可以得到多尺度多长宽比的Region Proposal。下图是RPN的网络结构图。<br><img src="/images/RPN.png" alt="RPN网络结构图"><br>给定输入图像（假设分辨率为$600*1000$），经过卷积操作得到最后一层卷积特征图（大小约为$40\times 60$）。在这个特征图上使用$3\times 3$的卷积核（滑动窗口）与特征图进行卷积，最后一层卷积层共有256个feature map，那么这个$3\times 3$的区域卷积后可以获得一个256维的特征向量，后边接cls layer和reg layer分别用于分类和边框回归（跟Fast R-CNN类似，只不过这里的类别只有目标和背景两个类别）。$3\times 3$滑窗对应的每个特征区域同时预测输入图像的3种尺度（128，256，512），3中长宽比（1：1，1：2，2：1）的Region Proposal，这种映射的机制称为Anchor。所以对于这个$40\times 60$的feature map，总共有约20000（$40\times 60\times 9$）个Anchor，也就是预测20000个Region Proposal。<br>Anchor是在原图上的区域而不是在特征图上<br><img src="/images/Anchor.png" alt="Anchor示例"><br>这样设计的好处是什么？虽然现在也是在用的滑动窗口策略，但是滑动串口操作是在卷积特征图上进行的，维度较原始图像降低了$16\times 16$倍；多尺度使用了9中Anchor，对应了三种尺度和三种长宽比，加上后边接了边框回归，所以几遍是这9种Anchor外的窗口也能得到一个跟目标比较接近的Region Proposal。<br><a href="https://www.okcode.net/article/65311" target="_blank" rel="noopener">anchor讲解</a></p>
<h4 id="RPN的损失函数"><a href="#RPN的损失函数" class="headerlink" title="RPN的损失函数"></a>RPN的损失函数</h4><p>损失函数的定义为：</p>
<script type="math/tex; mode=display">L({p_i}{t_i}) = \frac{1}{N_{cls}} \sum_i L_{cls}(p_i, p_i^*) +\lambda \frac{1}{N_{reg}} \sum_i p_i^* L_{reg}(t_i, t_i^*)</script><p>其中$i$表示一次Mini-Batch中Anchor的索引，$p_i$是Anchor $i$是否是一个物体，$L_{reg}$即为上面提到的$\text{smooth}_{L_1}(x)$函数，$N_{cls}$和$N_{reg}$是两个归一化项，分别表示Mini-Batch的大小和Anchor位置的数目。</p>
<h4 id="网络的训练"><a href="#网络的训练" class="headerlink" title="网络的训练"></a>网络的训练</h4><p>作者采用了4-step Alternating Training:<br>1) 用ImageNet模型初始化，独立训练一个RPN网络；<br>2) 仍然用ImageNet模型初始化，但是使用上一步RPN网络产生的Proposal作为输入，训练一个Fast-RCNN网络，至此，两个网络每一层的参数完全不共享；<br>3) 使用第二步的Fast-RCNN网络参数初始化一个新的RPN网络，但是把RPN、Fast-RCNN共享的那些卷积层的Learning Rate设置为0，也就是不更新，仅仅更新RPN特有的那些网络层，重新训练，此时，两个网络已经共享了所有公共的卷积层；<br>4) 仍然固定共享的那些网络层，把Fast-RCNN特有的网络层也加入进来，形成一个Unified Network，继续训练，Fine Tune Fast-RCNN特有的网络层，此时，该网络已经实现我们设想的目标，即网络内部预测Proposal并实现检测的功能。<br>在训练分类器和RoI边框修正时，步骤如下：<br>1）首先通过RPN生成约20000个anchor（40x60x9）<br>2）对20000个anchor进行第一次边框修正，得到修订边框后的proposal；<br>3）对超过图像边界的proposal的边进行clip，使得该proposal不超过图像范围；<br>4）忽略掉长或宽太小的proposal；<br>5）将所有的proposal按照前景分数从高到低排序，选取前12000个proposal；<br>6）使用阈值为0.7的NMS算法排除掉重叠的proposal；<br>7）针对上一步剩下的proposal，选取前2000个proposal进行分类和第二次边框修正。<br><img src="/images/fasterrcnn.png" alt="faster rcnn训练过程"></p>
<h3 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h3><p>ROI Align是在Mask R-CNN这篇论文里提出的一种区域特征聚集方式，很好地解决了ROI Pooling操作中两次量化造成的区域不匹配的问题。在检测阶段将ROI Pooling替换为ROI Align可以提升检测模型的准确性。<br>在常见的两级检测框架中，ROI Pooling的作用是根据候选框的位置坐标在特征图中将相应的区域池化为固定尺寸的特征图，以便后续的分类和bounding box回归操作。由于预选框的位置通常是由模型回归得到的，一般来讲都是浮点数，而池化后的特征图要求尺寸固定，故ROI Pooling这一操作存在两次量化的过程。1）将候选框的边界量化为整数点坐标值。2）将量化后的边界区域平均分割成$k\times k$个单元（bin），对每一个单元的边界进行量化。经过上述的两次量化，此时的候选框已经和最开始回归出来的位置存在一定的偏差，这个偏差会影响检测或分割的精确度。在论文里作者将它归结为“不匹配问题(misalignment)”。<br>下面我们用直观的例子具体分析一下上述区域不匹配问题。如图所示，这是一个Faster-RCNN检测框架。输入一张$800\times 800$的图片，图片上有一个$665\times 665$的包围框(框着一只狗)。图片经过主干网络提取特征后，特征图缩放步长（stride）为32。因此，图像和包围框的边长都是输入时的1/32。800正好可以被32整除变为25。但665除以32以后得到20.78，带有小数，于是ROI Pooling 直接将它量化成20。接下来需要把框内的特征池化$7\times 7$的大小，因此将上述包围框平均分割成$7\times 7$个矩形区域。显然，每个矩形区域的边长为2.86，又含有小数。于是ROI Pooling 再次把它量化到2。经过这两次量化，候选区域已经出现了较明显的偏差（如图中绿色部分所示）。更重要的是，该层特征图上0.1个像素的偏差，缩放到原图就是3.2个像素。那么0.8的偏差，在原图上就是接近30个像素点的差别，这一差别不容小觑。<br><img src="/images/ROIAlign.png" alt="ROIAlign示例"><br>为了解决ROI Pooling的上述缺点，作者提出了ROI Align这一改进的方法。ROI Align的思路很简单：取消量化操作，使用双线性内插的方法获得坐标为浮点数的像素点上的图像数值，从而将整个特征聚集过程转化为一个连续的操作。ROI Align流程如下：<br>1）遍历每一个候选区域，保持浮点数边界不做量化；2）将候选区域分割成$k\times k$个单元，每个单元的边界也不做量化；3）在每个单元中计算出固定的四个坐标位置，用双线性内插的方法计算出这四个位置的值，然后进行最大池化的操作。<br>需要注意的是，这个固定位置是指在每一个矩形单元（bin）中按照固定规则确定的位置。比如，如果采样点数是1，那么就是这个单元的中心点。如果采样点数是4，那么就是把这个单元平均分割成四个小方块以后它们分别的中心点。显然这些采样点的坐标通常是浮点数，所以需要使用插值的方法得到它的像素值。事实上，ROI Align 在遍历取样点的数量上没有ROIPooling那么多，但却可以获得更好的性能，这主要归功于解决了misalignment的问题。<br><img src="/images/ROIAlign2.png" alt="ROIAlign示例2"><br><img src="/images/maskrcnn.jpg" alt="Mask R-CNN结构图"><br>注意的是，在Mask R-CNN中的ROI Align之后有一个“head”部分，主要作用是将ROI Align的输出维度扩大，这样在预测Mask时会更加精确。<br>在Mask Branch的训练环节，作者没有采用FCN式的SoftmaxLoss，反而是输出了K个Mask预测图（为每一个类都输出一张），并采用average binary cross-entropy loss训练，当然在训练Mask branch的时候，输出K个特征图中，也就是对应ground truth类别的哪一个特征图对Mask loss有贡献。也就是说， Mask RCNN定义为多任务损失为$L=L_{class}+L_{boxes}+L_{mask}$。<br>$L_{class}$与$L_{boxes}$与Faster RCNN没区别。$L_{mask}$中，假设一共有K个类别，则mask分割分支的输出维度是$K\times m\times m$，对于$m\times m$中的每个点，都会输出K个二值Mask(每个类别使用sigmoid输出)。需要注意的是，计算loss的时候，并不是每个类别的sigmoid输出都计算二值交叉熵损失，而是该像素属于哪个类，哪个类的sigmoid输出才要计算损失函数，并且在测试的时候，我们通过分类分支预测类别来选择相应的mask预测。这样，mask预测和分类分支预测就彻底解耦了。</p>
<h3 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a>FPN</h3><p><a href="https://www.aiuai.cn/aifarm887.html" target="_blank" rel="noopener">特征金字塔网络FPN</a><br>在物体检测里面，在有限的计算量的情况下，网络的深度（对应到感受野）与 stride 通常是一对矛盾的东西，常用的网络结构对应的 stride 一般会比较大（如 32），而图像中的小物体甚至会小于 stride 的大小，造成的结果就是小物体的检测性能急剧下降。传统解决这个问题的思路包括：<br>（1）多尺度训练和测试，有称图像金字塔，如图（a）所示。目前几乎所有在 ImageNet 和 COCO 检测任务上取得好成绩的方法都使用了图像金字塔方法。然而这样的方法由于很高的时间及计算量消耗，难以在实际中应用。<br>（2）特征分层，即每层分别预测对应的scale分辨率的检测结果，如图（c）所示。SSD检测框架采用了相似的思想，这样的方法的问题在于直接强行让不同层学习同样的语义信息，而对于卷积神经网络而言，不同的深度对应着不同层次的语义特征，浅层网络的分辨率高，学的更多是细节特征，深层网络分辨率低，学的更多是语义特征。<br><img src="/images/FPN.jpg" alt="FPN网络结构"><br>目前多尺度的物体检测主要面临的挑战是：<br>1）如何学习具有强语义信息的多尺度特征表示？<br>2）如何设计通用的特征表示来解决物体检测中的多个子问题？如object proposal,box localization,instance segmentation.<br>3）如何高效计算多尺度的特征表示？<br>本文针对这些问题，提出了特征金字塔FPN，如图（d）所示，网络直接在原来的按网络上做修改，每个分辨率的feature map引入后，将分辨率缩放两倍的feature map做element-wise相加的操作。通过这样的连接，每一层预测所用的feature map都融合了不同分辨率、不同语义强度的特征，融合的不同分辨率的feature map分别做对应分辨率的物体检测。这样保证了每一层都有合适的分辨率以及强语义特征。同事，由于此方法只是在原网络的基础上家里额外的跨层连接，在实际应用中几乎不增加额外的时间和计算量。<br>自下而上的路径<br>CNN的前馈计算就是自下而上的路径，特征图经过卷积核计算，通常是越变越小，也有一些特征层的输出和原来的大小一样，称为“相同网络阶段”。对于本文的特征金字塔，作者为每个阶段定义一个金字塔级别，然后选择每个阶段的最后一层的输出作为特征图的参考集，这是因为每个阶段的最深层应该具有最强的特征。具体来说，对于ResNets，作者使用了每个阶段的最后一个残差结构的特征激活输出。将这些残差模块输出表示为{C2, C3, C4, C5}，对应于conv2，conv3，conv4和conv5的输出，并且注意它们相对于输入图像具有{4, 8, 16, 32}像素的步长。考虑到内存占用，没有将conv1包含在金字塔中。<br>自上而下的路径和横向连接<br>自上而下的路径（the top-down pathway ）是如何去结合低层高分辨率的特征呢？方法就是，把更抽象，语义更强的高层特征图进行上采样，然后把该特征横向连接（lateral connections）至前一层的特征，因此高层特征得到加强。值得注意的是，横向连接的两层特征在空间尺寸上要相同，这样做主要是为了利用底层的定位细节信息。<br>如图（d）所示，把高层特征做2倍上采样（最近邻上采样），然后将其和对应的前一层特征结合（前一层要经过$1\times 1$的卷积核才能用，目的是改变channels,使之和后一层的channels相同），结合方式就是element-wise相加的操作。重复迭代该过程，直至生成$1\times 1$最精细的特征图。迭代开始阶段，作者在C5层后面加了一个$1\times 1$的卷积核来产生最粗略的特征图，最后，作者用$3\times 3$的卷积核去处理已经融合的特征图（为了消除上采样的混叠效应），以生成最后需要的特征图。{C2, C3, C4, C5}层对应的融合特征层为{P2, P3, P4, P5}，对应的层空间尺寸是相通的。<br>FPN的优点：<br>1）低层的特征经过卷积，上采样操作之后和高层的信息进行融合在卷积神经网络中，高层的特征具有较强的语义信息，低层的特征具有结构信息，将高层和低层的信息进行结合，是可以增强特征的表达能力。2）将候选框产生和提取特征的位置分散到特征金字塔的每一层，这样可以增加小目标特征映射的分辨率，对最后的预测是有好处的。</p>
<h3 id="Retinanet"><a href="#Retinanet" class="headerlink" title="Retinanet"></a>Retinanet</h3><p>基于深度学习的目标检测算法有两类经典的结构：Two Stage 和 One Stage。<br>Two Stage：例如Faster-RCNN算法。第一级专注于proposal的提取，第二级对提取出的proposal进行分类和精确坐标回归。两级结构准确度较高，但因为第二级需要单独对每个proposal进行分类/回归，速度上就变慢。<br>One Stage：例如SSD，YOLO算法。此类算法摒弃了提取proposal的过程，只用一级就完成了识别/回归，虽然速度较快但准确率远远比不上两级结构。<br>产生精度差异的主要原因：类别失衡（Class Imbalance）。One Stage方法在得到特征图后，会产生密集的目标候选区域，而这些大量的候选区域中只有很少一部分是真正的目标，这样就造成了机器学习中经典的训练样本正负不平衡的问题。它往往会造成最终算出的training loss为占绝大多数但包含信息量却很少的负样本所支配，少样正样本提供的关键信息却不能在一般所用的training loss中发挥正常作用，从而无法得出一个能对模型训练提供正确指导的loss（而Two Stage方法得到proposal后，其候选区域要远远小于One Stage产生的候选区域，因此不会产生严重的类别失衡问题）。常用的解决此问题的方法就是负样本挖掘，或其它更复杂的用于过滤负样本从而使正负样本数维持一定比率的样本取样方法。该论文中提出了Focal Loss来对最终的Loss进行校正。<br>Focal Loss的目的：消除类别不平衡 + 挖掘难分样本<br>Focal Loss非常简单，就是在原有的交叉熵损失函数上增加了一个因子，让损失函数更加关注hard examples，以下是用于二值分类的交叉熵损失函数。其中$y\in{\pm1}$为类别真实标签，$p\in[0,1]$是模型预测的$y=1$的概率。</p>
<script type="math/tex; mode=display">CE(p,y)=
\begin{cases}
-log(p) & if\ y=1 \\
-log(1-p) & otherwise
\end{cases}</script><p>可以进行如下定义：</p>
<script type="math/tex; mode=display">p_t=
\begin{cases}
p & if\ y=1 \\
1-p & otherwise
\end{cases}</script><p>因此交叉熵可以写成如下形式，即如下loss曲线图中蓝色曲线所示，可以认为当模型预测得到的$p_t\ge 0.6$的样本为容易分类的样本，而$p_t$值预测较小的样本为hard examples，最后整个网络的loss就是所有训练样本经过模型预测得到的值的累加，因为hard examples通常为少数样本，所以虽然其对应的loss值较高，但是最后全部累加后，大部分的loss值来自于容易分类的样本，这样在模型优化的过程中就会将更多的优化放到容易分类的样本中，而忽略hard examples。</p>
<script type="math/tex; mode=display">CE(p,y)=CE(p_t)=-log(p_t)</script><p>对于这种类别不均衡问题常用的方法是引入一个权重因子$\alpha$，对于类别1的使用权重$\alpha$，对于类别-1使用权重$1-\alpha$，公式如下所示。但采用这种加权方式可以平衡正负样本的重要性，但无法区分容易分类的样本与难分类的样本。</p>
<script type="math/tex; mode=display">CE(p_t)=-\alpha_tlog(p_t)</script><p>因此论文中提出在交叉熵前增加一个调节因子$(1-p_t)^{\gamma}$，其中$\gamma$为focusing parameter，且$\gamma \ge 0$，其公式变为如下，当$\gamma$取不同数值时loss曲线如图1所示。通过图中可以看到，当$\gamma$越来越大时，loss函数在容易分类的部分其loss几乎为零，而$p_t$较小的部分（hard examples部分）loss值仍然较大，这样就可以保证在类别不平衡较大时，累加样本loss，可以让hard examples贡献更多的loss，从而可以在训练时给与hard examples部分更多的优化。</p>
<script type="math/tex; mode=display">FL(p_t)=-(1-p_t)^{\gamma}log(p_t)</script><p>在实际使用时，论文中提出在上述公式的基础上，增加一个$\alpha$平衡因子，可以产生一个轻微的精度提升，公式如下所示。</p>
<script type="math/tex; mode=display">CE(p_t)=-\alpha_t(1-p_t)^{\gamma}log(p_t)</script><p><img src="/images/focalloss.jpg" alt="focal loss曲线图"><br>下图是RetinaNet的网络结构，整个网络相对Faster-RCNN简单了很多，主要由ResNet+FPN+2xFCN子网络构成。<br><img src="/images/RetinaNet.jpg" alt="RetinaNet网络结构图"><br>首先RetinaNet的Backbone是由ResNet+FPN构成，输入图像经过Backbone的特征提取后，可以得到$P_3~P_7$特征图金字塔，其中下标$l$表示特征金字塔的层数（$P_l$特征图的分辨率比输入图像小$2^l$），得到的特征金字塔的每层$C=256$通道。<br>在得到特征金字塔后，对每层特征金字塔分别使用两个子网络（分类网络+检测框位置回归）。这两个子网络由RPN网络修改得到。<br>与RPN网络类似，也使用anchors来产生proposals。特征金字塔的每层对应一个anchor面积，为了产生更加密集的coverage，增加了三个面积比例$\begin{Bmatrix}2^0,2^{\frac{1}{2}},2^{\frac{2}{3}} \end{Bmatrix}$（即使用当前anchor对应的面积分别乘以相应的比例，形成三个尺度），然后anchors的长宽比仍为$\begin{Bmatrix}1:2,1:1,2:1  \end{Bmatrix}$，因此特征金字塔的每一层对应A = 9种Anchors。原始RPN网络的分类网络只是区分前景与背景两类，此处将其改为目标类别的个数K。<br>特征金字塔每层都相应的产生目标类别与位置的预测，最后再将其融合起来，同时使用NMS来得到最后的检测结果。</p>
<h3 id="Faster-R-CNN-FPN-Focal-loss"><a href="#Faster-R-CNN-FPN-Focal-loss" class="headerlink" title="Faster R-CNN+FPN+Focal loss"></a>Faster R-CNN+FPN+Focal loss</h3><p><a href="https://blog.csdn.net/qq_33547191/article/details/88695405" target="_blank" rel="noopener">Faster R-CNN+FPN结合细节</a><br><a href="https://github.com/jwyang/fpn.pytorch" target="_blank" rel="noopener">代码</a><br><a href="https://blog.csdn.net/dcxhun3/article/details/59055974" target="_blank" rel="noopener">网络结构</a><br><a href="https://www.cnblogs.com/leebxo/p/11291140.html" target="_blank" rel="noopener">优化方案</a></p>
<h3 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h3><p>算法特点：1）将物体检测作为回归问题求解。基于一个单独的End-To-End网络，完成从原始图像的输入到物体位置和类别的输出，输入图像经过一次Inference，便能得到图像中所有物体的位置和其所属类别及相应的置信概率。2）YOLO网络借鉴GoogleNet网络结构，不同的是，YOLO未使用Inception Module，而是使用$1\times 1$卷积层（此处$1\times 1$卷积层的存在是为了跨通道信息整合）+ $3\times 3$卷积层简单代替。3）Fast YOLO使用9个卷积层代替YOLO的24个，网络更轻快，速度从YOLO的45fps提升到155fps，但是同时损失了检测准确率。4）使用全图作为Context信息，背景错误（把背景错认为物体）比较少。5）泛化能力强。在自然图像上训练好的结果在艺术作品中依然具有很好的效果。<br><img src="/images/Yolo.png" alt="YOLO网络结构"><br>一、大致流程<br>1）对于一个输入图像，首先将图像划分成$7\times 7$的网络。<br>2）对于每个网格，我们都预测2个边框（包括每个边框是目标的置信度以及每个边框区域在多个类别上的概率）。<br>3）根据上一步可以预测出$7\times 7\times 2$个目标窗口，然后根据阈值去除可能性比较低的目标窗口，最后NMS去除冗余窗口即可。<br><img src="/images/Yolo2.png" alt="Yolo实例"><br>二、训练<br>1）预训练分类网络：在ImageNet 1000-class Competition Dataset预训练一个分类网络，这个网络时前文网络结构中前20个卷积网络+Average-Pooling Layer+Fully Connected Layer(此时网络的输入是$224\times 224$)。<br>2）训练检测网络：在预训练网络中增加卷积和全连接层可以改善性能。YOLO添加4个卷积层和2个全连接层，随机初始化权重。检测要求细粒度的视觉信息，所以把网络输入也从$224\times 224$变成$448\times 448$。一幅图像分成$7\times 7$个网格，某个物体的中心落在这个网格中此网络就负责预测这个物体。每个网络预测两个Bounding Box。网格负责类别信息，Bounding Box负责坐标信息（4个坐标信息及一个置信度），所以最后一层输出为$7\times 7\times (2\times (4+1) + 20) = 7\times 7\times 30$的维度。Bounding Box的坐标使用图像的大小进行归一化0-1，Confidence使用$P_r(Object) * IOU_{pred}^{truth}$计算，其中第一项表示是否有物体落在网格中，第二项表示预测的框和实际的框之间的IOU值。<br>3）损失函数的确定：损失函数的定义如下，损失函数的设计目标就是让坐标，置信度和类别这三个方面达到很好的平和。简单地全部采用Sum-Squared Error Loss来做这件事会有以下不足：a)8维的Localization Error和20维的Classification Error同等重要显然是不合理的；b)如果一个网格中没有Object（一幅图中这种玩个很多），那么就会将这些网络中的Box的COnfidence降低到0，相对于较少的有Object的网络，这种做法是Overpowering的，这会导致网络不稳定甚至发散。解决方案如下：<br><img src="/images/Yolo3.png" alt="Yolo的损失函数"><br>首先更重视8维的坐标预测，给这些损失前面赋予更大的Loss Weight，记为$\lambda_{coord}$，在Pascal VOC训练中取5（上图蓝色框）。对于没有Object的Bbox的Confidence Loss，赋予小的Loss Weight，记为$\lambda_{noobj}$，在Pascal VOC训练中取0.5（上图橙色框）。有Object的Bbox的Confidence Loss（上图红色框）和类别的Loss（上图紫色框）的Loss Weight正常取1。对于不同大小的Bbox预测中，相比于大Bbox预测偏一点，小Bbox预测偏一点更不能忍受。而Sum-Square Error Loss中对同样的偏移Loss是一样的。为了缓和这个问题，将Bbox的Width和Height取平方根代替原本的Height和Width。如下图所示：Small Bbox的横轴值较小，发生偏移时，反应到y轴上的Loss(下图绿色)比Big Bbox(下图红色)要大。一个网格预测多个Bbox，在训练时我们希望每个Object（Ground True box）只有一个Bbox专门负责（一个Object一个Bbox）。具体做法是与Ground True Box(Object)的IOU最大的Bbox负责该Ground True Box(Object)的预测。这种做法称作Bbox Predictor的Specialization（专职化）。每个预测器会对特定（Size,Aspect Ratio or Classed of Object）的Ground True Box预测的越来越好。<br>三、测试<br>1）计算每个Bbox的Class-Specific Confidence Score:每个网格预测的Class信息($Pr(Class_i|Object)$)和Bbox预测的Confidence信息($Pr(Object)\times IOU_{pred}^{truth}$)相乘，就得到每个Bbox的Class-Specific Confidence Score。</p>
<script type="math/tex; mode=display">Pr(Class_i|Object)\times Pr(Object)\times IOU_{pred}^{truth}=Pr(Class_i)\times IOU_{pred}^{truth}</script><p>2）进行Non-Maximum Suppression(NMS)：得到每个Bbox的Class-Specific Confidence Score以后，设置阈值，滤掉得分低的Bboxes，对保留的Bboxes进行NMS处理就得到最终的检测结果。<br>四、存在问题<br>1）YOLO对相互靠的很近的物体（挨在一起且中点都落在同一个格子上的情况），还有很小的群体检测效果不好，这是因为一个网络中只预测了两个框，并且只属于一类。<br>2）测试图像中，当同一类物体出现的不常见的长宽比和其他情况时泛化能力偏弱。<br>3）由于损失函数的问题，定位误差是影响检测效果的主要原因，尤其是大小物体的处理上，还有待加强。</p>
<h3 id="YOLOV2、YOLOV3"><a href="#YOLOV2、YOLOV3" class="headerlink" title="YOLOV2、YOLOV3"></a>YOLOV2、YOLOV3</h3><h4 id="YOLOV2-YOLO9000-更准、更快、更强"><a href="#YOLOV2-YOLO9000-更准、更快、更强" class="headerlink" title="YOLOV2/YOLO9000 更准、更快、更强"></a>YOLOV2/YOLO9000 更准、更快、更强</h4><p>YOLO v1对于bounding box的定位不是很好，在精度上比同类网络还有一定的差距。作者希望改进的方向是改善 recall，提升定位的准确度，同时保持分类的准确度。YOLO V2在V1基础上做出改进：<br>1）受到Faster RCNN方法的启发，引入了anchor。使用了K-Means方法，对anchor数量进行了讨论。<br>2）修改了网络结构，去掉了全连接层，改成了全卷积结构。<br>3）训练时引入了世界树（WordTree）结构，将检测和分类问题做成了一个统一的框架，并且提出了一种层次性联合训练方法，将ImageNet分类数据集和COCO检测数据集同时对模型训练。<br><strong>更准</strong><br>Batch Normalization<br>使用 Batch Normalization 对网络进行优化，让网络提高了收敛性，同时还消除了对其他形式的正则化（regularization）的依赖。通过对 YOLO 的每一个卷积层增加 Batch Normalization，最终使得 mAP 提高了2%，同时还使模型正则化。使用 Batch Normalization 可以从模型中去掉 Dropout，而不会产生过拟合。<br>High resolution classifier<br>目前业界标准的检测方法，都要先把分类器（classiﬁer）放在ImageNet上进行预训练。从 Alexnet 开始，大多数的分类器都运行在小于 $256\times 256$ 的图片上。而现在 YOLO 从 $224\times 224$ 增加到了 $448\times 448$，这就意味着网络需要适应新的输入分辨率。<br>为了适应新的分辨率，YOLO v2 的分类网络以 $448\times 448$ 的分辨率先在 ImageNet上进行微调，微调 10 个 epochs，让网络有时间调整滤波器（filters），好让其能更好的运行在新分辨率上，还需要调优用于检测的 Resulting Network。最终通过使用高分辨率，mAP 提升了4%。<br>Convolution with anchor boxes<br>YOLOV1包含有全连接层，从而能直接预测 Bounding Boxes 的坐标值。 Faster R-CNN 的方法只用卷积层与 Region Proposal Network 来预测 Anchor Box 偏移值与置信度，而不是直接预测坐标值。作者发现通过预测偏移量而不是坐标值能够简化问题，让神经网络学习起来更容易。<br>收缩网络让其运行在 $416\times 416$ 而不是 $448\times 448$。由于图片中的物体都倾向于出现在图片的中心位置，特别是那种比较大的物体，所以有一个单独位于物体中心的位置用于预测这些物体。YOLO 的卷积层采用 32 这个值来下采样图片，所以通过选择 $416\times 416$ 用作输入尺寸最终能输出一个 $13\times 13$ 的特征图。 使用 Anchor Box 会让精确度稍微下降，但用了它能让 YOLO 能预测出大于一千个框，同时 recall 达到88%，mAP 达到 69.2%。<br>Dimension clusters<br>Anchor boxes的宽高维度往往是精选的先验框（hand-picked priors）也就是说人工选定的先验框。虽然在训练过程中网络也会学习调整框的宽高维度，最终得到准确的bounding boxes。但是，如果一开始就选择了更好的、更有代表性的先验框维度，那么网络就更容易学到准确的预测位置。为了优化，在训练集的 Bounding Boxes 上跑一下 k-means聚类，来找到一个比较好的值。<br>Fine-Grained Features<br>YOLOv1在对于大目标检测有很好的效果，但是对小目标检测上，效果欠佳。为了改善这一问题，作者参考了Faster R-CNN和SSD的想法，在不同层次的特征图上获取不同分辨率的特征。作者将上层的(前面26×26)高分辨率的特征图（feature map）直接连到13×13的feature map上。把26×26×512转换为13×13×2048，并拼接在一起使整体性能提升1%。<br>Multi-Scale Training<br>和GoogleNet训练时一样，为了提高模型的鲁棒性（robust），在训练的时候使用多尺度的输入进行训练。YOLOv2 每迭代几次都会改变网络参数。每 10 个 Batch，网络会随机地选择一个新的图片尺寸，由于使用了下采样参数是 32，所以不同的尺寸大小也选择为 32 的倍数 {320，352,…,608}，最小 320x320，最大 608x608，网络会自动改变尺寸，并继续训练的过程。<br><strong>更快</strong><br>大多数目标检测的框架是建立在VGG-16上的，VGG-16在ImageNet上能达到90%的top-5，但是单张图片需要30.69 billion 浮点运算，YOLO2是依赖于DarkNet-19的结构，该模型在ImageNet上能达到91%的top-5，并且单张图片只需要5.58 billion 浮点运算，大大的加快了运算速度。<br>YOLOv2去掉YOLOv1的全连接层，同时去掉YOLO v1的最后一个池化层，增加特征的分辨率，修改网络的输入，保证特征图有一个中心点，这样可提高效率。并且是以每个anchor box来预测物体种类的。<br>作者将分类和检测分开训练，在训练分类时，以Darknet-19为模型在ImageNet上用随机梯度下降法（Stochastic gradient descent）跑了160epochs，跑完了160 epochs后，把输入尺寸从224×224上调为448×448，这时候学习率调到0.001，再跑了10 epochs， DarkNet达到了top-1准确率76.5%，top-5准确率93.3%。<br>在训练检测时，作者把分类网络改成检测网络，去掉原先网络的最后一个卷积层，取而代之的是使用3个3×3x1024的卷积层，并且每个新增的卷积层后面接1×1的卷积层，数量是我们要检测的类的数量。<br><strong>更强</strong><br>论文提出了一种联合训练的机制：使用识别数据集训练模型识别相关部分，使用分类数据集训练模型分类相关部分。<br>众多周知，检测数据集的标注要比分类数据集打标签繁琐的多，所以ImageNet分类数据集比VOC等检测数据集高出几个数量级。所以在YOLOv1中，边界框的预测其实并不依赖于物体的标签，YOLOv2实现了在分类和检测数据集上的联合训练。对于检测数据集，可以用来学习预测物体的边界框、置信度以及为物体分类，而对于分类数据集可以仅用来学习分类，但是其可以大大扩充模型所能检测的物体种类。<br>作者选择在COCO和ImageNet数据集上进行联合训练，遇到的第一问题是两者的类别并不是完全互斥的，比如”Norfolk terrier”明显属于”dog”，所以作者提出了一种层级分类方法（Hierarchical classification），根据各个类别之间的从属关系（根据WordNet）建立一种树结构WordTree，结合COCO和ImageNet建立的词树（WordTree）如下图所示：<br><img src="/images/WordTree.jpg" alt="词树结构"><br>WordTree中的根节点为”physical object”，每个节点的子节点都属于同一子类，可以对它们进行softmax处理。在给出某个类别的预测概率时，需要找到其所在的位置，遍历这个路径，然后计算路径上各个节点的概率之积。<br>在训练时，如果是检测样本，按照YOLOv2的loss计算误差，而对于分类样本，只计算分类误差。在预测时，YOLOv2给出的置信度就是 ，同时会给出边界框位置以及一个树状概率图。在这个概率图中找到概率最高的路径，当达到某一个阈值时停止，就用当前节点表示预测的类别。</p>
<h4 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h4><p>改进之处：<br>1）多尺度预测<br>2）更好的基础网络（类ResNet）和分类器darknet-53<br>多尺度预测<br>原来的YOLO v2有一个层叫：passthrough layer，假设最后提取的feature map的size是$13\times 13$，那么这个层的作用就是将前面一层的$26\times 26$的feature map和本层的$13\times 13$的feature map进行连接，有点像ResNet。这样的操作也是为了加强YOLO算法对小目标检测的精确度。这个思想在YOLO v3中得到了进一步加强，在YOLO v3中采用类似FPN的上采样（upsample）和融合做法（最后融合了3个scale，其他两个scale的大小分别是$26\times 26$和$52\times 52$），在多个scale的feature map上做检测，对于小目标的检测效果提升还是比较明显的。虽然在YOLO v3中每个网格预测3个边界框，看起来比YOLO v2中每个grid cell预测5个边界框要少，但因为YOLO v3采用了多个尺度的特征融合，所以边界框的数量要比之前多很多。<br>darknet-53<br><img src="/images/darknet53.jpg" alt="YOLOv3框图"></p>
<h3 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h3><p><a href="https://blog.csdn.net/xiaohu2022/article/details/79833786?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">SSD模型</a><br>算法特点<br>1）SSD结合了YOLO中的回归思想和Faster R-CNN中的Anchor机制，使用全图各个位置的尺度区域特征进行回归，既保持了YOLO速度快的特性，也保证了窗口预测的跟Faster-RCNN一样比较精准。<br>2）SSD的核心是在特征图上采用卷积核来预测一系列Default Bounding Boxes的类别、坐标偏移。为了提高检测准确率，SSD在不同尺度的特征图上进行预测。<br><img src="/images/SSD.png" alt="SSD网络结构"><br>一、模型结构<br>1、多尺度特征图（Multi-scale Feature Map For Detection）<br>在图像Base Network基础上，将Fc6，Fc7变为Conv6，Conv7两个卷积层，添加了一些卷积层（Conv8,Conv9,Conv10,Conv11），这些层的大小逐渐减小，可以进行多尺度预测。<br>2、卷积预测器（Convolutional Predictors For Detection）<br>每个新添加的卷积层和之前的部分卷积层，使用一系列的卷积核进行预测。对于一个大小为$m\times n$，$p$通道的卷积层，使用$3\times 3$的$p$通道卷积核作为基础预测元素进行预测，在某个位置上预测出一个值，该值可以是某一类别的得分，也可是相对于Default Bounding Boxes的偏移量，并且在图像中每个位置都将产生一个值。<br>3、默认框和比例（Default Boxes And Aspect Ratio）<br>在特征图的每个位置预测K个Box，对于每个Box，预测C个类别得分，以及相对于Default Bounding Box的4个偏移值，这样需要$(C+4)<em> k$个预测器，在$m </em> n$的特征图上将产生$(C+4)\times k\times m\times n$个预测值。这里，Default Bounding Box类似于Faster R-CNN中Anchor是，下图所示。<br><img src="/images/SSD2.png" alt="SSD默认框"><br>二、模型训练<br>1、监督学习的训练关键是人工标注的label，对于包含Default Box（在Faster R-CNN中叫做Anchor）的网络模型（如:YOLO,Faster R-CNN,MultiBox）关键点就是如何把标注信息（Ground True Box,Ground True Category）映射到（Default Box）上。<br>2、给定输入图像以及每个物体的Ground Truth，首先找到每个Ground True Box对应的Default Box中IOU最大的作为正样本。然后，在剩下的Default Box中找到那些与任意一个Ground truth Box的IOU大于0.5的Default Box作为正样本。其他的作为负样本（每个Default Box要么是正样本Box要么是负样本Box）。如上图中，两个Default Box与猫匹配，一个与狗匹配。在训练过程中，采用Hard Negative Mining 的策略（根据Confidence Loss对所有的Box进行排序，使正负例的比例保持在1:3） 来平衡正负样本的比率。<br>3、损失函数<br>与Faster-RCNN中的RPN是一样的，不过RPN是预测Box里面有Object或者没有，没有分类，SSD直接用的Softmax分类。Location的损失，还是一样，都是用Predict box和Default Box/Anchor的差 与Ground Truth Box和Default Box/Anchor的差进行对比，求损失。<br><img src="/images/SSDloss.png" alt="SSD loss求解"><br>其中，$x_{i,j}^p=1$表示 第i个Default Box与类别p的第j个Ground Truth Box相匹配，否则若不匹配的话，则$x_{i,j}^p=0$<br>4、Default Box的生成<br>对每一张特征图，按照不同的大小（Scale） 和长宽比（Ratio）生成生成k个默认框（Default Boxes）。<br>（1）Scale：每一个Feature Map中Default Box的尺寸大小计算如下：</p>
<script type="math/tex; mode=display">s_k=s_{min}+\frac{s_{max}-s_{min}}{m-1}(k-1), \quad k\in [1, m]</script><p>其中，$S_{min}$取值0.2，$s_{max}$取值0.95，意味着最低层的尺度是0.2，最高层的尺度是0.95。<br>（2）Ratio：使用不同的Ratio值$a_=1,2,3,\frac{1}{2},\frac{1}{3}$计算Default Box的宽度和高度：$w_k^a=s_k\sqrt{a_r},h_k^a=s_k/\sqrt{a_r}$。另外对于Ratio=1的情况，还增加了一个Default Box，这个Box的Scale为$s’_k=\sqrt{s_ks_k+1}$。也就是总共有6种不同的Default Box。<br>（3）Default Box中心：每个Default Box的中心位置设置成$(\frac{i+0.5}{|f_k|},\frac{j+0.5}{|f_k|})$，其中$|f_k|$表示第k个特征图的大小$i,j\in[0,|f_k|]$。<br>5）Data Augmentation：为了模型更加鲁棒，需要使用不同尺寸的输入和形状，作者对数据进行了多种方式的随机采样。</p>
<h3 id="mobile-net"><a href="#mobile-net" class="headerlink" title="mobile net"></a>mobile net</h3><h2 id="图像分割"><a href="#图像分割" class="headerlink" title="图像分割"></a>图像分割</h2><h3 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h3><h3 id="UNet"><a href="#UNet" class="headerlink" title="UNet"></a>UNet</h3><h2 id="目标追踪"><a href="#目标追踪" class="headerlink" title="目标追踪"></a>目标追踪</h2><h3 id="多目标跟踪介绍"><a href="#多目标跟踪介绍" class="headerlink" title="多目标跟踪介绍"></a>多目标跟踪介绍</h3><p>多目标跟踪，即MOT（Multi-Object Tracking），顾名思义，就是在一段视频中同时跟踪多个目标。MOT主要应用场景是安防监控和自动驾驶等，这些场景中我们往往需要对众多目标同时进行追踪。<br>而由于是多目标，自然就会产生新目标进入与旧目标消失的问题，这就是与单目标跟踪算法区别最大的一点。而由于这一点区别，也就导致跟踪策略的不同。在单目标跟踪中，我们往往会使用给定的初始框，在后续视频帧中对初始框内的物体进行位置预测。而多目标跟踪算法，大部分都是不考虑初始框的，原因就是上面的目标消失与产生问题。取而代之，在多目标跟踪领域常用的跟踪策略是TBD（Tracking-by-Detecton），又或者也可叫DBT（Detection-Based-Tracking）。即在每一帧进行目标检测，再利用目标检测的结果来进行目标跟踪，这一步我们一般称之为数据关联（Data Assoiation）。<br>这里自然引出了多目标跟踪算法的一种分类：TBD（Tracking-by-Detecton）与DFT（Detection-Free Tracking），也即基于检测的多目标跟踪与基于初始框无需检测器的多目标跟踪。基于初始化帧的跟踪，在视频第一帧中选择你的目标，之后交给跟踪算法去实现目标的跟踪。这种方式基本上只能跟踪你第一帧选中的目标，如果后续帧中出现了新的物体目标，算法是跟踪不到的。这种方式的优点是速度相对较快。缺点很明显，不能跟踪新出现的目标。基于目标检测的跟踪，在视频每帧中先检测出来所有感兴趣的目标物体，然后将其与前一帧中检测出来的目标进行关联来实现跟踪的效果。这种方式的优点是可以在整个视频中跟踪随时出现的新目标。TBD则是目前学界业界研究的主流。<br><img src="/images/TBDvsDFT.jpg" alt="TBD与DFT对比"><br>不得不提的是另一种多目标跟踪算法的分类方式：在线跟踪（Online）与离线跟踪（Offline）。上文提到，大家往往会使用数据关联来进行多目标跟踪。而数据关联的效果，与你能使用的数据是有着直接的关系的。在Online跟踪中，我们只能使用当前帧及之前帧的信息来进行当前帧的跟踪。而在Offline跟踪中则没有了这个限制，我们对每一帧的预测，都可以使用整个视频的信息，这样更容易获得一个全局最优解。两种方式各有优劣，一般视应用场合而定，Offline算法的效果一般会优于Online算法。而介于这两者之间，还有一种称之为Near-Online的跟踪方式，即可以部分利用未来帧的信息。下图形象解释了Online与Offline跟踪的区别。<br><img src="/images/OnlineAndOffline.jpg" alt="Online与Offline区别"></p>
<h3 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h3><p>Trajectory（轨迹）：一条轨迹对应这一目标在一段时间内的位置序列。<br>Tracklet（轨迹段）：形成Trajectory过程中的轨迹片段。完整的Trajectory是由属于同一物理目标的Tracklets构成。<br>ID switch（ID 切换）：又称ID sw.。对于同一个目标，由于跟踪算法误判，导致其ID发生切换的次数。跟踪算法中理想的ID switch应该为0.<br>对于多目标跟踪，最主要的评价指标就是MOTA。这个指标综合了三点因素：FP、FN、IDsw.。FP即False Postive，为误检测的目标数量；FN即False Negetive，为未检出的真实目标数量；IDsw.即同一目标发生ID切换的次数。</p>
<script type="math/tex; mode=display">MOTA=1-\frac{(FN+FP+IDSW)}{GT}\ \in(-\infty,1]</script><script type="math/tex; mode=display">MOTP=\frac{\sum_{t,i}d_{t,i}}{\sum_tc_t}</script><p>其中$c_t$表示帧t中的匹配数，并且$d_{t,i}$是假设i与分配的真实对象之间的边界框重叠。此度量标准很少考虑有关跟踪的信息，而侧重于检测的质量。</p>
<h3 id="SORT"><a href="#SORT" class="headerlink" title="SORT"></a>SORT</h3><p>现在多目标跟踪算法的效果，与目标检测的结果息息相关。在实际工程中，为了提高多目标跟踪的效果，可以从检测器入手，跟踪效果也会水涨船高。<br>SORT采用的是在线跟踪的方式，不使用未来帧的信息。在保持100fps以上的帧率的同时，也获得了较高的MOTA（在当时16年的结果中）。<br>多目标跟踪中SORT算法思想理解流程：<br>在跟踪之前，对所有目标已经完成检测，实现了特征建模过程。<br>1）对第一帧使用目标检测模型进行目标检测，得到第一帧中所有目标的分类和位置（假设有M个目标），并标注一个独有id。对每个目标初始化卡尔曼滤波跟踪器，预测每个目标在下一帧的位置；<br>2）对第二帧使用目标检测模型进行目标检测，得到第二帧中所有目标的分类和位置（假设有N个目标），求第一帧M个目标和第二帧N个目标两两目标之间的IOU，建立代价矩阵，使用匈牙利匹配算法得到IOU最大的唯一匹配（数据关联部分），再去掉匹配值小于iou_threshold的匹配对；<br>3）用第二帧中匹配到的目标的位置去更新卡尔曼跟踪器，计算第二帧时的卡尔曼增益Kk，状态估计值xk，估计误差协方差Pk。并输出状态估计值xk用来计算下一帧中的预测位置。对于本帧中没有匹配到的目标重新初始化卡尔曼滤波跟踪器；<br>后面每一帧图像都按第一帧和第二帧的做法进行类似处理即可。其中，卡尔曼跟踪器联合了历史跟踪记录，调节历史box与本帧box的残差，更好的匹配跟踪id。<br>匈牙利算法是一种寻找二分图的最大匹配的算法，在多目标跟踪问题中可以简单理解为寻找前后两帧的若干目标的匹配最优解的一种算法。而卡尔曼滤波可以看作是一种运动模型，用来对目标的轨迹进行预测，并且使用确信度较高的跟踪结果进行预测结果的修正。<br>SORT在以往二阶段匹配算法的基础上进行了创新。以往二阶段匹配算法是先使用匈牙利算法对相邻帧之间的目标进行匹配生成很多tracklets，之后使用这些tracklets进行二次匹配，以解决遮挡等问题引起的轨迹中断。但这种二阶段匹配方式弊端也很明显，因为这种方式先天地要求必须以Offline的方法进行跟踪，而无法做到Online。SORT将这种二阶段匹配算法改进为了一阶段方法，并且可以在线跟踪。具体而言，SORT引入了线性速度模型与卡尔曼滤波来进行位置预测，在无合适匹配检测框的情况下，使用运动模型来预测物体的位置。在数据关联的阶段，SORT使用的依旧是匈牙利算法逐帧关联，不过作者还引入了IOU（Intersection-Over-Union）距离。不过SORT用的是带权重的匈牙利算法，其实就是KM算法，用IOU距离作为权重（也叫cost矩阵）。作者代码里是直接用sklearn的linear_assignment实现。并且当IOU小于一定数值时，不认为是同一个目标，理论基础是视频中两帧之间物体移动不会过多。作者在代码中选取的阈值是0.3。<br>预测模型（卡尔曼滤波器）<br>作者近似地认为目标的不同帧间地运动是和其他物体及相机运动无关的线性运动。每一个目标的状态可以表示为：</p>
<script type="math/tex; mode=display">x=[u,v,s,r,\dot u,\dot v,\dot s]^T</script><p>其中u和v分别代表目标的中心坐标，而s和r分别代表目标边界框的比例（面积）和长宽比，长宽比被认为是常数，需要保持不变。<br>当进行目标关联时，使用卡尔曼滤波器，用上一帧中目标的位置信息预测下一帧中这个目标的位置。若上一帧中没有检测到下一帧中的某个目标，则对于这个目标，重新初始化一个新的卡尔曼滤波器。关联完成后，使用新关联的下一帧中该目标的位置来更新卡尔曼滤波器。<br>数据关联（匈牙利匹配）<br>SORT算法中的代价矩阵为上一帧的M个目标与下一帧的N个目标两两目标之间的IOU。当然，小于指定IOU阈值的指派结果是无效的（源码中阈值设置为0.3）。<br>此外，作者发现使用IOU能够解决目标的短时被遮挡问题。这是因为目标被遮挡时，检测到了遮挡物，没有检测到原有目标，假设把遮挡物和原有目标进行了关联。那么在遮挡结束后，因为在相近大小的目标IOU往往较大，因此很快就可以恢复正确的关联。这是建立在遮挡物面积大于目标的基础上的。</p>
<h3 id="deep-SORT"><a href="#deep-SORT" class="headerlink" title="deep SORT"></a>deep SORT</h3><p>之前的SORT算法使用简单的卡尔曼滤波处理逐帧数据的关联性以及使用匈牙利算法进行关联度量，这种简单的算法在高帧速率下获得了良好的性能。但由于SORT忽略了被检测物体的表面特征，因此只有在物体状态估计不确定性较低是才会准确，在Deep SORT中，我们使用更加可靠的度量来代替关联度量，并使用CNN网络在大规模行人数据集进行训练，并提取特征，已增加网络对遗失和障碍的鲁棒性。<br>状态估计<br>使用一个8维空间去刻画轨迹在某时刻的状态：</p>
<script type="math/tex; mode=display">(u,v,\gamma,h,\dot x,\dot y,\dot\gamma,\dot h)</script><p>使用一个kalman滤波器预测更新轨迹，该卡尔曼滤波器采用匀速模型和线性观测模型。通过卡尔曼估计对u,v,r,h进行估计，u，v是物体中心点的位置，r是长宽比，h是高。运动估计对于运动状态变化不是很剧烈和频繁的物体能取得比较好的效果。其观测变量为：</p>
<script type="math/tex; mode=display">(u,v,\gamma,h)</script><p>轨迹处理<br>对于每一个追踪目标，都有一个阈值ak用于记录轨迹从上一次成功匹配到当前时刻的时间（即连续没有匹配的帧数），我们称之为轨迹。当该值大于提前设定的阈值Amax则认为该轨迹终止，直观上说就是长时间匹配不上的轨迹则认为该轨迹已经结束。<br>在匹配时，对于没有匹配成功的目标都认为可能产生新的轨迹。但由于这些检测结果可能是一些错误警告，所以对这种情形新生成的轨迹标注状态’tentative’，然后观查在接下来的连续若干帧（论文中是3帧）中是否连续匹配成功，是的话则认为是新轨迹产生，标注为’confirmed’，否则则认为是假性轨迹,状态标注为’deleted’。<br>分配问题<br>在SORT中，我们直接使用匈牙利算法去解决预测的Kalman状态和新来的状态之间的关联度，现在我们需要将目标运动和表面特征信息相结合，通过融合这两个相似的测量指标。<br>Motion Metric<br>使用马氏距离来评测预测的Kalman状态和新来的状态：</p>
<script type="math/tex; mode=display">d^{(1)}(i,j)=(d_j-y_i)^TS_i^{-1}(d_j-y_i)</script><p>表示第j个detection和第i条轨迹之间的运动匹配度，其中$S_i$是轨迹由kalman滤波器预测得到的在当前时刻观测空间的协方差矩阵， $y_i$是轨迹在当前时刻的预测观测量， $d_i$时第j个detection的状态$(u,v,r,h)$<br>考虑到运动的连续性，可以通过该马氏距离对detections进行筛选，文中使用卡方分布的0.95分位点作为阈值$ t^(1)=0.4877$,我们可以定义一个门限函数。</p>
<script type="math/tex; mode=display">b_{i,j}^{(1)}=\mathbf{1}[d^{(1)}(i,j)\leq t^{(1)}]</script><p>Appearance Metric<br>当目标运动不确定性较低时，马氏距离是一个很好的关联度量，但在实际中，如相机运动时会造成马氏距离大量不能匹配，也就会使这个度量失效，因此，我们整合第二个度量标准，对每一个BBox检测框$d_j$我们计算一个表面特征描述子 $r_j,|r_j|=1$ , 我们会创建一个gallery用来存放最新的$L_k=100$个轨迹的描述子，即$R_k=\begin{Bmatrix}r_k^{(i)}\end{Bmatrix}_{k=1}^{L_k}$，然后我们使用第i个轨迹和第j个轨迹的最小余弦距离作为第二个衡量尺度！</p>
<script type="math/tex; mode=display">d^(2)(i,j)=min{1-r_j^Tr_k^{(i)}|r_k^(i)\in R_i}</script><p>当然，我们也可以用一个门限函数来表示</p>
<script type="math/tex; mode=display">b_{i,j}^{(2)}=\mathbf{d^{(2)}(i,j)\le t^{(2)}}</script><p>接着，我们把这两个尺度相融合为：</p>
<script type="math/tex; mode=display">c_{i,j}=\lambda d^{(1)}(i,j)+(1-\lambda)d^{(2)}(i,j)</script><script type="math/tex; mode=display">b_{i,j}=\prod_{m=1}^2b_{i,j}^{(m)}</script><p>总之，距离度量对于短期的预测和匹配效果很好，而表观信息对于长时间丢失的轨迹而言，匹配度度量的比较有效。超参数的选择要看具体的数据集，比如文中说对于相机运动幅度较大的数据集，直接不考虑运动匹配程度。<br>级联匹配<br>如果一条轨迹被遮挡了一段较长的时间，那么在kalman滤波器的不断预测中就会导致概率弥散。那么假设现在有两条轨迹竞争同一个目标，那么那条遮挡时间长的往往得到马氏距离更小，使目标倾向于匹配给丢失时间更长的轨迹，但是直观上，该目标应该匹配给时间上最近的轨迹。<br>导致这种现象的原因正是由于kalman滤波器连续预测没法更新导致的概率弥散。假设本来协方差矩阵是一个正态分布，那么连续的预测不更新就会导致这个正态分布的方差越来越大，那么离均值欧氏距离远的点可能和之前分布中离得较近的点获得同样的马氏距离值。<br>所以本文中才引入了级联匹配的策略将遮挡时间按等级分层，遮挡时间越小的匹配等级更高，即更容易被匹配。<br>首先是得到追踪框集合T和检测框集合D，设置最大的Amax为轨迹最大允许丢失匹配的帧数。通过计算上面的评价指标（两种度量的加权和）得到成本矩阵，再通过级联条件，设定阈值分别对外观和位置因素进行计算，满足条件则返回1，否则返回0。然后初始化匹配矩阵为空，初始化未匹配矩阵等于D。通过匈牙利算法，对于每个属于追踪框集合的元素T，在检测框里面查找成本最低且满足阈值过滤条件的检测框作为匹配结果，同时更新匹配矩阵和非匹配矩阵。<br>在匹配的最后阶段还对unconfirmed和age=1的未匹配轨迹进行基于IOU的匹配。这可以缓解因为表观突变或者部分遮挡导致的较大变化。当然有好处就有坏处，这样做也有可能导致一些新产生的轨迹被连接到了一些旧的轨迹上。但这种情况较少。<br>深度表观描述子<br>预训练的网络时一个在大规模ReID数据集上训练得到的，这个ReID数据集包含1261个人的1100000幅图像，使得学到的特征很适合行人跟踪。<br>然后使用该预训练网络作为基础网络，构建wide ResNet，用来提取bounding box的表观特征。</p>
<h3 id="匈牙利算法"><a href="#匈牙利算法" class="headerlink" title="匈牙利算法"></a>匈牙利算法</h3><p>（待补充）</p>
<h3 id="卡尔曼滤波器"><a href="#卡尔曼滤波器" class="headerlink" title="卡尔曼滤波器"></a>卡尔曼滤波器</h3><p>（待补充）</p>
<h2 id="姿态估计"><a href="#姿态估计" class="headerlink" title="姿态估计"></a>姿态估计</h2><p><a href="https://zhuanlan.zhihu.com/p/102457223" target="_blank" rel="noopener">姿态估计综述</a></p>
<h3 id="OpenPose"><a href="#OpenPose" class="headerlink" title="OpenPose"></a>OpenPose</h3><h2 id="注意机制"><a href="#注意机制" class="headerlink" title="注意机制"></a>注意机制</h2><p>注意力是人类大脑固有的一种信号处理机制。人类大脑通过快速从视觉信号中选择出需要重点关注的区域，也就是通常所说的注意力焦点，然后重点处理这些区域的细节信息。通过注意力机制可以利用有限的大脑资源从大量的信息中筛选出有价值的信息。<br>与传统的注意力机制不同，self-attention的查询（query）和键（key）属于同一个域，计算的是同一条语句（或同一张图片）中不同位置之间的注意力分配，从而提取该语句（或图片）的特征。何凯明首先将self-attention用于视觉任务中，提出了non-local network，来捕获图片（或视频）中的长程依赖（long-range dependency）。Self-attention机制在视觉任务解决了卷积神经网络的局部感受野问题，使得每个位置都可以获得全局的感受野。不过，由于在视觉任务中，像素数目极多，利用所有位置来计算每个位置的attention会导致巨大的计算和显存开销；另一方面，由于self-attention简单将图像当成一个序列进行处理，没有考虑不同位置之间的相对位置关系，使得所得到的attention丧失了图像的结构信息。<br>除了self-attention，视觉任务中另一类注意力机制为scale attention。与self-attention不同，scale attention基于每个位置本身的响应。就分类任务而言，每个位置的响应越大，则其对于最终的分类结果影响越大，那么这个位置本身的重要性就越强。根据响应大小有选择地对特征图进行强化或抑制，就可以在空间（或其他维度）上达到分配attention的目的。例如SENet，就相当于channel-wise的attention。这一类注意力机制仅仅基于图像中每个位置本身，对显著区域进行增强，非显著区域进行抑制，比self-attention机制更接近与人类视觉系统的注意力机制。</p>
<h3 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a>self-attention</h3><p>普通卷积将特征图的每个位置作为中心点，对该位置及其周围的位置进行加权求和，得到新的特征图上该位置对应的滤波结果，对于边缘，必要时可以用0进行填充。这一操作可以有效提取图片的局部信息。随着网络加深，卷积层不断堆叠，每个位置的感受域也越来越大，网络提取到的特征也逐渐由一些low-level的特征，如颜色、纹理，转变到一些high-level的结构信息。但是，简单通过加深网络来获取全局感受域，所带来的计算开销是很大的，并且，更深的网络会带来更大的优化难度。<br>Self-attention操作可以有效地捕获不同位置之间的long-range dependency，每个位置的特征都由所有位置的加权求和得到，这里的权重就是attention weight。由此，每个位置都可以获取全局的感受域，并且不会造成特征图的退化（分辨率降低），这对于一些密集的预测任务，如语义分割、目标检测等，具有很大的优势。<br>下图展示了self-attention的网络结构。给定输入X，将两个1x1卷积分别作用于X上，得到的两个特征利用f(⋅)得到相关性矩阵，图中展示的f(⋅)为矩阵乘法。最后将相关性矩阵作用在原特征经过1x1卷积变换后的特征上。</p>
<script type="math/tex; mode=display">y_i=\frac{1}{C(x)}\sum_{\forall j}f(x_i,x_j)g(x_j)</script><p>其中$f(⋅)$为相关性函数，$g(⋅)$为变换函数，$x_i$为输入第i个位置的特征，$y_i$为第i个位置的输出特征，$C(x)$为归一化因子，一般采用总位置的个数。<br><img src="/images/aelfattention.png" alt="self-attention结构"></p>
<h3 id="scale-attention"><a href="#scale-attention" class="headerlink" title="scale attention"></a>scale attention</h3><p>Scale attention是另一种注意力机制，与self-attention不同，scale attention是只基于key context的，对图像中的显著性区域进行增强，其他区域相应的进行抑制，从而使得输出的特征具有更强的区分性。这一类注意力机制的代表工作包括，residual attention network，squeeze-and-excite network，gather-and-excite network以及CBAM。</p>
<h4 id="Bottom-up-and-top-down形式的scale-attention"><a href="#Bottom-up-and-top-down形式的scale-attention" class="headerlink" title="Bottom-up and top-down形式的scale attention"></a>Bottom-up and top-down形式的scale attention</h4><p>在分类网络中，网络深层比浅层更关注于被分类的物体，也就是图片的主体内容，这是因为，深层网络具有更大的视野域，可以看到更广的范围；而浅层网络只能看到每个位置及其邻域。因此，如果将网络较深层的信息作为一种mask，作用在较浅层的特征上，就能更好的增强浅层特征中对于最终分类结果有帮助的特征，抑制不相关的特征。如图5所示，将attention作为mask作用在原来特征上，得到的输出就会更加集中在对分类有帮助的区域上。<br><img src="/images/attention1.png" alt="attention作用机制"><br>文章提出一种bottom-up top-down的前向传播方法来得到图片的attention map，并且将其作用在原来的特征上，使得输出的特征有更强的区分度。图6展示了这种attention的计算方式。由于更大的视野域可以看到更多的内容，从而获得更多的attention信息，因此，作者设计了一条支路，通过快速下采样和上采样来提前获得更大的视野域，将输出的特征进行归一化后作用在原有的特征上，将作用后的特征以残差的形式加到原来的特征上，就完成了一次对原有特征的注意力增强。文章还提出了一个堆叠的网络结构，即residual attention network，中间多次采用这种attention模块进行快速下采样和上采样。<br><img src="/images/attention2.png" alt="Bottom-up注意力机制"></p>
<h4 id="Squeeze-and-excite形式的注意力"><a href="#Squeeze-and-excite形式的注意力" class="headerlink" title="Squeeze and excite形式的注意力"></a>Squeeze and excite形式的注意力</h4><p>与residual attention不同，squeeze-and-excite通过global pooling来获得全局的视野域，并将其作为一种指导的信息，也就是attention信息，作用到原来的特征上。<br>SENet提出了channel-wise的scale attention。特征图的每个通道对应一种滤波器的滤波结果，即图片的某种特定模式的特征。对于最终的分类结果，这些模式的重要性是不同的，有些模式更重要，因此其全局的响应更大；有些模式不相关，其全局的响应较小。通过对不同通道的特征根据其全局响应值，进行响应的增强或抑制，就可以起到在channel上进行注意力分配的作用。其网络结构如图7所示，首先对输入特征进行global pooling，即为squeeze阶段，对得到的特征进行线性变换，即为excite阶段，最后将变换后的向量通过广播，乘到原来的特征图上，就完成了对不同通道的增强或抑制。<br><img src="/images/SEblock.jpg" alt="SE Bolck结构"><br>作为SENet的一个延续，convolutional block attention module （CBAM）将SENet中提出的channel attention扩展到了spatial attention上，通过一个串行的支路，将channel attention和spatial attention连接起来，对原特征进行增强。其网络结构如图9所示，首先进行channel attention，对通道进行增强和抑制，这一过程与SENet的操作完全相同，然后在每个位置上进行通道的squeeze和excite操作，得到与原特征图一样分辨率的1通道spatial attention，再作用到原特征图上，即为spatial attention操作。最终的输出即为spatial attention module的输出。相比SENet，CBAM带来的性能提升有限，在该模块中其主要作用的还是channel attention模块。<br><img src="/images/attention3.png" alt="CBAM网络结构"></p>
<h2 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h2><h1 id="序列神经网络"><a href="#序列神经网络" class="headerlink" title="序列神经网络"></a>序列神经网络</h1><h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p>RNN相对传统的ANN网络结构实现了信息的保留，具有一定的记忆功能。可以将过去的信息应用到当前的任务中。<br>下图展示了RNN的闭环结构和开环结构<br><img src="/images/RNN.png" alt="闭环和开环结构"><br>完成当前任务如果仅仅需要短期的信息而不需要长期的信息可以使用RNN。但是如果任务需要更多的上下文信息，仅仅依靠少量的过去信息无法完成准确的预测。也就是过去信息和当前任务存在较大的跳动，甚至需要未来的信息才能完成预测。这时经典的RNN就无法满足需要,而需要特殊的时间序列模型LSTM。LSTMs 就是用来解决长期依赖问题，这类模型可以记住长期信息。<br><img src="/images/RNN2.png" alt="RNN和LSTM结构"><br>典的RNN模型中的激活函数可能就是一个简单的tanh函数，但是LSTMs引入了四个门结构，具有增加或者移除信息状态的功能。门限可以有选择的让信息通过，它是由sigmoid神经网络层和pointwise乘法操作构成的。sigmoid层输入数值0-1 代表可以通过的比例，输入为0时代表不允许通过，输出为1时代表允许全部通过。<br>1）forget gate 遗忘门<br><img src="/images/latm1.png" alt="遗忘门结构"><br>遗忘门输入是$h_{t-1}$，输出是$f_t$，$f_t$作用于$C_{t-1}$。当$f_t$为1时，代表保留该值，当$f_t$为0时，代表完全舍去该值。<br>2）input gate 输入门<br><img src="images/lstm2.png" alt="输入门结构"><br>存储什么样的新信息包括两步，第一步输入门决定哪些值可以更新，第二步tanh层创造候选向量。$i_t$是sigmoid函数输出结果表示是否产生输入，其取值范围是0-1。$\tilde{C_t}$是新产生的候选向量。忘记门$f_t$乘$C_{t-1}$：忘掉决定忘掉的早期信息，其结果加上$i_t * \tilde{C_t}$，候选向量通过$i_t$缩放后表示多大程度上更新状态值。<br><img src="/images/lstm3.png" alt="遗忘门和输入门组合"><br>通过忘记门和输入门的组合可以表达出这样的信息：多大程度上忘记旧的信息以及多大程度上更新新的信息。<br>3）Output gate 输出门<br><img src="/images/lstm4.png" alt="输出门"><br>首先sigmoid函数决定输出的缩放比例$o_t$，然后cell 状态通过tanh函数，其结果与$o_t$相乘。</p>
<h2 id="TCN"><a href="#TCN" class="headerlink" title="TCN"></a>TCN</h2><p>时序问题的建模大家一般习惯性的采用循环神经网络（RNN）来建模，这是因为RNN天生的循环自回归的结构是对时间序列的很好的表示。传统的卷积神经网络一般认为不太适合时序问题的建模，这主要由于其卷积核大小的限制，不能很好的抓取长时的依赖信息。一种特殊的卷积神经网络——时序卷积网络（Temporal convolutional network， TCN）与多种RNN结构相对比，发现在多种任务上TCN都能达到甚至超过RNN模型。</p>
<h3 id="因果卷积-Causal-Convolution"><a href="#因果卷积-Causal-Convolution" class="headerlink" title="因果卷积(Causal Convolution)"></a>因果卷积(Causal Convolution)</h3><p><img src="/images/causalConv.jpg" alt="因果卷积"><br>因果卷积可以用上图直观表示。 即对于上一层t时刻的值，只依赖于下一层t时刻及其之前的值。和传统的卷积神经网络的不同之处在于，因果卷积不能看到未来的数据，它是单向的结构，不是双向的。也就是说只有有了前面的因才有后面的果，是一种严格的时间约束模型，因此被成为因果卷积。</p>
<h3 id="膨胀卷积-Dilated-Convolution"><a href="#膨胀卷积-Dilated-Convolution" class="headerlink" title="膨胀卷积(Dilated Convolution)"></a>膨胀卷积(Dilated Convolution)</h3><p> 单纯的因果卷积还是存在传统卷积神经网络的问题，即对时间的建模长度受限于卷积核大小的，如果要想抓去更长的依赖关系，就需要线性的堆叠很多的层。为了解决这个问题，研究人员提出了膨胀卷积。如下图所示。<br> <img src="/images/dilatedConv.jpg" alt="膨胀卷积"><br> 和传统卷积不同的是，膨胀卷积允许卷积时的输入存在间隔采样，采样率受图中的d控制。 最下面一层的d=1，表示输入时每个点都采样，中间层d=2，表示输入时每2个点采样一个作为输入。一般来讲，越高的层级使用的d的大小越大。所以，膨胀卷积使得有效窗口的大小随着层数呈指数型增长。这样卷积网络用比较少的层，就可以获得很大的感受野。</p>
<script type="math/tex; mode=display">F(s)=\sum_{i=0}^{k-1}f(i)\cdot x_{s-d\cdot i}</script><p> <a href="https://zhuanlan.zhihu.com/p/50369448" target="_blank" rel="noopener">空洞卷积</a></p>
<h3 id="残差连接-Residual-Connections"><a href="#残差连接-Residual-Connections" class="headerlink" title="残差连接(Residual Connections)"></a>残差连接(Residual Connections)</h3><p> <img src="/images/residualConnection.jpg" alt="残差连接"><br> 残差链接被证明是训练深层网络的有效方法，它使得网络可以以跨层的方式传递信息。本文构建了一个残差块来代替一层的卷积。如上图所示，一个残差块包含两层的卷积和非线性映射，在每层中还加入了WeightNorm和Dropout来正则化网络。</p>
<h3 id="TCN优点和缺点"><a href="#TCN优点和缺点" class="headerlink" title="TCN优点和缺点"></a>TCN优点和缺点</h3><p>优点<br>（1）并行性。当给定一个句子时，TCN可以将句子并行的处理，而不需要像RNN那样顺序的处理。<br>（2）灵活的感受野。TCN的感受野的大小受层数、卷积核大小、扩张系数等决定。可以根据不同的任务不同的特性灵活定制。<br>（3）稳定的梯度。RNN经常存在梯度消失和梯度爆炸的问题，这主要是由不同时间段上共用参数导致的，和传统卷积神经网络一样，TCN不太存在梯度消失和爆炸问题。<br>（4）内存更低。RNN在使用时需要将每步的信息都保存下来，这会占据大量的内存，TCN在一层里面卷积核是共享的，内存使用更低。<br>缺点<br>（1）TCN 在迁移学习方面可能没有那么强的适应能力。这是因为在不同的领域，模型预测所需要的历史信息量可能是不同的。因此，在将一个模型从一个对记忆信息需求量少的问题迁移到一个需要更长记忆的问题上时，TCN 可能会表现得很差，因为其感受野不够大。<br>（2）论文中描述的TCN还是一种单向的结构，在语音识别和语音合成等任务上，纯单向的结构还是相当有用的。但是在文本中大多使用双向的结构，当然将TCN也很容易扩展成双向的结构，不使用因果卷积，使用传统的卷积结构即可。<br>（3）TCN毕竟是卷积神经网络的变种，虽然使用扩展卷积可以扩大感受野，但是仍然受到限制，相比于Transformer那种可以任意长度的相关信息都可以抓取到的特性还是差了点。TCN在文本中的应用还有待检验。</p>
<h1 id="图网络"><a href="#图网络" class="headerlink" title="图网络"></a>图网络</h1><p><a href="http://bbs.cvmart.net/articles/281/cong-cnn-dao-gcn-de-lian-xi-yu-qu-bie-gcn-cong-ru-men-dao-jing-fang-tong-qi" target="_blank" rel="noopener">图卷积网络</a><br>卷积是通过计算中心像素点以及相邻像素点的加权和来构成feature map实现空间特征提取。图卷积主要分为空域图卷积和谱域图卷积。<br>空域图卷积，其思想是将每个节点与其相邻节点的特征进行加权，使用领域来确定每个节点的加权平均范围（卷积范围），使用label策略来为参与卷积的节点分配权重，其层间传播矩阵为：</p>
<script type="math/tex; mode=display">X^{l+1}=\delta(W^lX^lA)</script><p>其中A是邻接矩阵，包含邻居节点信息，A中节点相连为1否则为0。通过矩阵乘法可以使得每个节点和其邻居节点特征进行聚合。W是权重矩阵，主要是对边进行加权。这样的传播方法是没有对邻接矩阵进行归一化，这使得A在传播过程中不断扩张（每次乘A会导致特征值越来越大）。此外，由于A对角线元素为0，每个节点自身在进行卷积时不能将自己的特征计算在内。因此，在空域图卷积中引入了谱域图卷积的思想来解决这两个问题。谱域图卷积主要借助图的拉普拉斯矩阵和傅里叶变换来进行的，最后得到的层间传播公式为：</p>
<script type="math/tex; mode=display">X^{l+1}=\delta(\land^(-\frac{1}{2})(A+I)\land^(-\frac{1}{2})X^lW^l)</script><p>其中矩阵$\land$用于对扩展邻接矩阵(A+I)进行归一化。<br>首先和单纯的空域图卷积相比，对邻接矩阵做了自环操作(A+I)，通过加单位矩阵的方法，使得中心节点自身的特征能参与卷积。然后通过对邻接矩阵实现归一化，解决了A随层数不断增长的问题。其他的部分就和公式(1)完全一致了。因此我们可以说公式(2)是利用谱域图卷积的思想来弥补了空域图卷积的缺点，本质上是两种卷积思想的结合。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Kay</p>
  <div class="site-description" itemprop="description">千里之行，始于足下</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kay</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.1
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
