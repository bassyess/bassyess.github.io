<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"bassyess.github.io","root":"/","scheme":"Pisces","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="千里之行，始于足下">
<meta property="og:type" content="website">
<meta property="og:title" content="Home">
<meta property="og:url" content="https://bassyess.github.io/page/3/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="千里之行，始于足下">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Kay">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://bassyess.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Home</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Home</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="post-title-link" itemprop="url">机器学习基础知识</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-18 21:13:21" itemprop="dateCreated datePublished" datetime="2020-02-18T21:13:21+08:00">2020-02-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-04-05 15:54:27" itemprop="dateModified" datetime="2020-04-05T15:54:27+08:00">2020-04-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="传统的机器学习算法"><a href="#传统的机器学习算法" class="headerlink" title="传统的机器学习算法"></a>传统的机器学习算法</h2><p>常见的机器学习算法包括：</p>
<ol>
<li>回归算法：回归算法是试图采用对误差的衡量来探索变量之间的关系的一类算法。回归算法是统计机器学习的利器，常见的回归算法包括：最小二乘法（Ordinary Least Square），逻辑回归（Logistic Regression）,逐步式回归（Stepwise Regression），多元自适应回归样条（Multivariate Adaptive Regression Splines）以及本地散点平滑估计（Locally Estimated Scatterplot Smoothing）。</li>
<li>基于实例的算法：基于实例的算法常常用来对决策问题建立模型，这样的模型常常先选择一批样本数据，然后根据某些近似性把新数据与样本数据进行比较通过这种方式来寻找最佳的匹配。因此，基于实例的算法也被称为“基于记忆的学习”。常见的算法包括k-Nearest Neighbor(KNN)，学习矢量量化（Learning Vector Quantization, LVQ）以及自组织映射算法（Self-Organizing Map, SOM）。</li>
<li>决策树学习：决策树算法根据数据的属性采用树状结构建立决策模型，决策树模型常常用来解决分类和回归问题。常见的算法包括：分类及回归树（Classification And Regression Tree, CART），随机森林（Random Forest），多元自适应回归样条（MARS）以及梯度推进及（Gradient Boosting Machine, GBM）。</li>
<li>贝叶斯方法：贝叶斯算法是基于贝叶斯定理的一类算法，主要用来解决分类和回归问题。常见算法包括：朴素贝叶斯算法，平均单依赖估计（Averaged One-Dependence Estimators, AODE）以及Bayesian Belief Network(BBN)。</li>
<li>基于核的算法：基于核的算法中最著名的莫过于支持向量机（SVM）。基于核的算法吧输入数据映射到高阶的向量空间，在这些高阶向量空间里，有些分类或者回归问题能够更容易的解决。常见的基于核的算法包括：支持向量机（Support Vector Machine, SVM），径向基函数（Radial Basis Function, RBF）以及线性判别分析（Linear Discriminate Analysis, LDA）等。</li>
<li>聚类算法：聚类，就像回归一样，有时候人们描述的是一类问题，有时候描述的是一类算法。聚类算法通常按照中心店或者分层的方式对输入数据进行归并。所有的聚类算法都试图找到数据的内在结构，以便按照最大的共同点进行归类。常见的聚类算法包括k-means算法以及期望最大化算法（Expectation Maximization, EM）。</li>
<li>降低维度算法：像聚类算法一样，降低维度算法试图分析数据的内在结构，不过降低维度算法是以非监督学习的方式试图利用较少的信息来归纳或者解释数据。这类数据可以用高维数据的可视化或者用来简化数据以便监督式学习使用。常见的算法包括：主成份分析（Principle Component Analysis, PCA），偏最小二乘回归（Partial Least Square Regression, PLS），Sammon映射，多维尺度（Multi-Dimensional Scaling, MDS），投影追踪（Projection Pursuit）等。</li>
<li>关联规则学习：关联规则学习通过寻找最能够解释数据变量之间关系的规则，来找出大量多元数据集中有用的关联规则。常见算法包括Apriori算法和Eclat算法等。</li>
<li>集成算法：集成算法用一些相对较弱的学习模型队里地就同样的样本进行训练，然后把结果整合起来进行整体预测。集成算法的主要难点在于究竟集成哪些独立的较弱的学习模型以及如何把学习结果整合起来。常见的算法包括：Boosting，Bootstrapped Aggregation(Bagging)，AdaBoost，堆叠泛化（Stacked Generalization, Blending），梯度推进及（Gradient Boosting Machine, GBM），随机森林（Random Forest）。</li>
<li>人工神经网络：人工神经网络算法模拟生物神经网络，是一类模式匹配算法， 通常用于解决分类和回归问题。重要的人工神经网络算法包括：感知器神经网络（Perceptron Neural Network），反向传递（Back Propagation），自组织映射（Self-Organizing Map，SOM）以及学习矢量量化（Learning Vector Quantization, LVQ）。<h2 id="生成模型和判别模型"><a href="#生成模型和判别模型" class="headerlink" title="生成模型和判别模型"></a>生成模型和判别模型</h2>生成模型：学习得到联合概率分布P(x,y)，即特征x和标记y共同出现的概率，然后求条件概率分布。能够学习到数据生成的机制。<br>判别模型：学习得到条件概率分布P(y|x)，即在特征x出现的情况下标记y出现的概率。<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><h3 id="样本不均衡如何处理？"><a href="#样本不均衡如何处理？" class="headerlink" title="样本不均衡如何处理？"></a>样本不均衡如何处理？</h3>简单通用的方式：<br>1）对较多的那个类别进行欠采样(under-sampling)，舍弃一部分数据，使其与较少类别的数据相当。<br>2）对较少的类别进行过采样(over-sampling)，重复使用一部分数据，使其与较多类别的数据相当。<br>3）阈值调整（threshold moving），将原本默认为0.5的阈值调整到 较少类别/（较少类别+较多类别）即可。<br>一个比较靠谱的解决方案是：<br>不对数据进行过采样和欠采样，但使用现有的集成学习模型，如随机森林；输出随机森林的预测概率，调整阈值得到最终结果；选择合适的评估标准，如precision@n。我们使用了集成学习降低过拟合风险，使用阈值调整规避和采样问题，同时选择合适的评估手段以防止偏见。</li>
</ol>
<h2 id="逻辑回归问题"><a href="#逻辑回归问题" class="headerlink" title="逻辑回归问题"></a>逻辑回归问题</h2><p>（重点）逻辑回归假设数据服从伯努利分布，通过极大似然函数的方法，运用梯度下降来求解参数，达到将数据二分类的目的。</p>
<h3 id="逻辑回归的基本假设"><a href="#逻辑回归的基本假设" class="headerlink" title="逻辑回归的基本假设"></a>逻辑回归的基本假设</h3><p>任何的模型都有自己的假设，在这个假设下模型才是适用的。逻辑回归的第一个假设是假设服从伯努利分布。伯努利分布有一个简单地例子是抛硬币，投中正面的概率为p，抛中负面的概率为1-p。<br>在逻辑回归模型中假设$h_{\theta}(x)$为样本为正的概率，$1-h_{\theta}(x)$为样本为负的概率。那么这个模型可以描述为：</p>
<script type="math/tex; mode=display">h_{\theta}(x;\theta)=p</script><p>逻辑回归的第二个假设是假设样本为正的概率是：</p>
<script type="math/tex; mode=display">p=\frac{1}{1+e^{-\theta^Tx}}</script><p>所以逻辑回归的最终形式：</p>
<script type="math/tex; mode=display">h_{\theta}(x;\theta)=\frac{1}{1+e^{-\theta^Tx}}</script><h3 id="逻辑回归的损失函数"><a href="#逻辑回归的损失函数" class="headerlink" title="逻辑回归的损失函数"></a>逻辑回归的损失函数</h3><p>逻辑回归的损失函数是它的极大似然函数：</p>
<script type="math/tex; mode=display">L_{\theta}(x)=\prod_{i=1}^mh_{\theta}(x^i;\theta)^{yi}*(1-h_{\theta}(x^i;\theta))^{1-y^i}</script><p>逻辑回归的损失函数为什么要使用极大似然函数作为损失函数？<br>将极大似然函数取对数以后等同于对数损失函数。在逻辑回归这个模型下，对数损失函数的训练求参数的速度是比较快的。可以求得这个公式的梯度更新为：</p>
<script type="math/tex; mode=display">\theta_j=\theta_j-(y_i-h_{\theta}(x^i;\theta))*x_{ij}</script><p>梯度的更新速度只和$x_{ij},y_i$相关，和sigmoid函数本身的梯度是无关的，这样的更新速度是可以自始至终都比较稳定。<br>为什么不选平方损失函数呢？其一是因为如果你使用平方损失函数，会发现梯度更新的速度和sigmoid函数本身的梯度是相关的。sigmoid函数在它定义域内梯度都不大于0.25，这样训练会非常慢。</p>
<h3 id="逻辑回归的求解方法"><a href="#逻辑回归的求解方法" class="headerlink" title="逻辑回归的求解方法"></a>逻辑回归的求解方法</h3><p>由于极大似然函数无法直接求解，因此需要通过对该函数进行梯度下降来不断逼近最优解。该处的考点有批梯度下降、随机梯度下降、小批量梯度下降以及其他优化方式。要掌握每种方法的优劣以及如何选择最合适的梯度下降方式。<br>1）批梯度下降，这种方式可以获得全局最优解，缺点是更新每个参数的时候需要遍历所有的数据，计算量太大，存在冗余数据，当数据量特别大的时候，每个参数的更新会很慢。<br>2）随机梯度下降，这种方式每遍历一个样本更新一次参数，更新具有高方差。缺点点在于容易获得更好的局部最优解，但是收敛比较快。<br>3）小批量梯度下降，这种方式结合了批梯度下降和随机梯度下降的优点，每遍历一小批数据更新一次参数，减少了参数更新的次数，加快了收敛。一般在深度学习中我们采用这种方式。<br>这里还有一个隐藏的更深的加分项，诸如是否了解Adam、动量法等优化方法。因为上述的方法还存在两个致命的问题。<br>a). 如何对模型选择合适的学习率。自始至终保持同样的学习率其实不太合适，因为一开始参数刚刚开始学习的时候，此时的参数和最优解隔的比较远，需要保持一个较大的学习率尽快逼近最优解。但是学习到后面的时候，参数和最优解已经隔的比较近了，还保持最初的学习率，容易越过最优点，在最优点附近来回振荡。<br>b). 如何对参数选择合适的学习率。在实际中，对每个参数都保持同样的学习率也是很不合理的。有些参数更新频繁，那么学习率可以适当小一点；有些参数更新缓慢，那么学习率就应该大一点。<br><a href="https://chenrudan.github.io/blog/2016/01/09/logisticregression.html#4.2" target="_blank" rel="noopener">其他的梯度求解方法</a><br>4）牛顿法：牛顿法的基本思想是在现有极小点估计值的附近对$f(x)$做二阶泰勒展开，进而找到极小点的一个估计值。这个方法需要目标函数是二阶连续可微的。<br>5）BFGS：由于牛顿法中需要求解二阶偏导，这个计算量会比较大，而且又是目标函数求出的海森矩阵无法保持正定，因此提出了拟牛顿法。拟牛顿法是一些算法的总称，它们的目的是通过某种方式来近似表示海森矩阵（或者它的逆矩阵）。BFGS就是一种拟牛顿法，是求解无约束非线性优化问题最常用的方法之一，目标时用迭代地方法逼近海森矩阵。这个更新方法很牛顿法的区别是，它在更新参数$w$之后更新一下近似海森矩阵的值，而牛顿法是在更新$w$之前完全的计算一遍海森矩阵。</p>
<h3 id="逻辑回归的目的"><a href="#逻辑回归的目的" class="headerlink" title="逻辑回归的目的"></a>逻辑回归的目的</h3><p>目的是将数据二分类，提高准确率。<br>逻辑回归作为一个回归（也就是y值是连续的），如何应用到分类上呢。y值确实是一个连续的变量，逻辑回归的做法是划分一个阈值，y值大于这个阈值的是一类，y值小于这个阈值的是另外一类。阈值具体如何调整根据实际情况选择，一般选择0.5作为阈值来划分。</p>
<h3 id="逻辑回归的优缺点"><a href="#逻辑回归的优缺点" class="headerlink" title="逻辑回归的优缺点"></a>逻辑回归的优缺点</h3><p>这里总结了逻辑回归应用在工业界当中的一些优点：<br>1）形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响，某个特征的权重值比较高，那么这个特征最后对结果的影响比较大。<br>2）模型效果不错。在工程上是可以接受的（作为baseline），如果特征工程做的好，效果不会太差，并且特征工程可以大家并行开发，大大加快开发的速度。<br>3）训练速度快。分类的时候，计算量仅仅只和特征的数目相关，并且逻辑回归的分布式优化sgd发展比较成熟，训练的速度可以通过对机器进一步提高，这样我们可以在短时间内迭代好几个版本的模型。<br>4）资源占用小，尤其是内存。因为只需要存储各个维度的特征值。<br>5）方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值（大于阈值的是一类，小于阈值的是一类）<br>当然逻辑回归本身也有很多的缺点：<br>1）准确率并不是很高。因为形式非常的简单（非常类似线性模型），很难去拟合数据的真实分布。<br>2）很难处理数据不平衡的问题。举个例子：如果我们对于一个正负样本非常不平衡的问题比如正负样本比10000：1，我们把所有样本都预测为正也能使损失函数的值比较小，但是作为一个分类器，它对正负样本的区分能力不会很好。<br>3）处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据，或者进一步说，处理二分类的问题。<br>4）逻辑回归本身无法筛选特征。有时候，我们会有GDBT来筛选特征，然后再上逻辑回归。</p>
<h3 id="特征问题"><a href="#特征问题" class="headerlink" title="特征问题"></a>特征问题</h3><h4 id="特征相关性问题"><a href="#特征相关性问题" class="headerlink" title="特征相关性问题"></a>特征相关性问题</h4><p>逻辑回归在训练的过程当中，如果有很多特征高度相关或者说有一个特征重复了100遍，会造成怎样的影响？<br>如果在损失函数最终收敛的情况下，就算有很多特征高度相关也不会影响分类器的效果。<br>但是对特征本身来说，假设只有一个特征，在不考虑采样的情况下，你现在将它重复100遍。训练完以后，数据还是这么多，但是这个特征本身重复了100遍，实际上将原来的特征分成了100份，每一个特征都是原来特征权重值的百分之一。如果在随机采样的情况下，其实训练收敛完以后，还是可以认为这100个特征和原来那一个特征扮演的效果一样，只是可能中间很多特征的值正负相消了。<br>为什么我们还是会在训练的过程当中将高度相关的特征去除？1）去掉高度相关的特征会让模型的可解释性更好；2）可以大大提高训练的速度。如果模型当中有很多特征高度相关的话，就算损失函数本身收敛了，但实际上参数是没有收敛的，这样会拉低训练的速度。其次是特征多了，本身就会增大训练的时间。</p>
<h4 id="特征离散化"><a href="#特征离散化" class="headerlink" title="特征离散化"></a>特征离散化</h4><p>逻辑回归为什么要对特征进行离散化？<br>在工业界，很少直接将连续值作为特征送入逻辑回归模型，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：<br>1）稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展。<br>2）离散化后的特征对异常数据由很强的鲁棒性，如果特征没有离散化，一个异常数据会给模型造成很大的干扰。<br>3）逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合。<br>4）离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力。<br>5）特征离散化后，模型会更稳定。<br>李沐少帅指出，模型是使用离散特征还是连续特征，其实是一个“海量离散特征+简单模型”同“少量连续特征+复杂模型”的权衡。既可以离散化用线性模型，也可以用连续特征加深学习。</p>
<h4 id="特征交叉"><a href="#特征交叉" class="headerlink" title="特征交叉"></a>特征交叉</h4><p>在逻辑回国模型中，为什么常常要做特征组合（特征交叉）？<br>逻辑回归模型属于线性模型，线性模型不能很好处理非线性特征，特征组合可以引入非线性特征，提升模型的表达能力。另外，基本特征可以认为是全局建模，组合特征更加精细，是个性化建模，但对全局建模会对部分样本有偏，对每一个样本建模又会导致数据爆炸，过拟合，所以基本特征+特征组合兼顾了全局和个性化。</p>
<h3 id="逻辑回归是线性模型吗？"><a href="#逻辑回归是线性模型吗？" class="headerlink" title="逻辑回归是线性模型吗？"></a>逻辑回归是线性模型吗？</h3><p>1）逻辑回归是一种广义线性模型，它引入了Sigmoid函数，是非线性模型，但本质上还是一个线性回归模型，因为除去Sigmoid函数映射关系，其他的算法原理、步骤都是线性回归的。<br>2）逻辑回归和线性回归首先都是广义的线性回归，区别在于逻辑回归多了个Sigmoid函数，使样本映射到[0,1]之间的数值，从而来处理分类问题。另外逻辑回归是假设变量服从伯努利分布，线性回归假设变量服从高斯分布。逻辑回归输出的是离散型变量，用于分类，线性回归输出的是连续值，用于预测。逻辑回归是用最大似然法去计算预测函数中最优参数值，而线性回归是用最小二乘法去对自变量因变量关系进行拟合。</p>
<h3 id="逻辑回归输出值的意义"><a href="#逻辑回归输出值的意义" class="headerlink" title="逻辑回归输出值的意义"></a>逻辑回归输出值的意义</h3><p>逻辑回归输出的值是0到1之间的值，这个值是真实的概率吗？<br><a href="https://blog.csdn.net/tunghao/article/details/86480040" target="_blank" rel="noopener">推导过程</a><br>结论：逻辑回归模型之所以是sigmoid的形式，源于我们假设y服从伯努利分布，伯努利分布又属于指数分布族，经过推导，将伯努利分布变为指数分布族的形式后。我们发现伯努利分布的唯一参数$\Phi$与指数分布族中的参数$\eta$具有sigmoid函数关系，于是我们转而求$\eta$与$x$的关系，此时，我们又假设$\eta$与$x$具有线性关系。至此找到了我们要用的模型的样子，也就是逻辑回归。即只有在满足：$y$服从伯努利分布；$n$和$x$之间存在线性关系时，输出值才是概率值。不满足的情况下，得到的输出值，只是置信度。</p>
<h3 id="欠拟合和过拟合"><a href="#欠拟合和过拟合" class="headerlink" title="欠拟合和过拟合"></a>欠拟合和过拟合</h3><p>过拟合：其实就是所建的机器学习模型或者深度学习模型在训练样本中表现过于优越，导致在验证数据集以及测试数据集中表现不佳。<br>欠拟合：由于训练样本被提取的特征比较少，导致训练出来的模型不能很好地匹配，表现很差。<br>判断方法是从训练集中随机选一部分作为验证集，采用K折交叉验证的方式，用训练集训练的同时在验证集上测试算法效果。在缺少有效预防欠拟合和过拟合措施的情况下，随着模型拟合能力的增强，错误率在训练集上逐渐减小，而在验证集上先减小后增大；当两者的误差率都较大时，处于欠拟合状态；当验证集误差率达到最低点，说明拟合效果最好，有最低点增大时，处于过拟合状态。<br>![误差率曲线图])(/images/拟合状态.png)</p>
<h4 id="解决模型欠拟合与过拟合常用方法"><a href="#解决模型欠拟合与过拟合常用方法" class="headerlink" title="解决模型欠拟合与过拟合常用方法"></a>解决模型欠拟合与过拟合常用方法</h4><p>欠拟合：欠拟合的原因大多是模型不够复杂、拟合函数的能力不够。<br>因此，从数据层面考虑，可以增加新特征，例如：组合、泛化、相关性、高次特征等；从模型层面考虑，可以增加模型的复杂度，例如SVM的核函数、DNN等更复杂模型，去掉正则化或减少正则化参数，加深训练轮数等。<br>过拟合：成因是给定的数据集相对过于简单，使得模型在拟合函数时过分考虑了噪声等不必要的数据间关联。<br>解决方法：<br>1）数据扩增：人为增加数据量，可以用重采样、上采样、增加随机噪声、GAN、图像数据的空间变换（平移旋转镜像）、尺度变换（缩放裁剪）、颜色变换、改变分辨率、对比度、亮度等。<br>2）针对神经网络，采用dropout的方法：dropout的思想是当一组参数经过某一层神经元的时候，去掉这一层上的部分神经元，让参数只经过一部分神经元进行计算。这里的去掉不是真正意义上的去除，只是让参数不经过一部分神经元计算，从而减少了神经网络的规模（深度）。<br>3）提前停止训练<br>也就是减少训练的迭代次数。从上面的误差率曲线图，理论上可以找到有个训练程度，此时验证集误差率最低，视为拟合效果最好的点。<br>4）正则化<br>在所定义的损失函数后面加入一项永不为0的部分，那么经过不断优化损失函数还是会存在的。<br>L0正则化：损失函数后面加入L0范数，也就是权重向量中非零参数的个数。特点是可以实现参数的稀疏性，使尽可能多的参数都为0；缺点是在优化时是NP难问题，很难优化。<br>L1正则化：在损失函数后面加入权重向量的L1范数。L1范数是L0范数的最优凸近似，比L0范数容易优化，也可以很好地实现参数稀疏性。<br>L2正则化：在损失函数后面加入参数L2范数的平方项。与L0、L1不同的是，L2很难使某些参数达到0，它只能是参数接近0。<br>5）针对DNN，采用batch normalization：即BN，既能提高泛化能力，又大大提高训练速度，现被广泛应用于DNN的激活层之前。主要优势：减少了梯度对参数大小和初始值的依赖，将参数值（特征）缩放在[0,1]区间（若针对Relu还限制了输出的范围），这样反向传播时梯度控制在1左右，使得网络在较高的学习率之下也不易发生梯度爆炸或弥散（也防止了在使用sigmoid作为激活函数时训练容易陷入梯度极小饱和或极大的极端情况）。</p>
<h3 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h3><p>在上面，我们主要使用逻辑回归解决二分类的问题，那对于多分类的问题，也可以用逻辑回归来解决吗？</p>
<h4 id="one-vs-rest"><a href="#one-vs-rest" class="headerlink" title="one vs rest"></a>one vs rest</h4><p>由于概率函数$h_{\theta}(x)$所表示的是样本标记为某一类型的概率，但可以将一对一（二分类）扩展为一对多(one vs rest)：<br>1）将类型$class_1$看作正样本，其他类型全部看作负样本，然后我们就可以得到样本类型为该类型的概率$p_1$；<br>2）然后再讲另外类型$class_2$看作正样本，其他类型全部看作负样本，同理得到$p_2$；<br>3）以此循环，我们可以得到该待预测样本的标记类型分别为类型$class_i$时的概率$p_i$，最后我们取$p_i$中最大的那个概率对应的样本标记类型为我们的待预测样本类型。</p>
<h4 id="softmax函数"><a href="#softmax函数" class="headerlink" title="softmax函数"></a>softmax函数</h4><p>使用softmax函数构造模型解决多分类问题，与logistic回归不同的是，softmax回归分类模型会有多个的输出，且输出个数与类别个数相等，输出为样本$X$的各个类别的概率，最后对样本进行预测的类型为概率最高的那个类别。</p>
<h4 id="选择方案"><a href="#选择方案" class="headerlink" title="选择方案"></a>选择方案</h4><p>当标签类别之间是互斥时，适合选择softmax回归分类器；当标签类别之间不完全互斥时，适合选择建立多个独立的logistic回归分类器。</p>
<h2 id="模型之间的对比"><a href="#模型之间的对比" class="headerlink" title="模型之间的对比"></a>模型之间的对比</h2><h3 id="线性回归与逻辑回归"><a href="#线性回归与逻辑回归" class="headerlink" title="线性回归与逻辑回归"></a>线性回归与逻辑回归</h3><p>逻辑回归和线性回归首先都是广义的线性回归，其次经典线性模型的优化目标函数是最小二乘，二逻辑回归则是似然函数。另外线性回归在整个实数域范围内进行预测，敏感度一致，而分类范围则需要在[0,1]；逻辑回归就是一种减小预测范围，将预测值限定在[0,1]间的一种回归模型，因而对于这类问题来说，逻辑回归的鲁棒性比线性回归好。<br>逻辑回归的模型本质是一个线性回归模型，逻辑回归都是以线性回归为理论支持的。但线性回归模型无法做到sigmoid的非线性形式，sigmoid可以轻松处理0/1分类问题。逻辑回归在线性回归的实数范围输出值上施加sigmoid函数将值收敛到0~1范围，其目标函数也因此从差平方和变为对数损失函数，以提供最优化所需导数（sigmoid函数是softmax函数的二元特例）。注意，逻辑回归玩玩是解决二元0/1分类问题，只是它和线性回归耦合太紧，也被冠以回归的名字。若要求多分类，就要把sigmoid换成softmax。</p>
<h3 id="最大熵与逻辑回归"><a href="#最大熵与逻辑回归" class="headerlink" title="最大熵与逻辑回归"></a>最大熵与逻辑回归</h3><p>最大熵原理是概率模型学习的一个准则，最大熵认为，学习概率模型时，在所有可能分布中，熵最大的模型是最好的模型。<br><a href="https://www.jianshu.com/p/504b8d09c23e" target="_blank" rel="noopener">最大熵推导过程</a><br>最大熵在解决二分类问题时就是逻辑回归，在解决多分类问题时就是多项逻辑回归。此外，最大熵与逻辑回归都称为对数线性模型。</p>
<h3 id="SVM与逻辑回归"><a href="#SVM与逻辑回归" class="headerlink" title="SVM与逻辑回归"></a>SVM与逻辑回归</h3><p>这两个模型应用广泛且有很多相同点，所以把SVM和LR放在一起比较。<br>相同点：<br>1）都是线性分类器，本质上都是求一个最佳分类超平面<br>2）都是监督学习算法。<br>3）都是判别模型。通过决策函数，判别输入特征之间的差别来进行分类。<br>常见的判别模型：KNN、SVM、LR。<br>常见的生成模型：朴素贝叶斯、隐马尔科夫模型。<br>不同点：<br>1）本质上的损失函数不同<br>LR的损失函数是交叉熵：</p>
<script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}\sum_{i=1}^m(y^{(i)}logh_{\theta}(x^{(i)})+(1-y^{(i)})log(1-h_{\theta}(x^{(i)})))</script><p>SVM的目标函数是hinge loss：</p>
<script type="math/tex; mode=display">L(w,b,\alpha)=\frac{1}{2}||w||^2-\sum_{i=1}^n\alpha_i(y_i(w^Tx_i+b)-1)</script><p>逻辑回归基于概率理论，假设样本为正样本的概率可以用sigmoid函数来表示极大似然估计的方法估计出参数的值。支持向量机基于几何间隔最大化原理，认为存在最大间隔的分类面为最优分类面。<br>2）两个模型对数据和参数的敏感程度不同<br>SVM考虑分类边界线附近的样本（决定分类超平面的样本），在支持向量外添加或减少任何样本点对分类决策面没有任何影响。LR受所有数据点的影响，每个样本点都会影响决策面的结果。如果训练数据不同类别严重不平衡，则一般需要先对数据做平衡处理，让不同类别的样本尽量平衡。<br>3）SVM基于距离分类，LR基于概率分类<br>SVM依赖数据表达的距离测度，所以需要先对数据先做normalization；LR不受其影响。<br>4）逻辑回归是处理经验风险最小化，SVM是结构风险最小化。这点体现在SVM自带L2正则化项，而逻辑回归需要在损失函数之外添加正则项。<br>5）逻辑回归通过非线性变换减弱分离平面较远点的影响，SVM则只支持向量从而消去较远点的影响。</p>
<h2 id="支持向量机SVM"><a href="#支持向量机SVM" class="headerlink" title="支持向量机SVM"></a>支持向量机SVM</h2><p>SVM是一种二分类模型，其基本思想是在特征空间中寻找间隔最大的分离超平面使数据得到高效的二分类，具体来讲有三种情况（不加核函数的话就是个线性模型，加了之后会升级为一个非线性模型）：<br>当训练样本线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机；<br>当训练函数近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机；<br>当训练数据线性不可分时，通过使用核技巧及软间隔最大化，学习非线性支持向量机。</p>
<h3 id="一句话介绍SVM"><a href="#一句话介绍SVM" class="headerlink" title="一句话介绍SVM"></a>一句话介绍SVM</h3><p>SVM是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔大使它有别于普通的感知机，通过核技巧隐式的在输入空间直接求解映射空间中特征向量的内积，使其成为一个非线性分类器。SVM的学习策略是间隔最大化，可形式化为一个求解凸二次规划问题。</p>
<h3 id="SVM的几个核心概念"><a href="#SVM的几个核心概念" class="headerlink" title="SVM的几个核心概念"></a>SVM的几个核心概念</h3><h4 id="确定超平面及函数间隔"><a href="#确定超平面及函数间隔" class="headerlink" title="确定超平面及函数间隔"></a>确定超平面及函数间隔</h4><p>由空间上的平面公式确定超平面$wx+b=0$，且$|wx+b|$表示点$x$到平面上的距离。正例负例位于分割平面两侧，因此$y(wx+b)$可同时表示分类正确性以及距离置信度。这也就是函数间隔，其被定义为训练集中所有点到超平面距离的最小值。</p>
<h4 id="几何间隔"><a href="#几何间隔" class="headerlink" title="几何间隔"></a>几何间隔</h4><p>由于成比例地缩放$w$和$b$会使得$|wx+b|$跟着成比例缩放，因此需要对法向量w加上约束，使得间隔是确定的，也就是函数间隔整体除以$||w||$，也就得到了几何间隔。</p>
<h4 id="间隔最大化"><a href="#间隔最大化" class="headerlink" title="间隔最大化"></a>间隔最大化</h4><p>分为硬间隔最大和软间隔最大<br>SVM的基本思想就是求解可以正确划分数据集并且几何间隔最大的分离超平面，其原因是线性可分超平面有无数个，但是间隔最大超平面使唯一的。</p>
<h4 id="支持向量"><a href="#支持向量" class="headerlink" title="支持向量"></a>支持向量</h4><p>与超平面最近的点被称为支持向量，也就是使得原始问题约束项成立的点。</p>
<h4 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h4><p>核函数本质不是将特征映射到高维空间，而是找到一种直接在低维空间对高维空间中向量做点积运算的简便方法。</p>
<h3 id="SVM推导"><a href="#SVM推导" class="headerlink" title="SVM推导"></a>SVM推导</h3><p>（重点）<a href="https://zhuanlan.zhihu.com/p/45444502" target="_blank" rel="noopener">SVM算法推导过程</a><br><a href="https://blog.csdn.net/szlcw1/article/details/52259668?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">SVM常考问题</a></p>
<h3 id="SVM为什么采用间隔最大化（与感知机的区别）"><a href="#SVM为什么采用间隔最大化（与感知机的区别）" class="headerlink" title="SVM为什么采用间隔最大化（与感知机的区别）"></a>SVM为什么采用间隔最大化（与感知机的区别）</h3><p>当训练数据线性可分时，存在无穷个分离超平面可以将两类数据正确分开。感知机利用误分类最小策略，求得分离超平面，不过此时的解有无穷多个。线性可分支持向量机利用间隔最大化求得最优分离超平面，这个解是唯一的。另一方面，此时的间隔超平面所产生的分类结果是最鲁棒的，对未知实例的泛化能力最强。</p>
<h3 id="SVM的目标（硬间隔）"><a href="#SVM的目标（硬间隔）" class="headerlink" title="SVM的目标（硬间隔）"></a>SVM的目标（硬间隔）</h3><p>有两个目标：第一是使间隔最大化，第二是使样本正确分类，由此推出目标函数：</p>
<script type="math/tex; mode=display">\mathop{min}\limits_{w,b}\frac{1}{2}||w||^2\quad s.t. y_i(w^Tx_i+b)\ge 1,\forall i</script><p>目标以是从点到面的距离公式简化来的，目标二相当于感知机，只是把大于等于0进行缩放变成了大于等于1，方便后面的推导。</p>
<h3 id="将原始问题转化为对偶问题"><a href="#将原始问题转化为对偶问题" class="headerlink" title="将原始问题转化为对偶问题"></a>将原始问题转化为对偶问题</h3><p>做所以说对偶问题更容易求解，其原因在于降低了算法的计算复杂度。在原问题下，算法的复杂度与样本维度相关，即等于权重w的维度，而在对偶问题下，算法复杂度与样本数量相关，即为拉格朗日算子的个数。<br>因此，如果你是做线性分类，且样本维度低于样本数量的话，在原问题下求解就好了，Liblinear之类的线性SVM默认都是这样的；但如果你是做非线性分类，那就会涉及到升维（比如使用高斯核做核函数，其实是将样本升到无穷维），升维后的样本维度往往会远大于样本数量，此时显然在对偶问题下求解会更好。</p>
<h3 id="软间隔"><a href="#软间隔" class="headerlink" title="软间隔"></a>软间隔</h3><p>不管在原特征空间，还是在映射的高维空间，我们都假设样本是线性可分的。虽然理论上我们总能找到一个高维映射使数据线性可分，但在实际任务中，寻找一个合适的核函数很困难。此外，由于数据通常有噪声存在，一味追求数据线性可分可能会使模型陷入过拟合，因此我们放宽对样本的要求，允许少量样本分类错误。这样的想法就意味着对目标函数的改变，之前推导的目标函数里不允许任何错误，并且让间隔最大，现在给之前的目标函数加上一个误差，就相当于允许原先的目标出错，引入松弛变量，公式变为：</p>
<script type="math/tex; mode=display">\mathop{min}\limits_{w,b,\xi}\frac{1}{2}||w||^2+\sum_{i=1}^n\xi_i</script><p>在松弛变量中引入合页损失(hinge loss):</p>
<script type="math/tex; mode=display">l_{hinge}(z)=max(0,1-z)</script><p>但是这个代价需要一个控制的因子，引入C&gt;0，惩罚参数。C越大说明把错误放的越大，说明对错误地容忍度就小，反之亦然。当C无穷大时，就变成一点错误都不能容忍，即变成硬间隔。实际应用时我们要合理选取C，C越小越容易欠拟合，C越大越容易过拟合。<br>所以软间隔的目标函数为：</p>
<script type="math/tex; mode=display">\mathop{min}\limits_{w,b,\xi}\frac{1}{2}||w||^2+C\sum_{i=1}^n\xi_i</script><script type="math/tex; mode=display">s.t.\ y_i(w_i^Tx+b)\ge 1-\xi_i\quad \xi_i\ge 0, i=1,2,...,n</script><p>其中：$\xi_i=max(0,1-y_i(w^Tx_i+b))$</p>
<h3 id="核函数-1"><a href="#核函数-1" class="headerlink" title="核函数"></a>核函数</h3><p>为什么要引入核函数？<br>当样本在原始空间线性不可分时，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。而引入这样的映射后，所要求解的对偶问题中，无需求解真正的映射函数，而只需要知道其核函数。核函数的定义：$K(x,y)=&lt;(x),(y)&gt;$，即在特征空间的内积等于它们在原始样本空间中通过核函数K计算的结果。一方面数据变成高维空间中线性可分的数据，另一方面不需要求解具体的映射函数，只需要给定具体的核函数即可，这样使得求解的难度大大降低。因为核函数求得的值等于将两个低维空间找那个的向量映射到高维空间后的内积。<br>常用的核函数：<br>1）线性核函数；2）多项式核；3）径向基核（RBF）；4）傅里叶核；5）样条核；6）Sigmoid核函数。<br>其中Gauss径向基函数则是局部性强的核函数，其外推能力随着参数的增大而减弱；多项式形式的核函数具有良好的全局性质，局部性差。<br>如何选择和函数呢？<br>1）当特征维数远远大于样本数的情况下，使用线性核就可以<br>2）当特征维数和样本数都很大，例如文本分类，一般使用线性核<br>3）当特征维数远小于样本数，一般使用RBF。</p>
<h3 id="为什么SVM对缺失数据敏感？"><a href="#为什么SVM对缺失数据敏感？" class="headerlink" title="为什么SVM对缺失数据敏感？"></a>为什么SVM对缺失数据敏感？</h3><p>这里说的缺失数据是指缺失某些特征数据，向量数据不完整。SVM没有处理缺失值的策略。而SVM希望样本在特征空间中线性可分，所以特征空间的好坏对SVM的性能很重要，缺失特征数据将影响训练结果的好坏。</p>
<h3 id="SVM的优缺点"><a href="#SVM的优缺点" class="headerlink" title="SVM的优缺点"></a>SVM的优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>1）由于SVM是一个凸优化问题，所以求得的解一定是全局最优而不是局部最优。<br>2）不仅适用于线性问题还适用于非线性问题（用核技巧）<br>3）同游高维样本空间的数据也能用SVM，这是因为数据集的复杂度只取决于支持向量而不是数据集的维度，这在某种意义上避免了“维数灾难”。<br>4）理论基础比较完善</p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>1）二次规划问题求解将涉及m阶矩阵的计算（m为样本的个数），因此SVM不适用于超大数据集。（SMO算法可以缓解这个问题）<br>2）只适用于二分类问题。（SVM的退岗SVR也适用于回归问题；可以通过多个SVM的组合来解决多分类问题）</p>
<h2 id="常用的距离公式"><a href="#常用的距离公式" class="headerlink" title="常用的距离公式"></a>常用的距离公式</h2><h3 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h3><p>点$P_1(x_1,y_1)$和点$P_2(x_2,y_2)$的距离为：</p>
<script type="math/tex; mode=display">distance(P_1,P_2)=|x_2-x_1|+|y_2-y_1|</script><h3 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h3><p>欧式空间中两点的距离。点$P_1(x_1,x_2,…,x_n)$和点$P_2(y_1,y_2,…,y_n)$的距离如下：</p>
<script type="math/tex; mode=display">distance=\sqrt{\sum_1^n(x_i-y_i)^2}</script><h3 id="切比雪夫距离"><a href="#切比雪夫距离" class="headerlink" title="切比雪夫距离"></a>切比雪夫距离</h3><p>两点之间的距离定义为其各坐标数值差的最大值。点$P_1(x_1,x_2,…,x_n)$和点$P_2(y_1,y_2,…,y_n)$的距离如下：</p>
<script type="math/tex; mode=display">distance=(P_1,P_2)=max(|x_1-y_1|,|x_2-y_2|,...,|x_n-y_n|)</script><h3 id="余弦相似度"><a href="#余弦相似度" class="headerlink" title="余弦相似度"></a>余弦相似度</h3><p>余弦相似度是通过测量两个向量夹角的度数来度量他们之间的相似度。对于A和B的距离是：</p>
<script type="math/tex; mode=display">cos(\theta)=\frac{A\cdot B}{||A||\cdot||B||}=\frac{\sum_1^n(A_i\times B_i)}{\sqrt{\sum_i^n(A_i)^2}\times\sqrt{\sum_i^n(B_i)^2}}</script><h2 id="数据降维"><a href="#数据降维" class="headerlink" title="数据降维"></a>数据降维</h2><h3 id="数据降维原理"><a href="#数据降维原理" class="headerlink" title="数据降维原理"></a>数据降维原理</h3><p>降维就是一种对高维度特征数据预处理方法。降维是将高维度的数据保留下最重要的一些特征，去除噪声和不重要的特征，从而实现提升数据处理速度的目的。在实际的生产和应用中，降维在一定的信息损失范围内，可以为我们节省大量的时间和成本。<br>降维具有如下一些优点：<br>1) 使得数据集更易使用。<br>2) 降低算法的计算开销。<br>3) 去除噪声。<br>4) 使得结果容易理解。<br>降维的算法有很多，比如奇异值分解(SVD)、主成分分析(PCA)、因子分析(FA)、独立成分分析(ICA)。</p>
<h3 id="线性判别分析LDA"><a href="#线性判别分析LDA" class="headerlink" title="线性判别分析LDA"></a>线性判别分析LDA</h3><h3 id="PCA原理"><a href="#PCA原理" class="headerlink" title="PCA原理"></a>PCA原理</h3><p><a href="https://blog.csdn.net/program_developer/article/details/80632779?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">PCA介绍</a><br>PCA(Principal Component Analysis)，即主成分分析方法，是一种使用最广泛的数据降维算法。PCA的主要思想是将n维特征映射到k维上，这k维是全新的正交特征也被称为主成分，是在原有n维特征的基础上重新构造出来的k维特征。PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身是密切相关的。其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第1,2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。通过这种方式获得的新的坐标轴，我们发现，大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。于是，我们可以忽略余下的坐标轴，只保留前面k个含有绝大部分方差的坐标轴。事实上，这相当于只保留包含绝大部分方差的维度特征，而忽略包含方差几乎为0的特征维度，实现对数据特征的降维处理。<br>思考：我们如何得到这些包含最大差异性的主成分方向呢？<br>答案：事实上，通过计算数据矩阵的协方差矩阵，然后得到协方差矩阵的特征值特征向量，选择特征值最大(即方差最大)的k个特征所对应的特征向量组成的矩阵。这样就可以将数据矩阵转换到新的空间当中，实现数据特征的降维。<br>由于得到协方差矩阵的特征值特征向量有两种方法：特征值分解协方差矩阵、奇异值分解协方差矩阵，所以PCA算法有两种实现方法：基于特征值分解协方差矩阵实现PCA算法、基于SVD分解协方差矩阵实现PCA算法。<br>（推导过程）</p>
<h3 id="SVD奇异值分解"><a href="#SVD奇异值分解" class="headerlink" title="SVD奇异值分解"></a>SVD奇异值分解</h3><h3 id="LDA、PCA、SVD推导过程"><a href="#LDA、PCA、SVD推导过程" class="headerlink" title="LDA、PCA、SVD推导过程"></a>LDA、PCA、SVD推导过程</h3><p><a href="https://blog.csdn.net/weixin_31866177/article/details/88079612?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">简述LDA、PCA、SVD推导过程</a></p>
<h2 id="K近邻算法（KNN）"><a href="#K近邻算法（KNN）" class="headerlink" title="K近邻算法（KNN）"></a>K近邻算法（KNN）</h2><p>对于新的样本，根据其K个最近邻的训练样本的标签，通过多数表决等方式进行预测。<br>k近邻的三要数：k值选择；距离度量；决策规则。<br>K近邻的优点：第一就就是k近邻算法是一种在线技术，新数据可以直接加入数据集而不必进行重新训练，第二就是k近邻算法理论简单，容易实现。第三就是准确性高，对异常值和噪声有较高的容忍度。第四就是k近邻算法天生就支持多分类，区别与感知机、逻辑回归、SVM。<br>K近邻算法的缺点：基本的 k近邻算法每预测一个“点”的分类都会重新进行一次全局运算，对于样本容量大的数据集计算量比较大。而且K近邻算法容易导致维度灾难，在高维空间中计算距离的时候，就会变得非常远；样本不平衡时，预测偏差比较大，k值大小的选择得依靠经验或者交叉验证得到。k的选择可以使用交叉验证，也可以使用网格搜索。k的值越大，模型的偏差越大，对噪声数据越不敏感，当k的值很大的时候，可能造成模型欠拟合。k的值越小，模型的方差就会越大，当k的值很小的时候，就会造成模型的过拟合。<br>K值的选择：<br>1）K值较小，则模型复杂度较高，容易发生过拟合，学习的估计误差会增大，预测结果对近邻的实例点非常敏感。<br>2）K值较大可以减少学习的估计误差，但是学习的近似误差会增大，与输入实例较远的训练实例也会对预测起作用，使预测发生错误，k值增大模型的复杂度会下降。<br>3）在应用中，k值一般取一个比较小的值，通常采用交叉验证法来选取最优的K值。</p>
<h2 id="Bagging和Boosting"><a href="#Bagging和Boosting" class="headerlink" title="Bagging和Boosting"></a>Bagging和Boosting</h2><p>从原始样本集中抽取训练集。每轮从原始样本集中使用Bootstraping的方法抽取n个训练样本（在训练集中，有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中），共进行k轮抽取，得到k个训练集。（k个训练集相互独立）<br>Bagging是并行的学习算法，思想很简单，即每一次从原始数据中根据均匀概率分布有放回的抽取和原始数据集一样大小的数据集合。样本点可以出现重复，然后对每一次产生的数据集构造一个分类器，再对分类器进行组合。对于分类问题，将上步得到的k个模型采用投票的方式得到分类结果；对回归问题，计算上述模型的均值作为最后的结果。<br>Boosting是一种可将弱学习器提升为强学习器的算法。Boosting的每一次抽样的样本分布是不一样的，每一次迭代，都是根据上一次迭代的结果，增加被错误分类的样本的权重。使模型在之后的迭代中更加注重难以分类的样本。这是一个不断学习的过程，也是一个不断提升的过程，这就是Boosting思想的本质所在。迭代之后，将每次迭代的基分类器进行集成，那么如何进行样本权重的调整和分类器的集成是我们需要考虑的关键问题。<br>Bagging和Boosting的区别：<br>1）样本选择上：<br>Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。<br>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化，而权值是根据上一轮的分类结果进行调整。<br>2）样例权重：<br>Bagging：使用均匀取样，每个样例的权重相等。<br>Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。<br>3）预测函数：<br>Bagging：所有预测函数的权重相等。<br>Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。<br>4）并行计算：<br>Bagging：各个预测函数可以并行生成。<br>Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。</p>
<h2 id="贝叶斯算法"><a href="#贝叶斯算法" class="headerlink" title="贝叶斯算法"></a>贝叶斯算法</h2><h2 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h2><p>​ 聚类就是按照某个特定标准把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不在同一个簇中的数据对象的差异性也尽可能地大。主要的聚类算法可以划分为如下几类：划分方法、层次方法、基于密度的方法、基于网格的方法以及基于模型的方法。</p>
<h3 id="聚类和降维有什么区别和联系"><a href="#聚类和降维有什么区别和联系" class="headerlink" title="聚类和降维有什么区别和联系"></a>聚类和降维有什么区别和联系</h3><p>​ 聚类用于找寻数据内在的分布结构，既可以作为一个单独的过程，也可作为分类等其他学习任务的前驱过程。聚类是标准的无监督学习。在一些推荐系统中需确定新用户的类型，但定义“用户类型”却可能不太容易，此时往往可先对原有的用户数据进行聚类，根据聚类结果将每个簇定义为一个类,然后再基于这些类训练分类模型,用于判别新用户的类型。<br>降维则是为了缓解维数灾难的一个重要方法，就是通过某种数学变换将原始高维属性空间转变为一个低维“子空间”。从而通过最主要的几个特征维度就可以实现对数据的描述，对于后续的分类很有帮助。<br>聚类和降维都可以作为分类等问题的预处理步骤。虽然他们都能实现对数据的约减，但二者适用的对象不同，聚类针对的是数据点，而降维则是对于数据的特征。</p>
<h3 id="k-means聚类算法"><a href="#k-means聚类算法" class="headerlink" title="k-means聚类算法"></a>k-means聚类算法</h3><p>k-means算法以k为参数，把n个对象分成k个簇，使簇内具有较高的相似度，而簇间的相似度较低。k-means算法的处理过程如下：首先，随机地选择k个对象，每个对象初始地代表了一个簇的平均值或中心;对剩余的每个对象，根据其与各簇中心的距离，将它赋给最近的簇;然后重新计算每个簇的平均值。这个过程不断重复，直到准则函数收敛。通常，采用平方误差准则，其定义如下：</p>
<script type="math/tex; mode=display">E=\sum_{i=1}^k\sum_{p\in C_i}||p-m_i||^2</script><h4 id="k-means-算法"><a href="#k-means-算法" class="headerlink" title="k-means++算法"></a>k-means++算法</h4><p>k个初始化的质心的位置选择对最后的聚类结果和运行时间都有很大的影响，因此需要选择合适的k个质心。如果仅仅是完全随机的选择，有可能导致算法收敛很慢。K-Means++算法就是对K-Means随机初始化质心的方法的优化。<br>K-Means++的对于初始化质心的优化策略也很简单，如下：<br>a)从输入的数据点集合中随机选择一个点作为第一个聚类中心μ1<br>b)对于数据集中的每一个点$x_i$，计算它与已选择的聚类中心中最近聚类中心的距离$D(x_i)=arg min||x_i−μ_r||_2^2, r=1,2,…kselected$<br>c)选择一个新的数据点作为新的聚类中心，选择的原则是：D(x)较大的点，被选取作为聚类中心的概率较大<br>d) 重复b和c直到选择出k个聚类质心<br>e) 利用这k个质心来作为初始化质心去运行标准的K-Means算法</p>
<h4 id="K-Means与KNN的区别"><a href="#K-Means与KNN的区别" class="headerlink" title="K-Means与KNN的区别"></a>K-Means与KNN的区别</h4><p>K-Means是无监督学习的聚类算法，没有样本输出；而KNN是监督学习的分类算法，有对应的类别输出。KNN基本不需要训练，对测试集里面的点，只需要找到在训练集中最近的k个点，用这最近的k个点的类别来决定测试点的类别。而K-Means则有明显的训练过程，找到k个类别的最佳质心，从而决定样本的簇类别。<br>当然，两者也有一些相似点，两个算法都包含一个过程，即找出和某一个点最近的点。两者都利用了最近邻(nearest neighbors)的思想。</p>
<h4 id="k-means的优缺点"><a href="#k-means的优缺点" class="headerlink" title="k-means的优缺点"></a>k-means的优缺点</h4><p>K-Means的主要优点有：<br>1）原理比较简单，实现也是很容易，收敛速度快。<br>2）聚类效果较优。<br>3）算法的可解释度比较强。<br>4）主要需要调参的参数仅仅是簇数k。</p>
<p>K-Means的主要缺点有：<br>1）K值的选取不好把握<br>2）对于不是凸的数据集比较难收敛<br>3）如果各隐含类别的数据不平衡，比如各隐含类别的数据量严重失衡，或者各隐含类别的方差不同，则聚类效果不佳。<br>4）采用迭代方法，得到的结果只是局部最优。<br>5）对噪音和异常点比较的敏感。</p>
<h3 id="层次聚类算法"><a href="#层次聚类算法" class="headerlink" title="层次聚类算法"></a>层次聚类算法</h3><p>根据层次分解的顺序是自底向上的还是自上向下的，层次聚类算法分为凝聚的层次聚类算法和分裂的层次聚类算法。凝聚型层次聚类的策略是先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到所有对象都在一个簇中，或者某个终结条件被满足。<br>算法流程：<br>以采用最小距离的凝聚层次聚类算法为例：<br>(1) 将每个对象看作一类，计算两两之间的最小距离；<br>(2) 将距离最小的两个类合并成一个新类；<br>(3) 重新计算新类与所有类之间的距离；<br>(4) 重复(2)、(3)，直到所有类最后合并成一类。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/12/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/12/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">简历项目介绍</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-12 16:02:14" itemprop="dateCreated datePublished" datetime="2020-02-12T16:02:14+08:00">2020-02-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-26 18:16:34" itemprop="dateModified" datetime="2020-03-26T18:16:34+08:00">2020-03-26</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="智能辅助健身锻炼系统"><a href="#智能辅助健身锻炼系统" class="headerlink" title="智能辅助健身锻炼系统"></a>智能辅助健身锻炼系统</h1><h2 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>本项目（是和深圳趣感科技公司委托下）搭建的一个远程的在线辅助健身锻炼系统，类似于keep软件，但项目核心通过评分机制促进用户的锻炼效果。项目针对的是需要在家完成健身锻炼的人群，通过2D摄像头采集用户的锻炼视频，实时上传到系统的业务后台，利用服务器端提供的姿态估计和行为识别算法，评估用户的锻炼效果，辅助用户在家完成健身锻炼。</p>
<h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>深圳趣感科技公司是开发一款穿戴式跑步训练指导系统，通过传感器采集人体运动数据，对跑步姿态进行科学评估，根据评估结果生成个性化的力量训练和跑姿改善计划，并实时监测训练完成度和质量。<br>深圳趣感科技提供了的一系列标准5-6分钟的锻炼视频，作为锻炼动作的模板。每个动作持续时间是3-5s，</p>
<h2 id="项目架构"><a href="#项目架构" class="headerlink" title="项目架构"></a>项目架构</h2><p>本项目是分模块设计的，前端是网页版智能健身指导平台，结合摄像头采集用户的锻炼视频及标准的锻炼视频和用户锻炼效果的展示。中间是系统的业务后台，负责对视频流数据和姿态数据的处理、封装和转发。最后是服务器端，主要运行姿态估计和行为识别等算法，通过人体关键点评估用户的锻炼效果。</p>
<h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><p>项目的前端是基于vue.js的Element框架搭建，业务后台是基于java的SpringBoot+Mybatis框架；算法层大多基于python实现，主要完成2D的人体姿态估计和基于关键点的行为识别算法。利用openpose获取人体关键点，然后将17个关键点坐标输入HCN网络进行行为分类。在三次准备动作中，若两次动作类别正确，则判断用户开始锻炼。最后采用DTW算法对该段时间内用户锻炼的关键点和正确指导视频的关键点进行匹配，判断用户锻炼的效果。<br>HCN网络一种端到端的共现特征学习框架，其使用了 CNN 来自动地从骨架序列中学习分层的共现特征。我们首先使用核大小为 n×1 的卷积层独立地为每个关节学习了点层面的特征。然后我们再将该卷积层的输出转置，以将关节的维度作为通道。如果一个骨架的每个关节都被当作是一个通道，那么卷积层就可以轻松地学习所有关节的共现。在这个转置运算之后，后续的层分层地聚合来自所有关节的全局特征。通过构建这种结构，在使用7层的网络就能获得较高的行为识别的准确率。<br>共现性：人的某个行为动作常常和骨架的一些特定关节点构成的集合，以及这个集合中节点的交互密切相关。如要判别是否在打电话，关节点“手腕”、“手肘”、“肩膀”和“头”的动作最为关键。我们将这种几个关节点同时影响和决定判别的特性称为共现性。</p>
<h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><p>（1）结合openpose和基于骨骼的行为识别算法，实现了真实场景下具有较高鲁棒性的动作分类及评估。（2）算法层与平台之间的视频通信采用redis的消息中间件，采用发布/订阅模式为不同的任务订阅不同channel，实行并行的任务处理。（3）算法模块中行为识别算法创新主要体现在论文中，我可以给你详细介绍一下我的论文。</p>
<h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2><p>遇到的最大的问题是什么？怎么解决的？学到了什么？<br>项目遇到的最大问题是系统方案的设计，针对项目的需求，实时的姿态估计前后端、服务器间的通信机制的实现，单一动作样本实现动作评估的算法模型选择等等，都花费大量的时间进行前期的项目调研，查询相关的资料文献、咨询有开发经验的师兄们后才最终明确系统的设计方案。<br>系统后台和服务器端间的通信，为了满足项目的实时性需求，采用redis做二者的消息中间件，利用redis的发布/订阅模式，完成图像信息的传输。<br>在这次的项目中，培养了我对现有资料的总结和应用能力，对系统方案宏观考虑和设计的能力，以及在团队合作时成员间协作配合的能力。</p>
<h2 id="项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？"><a href="#项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？" class="headerlink" title="项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？"></a>项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？</h2><p>项目是四个人的团队。主要从功能模块和时间线规划项目。功能模块分为三个部分，主要是前端、后台和算法模块。前端和后台各安排一位同学完成，还有两个同学专注于算法模块的设计，分别负责姿态估计和行为识别算法。在时间上主要是半个月的调研以及和客户的沟通、方案的设计。然后是两个月的系统框架的初步搭建，以及最后三个月的界面调整和算法优化。</p>
<h2 id="项目最大的收获是什么？"><a href="#项目最大的收获是什么？" class="headerlink" title="项目最大的收获是什么？"></a>项目最大的收获是什么？</h2><p>在完整负责了一个项目设计和开发过程后，培养了我对现有资料的学习、总结和应用能力，对系统方案宏观考虑和设计的能力，以及在团队合作时成员间任务分配和协作配合能力。</p>
<h2 id="项目的后期扩展有哪些？"><a href="#项目的后期扩展有哪些？" class="headerlink" title="项目的后期扩展有哪些？"></a>项目的后期扩展有哪些？</h2><p>项目后期扩展可以从功能角度考虑，比如和专业健身教练合作为每个用户定制个性化的健身计划，通过系统评分有效促进健身锻炼。从算法层面考虑，通过更细粒度的标注信息，如动作锻炼的次数，关节角度等，提高动作评估的多样性和科学性。</p>
<h2 id="选取openpose的指标？为什么采用openpose"><a href="#选取openpose的指标？为什么采用openpose" class="headerlink" title="选取openpose的指标？为什么采用openpose?"></a>选取openpose的指标？为什么采用openpose?</h2><p>使用姿态估计算法时，主要考虑了openpose和alphapose两种技术，在准确率和速度上，openpose达到60mAP和10FPS，alphapose达到71mAP和20FPS，二者性能差距不大，但从系统的后期扩展性考虑，使用openpose可以估计半身或局部的人体姿态，便于系统功能扩展。<br>采用openpose的最大原因是视频数据单一，只有单人的标准健身视频，在通过深度学习判断动作类别时存在大量的背景干扰，采用姿态估计获得人体的关键点进行动作评估，可以有效减低背景干扰，增强系统的鲁棒性。</p>
<h2 id="动作相似度是怎么判断的？动作时间规划在项目中如何实现？"><a href="#动作相似度是怎么判断的？动作时间规划在项目中如何实现？" class="headerlink" title="动作相似度是怎么判断的？动作时间规划在项目中如何实现？"></a>动作相似度是怎么判断的？动作时间规划在项目中如何实现？</h2><p>DTW动态时间规划，可以计算两个时间序列的相似度，尤其适合用于不同长度、不同节奏的时间序列。DTW将自动对时间序列进行缩放，使得两个序列的形态尽可能一致，得到最大可能的相似度。<br>我们假设用户的动作序列为Q和标准的锻炼动作序列为C，其中Q和C分别代表动作开始到结束期间人体的关键点坐标序列，即序列中的每一时刻都是由人体的17个关键点的坐标构成，标准动作序列事先通过openpose采集存放在数据库，根据行为识别判断的人体动作类别来获取，所有的人体关键点的空间坐标转换为相对人体的重心位置的相对坐标。动作匹配就转化为比较在动作发生时间内用户动作的关键点序列与标准模板的关键点序列的相似度进行评分。我们需要构造一个nxm的矩阵网格，n和m分别表征两段动作序列的长度。矩阵元素(i, j)表示两段动作序列qi和cj两帧的空间距离d(qi, cj)（每一帧都是在计算17个对应的人体关键点空间距离，也就是序列Q的每一个点和序列C的每一个点之间的相似度，距离越小则相似度越高。）。从开始时间匹配这两个动作序列Q和C，每经过一帧，之前所计算的空间距离都会累加。到达终点(n, m)后，这个累积距离就是我们上面说的最后的总的距离，也就是序列Q和C的相似度。通过使累积的距离最小，来判断两动作序列的最大可能相似度。</p>
<h1 id="电信亿迅智慧安防系统"><a href="#电信亿迅智慧安防系统" class="headerlink" title="电信亿迅智慧安防系统"></a>电信亿迅智慧安防系统</h1><h2 id="项目介绍-1"><a href="#项目介绍-1" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>北邮和电信集团亿迅公司合作的智慧安防系统，系统采用基于深度学习的目标检测算法，对场景中的人脸和人体进行结构化分析和特征提取，分析人员的头部特征和穿着特征以及运动特征。</p>
<h2 id="主要工作"><a href="#主要工作" class="headerlink" title="主要工作"></a>主要工作</h2><p>主要负责多目标跟踪模块，采用YoloV3算法检测出人体位置，利用deepsort算法进行在线的多目标追踪。</p>
<h1 id="国家电网能力开放平台（项目核心成员）"><a href="#国家电网能力开放平台（项目核心成员）" class="headerlink" title="国家电网能力开放平台（项目核心成员）"></a>国家电网能力开放平台（项目核心成员）</h1><h2 id="项目介绍-2"><a href="#项目介绍-2" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>北邮与国家电网电车公司合作的，面向服务提供方ISP和应用开发方ISV设计开发的能力开放平台，能有效整合服务资源，通过能力开放的形式吸引服务提供商在平台完成注册、发布API，并与应用开发方建立商业联系。平台则需完成对ISP、ISV的服务监管和计量计费。</p>
<h2 id="项目架构-1"><a href="#项目架构-1" class="headerlink" title="项目架构"></a>项目架构</h2><p>基于微服务架构设计，分为协议转换模块、控制接入模块和平台管理模块。</p>
<h2 id="主要工作-1"><a href="#主要工作-1" class="headerlink" title="主要工作"></a>主要工作</h2><p>主要负责与国家电网南瑞子公司进行需求对接，并且主导了整体架构微服务的设计，完成了“协议转换模块”、“流量控制模块”、“权限管理模块”和“计费管理模块”的设计与实现。<br>1）协议转换模块：因为系统之间通信使用的基于阿里的HSF通信协议，所以需要将http接口转换为hsf需要的接口样式，对于用户的http调用，采用Spring AOP做了一个拦截，具体采用的Around方法，在调用之前，调用之中，调用之后分别对请求做了一些操作。<br>2）接入控制模块：对应协议控制模块中的拦截之前，对用户请求做了：鉴权、流控。在请求之后，做了计量计费操作。<br>鉴权：用户表，角色表，权限表，可见的菜单表，页面元素、文件表。<br>限流：基于Redis+Lua脚本，实现了基于固定时间分片的分布式限流。（1）通过spring AOP方法拦截的用户请求中获得用户调用的appid和apiid。根据appid和apiid组合的key值，在redis缓存中查找用户的流量控制策略。 （2）将appid、apiid和当前时间戳组合作为key值，将最大访问次数作为value值存入redis中，用户调用一次接口，将value值加一，在限制时间内达到最大次数，返回-1，否则返回+1，根据返回的状态对请求进行放行或拒绝。（3）Redis中不存在该流控策略，根据apiid从数据库中查找对应的流量控制策略，并将appid和apiid作为key值，流控策略作为value值存入redis中，并执行一次方法（2）。<br>计费：采用是工厂模式，产生三种计费方式：“按照时间计费（包年包月）”、“按照流量计费”、“按照次数计费”。</p>
<h2 id="亮点："><a href="#亮点：" class="headerlink" title="亮点："></a>亮点：</h2><p>设计模式：<br>1）代理模式：协议转换和访问控制模块之间采用了代理模式，整个协议控制模块都相当于中介。使用了AOP对原始方法做了处理，AOP本身利用反射对目标方法使用了动态代理模式。<br>2）策略模式：定义一系列控制算法，并且使得他们之间可以互换。访问控制模块使用该设计模式，分为“正常状态下的访问”和“测试状态下的访问”，这两种不同的状态，包含了不同的控制策略。“正常状态下的访问”：鉴权、流控、计费，“测试状态下的访问”：鉴权、流控，不包计费。利用Spring将这些策略注入到不同的List中，然后依次进行调用。<br>3）工厂模式：将“包年包月计费”、“按照流量计费”、“按照次数计费”实现同一个接口，并用工厂类，利用反射来调用这些计费方式。<br>微服务：<br>多个模块独立部署：对于不同的模块，进行不同方向上的拓展。项目中：协议转换模块承载最大的用户接入，需要做X轴拓展，通过负载均衡，对请求进行分发。而访问控制模块则分为不同的小模块，可以做数据库的Y轴上业务的拓展（功能性拆分）。可以按照服务队硬件资源不同的需求进行升级！<br>模块解耦，本项目是采用基于RPC的HSF协议进行模块之间的通信，面向连接。HSF是阿里内部使用的模块间通信方式。在调通分布式模块之间通信的遇到过一个比较大的问题，后来通过分析Edas平台各个服务器IP地址和服务端口以及redis日志文件，判断到最后是因为一个模块之间的redis地址出错导致没有启动redis，引发的后续通信的问题，体现了排错能力和自主解决问题的能力。</p>
<h1 id="2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别"><a href="#2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别" class="headerlink" title="2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别"></a>2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别</h1><h2 id="项目介绍-3"><a href="#项目介绍-3" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>在铝型材的实际生产过程中，由于各方面的影响，铝型材表面会产生<br>裂纹、起皮、划伤等瑕疵，影响铝型材的质量。为保证产品质量，需要人工进行肉眼目测。然而，铝型材的表面自身会含有纹路，与瑕疵的区分度不高。传统人工肉眼检查十分费力，不能及时准确的判断出表面瑕疵，质检的效率难以把控。铝型材制造商迫切希望采用最新的AI技术来革新现有质检流程，自动完成质检任务，减少漏检发生率，提高产品的质量。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>瑕疵类型：不导电、檫花、角位漏底、桔皮、漏底、喷流、漆泡、起坑、杂色和脏点10类。训练时加上“正常”类别和“其他”类别一共12类。<br>初赛数据量：3000张图片，包含所有的瑕疵类型。初赛的图片结果为单标签的，即一张图片只有一种瑕疵。“其他”的类别文件夹中瑕疵初赛不要求细分，只是统一划分为一类。<br>初赛是分类任务，初赛提交的文件是csv文件，只需要提交测试集中图片名称和对应的类别标签。<br>分辨率统一为2056x1920<br>训练集：guangdong_round1_train1_20180903，约240M，约250张图片<br>guangdong_round1_train2_20180916，约1G。<br>分为无瑕疵图片1018张，和有瑕疵图片1120张<br>测试集：a榜：guangdong_round1_test_a_20180916，约384兆，440张图片<br>b榜：guangdong_round1_test_b_20181009，约825兆，1000张图片。<br>复赛图片大约有4356张图片，包含单瑕疵图片、多瑕疵图片和无瑕疵图片。单瑕疵图片指所含瑕疵类型只有一种的图片，但图片中可能出现多处相同类型的瑕疵；多瑕疵图片指所含瑕疵类型多于一种的图片；无瑕疵图片指瑕疵可忽略不计的图片，这些图片不需要标注。<br>复赛是检测任务，需要检测测试集中每幅图像所有瑕疵的位置和类型，瑕疵的位置通过矩形检测框进行标记，需给出各个矩形检测框的置信度，并将检测结果保存为utf-8编码的json文件。<br>训练集：guangdong_round1_train2_20181011，约6G，分为单瑕疵图片2776张，多瑕疵图片229张和无瑕疵图片1351张。<br>测试集：a榜：guangdong_round2_test_a_20181011，约420M，500张图片<br>b榜：guangdong_round2_test_b_20181106，约841M，1000张图片</p>
<h2 id="比赛内容"><a href="#比赛内容" class="headerlink" title="比赛内容"></a>比赛内容</h2><p>在给定的生产线上铝型材监测影像上标注出瑕疵的位置并判断瑕疵类型。在前期的数据统计中，我们发现瑕疵的IOU占比小于0.1的样本数量占总体的63%左右，但还有5%的数据IOU占比达到0.7-0.8左右。样本数据存在瑕疵的尺寸大小变化大，两极分化严重，且微小瑕疵的样本数量多等问题。针对瑕疵的长宽比例不均匀，我们首先采用faster R-CNN来适应更多的长宽比，并采用resnet101作为骨干网络减少漏检的概率。针对微小瑕疵样本数量多的问题，我们采用特征金字塔网络（FPN）来对网络进行改进，并进一步采用ROIAlign替换ROIPooling，来提高小目标的检测效果。在训练过程中，我们使用数据增强和多尺度训练的方法，提高了模型的泛化能力及稳定性。在测试阶段，我们采用soft NMS替换NMS，实现更精细的回归框，提高检测结果。</p>
<h2 id="方案设计"><a href="#方案设计" class="headerlink" title="方案设计"></a>方案设计</h2><p>在前期的数据统计过程中，我们发现瑕疵的IOU占比小于0.1的数量占到总体的60%，但还有5%左右的数据主要是IOU占比达到0.7-0.8左右。瑕疵的矩形框尺寸大小变化大，两极分化严重，而且微小瑕疵的样本数量多。针对瑕疵的长宽比例不均匀，我们采用faster R-CNN两阶段来适应更多的长宽比。在单模的网络中我们首先会将图片缩小两倍之后才作为网络的输入。主干网络选取的是Resnet-101，在整个卷积的过程中，提取到特征的大小相对于输入图片是缩小了16倍。也就是说，从原图到最后一层的卷积特征，空间大小一共下降了32倍。 由于之后每一个候选框特征会被缩放到7x7的大小，如果说本身缩放前的特征就非常的小，那么缩放之后的特征是不具有判别力的。我们统计了一下数据集中边长&lt;=64的样本，发现这类小样本占了整个数据集的10%，这会严重地影响性能。为了解决这个问题，我们采用了特征金字塔结构(FPN)来对网络进行改进。把高层特征做2倍上采样（最近邻上采样），然后将其和对应的前一层特征结合（前一层要经过$1\times 1$的卷积核才能用，目的是改变channels,使之和后一层的channels相同），结合方式就是element-wise相加的操作。最后，使用$3\times 3$的卷积核去处理已经融合的特征图（为了消除上采样的混叠效应），以生成最后需要的特征图。我们总结了一下，特征金字塔在这个任务中具有两个优点：第一，在卷积神经网络中，高层的特征具有强的语义信息，低层的特征具有结构信息，因此 将高低层的信息进行结合，是可以增强特征的表达能力的。第二，我们将候选框产生和提取特征的位置分散到了特征金字塔的每一层，这样可以增加小目标的特征映射分辨率，对最后的预测也是有好处的。<br><img src="/images/faster rcnn+fpn.png" alt="Faster RCNN+FPN网络"><br>考虑到模型训练时间，实际的资源消耗以及网络的性能，采用多尺度训练，一方面增强了网络在多个尺度上的表现能力，另一方面提升了模型的泛化能力及稳定性。预先定义几个固定的尺度[(960,1024),(720,960),(640,800)]，每个epoch随机选择一个尺度进行训练。<br>考虑到小瑕疵的定位不准确导致误检，采用RoiAlign替代RoiPooling，取消量化误差，即遍历每一个候选区域，保持浮点数边界不做量化；将候选区域分割成$k\times k$个单元，每个单元的边界也不做量化；从而将整个特征聚集过程转化为一个连续的操作来细化检测框。<br>在测试阶段采用soft NMS替换NMS精细化检测框。<br>NMS：候选框的得分进行排序，选取得分最高的那个框，接下来计算其他框与当前框的重合程度(IOU)，如果重合程度大于一定的阈值就删除，这样不停的迭代下去就会得到所有想要找到的目标物体的区域。<br>而soft nms只是将重叠度大于一定的阈值进行抑制，最后再按分数过滤，从而使得重叠的物体被更大程度的保留下来。</p>
<h1 id="论文《基于注意增强的密集图卷积网络的人体行为识别》"><a href="#论文《基于注意增强的密集图卷积网络的人体行为识别》" class="headerlink" title="论文《基于注意增强的密集图卷积网络的人体行为识别》"></a>论文《基于注意增强的密集图卷积网络的人体行为识别》</h1><h2 id="论文介绍"><a href="#论文介绍" class="headerlink" title="论文介绍"></a>论文介绍</h2><p>论文的研究方向是基于骨骼关键点的人体行为识别，是对视频中人体动作进行分类。论文的创新点主要有两点，首先现有的分层图卷积网络在聚合节点更宽范围的领域信息时，在长期扩散中弱化了局部邻域的特征，针对这个问题，我们提出了残差图卷积操作，增强局部领域的特征，接着利用密集连接结合通道注意模块重用不同模块间的上下文信息，增强节点的全局和局部特征。其次，在现有的算法认为所有的节点和帧信息对行为的判断具有相同的贡献，但是视频序列中存在大量的冗余的信息干扰模型的判断，带来准确率的下降，因此我们引入注意模块，通过计算不同特征间的相关性，增强有效的特征，抑制无关的特征。</p>
<h2 id="创新点-1"><a href="#创新点-1" class="headerlink" title="创新点"></a>创新点</h2><p>残差图卷积操作，原始的图卷积操作层间传播可简化为$X^{l+1}=\delta(W^lX^lA)$，图中的邻接矩阵是根据拓扑结构预先设置的，我们认为邻接矩阵也是可以通过网络来自动学习的，为邻接矩阵中的每个元素都设置一个权重，我们提出$X^{l+1}=\delta(W^lX^l(A\cdot M)+X^l)$，使网络在学习一般的权重矩阵W外，还要学习一个邻接矩阵的权重矩阵M，使得网络可以学习节点更多的局部领域特征。并且我们将短连接将输入和输出进行逐元素求和，使得网络在聚合更宽范围领域的信息时也能更好的保留局部信息。<br>密集连接，网络的结构类似于densenet模型，和densenet将不同模块的信息在channel通道concate来重用上下文特征不同，在密集连接的图卷积网络中结合通道注意模块将不同模块的上下文信息逐元素求和，来降低图卷积网络层数过深容易梯度消失带来的影响，从而增强了节点的全局和局部特征。<br>注意模块，主要分为channel attention module和spatial-temporal attention module。通道注意模块主要是计算不同特征通道间的相关性，把重要的特征进行增强，结合密集连接可以有效增强上下文的时空特征。时空注意模块是计算不同节点和不同帧间的相关性，和通道注意模块不同，我们认为关节的重要性和时间是耦合关系，因此我们联合关节维度和时间维度来计算模块间的相关性，增强关键帧和关键关节的信息。<br>多流信息融合，通过关节信息计算人体骨架的二阶骨骼信息和运动信息，可以有效的补充单模态信息的不足，促进行为识别的准确率。</p>
<h1 id="基于机器学习的多模态手势识别算法研究与实现"><a href="#基于机器学习的多模态手势识别算法研究与实现" class="headerlink" title="基于机器学习的多模态手势识别算法研究与实现"></a>基于机器学习的多模态手势识别算法研究与实现</h1><h2 id="项目介绍-4"><a href="#项目介绍-4" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>本科毕设项目，选取美国手势语言数据集ASL为研究对象，研究基于卷积神经网络的手势图像处理和识别方法，主要的研究多模态的手势识别方法。基于RGB图像和深度图像的联合使用，能有效提高手势识别的准确率。</p>
<h2 id="项目内容"><a href="#项目内容" class="headerlink" title="项目内容"></a>项目内容</h2><p><a href="http://www.kevinlt.top/2018/10/23/hand_segment/" target="_blank" rel="noopener">手部区域分割</a><br>首先是手部区域的分割，将RGB图像转换到YCrCb颜色空间下，其Y通道表示明亮度，即灰阶值；Cr，Cb通道则表示色度，用于描述色彩及饱和度，其中Cr反映了图像信号红色部分与亮度值之间的差异，而Cb反应信号中蓝色部分与亮度之间的差异。在Cr通道下，手部区域和其他区域有较大差别，利用该特性对手部区域进行分割。采用Ostu阈值分割，将手部的前景区域提取出来。对于存在的一些噪声，通过先腐蚀再膨胀操作，可以去除其中的一些毛边。去除毛边后我们从中挑选出最大的contour，基本可以得到手部的前景区域。其次，上述的算法在存在人脸肤色干扰时，不能得到干净的手部区域，故采用深度图像来去除人脸肤色的干扰。将提取的人体肤色的mask和深度图像相乘，去除背景的干扰，然后利用k-means聚类算法从深度图像中分离出人脸区域的位置，只保留手部的区域。将手部的mask和RGB图像相乘，然后利用VGG16网络进行手势动作的分类，有效提高了手势识别的精确性和鲁棒性。<br>Ostu算法：假定图像包含两类像素（前景像素和背景像素），直方图为双峰直方图，然后计算使得两类像素能分开的最佳阈值（类内方差），或等价的间类间方差最大。</p>
<h1 id="自我介绍"><a href="#自我介绍" class="headerlink" title="自我介绍"></a>自我介绍</h1><p>（一分钟版本）<br>您好，很感谢你在百忙中抽出时间给我这次面试的机会。我叫高信凯，今年25岁，是北京邮电大学信息与通信工程专业2018级硕士研究生，想要应聘的职位是xxx。本科阶段由于我保送到北邮读研究生，在毕设期间参加了实验室关于手势识别方面的项目，坚定了我从事这方面工作的决心。在2018年9月份我和同学组队参加了天池的铝材瑕疵检测比赛，激烈的比赛使我对视觉领域有了更深入的认识和了解。后来我开始负责实验室的智能辅助健身锻炼系统的项目，参与并完成了整个平台的设计和搭建过程，在深入的研究过程中进一步发掘出自己的研究方向，因此我决定将计算机视觉方向作为我未来事业的起点。我非常喜欢贵公司的这个职位，相信它能充分满足我的兴趣并体现自身的价值，我也有信心有能力做好这份工作。非常感谢贵公司给与我这次面试学习的机会，谢谢。<br>（简短版本）<br>您好，我叫高信凯，今年25岁，是北京邮电大学信息与通信工程专业2018级硕士研究生，想要应聘的职位是xxx。我非常喜欢贵公司的这个职位，相信它能充分满足我的兴趣并体现自身的价值，我也有信心有能力做好这份工作。非常感谢贵公司给与我这次面试学习的机会，谢谢。</p>
<h1 id="平常如何学习"><a href="#平常如何学习" class="headerlink" title="平常如何学习"></a>平常如何学习</h1><p>在研究生阶段，除了学科知识的学习外，在课余阶段我通常以问题导向型进行知识的积累。比如在学习视觉算法中分类问题的时候，我先开始了解经典的网络模型，学习不同的网络模型的思路及创新点，然后查阅各种资料论文关注模型的参数设置，损失函数的收敛等等知识，从而是自己能够高效的学习该方面的知识。</p>
<h1 id="上过哪些CV课程"><a href="#上过哪些CV课程" class="headerlink" title="上过哪些CV课程"></a>上过哪些CV课程</h1><p>研究生课程：视频大数据的机器学习、模式识别与机器学习、神经网络与模糊系统、图像分析与机器视觉<br>自学课程：吴恩达教授的CS229网课、李飞飞教授的CS231n网课。</p>
<h1 id="项目中遇到的重大问题"><a href="#项目中遇到的重大问题" class="headerlink" title="项目中遇到的重大问题"></a>项目中遇到的重大问题</h1><p>在完成国家电网能力开发平台时，由于项目是采用的基于RPC的 HSF协议进行模块之间的通信。HSF是阿里内部使用的模块间通信的方式，我之前没有使用过，通过短期的学习能力，调通分布式模块之间通信的问题，在这个项目即将上线部署的时候，我们需要到电网公司内部进行压力测试，我遇到的比较大的一个难题是项目上线部署后各个模块之间无法通信。最后通过分析Edas平台各个服务IP地址和服务端口，以及redis日志文件，判断到最后是因为一个模块之中的redis地址出错导致没有启动redis。引发的后续通信的问题。体现了排错能力和自主解决问题的能力。</p>
<h1 id="项目如何跟别人合作"><a href="#项目如何跟别人合作" class="headerlink" title="项目如何跟别人合作"></a>项目如何跟别人合作</h1><p>在项目合作过程中，小组成员集体讨论项目需求，提出具体的项目方案后，根据每人的研究方向和动手能力分配工作量，并统一使用github进行代码的托管和维护。</p>
<h1 id="有什么想问的（一面、二面、三面分别问什么）"><a href="#有什么想问的（一面、二面、三面分别问什么）" class="headerlink" title="有什么想问的（一面、二面、三面分别问什么）"></a>有什么想问的（一面、二面、三面分别问什么）</h1><p>请问我应聘的这个职位所在团队面对着怎样的问题和挑战？另外，贵公司对这个职务有怎样的期待呢？<br>在刚入职的两三个月里，公司更希望这个岗位的信任把工作重心放在哪个方向呢？<br>公司针对实习生的培养机制是怎样的呢？团队的技术栈是什么样的？在去实习前应该重点学习哪些技术呢？</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/11/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D%EF%BC%88%E8%AF%A6%E7%BB%86%E7%89%88%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/11/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D%EF%BC%88%E8%AF%A6%E7%BB%86%E7%89%88%EF%BC%89/" class="post-title-link" itemprop="url">简历项目介绍（详细版）</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-11 09:07:30" itemprop="dateCreated datePublished" datetime="2020-02-11T09:07:30+08:00">2020-02-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-07 09:30:08" itemprop="dateModified" datetime="2020-03-07T09:30:08+08:00">2020-03-07</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="基于姿态估计的康复健身平台"><a href="#基于姿态估计的康复健身平台" class="headerlink" title="基于姿态估计的康复健身平台"></a>基于姿态估计的康复健身平台</h1><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul>
<li>系统架构<ul>
<li>前端设计</li>
<li>后台架构</li>
</ul>
</li>
<li>算法模块<ul>
<li>2D姿态估计</li>
<li>3D姿态估计</li>
<li>动作识别</li>
</ul>
</li>
</ul>
<h2 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>本项目来源是北京邮电大学的创新创业项目，主要目的是为了搭建基于人体姿态估计算法的平台，为用户在家中使用普通的2D摄像头，辅助进行健身和康复训练提供检测和指导。</p>
<h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p><img src="/images/system.jpg" alt="系统架构"><br>摄像头采集图片，每秒采集10帧，将视频帧(600, 400)转为base64编码格式，和用户的user-token、任务的task-id一起封装成Json对象。然后通过stomp通信协议，利用activemq消息中间件进行前端和后台之间的信息传递。前端模拟生产者发送消息，通过设定的topics发送到对应的队列Queues中。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> client, destination, login, passcode;</span><br><span class="line">url = <span class="string">"ws://10.103.238.165:61614"</span>;</span><br><span class="line">destination = <span class="string">"/queue/video"</span>;</span><br><span class="line">login = <span class="string">"admin"</span>;</span><br><span class="line">passcode = <span class="string">"password"</span>;</span><br><span class="line"></span><br><span class="line">client = Stomp.client(url);</span><br><span class="line"><span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">timer = setInterval(</span></span><br><span class="line"><span class="string">            function () &#123;</span></span><br><span class="line"><span class="string">                ctx.drawImage(video, 0, 0, 600, 400);</span></span><br><span class="line"><span class="string">                var data = canvas.toDataURL('</span>image/jpeg<span class="string">', 1.0);    //将获取到的图像转换为base64编码</span></span><br><span class="line"><span class="string">                //newblob = dataURItoBlob(data);</span></span><br><span class="line"><span class="string">                //添加状态判断，当为OPEN时，发送消息</span></span><br><span class="line"><span class="string">                //var message = &#123;&#125;;</span></span><br><span class="line"><span class="string">                client.send(destination, &#123;'</span>user-token<span class="string">': 123, '</span>task<span class="string">': 0x01&#125;, data);//发送消息, 0x02 -&gt; 0000 0010</span></span><br><span class="line"><span class="string">                //接收图片时间</span></span><br><span class="line"><span class="string">                var timestamp = new Date().getTime();</span></span><br><span class="line"><span class="string">            &#125;, 100);</span></span><br></pre></td></tr></table></figure><br>后台是是SpringBoot+Mybatis框架搭建，通过模拟一个消费者，应用监听器监听消息。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@JmsListener</span>(destination = <span class="string">"video"</span>,containerFactory = <span class="string">"jmsListenerContainerQueue"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processImage</span><span class="params">(Message message)</span> </span>&#123;</span><br><span class="line"><span class="comment">//      if (message instanceof BytesMessage) &#123;</span></span><br><span class="line">            BytesMessage bytesMessage = (BytesMessage)message;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 得到一些参数：</span></span><br><span class="line">                String user_token = String.valueOf(bytesMessage.getByteProperty(<span class="string">"user-token"</span>));  <span class="comment">// user-token</span></span><br><span class="line">                String task = String.valueOf(bytesMessage.getByteProperty(<span class="string">"task"</span>));               <span class="comment">// task</span></span><br><span class="line">                String image_base64 =<span class="string">""</span>;                                            <span class="comment">// origin image</span></span><br><span class="line">                UUID uuid= UUID.randomUUID();</span><br><span class="line">                String imageID = uuid.toString();                                   <span class="comment">// imageID</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>*<span class="number">1024</span>];</span><br><span class="line">                <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">while</span>((len=bytesMessage.readBytes(buffer))!=-<span class="number">1</span>)&#123;</span><br><span class="line">                    image_base64 = <span class="keyword">new</span> String(buffer,<span class="number">0</span>,len);</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                Jedis jedis = jedisPool.getResource();</span><br><span class="line">                Map&lt;String,String&gt; imageData = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">                imageData.put(<span class="string">"imageID"</span>,imageID);</span><br><span class="line">                imageData.put(<span class="string">"userToken"</span>,user_token);</span><br><span class="line">                imageData.put(<span class="string">"taskList"</span>,task);</span><br><span class="line">                imageData.put(<span class="string">"image"</span>,image_base64);</span><br><span class="line"></span><br><span class="line">                JSONObject jsonObject = JSONObject.fromObject(imageData);</span><br><span class="line"></span><br><span class="line"><span class="comment">//              比较task列表并分发存入对应的redis的list</span></span><br><span class="line">                <span class="keyword">int</span> taskToDo = Integer.parseInt(task);</span><br><span class="line">                <span class="keyword">if</span>((taskToDo&amp;<span class="number">0x01</span>)&gt;<span class="number">0</span>) &#123; <span class="comment">//pose</span></span><br><span class="line">                    jedis.rpush(<span class="string">"image_queue_to_pose_estimation"</span>, jsonObject.toString());</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>((taskToDo&amp;<span class="number">0x02</span>)&gt;<span class="number">0</span>)&#123; <span class="comment">//face</span></span><br><span class="line">                    jedis.rpush(<span class="string">"image_queue_to_face_recognition"</span>, jsonObject.toString());</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>((taskToDo&amp;<span class="number">0x04</span>)&gt;<span class="number">0</span>)&#123; <span class="comment">//object</span></span><br><span class="line">                    jedis.rpush(<span class="string">"image_queue_to_object_recognition"</span>, jsonObject.toString());</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">//手动释放资源，不然会因为jedisPool里面的maxActive=200的限制，只能创建200个jedis资源。</span></span><br><span class="line">                jedis.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (JMSException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><br>后台将前端发送的Json对象解析出来，为了保证每张图片不重复，使用UUID随机生成图片ID(image_id)，将image_id、user_token、task_id和image_base64放入Hashmap中，转成Json对象存入redis中，通过redis的发布/订阅模式，和服务器算法进行信息传输。算法一直运行在服务器上，订阅redis的频道channel，来监听redis中存储的消息。将消息中的Json对象解析出来后，将base_64编码的图片数据解码转变成numpy矩阵类型，送入深度学习模型，将得到的human对象的list,human对象里包含BodyParts，是每个对象的x,y坐标和置信度值。然后human对象封装成Json对象，通过发布新的通道存储在redis中，业务后台同样订阅该通道，将算法模块返回的结果通过websocket方式提供给前端展示。</p>
<h3 id="消息中间件"><a href="#消息中间件" class="headerlink" title="消息中间件"></a>消息中间件</h3><p>消息中间件事一种夸进程的通信方式，这种方式使得系统之间上下游进行了逻辑和物理解耦合。使用消息中间件，在C/S或B/S模型中，请求可以由服务器端主动发起；消息中间件与上下游相对独立，不关心系统的技术架构，更适用于异构系统之间的通信和数据交互。</p>
<ol>
<li>ActiveMQ<br>ActiveMQ支持两种消息队列模型为点对点（Point To Point）模型和发布-订阅（Publisher To Subscriber）模型。其中，点对点模型以queue作为消息的承载，消息生产者发送消息到queue中，然后消费者获取消息。对于已经被消费过的信息，queue中不再存储，虽然支持多个消费者，但一个消息只能被消费一次。发布-订阅模型，以topic承载消息，生产者发布消息到topic中，订阅该topic的多个消费者能同时接收到该消息。消息的两种传送机制为推送和拉取。推送的方式有消息中间件主动将消息发送给消费者，能处理快速即时的消息，但如果消费者处理消息能力较弱，消息推送不断，则有可能造成缓冲区的溢出；拉取的方式由消费者主动向消息中间件拉取信息，会造成消息的部分延迟。</li>
<li>Redis<br>Redis作为key-value内存型存储系统，一般作为缓存中间件使用，在某些场景下也可以作为消息中间件进行数据的缓存和传输。Redis具有基于内存的高速读写特性，支持String、List、Hash、Set、Zset五种类型的操作，支持原子性事务，还具有较为丰富的特性。将Redis作为消息中间件使用，一般利用其列表的数据结构，生产者通过Ipush来发布消息，消费者通过brpop来获取消息。此种实现方式，在Redis宕机且数据没有持久化的情况下可能造成数据的丢失，对于数据可靠性要求不是太高的场景中适用。</li>
</ol>
<h2 id="算法模块"><a href="#算法模块" class="headerlink" title="算法模块"></a>算法模块</h2><h3 id="2D姿态估计"><a href="#2D姿态估计" class="headerlink" title="2D姿态估计"></a>2D姿态估计</h3><p><a href="https://blog.csdn.net/zziahgf/article/details/79643752" target="_blank" rel="noopener">CPM模型</a><br><a href="https://blog.csdn.net/htt789/article/details/80283370" target="_blank" rel="noopener">openpose姿态估计</a><br><a href="https://zhuanlan.zhihu.com/p/66803058" target="_blank" rel="noopener">openpose</a><br><a href="https://blog.csdn.net/young__fan/article/details/90719285" target="_blank" rel="noopener">匈牙利算法</a><br>使用openpose获得人体的18个关键点坐标，然后输入HCN网络进行动作分类，然后使用动态时间规划进行动作匹配。<br>数据集：公司给的健身动作视频，每个动作是3-5s，每组动作锻炼30次，总共进行8组，每段视频都是是单一的健身指导视频。由于视频中只有单一的参与者指导动作，训练数据背景单一，估考虑采用基于骨骼关键点的行为识别。<br>算法流程：<br>1.从redis中读取图片，将base64编码转为矩阵数据<br>2.输入openpose算法，得到人体的18个关键点。<br>BODY_PARTS = { “Nose”: 0, “Neck”: 1, “RShoulder”: 2, “RElbow”:3, “RWrist”: 4, “LShoulder”: 5, “LElbow”: 6, “LWrist”: 7, “RHip”: 8, “RKnee”: 9, “RAnkle”: 10, “LHip”: 11, “LKnee”: 12, “LAnkle”: 13, “REye”: 14, “LEye”: 15, “REar”: 16, “LEar”: 17, “Background”: 18 }<br>3.将得到的17个关键点输入到HCN网络进行动作分类。<br>关键点：在训练动作分类网络时，可以对关键点信息进行数据增强。<br>1)归一化处理，将其他通道求平均，只保留C和V通道求数据的均值和方差，然后对每一个数据进行归一化处理。<br>2）时间片段选取，在150帧时间序列中选择有效的64帧<br>3）坐标旋转变换，随机设一个角度，对构建旋转矩阵，对关键点进行旋转变换。<br>CNN 模型在提取高层面信息方面能力出色，并且也已经被用于根据骨架学习空间-时间特征。这些基于 CNN 的方法可以通过将时间动态和骨架关节分别编码成行和列而将骨架序列表示成一张图像，然后就像图像分类一样将图像输入 CNN 来识别其中含有的动作。但是，在这种情况下，只有卷积核内的相邻关节才被认为是在学习共现特征。尽管感受野（receptive field）能在之后的卷积层中覆盖骨架的所有关节，但我们很难有效地从所有关节中挖掘共现特征。由于空间维度中的权重共享机制，CNN 模型无法为每个关节都学习自由的参数。这促使我们设计一个能获得所有关节的全局响应的模型，以利用不同关节之间的相关性。<br>着眼于人的行为动作的特点，我们将行为动作中关节点具有的共现性特性引入到网络设计中，将其作为网络参数学习的约束来优化识别性能。人的某个行为动作常常和骨架的一些特定关节点构成的集合，以及这个集合中节点的交互密切相关。如要判别是否在打电话，关节点“手腕”、“手肘”、“肩膀”和“头”的动作最为关键。不同的行为动作与之密切相关的节点集合有所不同。例如对于“走路”的行为动作，“脚腕”、“膝盖”、“臀部”等关节点构成具有判别力的节点集合。我们将这种几个关节点同时影响和决定判别的特性称为共现性（Co-occurrence）。<br>我们提出了一种端到端的共现特征学习框架，其使用了 CNN 来自动地从骨架序列中学习分层的共现特征。我们发现一个卷积层的输出是来自所有输入通道的全局响应。如果一个骨架的每个关节都被当作是一个通道，那么卷积层就可以轻松地学习所有关节的共现。更具体而言，我们将骨架序列表示成了一个形状帧×关节×3（最后一维作为通道）的张量。我们首先使用核大小为 n×1 的卷积层独立地为每个关节学习了点层面的特征。然后我们再将该卷积层的输出转置，以将关节的维度作为通道。在这个转置运算之后，后续的层分层地聚合来自所有关节的全局特征。<br><img src="/images/HCN.jpg" alt=""><br>我们提出的分层式共现网络（HCN：Hierarchical Co-occurrence Network）的概况。绿色模块是卷积层，其中最后一维表示输出通道的数量。后面的「/2」表示卷积之后附带的最大池化层，步幅为 2。转置层是根据顺序参数重新排列输入张量的维度。conv1、conv5、conv6 和 fc7 之后附加了 ReLU 激活函数以引入非线性。<br>4.动作匹配，采用动态时间规划（DTW）算法，判断用户的运动视频和标准动作是否匹配。<br><a href="https://zhuanlan.zhihu.com/p/32849741" target="_blank" rel="noopener">DTW介绍</a><br>比较在该段时间内用户的姿态的(x,y)坐标点与标准模板的相似度进行评分。我们需要构造一个nxm的矩阵网格，矩阵元素(i, j)表示qi和cj两个点的距离d(qi, cj)（也就是序列Q的每一个点和序列C的每一个点之间的相似度，距离越小则相似度越高。）我们定义一个累加距离cumulative distances。从(0, 0)点开始匹配这两个序列Q和C，每到一个点，之前所有的点计算的距离都会累加。到达终点(n, m)后，这个累积距离就是我们上面说的最后的总的距离，也就是序列Q和C的相似度。</p>
<script type="math/tex; mode=display">\gamma(i,j)=d(q_i,c_j)+min(\gamma(i-1,j-1),\gamma(i-1,j),\gamma(i,j-1))</script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/10/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/10/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-10 21:46:14" itemprop="dateCreated datePublished" datetime="2020-02-10T21:46:14+08:00">2020-02-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Kay</p>
  <div class="site-description" itemprop="description">千里之行，始于足下</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kay</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.1
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
