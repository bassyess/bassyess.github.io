<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"bassyess.github.io","root":"/","scheme":"Pisces","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="千里之行，始于足下">
<meta property="og:type" content="website">
<meta property="og:title" content="Home">
<meta property="og:url" content="https://bassyess.github.io/page/3/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="千里之行，始于足下">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Kay">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://bassyess.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Home</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Home</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/12/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/12/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">简历项目介绍</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-12 16:02:14" itemprop="dateCreated datePublished" datetime="2020-02-12T16:02:14+08:00">2020-02-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-14 19:21:33" itemprop="dateModified" datetime="2020-03-14T19:21:33+08:00">2020-03-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="智能辅助健身锻炼系统"><a href="#智能辅助健身锻炼系统" class="headerlink" title="智能辅助健身锻炼系统"></a>智能辅助健身锻炼系统</h1><h2 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>本项目（是和深圳趣感科技公司委托下）搭建的一个远程的在线辅助健身锻炼系统，类似于keep软件，但项目核心通过评分机制促进用户的锻炼效果。项目针对的是需要在家完成健身锻炼的人群，通过2D摄像头采集用户的锻炼视频，实时上传到系统的业务后台，利用服务器端提供的姿态估计和行为识别算法，评估用户的锻炼效果，辅助用户在家完成健身锻炼。</p>
<h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>深圳趣感科技公司是开发一款穿戴式跑步训练指导系统，通过传感器采集人体运动数据，对跑步姿态进行科学评估，根据评估结果生成个性化的力量训练和跑姿改善计划，并实时监测训练完成度和质量。<br>深圳趣感科技提供了的一系列标准5-6分钟的锻炼视频，作为锻炼动作的模板。每个动作持续时间是3-5s，</p>
<h2 id="项目架构"><a href="#项目架构" class="headerlink" title="项目架构"></a>项目架构</h2><p>本项目是分模块设计的，前端是网页版智能健身指导平台，结合摄像头采集用户的锻炼视频及标准的锻炼视频和用户锻炼效果的展示。中间是系统的业务后台，负责对视频流数据和姿态数据的处理、封装和转发。最后是服务器端，主要运行姿态估计和行为识别等算法，通过人体关键点评估用户的锻炼效果。</p>
<h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><p>项目的前端是基于vue.js的Element框架搭建，业务后台是基于java的SpringBoot+Mybatis框架；算法层大多基于python实现，主要完成2D的人体姿态估计和基于关键点的行为识别算法。利用openpose获取人体关键点，然后将17个关键点坐标输入HCN网络进行行为分类。在三次准备动作中，若两次动作类别正确，则判断用户开始锻炼。最后采用DTW算法对该段时间内用户锻炼的关键点和正确指导视频的关键点进行匹配，判断用户锻炼的效果。<br>HCN网络一种端到端的共现特征学习框架，其使用了 CNN 来自动地从骨架序列中学习分层的共现特征。我们发现一个卷积层的输出是来自所有输入通道的全局响应。如果一个骨架的每个关节都被当作是一个通道，那么卷积层就可以轻松地学习所有关节的共现。我们首先使用核大小为 n×1 的卷积层独立地为每个关节学习了点层面的特征。然后我们再将该卷积层的输出转置，以将关节的维度作为通道。在这个转置运算之后，后续的层分层地聚合来自所有关节的全局特征。通过构建这种结构，在使用7层的网络就能获得较高的行为识别的准确率。</p>
<h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><p>（1）结合openpose和基于骨骼的行为识别算法，实现了真实场景下具有较高鲁棒性的动作分类及评估。（2）算法层与平台之间的视频通信采用redis的消息中间件，采用发布/订阅模式为不同的任务订阅不同channel，实行并行的任务处理。（3）算法模块中行为识别算法创新主要体现在论文中，我可以给你详细介绍一下我的论文。</p>
<h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2><p>遇到的最大的问题是什么？怎么解决的？学到了什么？<br>项目遇到的最大问题是系统方案的设计，针对项目的需求，实时的姿态估计前后端、服务器间的通信机制的实现，单一动作样本实现动作评估的算法模型选择等等，都花费大量的时间进行前期的项目调研，查询相关的资料文献、咨询有开发经验的师兄们后才最终明确系统的设计方案。<br>系统后台和服务器端间的通信，为了满足项目的实时性需求，采用redis做二者的消息中间件，利用redis的发布/订阅模式，完成图像信息的传输。<br>在这次的项目中，培养了我对现有资料的总结和应用能力，对系统方案宏观考虑和设计的能力，以及在团队合作时成员间协作配合的能力。</p>
<h2 id="项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？"><a href="#项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？" class="headerlink" title="项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？"></a>项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？</h2><p>项目是四个人的团队。主要从功能模块和时间线规划项目。功能模块分为三个部分，主要是前端、后台和算法模块。前端和后台各安排一位同学完成，还有两个同学专注于算法模块的设计，分别负责姿态估计和行为识别算法。在时间上主要是半个月的调研以及和客户的沟通、方案的设计。然后是两个月的系统框架的初步搭建，以及最后三个月的界面调整和算法优化。</p>
<h2 id="项目最大的收获是什么？"><a href="#项目最大的收获是什么？" class="headerlink" title="项目最大的收获是什么？"></a>项目最大的收获是什么？</h2><p>在完整负责了一个项目设计和开发过程后，培养了我对现有资料的学习、总结和应用能力，对系统方案宏观考虑和设计的能力，以及在团队合作时成员间任务分配和协作配合能力。</p>
<h2 id="项目的后期扩展有哪些？"><a href="#项目的后期扩展有哪些？" class="headerlink" title="项目的后期扩展有哪些？"></a>项目的后期扩展有哪些？</h2><p>项目后期扩展可以从功能角度考虑，比如和专业健身教练合作为每个用户定制个性化的健身计划，通过系统评分有效促进健身锻炼。从算法层面考虑，通过更细粒度的标注信息，如动作锻炼的次数，关节角度等，提高动作评估的多样性和科学性。</p>
<h2 id="选取openpose的指标？为什么采用openpose"><a href="#选取openpose的指标？为什么采用openpose" class="headerlink" title="选取openpose的指标？为什么采用openpose?"></a>选取openpose的指标？为什么采用openpose?</h2><p>使用姿态估计算法时，主要考虑了openpose和alphapose两种技术，在准确率和速度上，openpose达到60mAP和10FPS，alphapose达到71mAP和20FPS，二者性能差距不大，但从系统的后期扩展性考虑，使用openpose可以估计半身或局部的人体姿态，便于系统功能扩展。<br>采用openpose的最大原因是视频数据单一，只有单人的标准健身视频，在通过深度学习判断动作类别时存在大量的背景干扰，采用姿态估计获得人体的关键点进行动作评估，可以有效减低背景干扰，增强系统的鲁棒性。</p>
<h2 id="动作相似度是怎么判断的？动作时间规划在项目中如何实现？"><a href="#动作相似度是怎么判断的？动作时间规划在项目中如何实现？" class="headerlink" title="动作相似度是怎么判断的？动作时间规划在项目中如何实现？"></a>动作相似度是怎么判断的？动作时间规划在项目中如何实现？</h2><p>DTW动态时间规划，可以计算两个时间序列的相似度，尤其适合用于不同长度、不同节奏的时间序列。DTW将自动对时间序列进行缩放，使得两个序列的形态尽可能一致，得到最大可能的相似度。<br>我们假设用户的动作序列为Q和标准的锻炼动作序列为C，其中Q和C分别代表动作开始到结束期间人体的关键点坐标序列，即序列中的每一时刻都是由人体的17个关键点的坐标构成，标准动作序列事先通过openpose采集存放在数据库，根据行为识别判断的人体动作类别来获取，所有的人体关键点的空间坐标转换为相对人体的重心位置的相对坐标。动作匹配就转化为比较在动作发生时间内用户动作的关键点序列与标准模板的关键点序列的相似度进行评分。我们需要构造一个nxm的矩阵网格，n和m分别表征两段动作序列的长度。矩阵元素(i, j)表示两段动作序列qi和cj两帧的空间距离d(qi, cj)（每一帧都是在计算17个对应的人体关键点空间距离，也就是序列Q的每一个点和序列C的每一个点之间的相似度，距离越小则相似度越高。）。从开始时间匹配这两个动作序列Q和C，每经过一帧，之前所计算的空间距离都会累加。到达终点(n, m)后，这个累积距离就是我们上面说的最后的总的距离，也就是序列Q和C的相似度。通过使累积的距离最小，来判断两动作序列的最大可能相似度。</p>
<h1 id="电信亿迅智慧安防系统"><a href="#电信亿迅智慧安防系统" class="headerlink" title="电信亿迅智慧安防系统"></a>电信亿迅智慧安防系统</h1><h2 id="项目介绍-1"><a href="#项目介绍-1" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>北邮和电信集团亿迅公司合作的智慧安防系统，系统采用基于深度学习的目标检测算法，对场景中的人脸和人体进行结构化分析和特征提取，分析人员的头部特征和穿着特征以及运动特征。</p>
<h2 id="主要工作"><a href="#主要工作" class="headerlink" title="主要工作"></a>主要工作</h2><p>主要负责多目标跟踪模块，采用YoloV3算法检测出人体位置，利用deepsort算法进行在线的多目标追踪。</p>
<h1 id="国家电网能力开放平台（项目核心成员）"><a href="#国家电网能力开放平台（项目核心成员）" class="headerlink" title="国家电网能力开放平台（项目核心成员）"></a>国家电网能力开放平台（项目核心成员）</h1><h2 id="项目介绍-2"><a href="#项目介绍-2" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>北邮与国家电网电车公司合作的，面向服务提供方ISP和应用开发方ISV设计开发的能力开放平台，能有效整合服务资源，通过能力开放的形式吸引服务提供商在平台完成注册、发布API，并与应用开发方建立商业联系。平台则需完成对ISP、ISV的服务监管和计量计费。</p>
<h2 id="项目架构-1"><a href="#项目架构-1" class="headerlink" title="项目架构"></a>项目架构</h2><p>基于微服务架构设计，分为协议转换模块、控制接入模块和平台管理模块。</p>
<h2 id="主要工作-1"><a href="#主要工作-1" class="headerlink" title="主要工作"></a>主要工作</h2><p>主要负责与国家电网南瑞子公司进行需求对接，并且主导了整体架构微服务的设计，完成了“协议转换模块”、“流量控制模块”、“权限管理模块”和“计费管理模块”的设计与实现。<br>1）协议转换模块：因为系统之间通信使用的基于阿里的HSF通信协议，所以需要将http接口转换为hsf需要的接口样式，对于用户的http调用，采用Spring AOP做了一个拦截，具体采用的Around方法，在调用之前，调用之中，调用之后分别对请求做了一些操作。<br>2）接入控制模块：对应协议控制模块中的拦截之前，对用户请求做了：鉴权、流控。在请求之后，做了计量计费操作。<br>鉴权：用户表，角色表，权限表，可见的菜单表，页面元素、文件表。<br>限流：基于Redis+Lua脚本，实现了基于固定时间分片的分布式限流。（1）通过spring AOP方法拦截的用户请求中获得用户调用的appid和apiid。根据appid和apiid组合的key值，在redis缓存中查找用户的流量控制策略。 （2）将appid、apiid和当前时间戳组合作为key值，将最大访问次数作为value值存入redis中，用户调用一次接口，将value值加一，在限制时间内达到最大次数，返回-1，否则返回+1，根据返回的状态对请求进行放行或拒绝。（3）Redis中不存在该流控策略，根据apiid从数据库中查找对应的流量控制策略，并将appid和apiid作为key值，流控策略作为value值存入redis中，并执行一次方法（2）。<br>计费：采用是工厂模式，产生三种计费方式：“按照时间计费（包年包月）”、“按照流量计费”、“按照次数计费”。</p>
<h2 id="亮点："><a href="#亮点：" class="headerlink" title="亮点："></a>亮点：</h2><p>设计模式：<br>1）代理模式：协议转换和访问控制模块之间采用了代理模式，整个协议控制模块都相当于中介。使用了AOP对原始方法做了处理，AOP本身利用反射对目标方法使用了动态代理模式。<br>2）策略模式：定义一系列控制算法，并且使得他们之间可以互换。访问控制模块使用该设计模式，分为“正常状态下的访问”和“测试状态下的访问”，这两种不同的状态，包含了不同的控制策略。“正常状态下的访问”：鉴权、流控、计费，“测试状态下的访问”：鉴权、流控，不包计费。利用Spring将这些策略注入到不同的List中，然后依次进行调用。<br>3）工厂模式：将“包年包月计费”、“按照流量计费”、“按照次数计费”实现同一个接口，并用工厂类，利用反射来调用这些计费方式。<br>微服务：<br>多个模块独立部署：对于不同的模块，进行不同方向上的拓展。项目中：协议转换模块承载最大的用户接入，需要做X轴拓展，通过负载均衡，对请求进行分发。而访问控制模块则分为不同的小模块，可以做数据库的Y轴上业务的拓展（功能性拆分）。可以按照服务队硬件资源不同的需求进行升级！<br>模块解耦，本项目是采用基于RPC的HSF协议进行模块之间的通信，面向连接。HSF是阿里内部使用的模块间通信方式。在调通分布式模块之间通信的遇到过一个比较大的问题，后来通过分析Edas平台各个服务器IP地址和服务端口以及redis日志文件，判断到最后是因为一个模块之间的redis地址出错导致没有启动redis，引发的后续通信的问题，体现了排错能力和自主解决问题的能力。</p>
<h1 id="2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别"><a href="#2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别" class="headerlink" title="2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别"></a>2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别</h1><h2 id="项目介绍-3"><a href="#项目介绍-3" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>在铝型材的实际生产过程中，由于各方面的影响，铝型材表面会产生<br>裂纹、起皮、划伤等瑕疵，影响铝型材的质量。为保证产品质量，需要人工进行肉眼目测。然而，铝型材的表面自身会含有纹路，与瑕疵的区分度不高。传统人工肉眼检查十分费力，不能及时准确的判断出表面瑕疵，质检的效率难以把控。铝型材制造商迫切希望采用最新的AI技术来革新现有质检流程，自动完成质检任务，减少漏检发生率，提高产品的质量。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>瑕疵类型：不导电、檫花、角位漏底、桔皮、漏底、喷流、漆泡、起坑、杂色和脏点10类。训练时加上“正常”类别和“其他”类别一共12类。<br>初赛数据量：3000张图片，包含所有的瑕疵类型。初赛的图片结果为单标签的，即一张图片只有一种瑕疵。“其他”的类别文件夹中瑕疵初赛不要求细分，只是统一划分为一类。<br>初赛是分类任务，初赛提交的文件是csv文件，只需要提交测试集中图片名称和对应的类别标签。<br>分辨率统一为2056x1920<br>训练集：guangdong_round1_train1_20180903，约240M，约250张图片<br>guangdong_round1_train2_20180916，约1G。<br>分为无瑕疵图片1018张，和有瑕疵图片1120张<br>测试集：a榜：guangdong_round1_test_a_20180916，约384兆，440张图片<br>b榜：guangdong_round1_test_b_20181009，约825兆，1000张图片。<br>复赛图片大约有4356张图片，包含单瑕疵图片、多瑕疵图片和无瑕疵图片。单瑕疵图片指所含瑕疵类型只有一种的图片，但图片中可能出现多处相同类型的瑕疵；多瑕疵图片指所含瑕疵类型多于一种的图片；无瑕疵图片指瑕疵可忽略不计的图片，这些图片不需要标注。<br>复赛是检测任务，需要检测测试集中每幅图像所有瑕疵的位置和类型，瑕疵的位置通过矩形检测框进行标记，需给出各个矩形检测框的置信度，并将检测结果保存为utf-8编码的json文件。<br>训练集：guangdong_round1_train2_20181011，约6G，分为单瑕疵图片2776张，多瑕疵图片229张和无瑕疵图片1351张。<br>测试集：a榜：guangdong_round2_test_a_20181011，约420M，500张图片<br>b榜：guangdong_round2_test_b_20181106，约841M，1000张图片</p>
<h2 id="比赛内容"><a href="#比赛内容" class="headerlink" title="比赛内容"></a>比赛内容</h2><p>在给定的生产线上铝型材监测影像上标注出瑕疵的位置并判断瑕疵类型。在前期的数据统计中，我们发现瑕疵的IOU占比小于0.1的样本数量占总体的63%左右，但还有5%的数据IOU占比达到0.7-0.8左右。样本数据存在瑕疵的尺寸大小变化大，两极分化严重，且微小瑕疵的样本数量多等问题。针对瑕疵的长宽比例不均匀，我们首先采用faster R-CNN来适应更多的长宽比，并采用resnet101作为骨干网络减少漏检的概率。针对微小瑕疵样本数量多的问题，我们采用特征金字塔网络（FPN）来对网络进行改进，并进一步采用ROIAlign替换ROIPooling，来提高小目标的检测效果。在训练过程中，我们使用数据增强和多尺度训练的方法，提高了模型的泛化能力及稳定性。在测试阶段，我们采用soft NMS替换NMS，实现更精细的回归框，提高检测结果。</p>
<h2 id="方案设计"><a href="#方案设计" class="headerlink" title="方案设计"></a>方案设计</h2><p>在前期的数据统计过程中，我们发现瑕疵的IOU占比小于0.1的数量占到总体的60%，但还有5%左右的数据主要是IOU占比达到0.7-0.8左右。瑕疵的矩形框尺寸大小变化大，两极分化严重，而且微小瑕疵的样本数量多。针对瑕疵的长宽比例不均匀，我们采用faster R-CNN两阶段来适应更多的长宽比。在单模的网络中我们首先会将图片缩小两倍之后才作为网络的输入。主干网络选取的是Resnet-101，在整个卷积的过程中，提取到特征的大小相对于输入图片是缩小了16倍。也就是说，从原图到最后一层的卷积特征，空间大小一共下降了32倍。 由于之后每一个候选框特征会被缩放到7x7的大小，如果说本身缩放前的特征就非常的小，那么缩放之后的特征是不具有判别力的。我们统计了一下数据集中边长&lt;=64的样本，发现这类小样本占了整个数据集的10%，这会严重地影响性能。为了解决这个问题，我们采用了特征金字塔结构(FPN)来对网络进行改进。把高层特征做2倍上采样（最近邻上采样），然后将其和对应的前一层特征结合（前一层要经过$1\times 1$的卷积核才能用，目的是改变channels,使之和后一层的channels相同），结合方式就是element-wise相加的操作。最后，使用$3\times 3$的卷积核去处理已经融合的特征图（为了消除上采样的混叠效应），以生成最后需要的特征图。我们总结了一下，特征金字塔在这个任务中具有两个优点：第一，在卷积神经网络中，高层的特征具有强的语义信息，低层的特征具有结构信息，因此 将高低层的信息进行结合，是可以增强特征的表达能力的。第二，我们将候选框产生和提取特征的位置分散到了特征金字塔的每一层，这样可以增加小目标的特征映射分辨率，对最后的预测也是有好处的。<br><img src="/images/faster rcnn+fpn.png" alt="Faster RCNN+FPN网络"><br>考虑到模型训练时间，实际的资源消耗以及网络的性能，采用多尺度训练，一方面增强了网络在多个尺度上的表现能力，另一方面提升了模型的泛化能力及稳定性。预先定义几个固定的尺度[(960,1024),(720,960),(640,800)]，每个epoch随机选择一个尺度进行训练。<br>考虑到小瑕疵的定位不准确导致误检，采用RoiAlign替代RoiPooling，取消量化误差，即遍历每一个候选区域，保持浮点数边界不做量化；将候选区域分割成$k\times k$个单元，每个单元的边界也不做量化；从而将整个特征聚集过程转化为一个连续的操作来细化检测框。<br>在测试阶段采用soft NMS替换NMS精细化检测框。<br>NMS：候选框的得分进行排序，选取得分最高的那个框，接下来计算其他框与当前框的重合程度(IOU)，如果重合程度大于一定的阈值就删除，这样不停的迭代下去就会得到所有想要找到的目标物体的区域。<br>而soft nms只是将重叠度大于一定的阈值进行抑制，最后再按分数过滤，从而使得重叠的物体被更大程度的保留下来。</p>
<h1 id="论文《基于注意增强的密集图卷积网络的人体行为识别》"><a href="#论文《基于注意增强的密集图卷积网络的人体行为识别》" class="headerlink" title="论文《基于注意增强的密集图卷积网络的人体行为识别》"></a>论文《基于注意增强的密集图卷积网络的人体行为识别》</h1><h2 id="论文介绍"><a href="#论文介绍" class="headerlink" title="论文介绍"></a>论文介绍</h2><p>论文的研究方向是基于骨骼关键点的人体行为识别，是对视频中人体动作进行分类。论文的创新点主要有两点，首先现有的分层图卷积网络在聚合节点更宽范围的领域信息时，在长期扩散中弱化了局部邻域的特征，针对这个问题，我们提出了残差图卷积操作，增强局部领域的特征，接着利用密集连接结合通道注意模块重用不同模块间的上下文信息，增强节点的全局和局部特征。其次，在现有的算法认为所有的节点和帧信息对行为的判断具有相同的贡献，但是视频序列中存在大量的冗余的信息干扰模型的判断，带来准确率的下降，因此我们引入注意模块，通过计算不同特征间的相关性，增强有效的特征，抑制无关的特征。</p>
<h2 id="创新点-1"><a href="#创新点-1" class="headerlink" title="创新点"></a>创新点</h2><p>残差图卷积操作，原始的图卷积操作层间传播可简化为$X^{l+1}=\delta(W^lX^lA)$，图中的邻接矩阵是根据拓扑结构预先设置的，我们认为邻接矩阵也是可以通过网络来自动学习的，为邻接矩阵中的每个元素都设置一个权重，我们提出$X^{l+1}=\delta(W^lX^l(A\cdot M)+X^l)$，使网络在学习一般的权重矩阵W外，还要学习一个邻接矩阵的权重矩阵M，使得网络可以学习节点更多的局部领域特征。并且我们将短连接将输入和输出进行逐元素求和，使得网络在聚合更宽范围领域的信息时也能更好的保留局部信息。<br>密集连接，网络的结构类似于densenet模型，和densenet将不同模块的信息在channel通道concate来重用上下文特征不同，在密集连接的图卷积网络中结合通道注意模块将不同模块的上下文信息逐元素求和，来降低图卷积网络层数过深容易梯度消失带来的影响，从而增强了节点的全局和局部特征。<br>注意模块，主要分为channel attention module和spatial-temporal attention module。通道注意模块主要是计算不同特征通道间的相关性，把重要的特征进行增强，结合密集连接可以有效增强上下文的时空特征。时空注意模块是计算不同节点和不同帧间的相关性，和通道注意模块不同，我们认为关节的重要性和时间是耦合关系，因此我们联合关节维度和时间维度来计算模块间的相关性，增强关键帧和关键关节的信息。<br>多流信息融合，通过关节信息计算人体骨架的二阶骨骼信息和运动信息，可以有效的补充单模态信息的不足，促进行为识别的准确率。</p>
<h1 id="基于机器学习的多模态手势识别算法研究与实现"><a href="#基于机器学习的多模态手势识别算法研究与实现" class="headerlink" title="基于机器学习的多模态手势识别算法研究与实现"></a>基于机器学习的多模态手势识别算法研究与实现</h1><h2 id="项目介绍-4"><a href="#项目介绍-4" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>本科毕设项目，选取美国手势语言数据集ASL为研究对象，研究基于卷积神经网络的手势图像处理和识别方法，主要的研究多模态的手势识别方法。基于RGB图像和深度图像的联合使用，能有效提高手势识别的准确率。</p>
<h2 id="项目内容"><a href="#项目内容" class="headerlink" title="项目内容"></a>项目内容</h2><p><a href="http://www.kevinlt.top/2018/10/23/hand_segment/" target="_blank" rel="noopener">手部区域分割</a><br>首先是手部区域的分割，将RGB图像转换到YCrCb颜色空间下，其Y通道表示明亮度，即灰阶值；Cr，Cb通道则表示色度，用于描述色彩及饱和度，其中Cr反映了图像信号红色部分与亮度值之间的差异，而Cb反应信号中蓝色部分与亮度之间的差异。在Cr通道下，手部区域和其他区域有较大差别，利用该特性对手部区域进行分割。采用Ostu阈值分割，将手部的前景区域提取出来。对于存在的一些噪声，通过先腐蚀再膨胀操作，可以去除其中的一些毛边。去除毛边后我们从中挑选出最大的contour，基本可以得到手部的前景区域。其次，上述的算法在存在人脸肤色干扰时，不能得到干净的手部区域，故采用深度图像来去除人脸肤色的干扰。将提取的人体肤色的mask和深度图像相乘，去除背景的干扰，然后利用k-means聚类算法从深度图像中分离出人脸区域的位置，只保留手部的区域。将手部的mask和RGB图像相乘，然后利用VGG16网络进行手势动作的分类，有效提高了手势识别的精确性和鲁棒性。<br>Ostu算法：假定图像包含两类像素（前景像素和背景像素），直方图为双峰直方图，然后计算使得两类像素能分开的最佳阈值（类内方差），或等价的间类间方差最大。</p>
<h1 id="自我介绍"><a href="#自我介绍" class="headerlink" title="自我介绍"></a>自我介绍</h1><p>（一分钟版本）<br>您好，很感谢你在百忙中抽出时间给我这次面试的机会。我叫高信凯，今年25岁，是北京邮电大学信息与通信工程专业2018级硕士研究生，想要应聘的职位是xxx。本科阶段由于我保送到北邮读研究生，在毕设期间参加了实验室关于手势识别方面的项目，坚定了我从事这方面工作的决心。在2018年9月份我和同学组队参加了天池的铝材瑕疵检测比赛，激烈的比赛使我对视觉领域有了更深入的认识和了解。后来我开始负责实验室的智能辅助健身锻炼系统的项目，参与并完成了整个平台的设计和搭建过程，在深入的研究过程中进一步发掘出自己的研究方向，因此我决定将计算机视觉方向作为我未来事业的起点。我非常喜欢贵公司的这个职位，相信它能充分满足我的兴趣并体现自身的价值，我也有信心有能力做好这份工作。非常感谢贵公司给与我这次面试学习的机会，谢谢。<br>（简短版本）<br>您好，我叫高信凯，今年25岁，是北京邮电大学信息与通信工程专业2018级硕士研究生，想要应聘的职位是xxx。我非常喜欢贵公司的这个职位，相信它能充分满足我的兴趣并体现自身的价值，我也有信心有能力做好这份工作。非常感谢贵公司给与我这次面试学习的机会，谢谢。</p>
<h1 id="平常如何学习"><a href="#平常如何学习" class="headerlink" title="平常如何学习"></a>平常如何学习</h1><p>在研究生阶段，除了学科知识的学习外，在课余阶段我通常以问题导向型进行知识的积累。比如在学习视觉算法中分类问题的时候，我先开始了解经典的网络模型，学习不同的网络模型的思路及创新点，然后查阅各种资料论文关注模型的参数设置，损失函数的收敛等等知识，从而是自己能够高效的学习该方面的知识。</p>
<h1 id="上过哪些CV课程"><a href="#上过哪些CV课程" class="headerlink" title="上过哪些CV课程"></a>上过哪些CV课程</h1><p>研究生课程：视频大数据的机器学习、模式识别与机器学习、神经网络与模糊系统、图像分析与机器视觉<br>自学课程：吴恩达教授的CS229网课、李飞飞教授的CS231n网课。</p>
<h1 id="项目中遇到的重大问题"><a href="#项目中遇到的重大问题" class="headerlink" title="项目中遇到的重大问题"></a>项目中遇到的重大问题</h1><p>在完成国家电网能力开发平台时，由于项目是采用的基于RPC的 HSF协议进行模块之间的通信。HSF是阿里内部使用的模块间通信的方式，我之前没有使用过，通过短期的学习能力，调通分布式模块之间通信的问题，在这个项目即将上线部署的时候，我们需要到电网公司内部进行压力测试，我遇到的比较大的一个难题是项目上线部署后各个模块之间无法通信。最后通过分析Edas平台各个服务IP地址和服务端口，以及redis日志文件，判断到最后是因为一个模块之中的redis地址出错导致没有启动redis。引发的后续通信的问题。体现了排错能力和自主解决问题的能力。</p>
<h1 id="项目如何跟别人合作"><a href="#项目如何跟别人合作" class="headerlink" title="项目如何跟别人合作"></a>项目如何跟别人合作</h1><p>在项目合作过程中，小组成员集体讨论项目需求，提出具体的项目方案后，根据每人的研究方向和动手能力分配工作量，并统一使用github进行代码的托管和维护。</p>
<h1 id="有什么想问的（一面、二面、三面分别问什么）"><a href="#有什么想问的（一面、二面、三面分别问什么）" class="headerlink" title="有什么想问的（一面、二面、三面分别问什么）"></a>有什么想问的（一面、二面、三面分别问什么）</h1><p>请问我应聘的这个职位所在团队面对着怎样的问题和挑战？另外，贵公司对这个职务有怎样的期待呢？<br>在刚入职的两三个月里，公司更希望这个岗位的信任把工作重心放在哪个方向呢？<br>公司针对实习生的培养机制是怎样的呢？团队的技术栈是什么样的？在去实习前应该重点学习哪些技术呢？</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/11/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D%EF%BC%88%E8%AF%A6%E7%BB%86%E7%89%88%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/11/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D%EF%BC%88%E8%AF%A6%E7%BB%86%E7%89%88%EF%BC%89/" class="post-title-link" itemprop="url">简历项目介绍（详细版）</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-11 09:07:30" itemprop="dateCreated datePublished" datetime="2020-02-11T09:07:30+08:00">2020-02-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-07 09:30:08" itemprop="dateModified" datetime="2020-03-07T09:30:08+08:00">2020-03-07</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="基于姿态估计的康复健身平台"><a href="#基于姿态估计的康复健身平台" class="headerlink" title="基于姿态估计的康复健身平台"></a>基于姿态估计的康复健身平台</h1><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul>
<li>系统架构<ul>
<li>前端设计</li>
<li>后台架构</li>
</ul>
</li>
<li>算法模块<ul>
<li>2D姿态估计</li>
<li>3D姿态估计</li>
<li>动作识别</li>
</ul>
</li>
</ul>
<h2 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>本项目来源是北京邮电大学的创新创业项目，主要目的是为了搭建基于人体姿态估计算法的平台，为用户在家中使用普通的2D摄像头，辅助进行健身和康复训练提供检测和指导。</p>
<h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p><img src="/images/system.jpg" alt="系统架构"><br>摄像头采集图片，每秒采集10帧，将视频帧(600, 400)转为base64编码格式，和用户的user-token、任务的task-id一起封装成Json对象。然后通过stomp通信协议，利用activemq消息中间件进行前端和后台之间的信息传递。前端模拟生产者发送消息，通过设定的topics发送到对应的队列Queues中。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> client, destination, login, passcode;</span><br><span class="line">url = <span class="string">"ws://10.103.238.165:61614"</span>;</span><br><span class="line">destination = <span class="string">"/queue/video"</span>;</span><br><span class="line">login = <span class="string">"admin"</span>;</span><br><span class="line">passcode = <span class="string">"password"</span>;</span><br><span class="line"></span><br><span class="line">client = Stomp.client(url);</span><br><span class="line"><span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">timer = setInterval(</span></span><br><span class="line"><span class="string">            function () &#123;</span></span><br><span class="line"><span class="string">                ctx.drawImage(video, 0, 0, 600, 400);</span></span><br><span class="line"><span class="string">                var data = canvas.toDataURL('</span>image/jpeg<span class="string">', 1.0);    //将获取到的图像转换为base64编码</span></span><br><span class="line"><span class="string">                //newblob = dataURItoBlob(data);</span></span><br><span class="line"><span class="string">                //添加状态判断，当为OPEN时，发送消息</span></span><br><span class="line"><span class="string">                //var message = &#123;&#125;;</span></span><br><span class="line"><span class="string">                client.send(destination, &#123;'</span>user-token<span class="string">': 123, '</span>task<span class="string">': 0x01&#125;, data);//发送消息, 0x02 -&gt; 0000 0010</span></span><br><span class="line"><span class="string">                //接收图片时间</span></span><br><span class="line"><span class="string">                var timestamp = new Date().getTime();</span></span><br><span class="line"><span class="string">            &#125;, 100);</span></span><br></pre></td></tr></table></figure><br>后台是是SpringBoot+Mybatis框架搭建，通过模拟一个消费者，应用监听器监听消息。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@JmsListener</span>(destination = <span class="string">"video"</span>,containerFactory = <span class="string">"jmsListenerContainerQueue"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processImage</span><span class="params">(Message message)</span> </span>&#123;</span><br><span class="line"><span class="comment">//      if (message instanceof BytesMessage) &#123;</span></span><br><span class="line">            BytesMessage bytesMessage = (BytesMessage)message;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 得到一些参数：</span></span><br><span class="line">                String user_token = String.valueOf(bytesMessage.getByteProperty(<span class="string">"user-token"</span>));  <span class="comment">// user-token</span></span><br><span class="line">                String task = String.valueOf(bytesMessage.getByteProperty(<span class="string">"task"</span>));               <span class="comment">// task</span></span><br><span class="line">                String image_base64 =<span class="string">""</span>;                                            <span class="comment">// origin image</span></span><br><span class="line">                UUID uuid= UUID.randomUUID();</span><br><span class="line">                String imageID = uuid.toString();                                   <span class="comment">// imageID</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>*<span class="number">1024</span>];</span><br><span class="line">                <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">while</span>((len=bytesMessage.readBytes(buffer))!=-<span class="number">1</span>)&#123;</span><br><span class="line">                    image_base64 = <span class="keyword">new</span> String(buffer,<span class="number">0</span>,len);</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                Jedis jedis = jedisPool.getResource();</span><br><span class="line">                Map&lt;String,String&gt; imageData = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">                imageData.put(<span class="string">"imageID"</span>,imageID);</span><br><span class="line">                imageData.put(<span class="string">"userToken"</span>,user_token);</span><br><span class="line">                imageData.put(<span class="string">"taskList"</span>,task);</span><br><span class="line">                imageData.put(<span class="string">"image"</span>,image_base64);</span><br><span class="line"></span><br><span class="line">                JSONObject jsonObject = JSONObject.fromObject(imageData);</span><br><span class="line"></span><br><span class="line"><span class="comment">//              比较task列表并分发存入对应的redis的list</span></span><br><span class="line">                <span class="keyword">int</span> taskToDo = Integer.parseInt(task);</span><br><span class="line">                <span class="keyword">if</span>((taskToDo&amp;<span class="number">0x01</span>)&gt;<span class="number">0</span>) &#123; <span class="comment">//pose</span></span><br><span class="line">                    jedis.rpush(<span class="string">"image_queue_to_pose_estimation"</span>, jsonObject.toString());</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>((taskToDo&amp;<span class="number">0x02</span>)&gt;<span class="number">0</span>)&#123; <span class="comment">//face</span></span><br><span class="line">                    jedis.rpush(<span class="string">"image_queue_to_face_recognition"</span>, jsonObject.toString());</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>((taskToDo&amp;<span class="number">0x04</span>)&gt;<span class="number">0</span>)&#123; <span class="comment">//object</span></span><br><span class="line">                    jedis.rpush(<span class="string">"image_queue_to_object_recognition"</span>, jsonObject.toString());</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">//手动释放资源，不然会因为jedisPool里面的maxActive=200的限制，只能创建200个jedis资源。</span></span><br><span class="line">                jedis.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (JMSException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><br>后台将前端发送的Json对象解析出来，为了保证每张图片不重复，使用UUID随机生成图片ID(image_id)，将image_id、user_token、task_id和image_base64放入Hashmap中，转成Json对象存入redis中，通过redis的发布/订阅模式，和服务器算法进行信息传输。算法一直运行在服务器上，订阅redis的频道channel，来监听redis中存储的消息。将消息中的Json对象解析出来后，将base_64编码的图片数据解码转变成numpy矩阵类型，送入深度学习模型，将得到的human对象的list,human对象里包含BodyParts，是每个对象的x,y坐标和置信度值。然后human对象封装成Json对象，通过发布新的通道存储在redis中，业务后台同样订阅该通道，将算法模块返回的结果通过websocket方式提供给前端展示。</p>
<h3 id="消息中间件"><a href="#消息中间件" class="headerlink" title="消息中间件"></a>消息中间件</h3><p>消息中间件事一种夸进程的通信方式，这种方式使得系统之间上下游进行了逻辑和物理解耦合。使用消息中间件，在C/S或B/S模型中，请求可以由服务器端主动发起；消息中间件与上下游相对独立，不关心系统的技术架构，更适用于异构系统之间的通信和数据交互。</p>
<ol>
<li>ActiveMQ<br>ActiveMQ支持两种消息队列模型为点对点（Point To Point）模型和发布-订阅（Publisher To Subscriber）模型。其中，点对点模型以queue作为消息的承载，消息生产者发送消息到queue中，然后消费者获取消息。对于已经被消费过的信息，queue中不再存储，虽然支持多个消费者，但一个消息只能被消费一次。发布-订阅模型，以topic承载消息，生产者发布消息到topic中，订阅该topic的多个消费者能同时接收到该消息。消息的两种传送机制为推送和拉取。推送的方式有消息中间件主动将消息发送给消费者，能处理快速即时的消息，但如果消费者处理消息能力较弱，消息推送不断，则有可能造成缓冲区的溢出；拉取的方式由消费者主动向消息中间件拉取信息，会造成消息的部分延迟。</li>
<li>Redis<br>Redis作为key-value内存型存储系统，一般作为缓存中间件使用，在某些场景下也可以作为消息中间件进行数据的缓存和传输。Redis具有基于内存的高速读写特性，支持String、List、Hash、Set、Zset五种类型的操作，支持原子性事务，还具有较为丰富的特性。将Redis作为消息中间件使用，一般利用其列表的数据结构，生产者通过Ipush来发布消息，消费者通过brpop来获取消息。此种实现方式，在Redis宕机且数据没有持久化的情况下可能造成数据的丢失，对于数据可靠性要求不是太高的场景中适用。</li>
</ol>
<h2 id="算法模块"><a href="#算法模块" class="headerlink" title="算法模块"></a>算法模块</h2><h3 id="2D姿态估计"><a href="#2D姿态估计" class="headerlink" title="2D姿态估计"></a>2D姿态估计</h3><p><a href="https://blog.csdn.net/zziahgf/article/details/79643752" target="_blank" rel="noopener">CPM模型</a><br><a href="https://blog.csdn.net/htt789/article/details/80283370" target="_blank" rel="noopener">openpose姿态估计</a><br><a href="https://zhuanlan.zhihu.com/p/66803058" target="_blank" rel="noopener">openpose</a><br><a href="https://blog.csdn.net/young__fan/article/details/90719285" target="_blank" rel="noopener">匈牙利算法</a><br>使用openpose获得人体的18个关键点坐标，然后输入HCN网络进行动作分类，然后使用动态时间规划进行动作匹配。<br>数据集：公司给的健身动作视频，每个动作是3-5s，每组动作锻炼30次，总共进行8组，每段视频都是是单一的健身指导视频。由于视频中只有单一的参与者指导动作，训练数据背景单一，估考虑采用基于骨骼关键点的行为识别。<br>算法流程：<br>1.从redis中读取图片，将base64编码转为矩阵数据<br>2.输入openpose算法，得到人体的18个关键点。<br>BODY_PARTS = { “Nose”: 0, “Neck”: 1, “RShoulder”: 2, “RElbow”:3, “RWrist”: 4, “LShoulder”: 5, “LElbow”: 6, “LWrist”: 7, “RHip”: 8, “RKnee”: 9, “RAnkle”: 10, “LHip”: 11, “LKnee”: 12, “LAnkle”: 13, “REye”: 14, “LEye”: 15, “REar”: 16, “LEar”: 17, “Background”: 18 }<br>3.将得到的17个关键点输入到HCN网络进行动作分类。<br>关键点：在训练动作分类网络时，可以对关键点信息进行数据增强。<br>1)归一化处理，将其他通道求平均，只保留C和V通道求数据的均值和方差，然后对每一个数据进行归一化处理。<br>2）时间片段选取，在150帧时间序列中选择有效的64帧<br>3）坐标旋转变换，随机设一个角度，对构建旋转矩阵，对关键点进行旋转变换。<br>CNN 模型在提取高层面信息方面能力出色，并且也已经被用于根据骨架学习空间-时间特征。这些基于 CNN 的方法可以通过将时间动态和骨架关节分别编码成行和列而将骨架序列表示成一张图像，然后就像图像分类一样将图像输入 CNN 来识别其中含有的动作。但是，在这种情况下，只有卷积核内的相邻关节才被认为是在学习共现特征。尽管感受野（receptive field）能在之后的卷积层中覆盖骨架的所有关节，但我们很难有效地从所有关节中挖掘共现特征。由于空间维度中的权重共享机制，CNN 模型无法为每个关节都学习自由的参数。这促使我们设计一个能获得所有关节的全局响应的模型，以利用不同关节之间的相关性。<br>着眼于人的行为动作的特点，我们将行为动作中关节点具有的共现性特性引入到网络设计中，将其作为网络参数学习的约束来优化识别性能。人的某个行为动作常常和骨架的一些特定关节点构成的集合，以及这个集合中节点的交互密切相关。如要判别是否在打电话，关节点“手腕”、“手肘”、“肩膀”和“头”的动作最为关键。不同的行为动作与之密切相关的节点集合有所不同。例如对于“走路”的行为动作，“脚腕”、“膝盖”、“臀部”等关节点构成具有判别力的节点集合。我们将这种几个关节点同时影响和决定判别的特性称为共现性（Co-occurrence）。<br>我们提出了一种端到端的共现特征学习框架，其使用了 CNN 来自动地从骨架序列中学习分层的共现特征。我们发现一个卷积层的输出是来自所有输入通道的全局响应。如果一个骨架的每个关节都被当作是一个通道，那么卷积层就可以轻松地学习所有关节的共现。更具体而言，我们将骨架序列表示成了一个形状帧×关节×3（最后一维作为通道）的张量。我们首先使用核大小为 n×1 的卷积层独立地为每个关节学习了点层面的特征。然后我们再将该卷积层的输出转置，以将关节的维度作为通道。在这个转置运算之后，后续的层分层地聚合来自所有关节的全局特征。<br><img src="/images/HCN.jpg" alt=""><br>我们提出的分层式共现网络（HCN：Hierarchical Co-occurrence Network）的概况。绿色模块是卷积层，其中最后一维表示输出通道的数量。后面的「/2」表示卷积之后附带的最大池化层，步幅为 2。转置层是根据顺序参数重新排列输入张量的维度。conv1、conv5、conv6 和 fc7 之后附加了 ReLU 激活函数以引入非线性。<br>4.动作匹配，采用动态时间规划（DTW）算法，判断用户的运动视频和标准动作是否匹配。<br><a href="https://zhuanlan.zhihu.com/p/32849741" target="_blank" rel="noopener">DTW介绍</a><br>比较在该段时间内用户的姿态的(x,y)坐标点与标准模板的相似度进行评分。我们需要构造一个nxm的矩阵网格，矩阵元素(i, j)表示qi和cj两个点的距离d(qi, cj)（也就是序列Q的每一个点和序列C的每一个点之间的相似度，距离越小则相似度越高。）我们定义一个累加距离cumulative distances。从(0, 0)点开始匹配这两个序列Q和C，每到一个点，之前所有的点计算的距离都会累加。到达终点(n, m)后，这个累积距离就是我们上面说的最后的总的距离，也就是序列Q和C的相似度。</p>
<script type="math/tex; mode=display">\gamma(i,j)=d(q_i,c_j)+min(\gamma(i-1,j-1),\gamma(i-1,j),\gamma(i,j-1))</script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/10/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/10/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-10 21:46:14" itemprop="dateCreated datePublished" datetime="2020-02-10T21:46:14+08:00">2020-02-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/03/%E7%AC%AC%E4%B8%89%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/03/%E7%AC%AC%E4%B8%89%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">第三章 深度学习基础</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-03 21:13:44" itemprop="dateCreated datePublished" datetime="2020-02-03T21:13:44+08:00">2020-02-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-21 19:37:32" itemprop="dateModified" datetime="2020-03-21T19:37:32+08:00">2020-03-21</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="第三章-深度学习基础"><a href="#第三章-深度学习基础" class="headerlink" title="第三章 深度学习基础"></a>第三章 深度学习基础</h1><h2 id="3-1-基本概念"><a href="#3-1-基本概念" class="headerlink" title="3.1 基本概念"></a>3.1 基本概念</h2><h3 id="3-1-1-神经网络组成？"><a href="#3-1-1-神经网络组成？" class="headerlink" title="3.1.1 神经网络组成？"></a>3.1.1 神经网络组成？</h3><p>神经网络类型众多，其中最为重要的是多层感知机。为了详细地描述神经网络，我们先从最简单的神经网络说起。</p>
<p><strong>感知机</strong></p>
<p>多层感知机中的特征神经元模型称为感知机，由<em>Frank Rosenblatt</em>于1957年发明。</p>
<p>简单的感知机如下图所示：</p>
<p><img src="/img/ch3/3-1.png" alt=""></p>
<p>其中$x_1$，$x_2$，$x_3$为感知机的输入，其输出为：</p>
<script type="math/tex; mode=display">
output = \left\{
\begin{aligned}
0, \quad if \ \ \sum_i w_i x_i \leqslant threshold \\
1, \quad if \ \ \sum_i w_i x_i > threshold
\end{aligned}
\right.</script><p>假如把感知机想象成一个加权投票机制，比如 3 位评委给一个歌手打分，打分分别为$ 4 $分、$1$ 分、$-3 $分，这$ 3$ 位评分的权重分别是 $1、3、2$，则该歌手最终得分为 $4 \times 1 + 1 \times 3 + (-3) \times 2 = 1$ 。按照比赛规则，选取的 $threshold$ 为 $3$，说明只有歌手的综合评分大于$ 3$ 时，才可顺利晋级。对照感知机，该选手被淘汰，因为：</p>
<script type="math/tex; mode=display">
\sum_i w_i x_i < threshold=3, output = 0</script><p>用 $-b$  代替 $threshold$，输出变为：</p>
<script type="math/tex; mode=display">
output = \left\{
\begin{aligned}
0, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b \leqslant 0 \\
1, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b > 0
\end{aligned}
\right.</script><p>设置合适的  $\boldsymbol{x}$  和  $b$ ，一个简单的感知机单元的与非门表示如下：</p>
<p><img src="/img/ch3/3-2.png" alt=""></p>
<p>当输入为 $0$，$1$ 时，感知机输出为 $ 0 \times (-2) + 1 \times (-2) + 3 = 1$。</p>
<p>复杂一些的感知机由简单的感知机单元组合而成：</p>
<p><img src="/img/ch3/3-3.png" alt=""></p>
<p><strong>多层感知机</strong></p>
<p>多层感知机由感知机推广而来，最主要的特点是有多个神经元层，因此也叫深度神经网络。相比于单独的感知机，多层感知机的第 $ i $ 层的每个神经元和第 $ i-1 $ 层的每个神经元都有连接。</p>
<p><img src="/img/ch3/3.1.1.5.png" alt=""></p>
<p>输出层可以不止有$ 1$ 个神经元。隐藏层可以只有$ 1$ 层，也可以有多层。输出层为多个神经元的神经网络例如下图所示：</p>
<p><img src="/img/ch3/3.1.1.6.png" alt=""></p>
<h3 id="3-1-2-神经网络有哪些常用模型结构？"><a href="#3-1-2-神经网络有哪些常用模型结构？" class="headerlink" title="3.1.2 神经网络有哪些常用模型结构？"></a>3.1.2 神经网络有哪些常用模型结构？</h3><p>下图包含了大部分常用的模型：</p>
<p><img src="/img/ch3/3-7.jpg" alt=""></p>
<h3 id="3-1-3-如何选择深度学习开发平台？"><a href="#3-1-3-如何选择深度学习开发平台？" class="headerlink" title="3.1.3 如何选择深度学习开发平台？"></a>3.1.3 如何选择深度学习开发平台？</h3><p>​    现有的深度学习开源平台主要有 Caffe, PyTorch, MXNet, CNTK, Theano, TensorFlow, Keras, fastai等。那如何选择一个适合自己的平台呢，下面列出一些衡量做参考。</p>
<p><strong>参考1：与现有编程平台、技能整合的难易程度</strong></p>
<p>​    主要是前期积累的开发经验和资源，比如编程语言，前期数据集存储格式等。</p>
<p><strong>参考2: 与相关机器学习、数据处理生态整合的紧密程度</strong></p>
<p>​    深度学习研究离不开各种数据处理、可视化、统计推断等软件包。考虑建模之前，是否具有方便的数据预处理工具？建模之后，是否具有方便的工具进行可视化、统计推断、数据分析。  </p>
<p><strong>参考3：对数据量及硬件的要求和支持</strong></p>
<p>​    深度学习在不同应用场景的数据量是不一样的，这也就导致我们可能需要考虑分布式计算、多GPU计算的问题。例如，对计算机图像处理研究的人员往往需要将图像文件和计算任务分部到多台计算机节点上进行执行。当下每个深度学习平台都在快速发展，每个平台对分布式计算等场景的支持也在不断演进。</p>
<p><strong>参考4：深度学习平台的成熟程度</strong></p>
<p>​    成熟程度的考量是一个比较主观的考量因素，这些因素可包括：社区的活跃程度；是否容易和开发人员进行交流；当前应用的势头。</p>
<p><strong>参考5：平台利用是否多样性？</strong></p>
<p>​    有些平台是专门为深度学习研究和应用进行开发的，有些平台对分布式计算、GPU 等构架都有强大的优化，能否用这些平台/软件做其他事情？比如有些深度学习软件是可以用来求解二次型优化；有些深度学习平台很容易被扩展，被运用在强化学习的应用中。</p>
<h3 id="3-1-4-为什么使用深层表示"><a href="#3-1-4-为什么使用深层表示" class="headerlink" title="3.1.4 为什么使用深层表示?"></a>3.1.4 为什么使用深层表示?</h3><ol>
<li>深度神经网络是一种特征递进式的学习算法，浅层的神经元直接从输入数据中学习一些低层次的简单特征，例如边缘、纹理等。而深层的特征则基于已学习到的浅层特征继续学习更高级的特征，从计算机的角度学习深层的语义信息。</li>
<li>深层的网络隐藏单元数量相对较少，隐藏层数目较多，如果浅层的网络想要达到同样的计算结果则需要指数级增长的单元数量才能达到。</li>
</ol>
<h3 id="3-1-5-为什么深层神经网络难以训练？"><a href="#3-1-5-为什么深层神经网络难以训练？" class="headerlink" title="3.1.5 为什么深层神经网络难以训练？"></a>3.1.5 为什么深层神经网络难以训练？</h3><ol>
<li><p>梯度消失</p>
<pre><code> 梯度消失是指通过隐藏层从后向前看，梯度会变的越来越小，说明前面层的学习会显著慢于后面层的学习，所以学习会卡住，除非梯度变大。
</code></pre><p> ​    梯度消失的原因受到多种因素影响，例如学习率的大小，网络参数的初始化，激活函数的边缘效应等。在深层神经网络中，每一个神经元计算得到的梯度都会传递给前一层，较浅层的神经元接收到的梯度受到之前所有层梯度的影响。如果计算得到的梯度值非常小，随着层数增多，求出的梯度更新信息将会以指数形式衰减，就会发生梯度消失。下图是不同隐含层的学习速率：</p>
</li>
</ol>
<p><img src="/img/ch3/3-8.png" alt=""></p>
<ol>
<li><p>梯度爆炸</p>
<pre><code> 在深度网络或循环神经网络（Recurrent Neural Network, RNN）等网络结构中，梯度可在网络更新的过程中不断累积，变成非常大的梯度，导致网络权重值的大幅更新，使得网络不稳定；在极端情况下，权重值甚至会溢出，变为$NaN$值，再也无法更新。
</code></pre></li>
<li><p>权重矩阵的退化导致模型的有效自由度减少。</p>
<p> ​    参数空间中学习的退化速度减慢，导致减少了模型的有效维数，网络的可用自由度对学习中梯度范数的贡献不均衡，随着相乘矩阵的数量（即网络深度）的增加，矩阵的乘积变得越来越退化。在有硬饱和边界的非线性网络中（例如 ReLU 网络），随着深度增加，退化过程会变得越来越快。Duvenaud等人2014年的论文里展示了关于该退化过程的可视化：</p>
</li>
</ol>
<p><img src="/img/ch3/3-9.jpg" alt=""></p>
<p>随着深度的增加，输入空间（左上角所示）会在输入空间中的每个点处被扭曲成越来越细的单丝，只有一个与细丝正交的方向影响网络的响应。沿着这个方向，网络实际上对变化变得非常敏感。</p>
<h3 id="3-1-6-深度学习和机器学习有什么不同？"><a href="#3-1-6-深度学习和机器学习有什么不同？" class="headerlink" title="3.1.6 深度学习和机器学习有什么不同？"></a>3.1.6 深度学习和机器学习有什么不同？</h3><p>​    <strong>机器学习</strong>：利用计算机、概率论、统计学等知识，输入数据，让计算机学会新知识。机器学习的过程，就是训练数据去优化目标函数。</p>
<p>​    <strong>深度学习</strong>：是一种特殊的机器学习，具有强大的能力和灵活性。它通过学习将世界表示为嵌套的层次结构，每个表示都与更简单的特征相关，而抽象的表示则用于计算更抽象的表示。</p>
<p>​    传统的机器学习需要定义一些手工特征，从而有目的的去提取目标信息， 非常依赖任务的特异性以及设计特征的专家经验。而深度学习可以从大数据中先学习简单的特征，并从其逐渐学习到更为复杂抽象的深层特征，不依赖人工的特征工程，这也是深度学习在大数据时代受欢迎的一大原因。</p>
<p><img src="/img/ch3/3.1.6.1.png" alt=""></p>
<p><img src="/img/ch3/3-11.jpg" alt=""></p>
<h2 id="3-2-网络操作与计算"><a href="#3-2-网络操作与计算" class="headerlink" title="3.2 网络操作与计算"></a>3.2 网络操作与计算</h2><h3 id="3-2-1-前向传播与反向传播？"><a href="#3-2-1-前向传播与反向传播？" class="headerlink" title="3.2.1 前向传播与反向传播？"></a>3.2.1 前向传播与反向传播？</h3><p>神经网络的计算主要有两种：前向传播（foward propagation, FP）作用于每一层的输入，通过逐层计算得到输出结果；反向传播（backward propagation, BP）作用于网络的输出，通过计算梯度由深到浅更新网络参数。</p>
<p><strong>前向传播</strong></p>
<p><img src="/img/ch3/3.2.1.1.png" alt=""></p>
<p>假设上一层结点 $ i,j,k,… $ 等一些结点与本层的结点 $ w $ 有连接，那么结点 $ w $ 的值怎么算呢？就是通过上一层的 $ i,j,k,… $ 等结点以及对应的连接权值进行加权和运算，最终结果再加上一个偏置项（图中为了简单省略了），最后在通过一个非线性函数（即激活函数），如 $ReLu$，$sigmoid$ 等函数，最后得到的结果就是本层结点 $ w $ 的输出。 </p>
<p>最终不断的通过这种方法一层层的运算，得到输出层结果。</p>
<p><strong>反向传播</strong></p>
<p><img src="/img/ch3/3.2.1.2.png" alt=""></p>
<p>由于我们前向传播最终得到的结果，以分类为例，最终总是有误差的，那么怎么减少误差呢，当前应用广泛的一个算法就是梯度下降算法，但是求梯度就要求偏导数，下面以图中字母为例讲解一下：</p>
<p>设最终误差为 $ E $且输出层的激活函数为线性激活函数，对于输出那么 $ E $ 对于输出节点 $ y_l $ 的偏导数是 $ y_l - t_l $，其中 $ t_l $ 是真实值，$ \frac{\partial y_l}{\partial z_l} $ 是指上面提到的激活函数，$ z_l $ 是上面提到的加权和，那么这一层的 $ E $ 对于 $ z_l $ 的偏导数为 $ \frac{\partial E}{\partial z_l} = \frac{\partial E}{\partial y_l} \frac{\partial y_l}{\partial z_l} $。同理，下一层也是这么计算，只不过 $ \frac{\partial E}{\partial y_k} $ 计算方法变了，一直反向传播到输入层，最后有 $ \frac{\partial E}{\partial x_i} = \frac{\partial E}{\partial y_j} \frac{\partial y_j}{\partial z_j} $，且 $ \frac{\partial z_j}{\partial x_i} = w_i j $。然后调整这些过程中的权值，再不断进行前向传播和反向传播的过程，最终得到一个比较好的结果。</p>
<h3 id="3-2-2-如何计算神经网络的输出？"><a href="#3-2-2-如何计算神经网络的输出？" class="headerlink" title="3.2.2 如何计算神经网络的输出？"></a>3.2.2 如何计算神经网络的输出？</h3><p><img src="/img/ch3/3.2.2.1.png" alt=""></p>
<p>如上图，输入层有三个节点，我们将其依次编号为 1、2、3；隐藏层的 4 个节点，编号依次为 4、5、6、7；最后输出层的两个节点编号为 8、9。比如，隐藏层的节点 4，它和输入层的三个节点 1、2、3 之间都有连接，其连接上的权重分别为是 $ w_{41}, w_{42}, w_{43} $。</p>
<p>为了计算节点 4 的输出值，我们必须先得到其所有上游节点（也就是节点 1、2、3）的输出值。节点 1、2、3 是输入层的节点，所以，他们的输出值就是输入向量本身。按照上图画出的对应关系，可以看到节点 1、2、3 的输出值分别是 $ x_1, x_2, x_3 $。</p>
<script type="math/tex; mode=display">
a_4 = \sigma(w^T \cdot a) = \sigma(w_{41}x_4 + w_{42}x_2 + w_{43}a_3 + w_{4b})</script><p>其中 $ w_{4b} $ 是节点 4 的偏置项。</p>
<p>同样，我们可以继续计算出节点 5、6、7 的输出值 $ a_5, a_6, a_7 $。</p>
<p>计算输出层的节点 8 的输出值 $ y_1 $：</p>
<script type="math/tex; mode=display">
y_1 = \sigma(w^T \cdot a) = \sigma(w_{84}a_4 + w_{85}a_5 + w_{86}a_6 + w_{87}a_7 + w_{8b})</script><p>其中 $ w_{8b} $ 是节点 8 的偏置项。</p>
<p>同理，我们还可以计算出 $ y_2 $。这样输出层所有节点的输出值计算完毕，我们就得到了在输入向量 $ x_1, x_2, x_3, x_4 $ 时，神经网络的输出向量 $ y_1, y_2 $ 。这里我们也看到，输出向量的维度和输出层神经元个数相同。</p>
<h3 id="3-2-3-如何计算卷积神经网络输出值？"><a href="#3-2-3-如何计算卷积神经网络输出值？" class="headerlink" title="3.2.3 如何计算卷积神经网络输出值？"></a>3.2.3 如何计算卷积神经网络输出值？</h3><p>假设有一个 5*5 的图像，使用一个 3*3 的 filter 进行卷积，想得到一个 3*3 的 Feature Map，如下所示：</p>
<p><img src="/img/ch3/3.2.3.1.png" alt=""></p>
<p>$ x_{i,j} $ 表示图像第  $ i $ 行第 $ j $ 列元素。$ w_{m,n} $ 表示 filter​ 第 $ m $ 行第 $ n $ 列权重。 $ w_b $ 表示 $filter$ 的偏置项。 表$a_i,_j$示 feature map 第 $ i$ 行第 $ j $ 列元素。 $f$ 表示激活函数，这里以$ ReLU$ 函数为例。</p>
<p>卷积计算公式如下：</p>
<script type="math/tex; mode=display">
a_{i,j} = f(\sum_{m=0}^2 \sum_{n=0}^2 w_{m,n} x_{i+m, j+n} + w_b )</script><p>当步长为 $1$ 时，计算 feature map 元素 $ a_{0,0} $ 如下：</p>
<script type="math/tex; mode=display">
a_{0,0} = f(\sum_{m=0}^2 \sum_{n=0}^2 w_{m,n} x_{0+m, 0+n} + w_b )

= relu(w_{0,0} x_{0,0} + w_{0,1} x_{0,1} + w_{0,2} x_{0,2} + w_{1,0} x_{1,0} + \\w_{1,1} x_{1,1} + w_{1,2} x_{1,2} + w_{2,0} x_{2,0} + w_{2,1} x_{2,1} + w_{2,2} x_{2,2}) \\

= 1 + 0 + 1 + 0 + 1 + 0 + 0 + 0 + 1 \\

= 4</script><p>其计算过程图示如下：</p>
<p><img src="/img/ch3/3.2.3.2.png" alt=""></p>
<p>以此类推，计算出全部的Feature Map。</p>
<p><img src="/img/ch3/3.2.3.4.png" alt=""></p>
<p>当步幅为 2 时，Feature Map计算如下</p>
<p><img src="/img/ch3/3.2.3.5.png" alt=""></p>
<p>注：图像大小、步幅和卷积后的Feature Map大小是有关系的。它们满足下面的关系：</p>
<script type="math/tex; mode=display">
W_2 = (W_1 - F + 2P)/S + 1\\
H_2 = (H_1 - F + 2P)/S + 1</script><p>​    其中 $ W_2 $， 是卷积后 Feature Map 的宽度；$ W_1 $ 是卷积前图像的宽度；$ F $ 是 filter 的宽度；$ P $ 是 Zero Padding 数量，Zero Padding 是指在原始图像周围补几圈 $0$，如果 $P$ 的值是 $1$，那么就补 $1$ 圈 $0$；$S$ 是步幅；$ H_2 $ 卷积后 Feature Map 的高度；$ H_1 $ 是卷积前图像的宽度。</p>
<p>​    举例：假设图像宽度 $ W_1 = 5 $，filter 宽度 $ F=3 $，Zero Padding $ P=0 $，步幅 $ S=2 $，$ Z $ 则</p>
<script type="math/tex; mode=display">
W_2 = (W_1 - F + 2P)/S + 1

= (5-3+0)/2 + 1

= 2</script><p>​    说明 Feature Map 宽度是2。同样，我们也可以计算出 Feature Map 高度也是 2。</p>
<p>如果卷积前的图像深度为 $ D $，那么相应的 filter 的深度也必须为 $ D $。深度大于 1 的卷积计算公式：</p>
<script type="math/tex; mode=display">
a_{i,j} = f(\sum_{d=0}^{D-1} \sum_{m=0}^{F-1} \sum_{n=0}^{F-1} w_{d,m,n} x_{d,i+m,j+n} + w_b)</script><p>​    其中，$ D $ 是深度；$ F $ 是 filter 的大小；$ w_{d,m,n} $ 表示 filter 的第 $ d $ 层第 $ m $ 行第 $ n $ 列权重；$ a_{d,i,j} $ 表示 feature map 的第 $ d $ 层第 $ i $ 行第 $ j $ 列像素；其它的符号含义前面相同，不再赘述。</p>
<p>​    每个卷积层可以有多个 filter。每个 filter 和原始图像进行卷积后，都可以得到一个 Feature Map。卷积后 Feature Map 的深度(个数)和卷积层的 filter 个数相同。下面的图示显示了包含两个 filter 的卷积层的计算。$7<em>7</em>3$ 输入，经过两个 $3<em>3</em>3$ filter 的卷积(步幅为 $2$)，得到了 $3<em>3</em>2$ 的输出。图中的 Zero padding 是 $1$，也就是在输入元素的周围补了一圈 $0$。</p>
<p><img src="/img/ch3/3.2.3.6.png" alt=""></p>
<p>​    以上就是卷积层的计算方法。这里面体现了局部连接和权值共享：每层神经元只和上一层部分神经元相连(卷积计算规则)，且 filter 的权值对于上一层所有神经元都是一样的。对于包含两个 $ 3 <em> 3 </em> 3 $ 的 fitler 的卷积层来说，其参数数量仅有 $ (3 <em> 3 </em> 3+1) * 2 = 56 $ 个，且参数数量与上一层神经元个数无关。与全连接神经网络相比，其参数数量大大减少了。</p>
<h3 id="3-2-4-如何计算-Pooling-层输出值输出值？"><a href="#3-2-4-如何计算-Pooling-层输出值输出值？" class="headerlink" title="3.2.4 如何计算 Pooling 层输出值输出值？"></a>3.2.4 如何计算 Pooling 层输出值输出值？</h3><p>​    Pooling 层主要的作用是下采样，通过去掉 Feature Map 中不重要的样本，进一步减少参数数量。Pooling 的方法很多，最常用的是 Max Pooling。Max Pooling 实际上就是在 n*n 的样本中取最大值，作为采样后的样本值。下图是 2*2 max pooling：</p>
<p><img src="/img/ch3/3.2.4.1.png" alt=""></p>
<p>​    除了 Max Pooing 之外，常用的还有 Average Pooling ——取各样本的平均值。<br>​    对于深度为 $ D $ 的 Feature Map，各层独立做 Pooling，因此 Pooling 后的深度仍然为 $ D $。</p>
<h3 id="3-2-5-实例理解反向传播"><a href="#3-2-5-实例理解反向传播" class="headerlink" title="3.2.5 实例理解反向传播"></a>3.2.5 实例理解反向传播</h3><p>​    一个典型的三层神经网络如下所示：</p>
<p><img src="/img/ch3/3.2.5.1.png" alt=""></p>
<p>​    其中 Layer $ L_1 $ 是输入层，Layer $ L_2 $ 是隐含层，Layer $ L_3 $ 是输出层。</p>
<p>​    假设输入数据集为 $ D={x_1, x_2, …, x_n} $，输出数据集为 $ y_1, y_2, …, y_n $。</p>
<p>​    如果输入和输出是一样，即为自编码模型。如果原始数据经过映射，会得到不同于输入的输出。</p>
<p>假设有如下的网络层：</p>
<p><img src="/img/ch3/3.2.5.2.png" alt=""></p>
<p>​    输入层包含神经元 $ i_1, i_2 $，偏置 $ b_1 $；隐含层包含神经元 $ h_1, h_2 $，偏置 $ b_2 $，输出层为  $ o_1, o_2 $，$ w_i $ 为层与层之间连接的权重，激活函数为 $sigmoid$ 函数。对以上参数取初始值，如下图所示：</p>
<p><img src="/img/ch3/3.2.5.3.png" alt=""></p>
<p>其中：</p>
<ul>
<li>输入数据 $ i1=0.05, i2 = 0.10 $</li>
<li>输出数据 $ o1=0.01, o2=0.99 $;</li>
<li>初始权重 $ w1=0.15, w2=0.20, w3=0.25,w4=0.30, w5=0.40, w6=0.45, w7=0.50, w8=0.55 $</li>
<li>目标：给出输入数据 $ i1,i2 $ ( $0.05$和$0.10$ )，使输出尽可能与原始输出 $ o1,o2 $，( $0.01$和$0.99$)接近。</li>
</ul>
<p><strong>前向传播</strong></p>
<ol>
<li>输入层 —&gt; 输出层</li>
</ol>
<p>计算神经元 $ h1 $ 的输入加权和：</p>
<script type="math/tex; mode=display">
net_{h1} = w_1 * i_1 + w_2 * i_2 + b_1 * 1\\

net_{h1} = 0.15 * 0.05 + 0.2 * 0.1 + 0.35 * 1 = 0.3775</script><p>神经元 $ h1 $ 的输出 $ o1 $ ：（此处用到激活函数为 sigmoid 函数）：</p>
<script type="math/tex; mode=display">
out_{h1} = \frac{1}{1 + e^{-net_{h1}}} = \frac{1}{1 + e^{-0.3775}} = 0.593269992</script><p>同理，可计算出神经元 $ h2 $ 的输出 $ o1 $：</p>
<script type="math/tex; mode=display">
out_{h2} = 0.596884378</script><ol>
<li>隐含层—&gt;输出层：  　　</li>
</ol>
<p>计算输出层神经元 $ o1 $ 和 $ o2 $ 的值：</p>
<script type="math/tex; mode=display">
net_{o1} = w_5 * out_{h1} + w_6 * out_{h2} + b_2 * 1</script><script type="math/tex; mode=display">
net_{o1} = 0.4 * 0.593269992 + 0.45 * 0.596884378 + 0.6 * 1 = 1.105905967</script><script type="math/tex; mode=display">
out_{o1} = \frac{1}{1 + e^{-net_{o1}}} = \frac{1}{1 + e^{1.105905967}} = 0.75136079</script><p>这样前向传播的过程就结束了，我们得到输出值为 $ [0.75136079 ,  0.772928465] $，与实际值 $ [0.01 , 0.99] $ 相差还很远，现在我们对误差进行反向传播，更新权值，重新计算输出。</p>
<p><strong>反向传播 </strong></p>
<p>​    1.计算总误差</p>
<p>总误差：(这里使用Square Error)</p>
<script type="math/tex; mode=display">
E_{total} = \sum \frac{1}{2}(target - output)^2</script><p>但是有两个输出，所以分别计算 $ o1 $ 和 $ o2 $ 的误差，总误差为两者之和：</p>
<p>$E_{o1} = \frac{1}{2}(target_{o1} - out_{o1})^2<br>= \frac{1}{2}(0.01 - 0.75136507)^2 = 0.274811083$.</p>
<p>$E_{o2} = 0.023560026$.</p>
<p>$E_{total} = E_{o1} + E_{o2} = 0.274811083 + 0.023560026 = 0.298371109$.</p>
<p>​    2.隐含层 —&gt; 输出层的权值更新：</p>
<p>以权重参数 $ w5 $ 为例，如果我们想知道 $ w5 $ 对整体误差产生了多少影响，可以用整体误差对 $ w5 $ 求偏导求出：（链式法则）</p>
<script type="math/tex; mode=display">
\frac{\partial E_{total}}{\partial w5} = \frac{\partial E_{total}}{\partial out_{o1}} * \frac{\partial out_{o1}}{\partial net_{o1}} * \frac{\partial net_{o1}}{\partial w5}</script><p>下面的图可以更直观的看清楚误差是怎样反向传播的：</p>
<p><img src="/img/ch3/3.2.5.4.png" alt=""></p>
<h3 id="3-2-6-神经网络更“深”有什么意义？"><a href="#3-2-6-神经网络更“深”有什么意义？" class="headerlink" title="3.2.6 神经网络更“深”有什么意义？"></a>3.2.6 神经网络更“深”有什么意义？</h3><p>前提：在一定范围内。</p>
<ul>
<li>在神经元数量相同的情况下，深层网络结构具有更大容量，分层组合带来的是指数级的表达空间，能够组合成更多不同类型的子结构，这样可以更容易地学习和表示各种特征。</li>
<li>隐藏层增加则意味着由激活函数带来的非线性变换的嵌套层数更多，就能构造更复杂的映射关系。</li>
</ul>
<h2 id="3-3-超参数"><a href="#3-3-超参数" class="headerlink" title="3.3 超参数"></a>3.3 超参数</h2><h3 id="3-3-1-什么是超参数？"><a href="#3-3-1-什么是超参数？" class="headerlink" title="3.3.1 什么是超参数？"></a>3.3.1 什么是超参数？</h3><p>​    <strong>超参数</strong> : 在机器学习的上下文中，超参数是在开始学习过程之前设置值的参数，而不是通过训练得到的参数数据。通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果。</p>
<p>​    超参数通常存在于：</p>
<pre><code>1.  定义关于模型的更高层次的概念，如复杂性或学习能力。
2.  不能直接从标准模型培训过程中的数据中学习，需要预先定义。
3.  可以通过设置不同的值，训练不同的模型和选择更好的测试值来决定
</code></pre><p>​    超参数具体来讲比如算法中的学习率（learning rate）、梯度下降法迭代的数量（iterations）、隐藏层数目（hidden layers）、隐藏层单元数目、激活函数（ activation function）都需要根据实际情况来设置，这些数字实际上控制了最后的参数和的值，所以它们被称作超参数。</p>
<h3 id="3-3-2-如何寻找超参数的最优值？"><a href="#3-3-2-如何寻找超参数的最优值？" class="headerlink" title="3.3.2 如何寻找超参数的最优值？"></a>3.3.2 如何寻找超参数的最优值？</h3><p>​    在使用机器学习算法时，总有一些难调的超参数。例如权重衰减大小，高斯核宽度等等。这些参数需要人为设置，设置的值对结果产生较大影响。常见设置超参数的方法有：</p>
<ol>
<li><p>猜测和检查：根据经验或直觉，选择参数，一直迭代。</p>
</li>
<li><p>网格搜索：让计算机尝试在一定范围内均匀分布的一组值。</p>
</li>
<li><p>随机搜索：让计算机随机挑选一组值。</p>
</li>
<li><p>贝叶斯优化：使用贝叶斯优化超参数，会遇到贝叶斯优化算法本身就需要很多的参数的困难。</p>
</li>
<li><p>MITIE方法，好初始猜测的前提下进行局部优化。它使用BOBYQA算法，并有一个精心选择的起始点。由于BOBYQA只寻找最近的局部最优解，所以这个方法是否成功很大程度上取决于是否有一个好的起点。在MITIE的情况下，我们知道一个好的起点，但这不是一个普遍的解决方案，因为通常你不会知道好的起点在哪里。从好的方面来说，这种方法非常适合寻找局部最优解。稍后我会再讨论这一点。</p>
</li>
<li><p>最新提出的LIPO的全局优化方法。这个方法没有参数，而且经验证比随机搜索方法好。</p>
</li>
</ol>
<h3 id="3-3-3-超参数搜索一般过程？"><a href="#3-3-3-超参数搜索一般过程？" class="headerlink" title="3.3.3 超参数搜索一般过程？"></a>3.3.3 超参数搜索一般过程？</h3><p>超参数搜索一般过程：</p>
<ol>
<li>将数据集划分成训练集、验证集及测试集。</li>
<li>在训练集上根据模型的性能指标对模型参数进行优化。</li>
<li>在验证集上根据模型的性能指标对模型的超参数进行搜索。</li>
<li>步骤 2 和步骤 3 交替迭代，最终确定模型的参数和超参数，在测试集中验证评价模型的优劣。</li>
</ol>
<p>其中，搜索过程需要搜索算法，一般有：网格搜索、随机搜过、启发式智能搜索、贝叶斯搜索。</p>
<h2 id="3-4-激活函数"><a href="#3-4-激活函数" class="headerlink" title="3.4 激活函数"></a>3.4 激活函数</h2><h3 id="3-4-1-为什么需要非线性激活函数？"><a href="#3-4-1-为什么需要非线性激活函数？" class="headerlink" title="3.4.1 为什么需要非线性激活函数？"></a>3.4.1 为什么需要非线性激活函数？</h3><p><strong>为什么需要激活函数？</strong></p>
<ol>
<li>激活函数对模型学习、理解非常复杂和非线性的函数具有重要作用。</li>
<li>激活函数可以引入非线性因素。如果不使用激活函数，则输出信号仅是一个简单的线性函数。线性函数一个一级多项式，线性方程的复杂度有限，从数据中学习复杂函数映射的能力很小。没有激活函数，神经网络将无法学习和模拟其他复杂类型的数据，例如图像、视频、音频、语音等。</li>
<li>激活函数可以把当前特征空间通过一定的线性映射转换到另一个空间，让数据能够更好的被分类。</li>
</ol>
<p><strong>为什么激活函数需要非线性函数？</strong></p>
<ol>
<li>假若网络中全部是线性部件，那么线性的组合还是线性，与单独一个线性分类器无异。这样就做不到用非线性来逼近任意函数。</li>
<li>使用非线性激活函数 ，以便使网络更加强大，增加它的能力，使它可以学习复杂的事物，复杂的表单数据，以及表示输入输出之间非线性的复杂的任意函数映射。使用非线性激活函数，能够从输入输出之间生成非线性映射。</li>
</ol>
<h3 id="3-4-2-常见的激活函数及图像"><a href="#3-4-2-常见的激活函数及图像" class="headerlink" title="3.4.2 常见的激活函数及图像"></a>3.4.2 常见的激活函数及图像</h3><ol>
<li><p>sigmoid 激活函数</p>
<p>函数的定义为：$ f(x) = \frac{1}{1 + e^{-x}} $，其值域为 $ (0,1) $。</p>
<p>函数图像如下：</p>
</li>
</ol>
<p><img src="/img/ch3/3-26.png" alt=""></p>
<ol>
<li><p>tanh激活函数</p>
<p>函数的定义为：$ f(x) = tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} $，值域为 $ (-1,1) $。</p>
<p>函数图像如下：</p>
</li>
</ol>
<p><img src="/img/ch3/3-27.png" alt=""></p>
<ol>
<li><p>Relu激活函数</p>
<p>函数的定义为：$ f(x) = max(0, x) $  ，值域为 $ [0,+∞) $；</p>
<p>函数图像如下：</p>
</li>
</ol>
<p><img src="/img/ch3/3-28.png" alt=""></p>
<ol>
<li><p>Leak Relu 激活函数 </p>
<p>函数定义为： $ f(x) =  \left\{<br>\begin{aligned}<br>ax, \quad x<0 \\
x, \quad x>0<br>\end{aligned}<br>\right. $，值域为 $ (-∞,+∞) $。 </p>
<p>图像如下（$ a = 0.5 $）：</p>
</li>
</ol>
<p><img src="/img/ch3/3-29.png" alt=""></p>
<ol>
<li><p>SoftPlus 激活函数</p>
<p>函数的定义为：$ f(x) = ln( 1 + e^x) $，值域为 $ (0,+∞) $。</p>
<p>函数图像如下:</p>
</li>
</ol>
<p><img src="/img/ch3/3-30.png" alt=""></p>
<ol>
<li><p>softmax 函数</p>
<p>函数定义为： $ \sigma(z)_j = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} $。</p>
<p>Softmax 多用于多分类神经网络输出。</p>
</li>
</ol>
<h3 id="3-4-3-常见激活函数的导数计算？"><a href="#3-4-3-常见激活函数的导数计算？" class="headerlink" title="3.4.3 常见激活函数的导数计算？"></a>3.4.3 常见激活函数的导数计算？</h3><p>对常见激活函数，导数计算如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>原函数</th>
<th>函数表达式</th>
<th>导数</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sigmoid激活函数</td>
<td>$f(x)=\frac{1}{1+e^{-x}}$</td>
<td>$f^{‘}(x)=\frac{1}{1+e^{-x}}\left( 1- \frac{1}{1+e^{-x}} \right)=f(x)(1-f(x))$</td>
<td>当$x=10$,或$x=-10​$，$f^{‘}(x) \approx0​$,当$x=0​$$f^{‘}(x) =0.25​$</td>
</tr>
<tr>
<td>Tanh激活函数</td>
<td>$f(x)=tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}$</td>
<td>$f^{‘}(x)=-(tanh(x))^2$</td>
<td>当$x=10$,或$x=-10$，$f^{‘}(x) \approx0$,当$x=0$$f^{`}(x) =1$</td>
</tr>
<tr>
<td>Relu激活函数</td>
<td>$f(x)=max(0,x)$</td>
<td>$c(u)=\begin{cases} 0,x<0 \\ 1,x>0 \ undefined,x=0\end{cases}$</td>
<td>通常$x=0$时，给定其导数为1和0</td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-4-4-激活函数有哪些性质？"><a href="#3-4-4-激活函数有哪些性质？" class="headerlink" title="3.4.4 激活函数有哪些性质？"></a>3.4.4 激活函数有哪些性质？</h3><ol>
<li>非线性： 当激活函数是线性的，一个两层的神经网络就可以基本上逼近所有的函数。但如果激活函数是恒等激活函数的时候，即 $ f(x)=x $，就不满足这个性质，而且如果 MLP 使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的；</li>
<li>可微性： 当优化方法是基于梯度的时候，就体现了该性质；</li>
<li>单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数；</li>
<li>$ f(x)≈x $： 当激活函数满足这个性质的时候，如果参数的初始化是随机的较小值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要详细地去设置初始值；</li>
<li>输出值的范围： 当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的 Learning Rate。</li>
</ol>
<h3 id="3-4-5-如何选择激活函数？"><a href="#3-4-5-如何选择激活函数？" class="headerlink" title="3.4.5 如何选择激活函数？"></a>3.4.5 如何选择激活函数？</h3><p>​    选择一个适合的激活函数并不容易，需要考虑很多因素，通常的做法是，如果不确定哪一个激活函数效果更好，可以把它们都试试，然后在验证集或者测试集上进行评价。然后看哪一种表现的更好，就去使用它。</p>
<p>以下是常见的选择情况：</p>
<ol>
<li>如果输出是 0、1 值（二分类问题），则输出层选择 sigmoid 函数，然后其它的所有单元都选择 Relu 函数。</li>
<li>如果在隐藏层上不确定使用哪个激活函数，那么通常会使用 Relu 激活函数。有时，也会使用 tanh 激活函数，但 Relu 的一个优点是：当是负值的时候，导数等于 0。</li>
<li>sigmoid 激活函数：除了输出层是一个二分类问题基本不会用它。</li>
<li>tanh 激活函数：tanh 是非常优秀的，几乎适合所有场合。</li>
<li>ReLu 激活函数：最常用的默认函数，如果不确定用哪个激活函数，就使用 ReLu 或者 Leaky ReLu，再去尝试其他的激活函数。</li>
<li>如果遇到了一些死的神经元，我们可以使用 Leaky ReLU 函数。</li>
</ol>
<h3 id="3-4-6-使用-ReLu-激活函数的优点？"><a href="#3-4-6-使用-ReLu-激活函数的优点？" class="headerlink" title="3.4.6 使用 ReLu 激活函数的优点？"></a>3.4.6 使用 ReLu 激活函数的优点？</h3><ol>
<li>在区间变动很大的情况下，ReLu 激活函数的导数或者激活函数的斜率都会远大于 0，在程序实现就是一个 if-else 语句，而 sigmoid 函数需要进行浮点四则运算，在实践中，使用 ReLu 激活函数神经网络通常会比使用 sigmoid 或者 tanh 激活函数学习的更快。</li>
<li>sigmoid 和 tanh 函数的导数在正负饱和区的梯度都会接近于 0，这会造成梯度弥散，而 Relu 和Leaky ReLu 函数大于 0 部分都为常数，不会产生梯度弥散现象。</li>
<li>需注意，Relu 进入负半区的时候，梯度为 0，神经元此时不会训练，产生所谓的稀疏性，而 Leaky ReLu 不会产生这个问题。</li>
</ol>
<h3 id="3-4-7-什么时候可以用线性激活函数？"><a href="#3-4-7-什么时候可以用线性激活函数？" class="headerlink" title="3.4.7 什么时候可以用线性激活函数？"></a>3.4.7 什么时候可以用线性激活函数？</h3><ol>
<li>输出层，大多使用线性激活函数。</li>
<li>在隐含层可能会使用一些线性激活函数。</li>
<li>一般用到的线性激活函数很少。</li>
</ol>
<h3 id="3-4-8-怎样理解-Relu（-lt-0-时）是非线性激活函数？"><a href="#3-4-8-怎样理解-Relu（-lt-0-时）是非线性激活函数？" class="headerlink" title="3.4.8 怎样理解 Relu（&lt; 0 时）是非线性激活函数？"></a>3.4.8 怎样理解 Relu（&lt; 0 时）是非线性激活函数？</h3><p>Relu 激活函数图像如下：</p>
<p><img src="/img/ch3/3-32.png" alt=""></p>
<p>根据图像可看出具有如下特点：</p>
<ol>
<li><p>单侧抑制；</p>
</li>
<li><p>相对宽阔的兴奋边界；</p>
</li>
<li><p>稀疏激活性；</p>
<p>ReLU 函数从图像上看，是一个分段线性函数，把所有的负值都变为 0，而正值不变，这样就成为单侧抑制。</p>
<p>因为有了这单侧抑制，才使得神经网络中的神经元也具有了稀疏激活性。</p>
<p><strong>稀疏激活性</strong>：从信号方面来看，即神经元同时只对输入信号的少部分选择性响应，大量信号被刻意的屏蔽了，这样可以提高学习的精度，更好更快地提取稀疏特征。当 $ x<0 $ 时，ReLU 硬饱和，而当 $ x>0 $ 时，则不存在饱和问题。ReLU 能够在 $ x&gt;0 $ 时保持梯度不衰减，从而缓解梯度消失问题。</p>
</li>
</ol>
<h3 id="3-4-9-Softmax-定义及作用"><a href="#3-4-9-Softmax-定义及作用" class="headerlink" title="3.4.9 Softmax 定义及作用"></a>3.4.9 Softmax 定义及作用</h3><p>Softmax 是一种形如下式的函数：</p>
<script type="math/tex; mode=display">
P(i) = \frac{exp(\theta_i^T x)}{\sum_{k=1}^{K} exp(\theta_i^T x)}</script><p>​    其中，$ \theta_i $ 和 $ x $ 是列向量，$ \theta_i^T x $ 可能被换成函数关于 $ x $ 的函数 $ f_i(x) $</p>
<p>​    通过 softmax 函数，可以使得 $ P(i) $ 的范围在 $ [0,1] $ 之间。在回归和分类问题中，通常 $ \theta $ 是待求参数，通过寻找使得 $ P(i) $ 最大的 $ \theta_i $ 作为最佳参数。</p>
<p>​    但是，使得范围在 $ [0,1] $  之间的方法有很多，为啥要在前面加上以 $ e $ 的幂函数的形式呢？参考 logistic 函数：</p>
<script type="math/tex; mode=display">
P(i) = \frac{1}{1+exp(-\theta_i^T x)}</script><p>​    这个函数的作用就是使得 $ P(i) $ 在负无穷到 0 的区间趋向于 0， 在 0 到正无穷的区间趋向 1,。同样 softmax 函数加入了 $ e $ 的幂函数正是为了两极化：正样本的结果将趋近于 1，而负样本的结果趋近于 0。这样为多类别提供了方便（可以把 $ P(i) $ 看做是样本属于类别的概率）。可以说，Softmax 函数是 logistic 函数的一种泛化。</p>
<p>​    softmax 函数可以把它的输入，通常被称为 logits 或者 logit scores，处理成 0 到 1 之间，并且能够把输出归一化到和为 1。这意味着 softmax 函数与分类的概率分布等价。它是一个网络预测多酚类问题的最佳输出激活函数。</p>
<h3 id="3-4-10-Softmax-函数如何应用于多分类？"><a href="#3-4-10-Softmax-函数如何应用于多分类？" class="headerlink" title="3.4.10 Softmax 函数如何应用于多分类？"></a>3.4.10 Softmax 函数如何应用于多分类？</h3><p>​    softmax 用于多分类过程中，它将多个神经元的输出，映射到 $ (0,1) $ 区间内，可以看成概率来理解，从而来进行多分类！</p>
<p>​    假设我们有一个数组，$ V_i $ 表示 $ V $  中的第 $ i $ 个元素，那么这个元素的 softmax 值就是</p>
<script type="math/tex; mode=display">
S_i = \frac{e^{V_i}}{\sum_j e^{V_j}}</script><p>​    从下图看，神经网络中包含了输入层，然后通过两个特征层处理，最后通过 softmax 分析器就能得到不同条件下的概率，这里需要分成三个类别，最终会得到 $ y=0, y=1, y=2 $ 的概率值。</p>
<p><img src="/img/ch3/3.4.9.1.png" alt=""></p>
<p>继续看下面的图，三个输入通过 softmax 后得到一个数组 $ [0.05 , 0.10 , 0.85] $，这就是 soft 的功能。</p>
<p><img src="/img/ch3/3.4.9.2.png" alt=""></p>
<p>更形象的映射过程如下图所示：</p>
<p><img src="/img/ch3/3.4.9.3.png" alt="****"></p>
<p>​    softmax 直白来说就是将原来输出是 $ 3,1,-3 $ 通过 softmax 函数一作用，就映射成为 $ (0,1) $ 的值，而这些值的累和为 $ 1 $（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标！</p>
<h3 id="3-4-11-交叉熵代价函数定义及其求导推导"><a href="#3-4-11-交叉熵代价函数定义及其求导推导" class="headerlink" title="3.4.11 交叉熵代价函数定义及其求导推导"></a>3.4.11 交叉熵代价函数定义及其求导推导</h3><p>(<strong>贡献者：黄钦建－华南理工大学</strong>)</p>
<p>​    神经元的输出就是 a = σ(z)，其中$z=\sum w_{j}i_{j}+b$是输⼊的带权和。</p>
<p>$C=-\frac{1}{n}\sum[ylna+(1-y)ln(1-a)]$</p>
<p>​    其中 n 是训练数据的总数，求和是在所有的训练输⼊ x 上进⾏的， y 是对应的⽬标输出。</p>
<p>​    表达式是否解决学习缓慢的问题并不明显。实际上，甚⾄将这个定义看做是代价函数也不是显⽽易⻅的！在解决学习缓慢前，我们来看看交叉熵为何能够解释成⼀个代价函数。</p>
<p>​    将交叉熵看做是代价函数有两点原因。</p>
<p>​    第⼀，它是⾮负的， C &gt; 0。可以看出：式子中的求和中的所有独⽴的项都是负数的，因为对数函数的定义域是 (0，1)，并且求和前⾯有⼀个负号，所以结果是非负。</p>
<p>​    第⼆，如果对于所有的训练输⼊ x，神经元实际的输出接近⽬标值，那么交叉熵将接近 0。</p>
<p>​    假设在这个例⼦中， y = 0 ⽽ a ≈ 0。这是我们想到得到的结果。我们看到公式中第⼀个项就消去了，因为 y = 0，⽽第⼆项实际上就是 − ln(1 − a) ≈ 0。反之， y = 1 ⽽ a ≈ 1。所以在实际输出和⽬标输出之间的差距越⼩，最终的交叉熵的值就越低了。（这里假设输出结果不是0，就是1，实际分类也是这样的）</p>
<p>​    综上所述，交叉熵是⾮负的，在神经元达到很好的正确率的时候会接近 0。这些其实就是我们想要的代价函数的特性。其实这些特性也是⼆次代价函数具备的。所以，交叉熵就是很好的选择了。但是交叉熵代价函数有⼀个⽐⼆次代价函数更好的特性就是它避免了学习速度下降的问题。为了弄清楚这个情况，我们来算算交叉熵函数关于权重的偏导数。我们将$a={\varsigma}(z)$代⼊到 公式中应⽤两次链式法则，得到：</p>
<p>$\begin{eqnarray}\frac{\partial C}{\partial w_{j}}&amp;=&amp;-\frac{1}{n}\sum \frac{\partial }{\partial w_{j}}[ylna+(1-y)ln(1-a)]\\&amp;=&amp;-\frac{1}{n}\sum \frac{\partial }{\partial a}[ylna+(1-y)ln(1-a)]<em>\frac{\partial a}{\partial w_{j}}\\&amp;=&amp;-\frac{1}{n}\sum (\frac{y}{a}-\frac{1-y}{1-a})</em>\frac{\partial a}{\partial w_{j}}\\&amp;=&amp;-\frac{1}{n}\sum (\frac{y}{\varsigma(z)}-\frac{1-y}{1-\varsigma(z)})\frac{\partial \varsigma(z)}{\partial w_{j}}\\&amp;=&amp;-\frac{1}{n}\sum (\frac{y}{\varsigma(z)}-\frac{1-y}{1-\varsigma(z)}){\varsigma}’(z)x_{j}\end{eqnarray}$</p>
<p>​    根据$\varsigma(z)=\frac{1}{1+e^{-z}}$ 的定义，和⼀些运算，我们可以得到 ${\varsigma}’(z)=\varsigma(z)(1-\varsigma(z))$。化简后可得：</p>
<p>$\frac{\partial C}{\partial w_{j}}=\frac{1}{n}\sum x_{j}({\varsigma}(z)-y)$</p>
<p>​    这是⼀个优美的公式。它告诉我们权重学习的速度受到$\varsigma(z)-y$，也就是输出中的误差的控制。更⼤的误差，更快的学习速度。这是我们直觉上期待的结果。特别地，这个代价函数还避免了像在⼆次代价函数中类似⽅程中${\varsigma}’(z)$导致的学习缓慢。当我们使⽤交叉熵的时候，${\varsigma}’(z)$被约掉了，所以我们不再需要关⼼它是不是变得很⼩。这种约除就是交叉熵带来的特效。实际上，这也并不是⾮常奇迹的事情。我们在后⾯可以看到，交叉熵其实只是满⾜这种特性的⼀种选择罢了。</p>
<p>​    根据类似的⽅法，我们可以计算出关于偏置的偏导数。我这⾥不再给出详细的过程，你可以轻易验证得到：</p>
<p>$\frac{\partial C}{\partial b}=\frac{1}{n}\sum ({\varsigma}(z)-y)$</p>
<p>​    再⼀次, 这避免了⼆次代价函数中类似${\varsigma}’(z)$项导致的学习缓慢。</p>
<h3 id="3-4-12-为什么Tanh收敛速度比Sigmoid快？"><a href="#3-4-12-为什么Tanh收敛速度比Sigmoid快？" class="headerlink" title="3.4.12 为什么Tanh收敛速度比Sigmoid快？"></a>3.4.12 为什么Tanh收敛速度比Sigmoid快？</h3><p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<p>首先看如下两个函数的求导：</p>
<p>$tanh^{,}(x)=1-tanh(x)^{2}\in (0,1)$</p>
<p>$s^{,}(x)=s(x)*(1-s(x))\in (0,\frac{1}{4}]$</p>
<p>由上面两个公式可知tanh(x)梯度消失的问题比sigmoid轻，所以Tanh收敛速度比Sigmoid快。</p>
<p>3.4.13</p>
<h3 id="3-4-12-内聚外斥-Center-Loss"><a href="#3-4-12-内聚外斥-Center-Loss" class="headerlink" title="3.4.12 内聚外斥 - Center Loss"></a>3.4.12 内聚外斥 - Center Loss</h3><p><strong>（贡献者：李世轩－加州大学伯克利分校）</strong></p>
<p>在计算机视觉任务中, 由于其简易性, 良好的表现, 与对分类任务的概率性理解, Cross Entropy Loss (交叉熵代价) + Softmax 组合被广泛应用于以分类任务为代表的任务中. 在此应用下, 我们可将其学习过程进一步理解为: 更相似(同类/同物体)的图像在特征域中拥有“更近的距离”, 相反则”距离更远“. 换而言之, 我们可以进一步理解为其学习了一种低类内距离(Intra-class Distance)与高类间距离(Inter-class Distance)的特征判别模型. 在此Center Loss则可以高效的计算出这种具判别性的特征. 不同于传统的Softmax Loss, Center Loss通过学习“特征中心”从而最小化其类内距离. 其表达形式如下:</p>
<p>$L_{C} = \frac{1}{2}\sum^{m}_{i=1}||x_{i}-c_{y_{i}}||^{2}_{2}$</p>
<p>其中$x_{i}$表示FCN(全连接层)之前的特征, $c_{y_{i}}$表示第$y_{i} $个类别的特征中心, $m$表示mini-batch的大小. 我们很清楚的看到$L_{C}$的终极目标为最小化每个特征与其特征中心的方差, 即最小化类内距离. 其迭代公式为:</p>
<p>$\frac{\partial L_{C}}{\partial x_{i}}=x_{i}-c_{y_{i}}$</p>
<p>$\Delta{c_{j}} = \frac{\sum^{m}_{i=1}\delta(y_{i}=j)\cdot(c_{j}-x_{i})}{1+\sum^{m}_{i=1}\delta(y_{i}=j)}$</p>
<p>其中$ \delta(condition)=\left\{<br>\begin{array}{rcl}<br>1       &amp;      &amp; {condition is True}\\<br>0     &amp;      &amp; {otherwise}\ \end{array} \right.$</p>
<p>结合Softmax, 我们可以搭配二者使用, 适当平衡这两种监督信号. 在Softmax拉开类间距离的同时, 利用Center Loss最小化类内距离. 例如:</p>
<p>$\begin{eqnarray}L &amp; = &amp; L_{S} + \lambda L_{C} \ &amp;=&amp; -\sum^{m}_{i=1}log\frac{e^{W_{y}^{T}x_{i}+b_{y_{i}}}}{\sum^{m}_{i=1}e^{W^{T}_{j}x_{i}+b_{j}}} + \frac{\lambda}{2}\sum^{m}_{i=1}||x_{i}-c_{y_{i}}||^{2}_{2}\ \end{eqnarray}$</p>
<p>即便如此, Center Loss仍有它的不足之处: 其特征中心为存储在网络模型之外的额外参数, 不能与模型参数一同优化. 这些额外参数将与记录每一步特征变化的自动回归均值估计(autoregressive mean estimator)进行更迭. 当需要学习的类别数量较大时, mini-batch可能无力提供足够的样本进行均值估计. 若此Center Loss将需要平衡两种监督损失来以确定更迭, 其过程需要一个对平衡超参数的搜索过程, 使得其择值消耗昂贵.</p>
<h2 id="3-5-Batch-Size"><a href="#3-5-Batch-Size" class="headerlink" title="3.5 Batch_Size"></a>3.5 Batch_Size</h2><h3 id="3-5-1-为什么需要-Batch-Size？"><a href="#3-5-1-为什么需要-Batch-Size？" class="headerlink" title="3.5.1 为什么需要 Batch_Size？"></a>3.5.1 为什么需要 Batch_Size？</h3><p>Batch的选择，首先决定的是下降的方向。</p>
<p>如果数据集比较小，可采用全数据集的形式，好处是：</p>
<ol>
<li>由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。</li>
<li>由于不同权重的梯度值差别巨大，因此选取一个全局的学习率很困难。 Full Batch Learning 可以使用 Rprop 只基于梯度符号并且针对性单独更新各权值。</li>
</ol>
<p>对于更大的数据集，假如采用全数据集的形式，坏处是：</p>
<ol>
<li>随着数据集的海量增长和内存限制，一次性载入所有的数据进来变得越来越不可行。</li>
<li>以 Rprop 的方式迭代，会由于各个 Batch 之间的采样差异性，各次梯度修正值相互抵消，无法修正。这才有了后来 RMSProp 的妥协方案。 </li>
</ol>
<h3 id="3-5-2-Batch-Size-值的选择"><a href="#3-5-2-Batch-Size-值的选择" class="headerlink" title="3.5.2 Batch_Size 值的选择"></a>3.5.2 Batch_Size 值的选择</h3><p>​    假如每次只训练一个样本，即 Batch_Size = 1。线性神经元在均方误差代价函数的错误面是一个抛物面，横截面是椭圆。对于多层神经元、非线性网络，在局部依然近似是抛物面。此时，每次修正方向以各自样本的梯度方向修正，横冲直撞各自为政，难以达到收敛。</p>
<p>​    既然 Batch_Size 为全数据集或者Batch_Size = 1都有各自缺点，可不可以选择一个适中的Batch_Size值呢？</p>
<p>​    此时，可采用批梯度下降法（Mini-batches Learning）。因为如果数据集足够充分，那么用一半（甚至少得多）的数据训练算出来的梯度与用全部数据训练出来的梯度是几乎一样的。</p>
<h3 id="3-5-3-在合理范围内，增大Batch-Size有何好处？"><a href="#3-5-3-在合理范围内，增大Batch-Size有何好处？" class="headerlink" title="3.5.3 在合理范围内，增大Batch_Size有何好处？"></a>3.5.3 在合理范围内，增大Batch_Size有何好处？</h3><ol>
<li>内存利用率提高了，大矩阵乘法的并行化效率提高。</li>
<li>跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。</li>
<li>在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。</li>
</ol>
<h3 id="3-5-4-盲目增大-Batch-Size-有何坏处？"><a href="#3-5-4-盲目增大-Batch-Size-有何坏处？" class="headerlink" title="3.5.4 盲目增大 Batch_Size 有何坏处？"></a>3.5.4 盲目增大 Batch_Size 有何坏处？</h3><ol>
<li>内存利用率提高了，但是内存容量可能撑不住了。</li>
<li>跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。</li>
<li>Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。</li>
</ol>
<h3 id="3-5-5-调节-Batch-Size-对训练效果影响到底如何？"><a href="#3-5-5-调节-Batch-Size-对训练效果影响到底如何？" class="headerlink" title="3.5.5 调节 Batch_Size 对训练效果影响到底如何？"></a>3.5.5 调节 Batch_Size 对训练效果影响到底如何？</h3><ol>
<li>Batch_Size 太小，模型表现效果极其糟糕(error飙升)。</li>
<li>随着 Batch_Size 增大，处理相同数据量的速度越快。</li>
<li>随着 Batch_Size 增大，达到相同精度所需要的 epoch 数量越来越多。</li>
<li>由于上述两种因素的矛盾， Batch_Size 增大到某个时候，达到时间上的最优。</li>
<li>由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到某些时候，达到最终收敛精度上的最优。 </li>
</ol>
<h2 id="3-6-归一化"><a href="#3-6-归一化" class="headerlink" title="3.6 归一化"></a>3.6 归一化</h2><h3 id="3-6-1-归一化含义？"><a href="#3-6-1-归一化含义？" class="headerlink" title="3.6.1 归一化含义？"></a>3.6.1 归一化含义？</h3><ol>
<li><p>归纳统一样本的统计分布性。归一化在 $ 0-1$ 之间是统计的概率分布，归一化在$ -1—+1$ 之间是统计的坐标分布。</p>
</li>
<li><p>无论是为了建模还是为了计算，首先基本度量单位要同一，神经网络是以样本在事件中的统计分别几率来进行训练（概率计算）和预测，且 sigmoid 函数的取值是 0 到 1 之间的，网络最后一个节点的输出也是如此，所以经常要对样本的输出归一化处理。</p>
</li>
<li><p>归一化是统一在 $ 0-1 $ 之间的统计概率分布，当所有样本的输入信号都为正值时，与第一隐含层神经元相连的权值只能同时增加或减小，从而导致学习速度很慢。</p>
</li>
<li><p>另外在数据中常存在奇异样本数据，奇异样本数据存在所引起的网络训练时间增加，并可能引起网络无法收敛。为了避免出现这种情况及后面数据处理的方便，加快网络学习速度，可以对输入信号进行归一化，使得所有样本的输入信号其均值接近于 0 或与其均方差相比很小。</p>
</li>
</ol>
<h3 id="3-6-2-为什么要归一化？"><a href="#3-6-2-为什么要归一化？" class="headerlink" title="3.6.2 为什么要归一化？"></a>3.6.2 为什么要归一化？</h3><ol>
<li>为了后面数据处理的方便，归一化的确可以避免一些不必要的数值问题。</li>
<li>为了程序运行时收敛加快。 </li>
<li>同一量纲。样本数据的评价标准不一样，需要对其量纲化，统一评价标准。这算是应用层面的需求。</li>
<li>避免神经元饱和。啥意思？就是当神经元的激活在接近 0 或者 1 时会饱和，在这些区域，梯度几乎为 0，这样，在反向传播过程中，局部梯度就会接近 0，这会有效地“杀死”梯度。</li>
<li>保证输出数据中数值小的不被吞食。 </li>
</ol>
<h3 id="3-6-3-为什么归一化能提高求解最优解速度？"><a href="#3-6-3-为什么归一化能提高求解最优解速度？" class="headerlink" title="3.6.3 为什么归一化能提高求解最优解速度？"></a>3.6.3 为什么归一化能提高求解最优解速度？</h3><p><img src="/img/ch3/3.6.3.1.png" alt=""></p>
<p>​    上图是代表数据是否均一化的最优解寻解过程（圆圈可以理解为等高线）。左图表示未经归一化操作的寻解过程，右图表示经过归一化后的寻解过程。</p>
<p>​    当使用梯度下降法寻求最优解时，很有可能走“之字型”路线（垂直等高线走），从而导致需要迭代很多次才能收敛；而右图对两个原始特征进行了归一化，其对应的等高线显得很圆，在梯度下降进行求解时能较快的收敛。</p>
<p>​    因此如果机器学习模型使用梯度下降法求最优解时，归一化往往非常有必要，否则很难收敛甚至不能收敛。</p>
<h3 id="3-6-4-3D-图解未归一化"><a href="#3-6-4-3D-图解未归一化" class="headerlink" title="3.6.4 3D 图解未归一化"></a>3.6.4 3D 图解未归一化</h3><p>例子：</p>
<p>​    假设 $ w1 $ 的范围在 $ [-10, 10] $，而 $ w2 $ 的范围在 $ [-100, 100] $，梯度每次都前进 1 单位，那么在 $ w1 $ 方向上每次相当于前进了 $ 1/20 $，而在 $ w2 $ 上只相当于 $ 1/200 $！某种意义上来说，在 $ w2 $ 上前进的步长更小一些,而 $ w1 $ 在搜索过程中会比 $ w2 $ “走”得更快。</p>
<p>​    这样会导致，在搜索过程中更偏向于 $ w1 $ 的方向。走出了“L”形状，或者成为“之”字形。</p>
<p><img src="/img/ch3/3-37.png" alt=""></p>
<h3 id="3-6-5-归一化有哪些类型？"><a href="#3-6-5-归一化有哪些类型？" class="headerlink" title="3.6.5 归一化有哪些类型？"></a>3.6.5 归一化有哪些类型？</h3><ol>
<li>线性归一化</li>
</ol>
<script type="math/tex; mode=display">
x^{\prime} = \frac{x-min(x)}{max(x) - min(x)}</script><p>​    适用范围：比较适用在数值比较集中的情况。</p>
<p>​    缺点：如果 max 和 min 不稳定，很容易使得归一化结果不稳定，使得后续使用效果也不稳定。</p>
<ol>
<li>标准差标准化</li>
</ol>
<script type="math/tex; mode=display">
x^{\prime} = \frac{x-\mu}{\sigma}</script><p>​    含义：经过处理的数据符合标准正态分布，即均值为 0，标准差为 1 其中 $ \mu $ 为所有样本数据的均值，$ \sigma $ 为所有样本数据的标准差。</p>
<ol>
<li><p>非线性归一化</p>
<p>适用范围：经常用在数据分化比较大的场景，有些数值很大，有些很小。通过一些数学函数，将原始值进行映射。该方法包括 $ log $、指数，正切等。</p>
</li>
</ol>
<h3 id="3-6-6-局部响应归一化作用"><a href="#3-6-6-局部响应归一化作用" class="headerlink" title="3.6.6 局部响应归一化作用"></a>3.6.6 局部响应归一化作用</h3><p>​    LRN 是一种提高深度学习准确度的技术方法。LRN 一般是在激活、池化函数后的一种方法。</p>
<p>​    在 ALexNet 中，提出了 LRN 层，对局部神经元的活动创建竞争机制，使其中响应比较大对值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。</p>
<h3 id="3-6-7-理解局部响应归一化"><a href="#3-6-7-理解局部响应归一化" class="headerlink" title="3.6.7 理解局部响应归一化"></a>3.6.7 理解局部响应归一化</h3><p>​    局部响应归一化原理是仿造生物学上活跃的神经元对相邻神经元的抑制现象（侧抑制），其公式如下：</p>
<script type="math/tex; mode=display">
b_{x,y}^i = a_{x,y}^i / (k + \alpha \sum_{j=max(0, i-n/2)}^{min(N-1, i+n/2)}(a_{x,y}^j)^2 )^\beta</script><p>其中，<br>1) $ a $：表示卷积层（包括卷积操作和池化操作）后的输出结果，是一个四维数组[batch,height,width,channel]。</p>
<ul>
<li>batch：批次数(每一批为一张图片)。</li>
<li>height：图片高度。</li>
<li>width：图片宽度。</li>
<li>channel：通道数。可以理解成一批图片中的某一个图片经过卷积操作后输出的神经元个数，或理解为处理后的图片深度。</li>
</ul>
<p>2) $ a_{x,y}^i $ 表示在这个输出结构中的一个位置 $ [a,b,c,d] $，可以理解成在某一张图中的某一个通道下的某个高度和某个宽度位置的点，即第 $ a $ 张图的第 $ d $ 个通道下的高度为b宽度为c的点。</p>
<p>3) $ N $：论文公式中的 $ N $ 表示通道数 (channel)。</p>
<p>4) $ a $，$ n/2 $， $ k $ 分别表示函数中的 input,depth_radius,bias。参数 $ k, n, \alpha, \beta $ 都是超参数，一般设置 $ k=2, n=5, \alpha=1*e-4, \beta=0.75 $</p>
<p>5) $ \sum $：$ \sum $ 叠加的方向是沿着通道方向的，即每个点值的平方和是沿着 $ a $ 中的第 3 维 channel 方向的，也就是一个点同方向的前面 $ n/2 $ 个通道（最小为第 $ 0 $ 个通道）和后 $ n/2 $ 个通道（最大为第 $ d-1 $ 个通道）的点的平方和(共 $ n+1 $ 个点)。而函数的英文注解中也说明了把 input 当成是 $ d $ 个 3 维的矩阵，说白了就是把 input 的通道数当作 3 维矩阵的个数，叠加的方向也是在通道方向。 </p>
<p>简单的示意图如下：</p>
<p><img src="/img/ch3/3.6.7.1.png" alt=""></p>
<h3 id="3-6-8-什么是批归一化（Batch-Normalization）"><a href="#3-6-8-什么是批归一化（Batch-Normalization）" class="headerlink" title="3.6.8 什么是批归一化（Batch Normalization）"></a>3.6.8 什么是批归一化（Batch Normalization）</h3><p>​    以前在神经网络训练中，只是对输入层数据进行归一化处理，却没有在中间层进行归一化处理。要知道，虽然我们对输入数据进行了归一化处理，但是输入数据经过 $ \sigma(WX+b) $ 这样的矩阵乘法以及非线性运算之后，其数据分布很可能被改变，而随着深度网络的多层运算之后，数据分布的变化将越来越大。如果我们能在网络的中间也进行归一化处理，是否对网络的训练起到改进作用呢？答案是肯定的。 </p>
<p>​    这种在神经网络中间层也进行归一化处理，使训练效果更好的方法，就是批归一化Batch Normalization（BN）。</p>
<h3 id="3-6-9-批归一化（BN）算法的优点"><a href="#3-6-9-批归一化（BN）算法的优点" class="headerlink" title="3.6.9 批归一化（BN）算法的优点"></a>3.6.9 批归一化（BN）算法的优点</h3><p>下面我们来说一下BN算法的优点： </p>
<ol>
<li>减少了人为选择参数。在某些情况下可以取消 dropout 和 L2 正则项参数,或者采取更小的 L2 正则项约束参数； </li>
<li>减少了对学习率的要求。现在我们可以使用初始很大的学习率或者选择了较小的学习率，算法也能够快速训练收敛； </li>
<li>可以不再使用局部响应归一化。BN 本身就是归一化网络(局部响应归一化在 AlexNet 网络中存在) </li>
<li>破坏原来的数据分布，一定程度上缓解过拟合（防止每批训练中某一个样本经常被挑选到，文献说这个可以提高 1% 的精度）。 </li>
<li>减少梯度消失，加快收敛速度，提高训练精度。</li>
</ol>
<h3 id="3-6-10-批归一化（BN）算法流程"><a href="#3-6-10-批归一化（BN）算法流程" class="headerlink" title="3.6.10 批归一化（BN）算法流程"></a>3.6.10 批归一化（BN）算法流程</h3><p>下面给出 BN 算法在训练时的过程</p>
<p>输入：上一层输出结果 $ X = {x_1, x_2, …, x_m} $，学习参数 $ \gamma, \beta $</p>
<p>算法流程：</p>
<ol>
<li>计算上一层输出数据的均值</li>
</ol>
<script type="math/tex; mode=display">
\mu_{\beta} = \frac{1}{m} \sum_{i=1}^m(x_i)</script><p>其中，$ m $ 是此次训练样本 batch 的大小。</p>
<ol>
<li>计算上一层输出数据的标准差</li>
</ol>
<script type="math/tex; mode=display">
\sigma_{\beta}^2 = \frac{1}{m} \sum_{i=1}^m (x_i - \mu_{\beta})^2</script><ol>
<li>归一化处理，得到</li>
</ol>
<script type="math/tex; mode=display">
\hat x_i = \frac{x_i + \mu_{\beta}}{\sqrt{\sigma_{\beta}^2} + \epsilon}</script><p>其中 $ \epsilon $ 是为了避免分母为 0 而加进去的接近于 0 的很小值</p>
<ol>
<li>重构，对经过上面归一化处理得到的数据进行重构，得到</li>
</ol>
<script type="math/tex; mode=display">
y_i = \gamma \hat x_i + \beta</script><p>其中，$ \gamma, \beta $ 为可学习参数。</p>
<p>注：上述是 BN 训练时的过程，但是当在投入使用时，往往只是输入一个样本，没有所谓的均值 $ \mu_{\beta} $ 和标准差 $ \sigma_{\beta}^2 $。此时，均值 $ \mu_{\beta} $ 是计算所有 batch $ \mu_{\beta} $ 值的平均值得到，标准差 $ \sigma_{\beta}^2 $ 采用每个batch $ \sigma_{\beta}^2 $  的无偏估计得到。</p>
<h3 id="3-6-11-批归一化和群组归一化比较"><a href="#3-6-11-批归一化和群组归一化比较" class="headerlink" title="3.6.11 批归一化和群组归一化比较"></a>3.6.11 批归一化和群组归一化比较</h3><div class="table-container">
<table>
<thead>
<tr>
<th>名称</th>
<th style="text-align:left">特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>批量归一化（Batch Normalization，以下简称 BN）</td>
<td style="text-align:left">可让各种网络并行训练。但是，批量维度进行归一化会带来一些问题——批量统计估算不准确导致批量变小时，BN 的误差会迅速增加。在训练大型网络和将特征转移到计算机视觉任务中（包括检测、分割和视频），内存消耗限制了只能使用小批量的 BN。</td>
</tr>
<tr>
<td>群组归一化 Group Normalization (简称 GN)</td>
<td style="text-align:left">GN 将通道分成组，并在每组内计算归一化的均值和方差。GN 的计算与批量大小无关，并且其准确度在各种批量大小下都很稳定。</td>
</tr>
<tr>
<td>比较</td>
<td style="text-align:left">在 ImageNet 上训练的 ResNet-50上，GN 使用批量大小为 2 时的错误率比 BN 的错误率低 10.6％ ;当使用典型的批量时，GN 与 BN 相当，并且优于其他标归一化变体。而且，GN 可以自然地从预训练迁移到微调。在进行 COCO 中的目标检测和分割以及 Kinetics 中的视频分类比赛中，GN 可以胜过其竞争对手，表明 GN 可以在各种任务中有效地取代强大的 BN。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-6-12-Weight-Normalization和Batch-Normalization比较"><a href="#3-6-12-Weight-Normalization和Batch-Normalization比较" class="headerlink" title="3.6.12 Weight Normalization和Batch Normalization比较"></a>3.6.12 Weight Normalization和Batch Normalization比较</h3><p>​    Weight Normalization 和 Batch Normalization 都属于参数重写（Reparameterization）的方法，只是采用的方式不同。</p>
<p>​    Weight Normalization 是对网络权值$  W $ 进行 normalization，因此也称为 Weight Normalization；</p>
<p>​    Batch Normalization 是对网络某一层输入数据进行 normalization。</p>
<p>​    Weight Normalization相比Batch Normalization有以下三点优势：</p>
<ol>
<li><p>Weight Normalization 通过重写深度学习网络的权重W的方式来加速深度学习网络参数收敛，没有引入 minbatch 的依赖，适用于 RNN（LSTM）网络（Batch Normalization 不能直接用于RNN，进行 normalization 操作，原因在于：1) RNN 处理的 Sequence 是变长的；2) RNN 是基于 time step 计算，如果直接使用 Batch Normalization 处理，需要保存每个 time step 下，mini btach 的均值和方差，效率低且占内存）。</p>
</li>
<li><p>Batch Normalization 基于一个 mini batch 的数据计算均值和方差，而不是基于整个 Training set 来做，相当于进行梯度计算式引入噪声。因此，Batch Normalization 不适用于对噪声敏感的强化学习、生成模型（Generative model：GAN，VAE）使用。相反，Weight Normalization 对通过标量 $ g $ 和向量 $ v $ 对权重 $ W $ 进行重写，重写向量 $ v $ 是固定的，因此，基于 Weight Normalization 的 Normalization 可以看做比 Batch Normalization 引入更少的噪声。    </p>
</li>
<li><p>不需要额外的存储空间来保存 mini batch 的均值和方差，同时实现 Weight Normalization 时，对深度学习网络进行正向信号传播和反向梯度计算带来的额外计算开销也很小。因此，要比采用 Batch Normalization 进行 normalization 操作时，速度快。  但是 Weight Normalization 不具备 Batch Normalization 把网络每一层的输出 Y 固定在一个变化范围的作用。因此，采用 Weight Normalization 进行 Normalization 时需要特别注意参数初始值的选择。</p>
</li>
</ol>
<h3 id="3-6-13-Batch-Normalization在什么时候用比较合适？"><a href="#3-6-13-Batch-Normalization在什么时候用比较合适？" class="headerlink" title="3.6.13 Batch Normalization在什么时候用比较合适？"></a>3.6.13 Batch Normalization在什么时候用比较合适？</h3><p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<p>​    在CNN中，BN应作用在非线性映射前。在神经网络训练时遇到收敛速度很慢，或梯度爆炸等无法训练的状况时可以尝试BN来解决。另外，在一般使用情况下也可以加入BN来加快训练速度，提高模型精度。</p>
<p>​    BN比较适用的场景是：每个mini-batch比较大，数据分布比较接近。在进行训练之前，要做好充分的shuffle，否则效果会差很多。另外，由于BN需要在运行过程中统计每个mini-batch的一阶统计量和二阶统计量，因此不适用于动态的网络结构和RNN网络。</p>
<h2 id="3-7-预训练与微调-fine-tuning"><a href="#3-7-预训练与微调-fine-tuning" class="headerlink" title="3.7 预训练与微调(fine tuning)"></a>3.7 预训练与微调(fine tuning)</h2><h3 id="3-7-1-为什么无监督预训练可以帮助深度学习？"><a href="#3-7-1-为什么无监督预训练可以帮助深度学习？" class="headerlink" title="3.7.1 为什么无监督预训练可以帮助深度学习？"></a>3.7.1 为什么无监督预训练可以帮助深度学习？</h3><p>深度网络存在问题:</p>
<ol>
<li><p>网络越深，需要的训练样本数越多。若用监督则需大量标注样本，不然小规模样本容易造成过拟合。深层网络特征比较多，会出现的多特征问题主要有多样本问题、规则化问题、特征选择问题。</p>
</li>
<li><p>多层神经网络参数优化是个高阶非凸优化问题，经常得到收敛较差的局部解；</p>
</li>
<li><p>梯度扩散问题，BP算法计算出的梯度随着深度向前而显著下降，导致前面网络参数贡献很小，更新速度慢。</p>
</li>
</ol>
<p><strong>解决方法：</strong></p>
<p>​    逐层贪婪训练，无监督预训练（unsupervised pre-training）即训练网络的第一个隐藏层，再训练第二个…最后用这些训练好的网络参数值作为整体网络参数的初始值。</p>
<p>经过预训练最终能得到比较好的局部最优解。</p>
<h3 id="3-7-2-什么是模型微调fine-tuning"><a href="#3-7-2-什么是模型微调fine-tuning" class="headerlink" title="3.7.2 什么是模型微调fine tuning"></a>3.7.2 什么是模型微调fine tuning</h3><p>​    用别人的参数、修改后的网络和自己的数据进行训练，使得参数适应自己的数据，这样一个过程，通常称之为微调（fine tuning). </p>
<p><strong>模型的微调举例说明：</strong></p>
<p>​    我们知道，CNN 在图像识别这一领域取得了巨大的进步。如果想将 CNN 应用到我们自己的数据集上，这时通常就会面临一个问题：通常我们的 dataset 都不会特别大，一般不会超过 1 万张，甚至更少，每一类图片只有几十或者十几张。这时候，直接应用这些数据训练一个网络的想法就不可行了，因为深度学习成功的一个关键性因素就是大量带标签数据组成的训练集。如果只利用手头上这点数据，即使我们利用非常好的网络结构，也达不到很高的 performance。这时候，fine-tuning 的思想就可以很好解决我们的问题：我们通过对 ImageNet 上训练出来的模型（如CaffeNet,VGGNet,ResNet) 进行微调，然后应用到我们自己的数据集上。</p>
<h3 id="3-7-3-微调时候网络参数是否更新？"><a href="#3-7-3-微调时候网络参数是否更新？" class="headerlink" title="3.7.3 微调时候网络参数是否更新？"></a>3.7.3 微调时候网络参数是否更新？</h3><p>答案：会更新。</p>
<ol>
<li>finetune 的过程相当于继续训练，跟直接训练的区别是初始化的时候。 </li>
<li>直接训练是按照网络定义指定的方式初始化。</li>
<li>finetune是用你已经有的参数文件来初始化。</li>
</ol>
<h3 id="3-7-4-fine-tuning-模型的三种状态"><a href="#3-7-4-fine-tuning-模型的三种状态" class="headerlink" title="3.7.4 fine-tuning 模型的三种状态"></a>3.7.4 fine-tuning 模型的三种状态</h3><ol>
<li><p>状态一：只预测，不训练。<br>特点：相对快、简单，针对那些已经训练好，现在要实际对未知数据进行标注的项目，非常高效；</p>
</li>
<li><p>状态二：训练，但只训练最后分类层。<br>特点：fine-tuning的模型最终的分类以及符合要求，现在只是在他们的基础上进行类别降维。</p>
</li>
<li><p>状态三：完全训练，分类层+之前卷积层都训练<br>特点：跟状态二的差异很小，当然状态三比较耗时和需要训练GPU资源，不过非常适合fine-tuning到自己想要的模型里面，预测精度相比状态二也提高不少。</p>
</li>
</ol>
<h2 id="3-8-权重偏差初始化"><a href="#3-8-权重偏差初始化" class="headerlink" title="3.8 权重偏差初始化"></a>3.8 权重偏差初始化</h2><h3 id="3-8-1-全都初始化为-0"><a href="#3-8-1-全都初始化为-0" class="headerlink" title="3.8.1 全都初始化为 0"></a>3.8.1 全都初始化为 0</h3><p><strong>偏差初始化陷阱</strong>： 都初始化为 0。</p>
<p><strong>产生陷阱原因</strong>：因为并不知道在训练神经网络中每一个权重最后的值，但是如果进行了恰当的数据归一化后，我们可以有理由认为有一半的权重是正的，另一半是负的。令所有权重都初始化为 0，如果神经网络计算出来的输出值是一样的，神经网络在进行反向传播算法计算出来的梯度值也一样，并且参数更新值也一样。更一般地说，如果权重初始化为同一个值，网络就是对称的。</p>
<p><strong>形象化理解</strong>：在神经网络中考虑梯度下降的时候，设想你在爬山，但身处直线形的山谷中，两边是对称的山峰。由于对称性，你所在之处的梯度只能沿着山谷的方向，不会指向山峰；你走了一步之后，情况依然不变。结果就是你只能收敛到山谷中的一个极大值，而走不到山峰上去。</p>
<h3 id="3-8-2-全都初始化为同样的值"><a href="#3-8-2-全都初始化为同样的值" class="headerlink" title="3.8.2 全都初始化为同样的值"></a>3.8.2 全都初始化为同样的值</h3><p>​    偏差初始化陷阱： 都初始化为一样的值。<br>​    以一个三层网络为例：<br>首先看下结构</p>
<p><img src="/img/ch3/3.8.2.1.png" alt=""></p>
<p>它的表达式为： </p>
<script type="math/tex; mode=display">
a_1^{(2)} = f(W_{11}^{(1)} x_1 + W_{12}^{(1)} x_2 + W_{13}^{(1)} x_3 + b_1^{(1)})</script><script type="math/tex; mode=display">
a_2^{(2)} = f(W_{21}^{(1)} x_1 + W_{22}^{(1)} x_2 + W_{23}^{(1)} x_3 + b_2^{(1)})</script><script type="math/tex; mode=display">
a_3^{(2)} = f(W_{31}^{(1)} x_1 + W_{32}^{(1)} x_2 + W_{33}^{(1)} x_3 + b_3^{(1)})</script><script type="math/tex; mode=display">
h_{W,b}(x) = a_1^{(3)} = f(W_{11}^{(2)} a_1^{(2)} + W_{12}^{(2)} a_2^{(2)} + W_{13}^{(2)} a_3^{(2)} + b_1^{(2)})</script><script type="math/tex; mode=display">
xa_1^{(2)} = f(W_{11}^{(1)} x_1 + W_{12}^{(1)} x_2 + W_{13}^{(1)} x_3 + b_1^{(1)})a_2^{(2)} = f(W_{21}^{(1)} x_1 + W_{22}^{(1)} x_2 + W_{23}^{(1)} x_3 +</script><p>如果每个权重都一样，那么在多层网络中，从第二层开始，每一层的输入值都是相同的了也就是$ a1=a2=a3=…. $，既然都一样，就相当于一个输入了，为啥呢？？</p>
<p>如果是反向传递算法（如果这里不明白请看上面的连接），其中的偏置项和权重项的迭代的偏导数计算公式如下</p>
<script type="math/tex; mode=display">
\frac{\partial}{\partial W_{ij}^{(l)}} J(W,b;x,y) = a_j^{(l)} \delta_i^{(l+1)}

\frac{\partial}{\partial b_{i}^{(l)}} J(W,b;x,y) = \delta_i^{(l+1)}</script><p>$ \delta $ 的计算公式</p>
<script type="math/tex; mode=display">
\delta_i^{(l)} = (\sum_{j=1}^{s_{t+1}} W_{ji}^{(l)} \delta_j^{(l+1)} ) f^{\prime}(z_i^{(l)})</script><p>如果用的是 sigmoid 函数</p>
<script type="math/tex; mode=display">
f^{\prime}(z_i^{(l)}) = a_i^{(l)}(1-a_i^{(l)})</script><p>把后两个公式代入，可以看出所得到的梯度下降法的偏导相同，不停的迭代，不停的相同，不停的迭代，不停的相同……，最后就得到了相同的值（权重和截距）。</p>
<h3 id="3-8-3-初始化为小的随机数"><a href="#3-8-3-初始化为小的随机数" class="headerlink" title="3.8.3 初始化为小的随机数"></a>3.8.3 初始化为小的随机数</h3><p>​    将权重初始化为很小的数字是一个普遍的打破网络对称性的解决办法。这个想法是，神经元在一开始都是随机的、独一无二的，所以它们会计算出不同的更新，并将自己整合到整个网络的各个部分。一个权重矩阵的实现可能看起来像 $ W=0.01∗np.random.randn(D,H) $，其中 randn 是从均值为 0 的单位标准高斯分布进行取样。通过这个公式(函数)，每个神经元的权重向量初始化为一个从多维高斯分布取样的随机向量，所以神经元在输入空间中指向随机的方向(so the neurons point in random direction in the input space). 应该是指输入空间对于随机方向有影响)。其实也可以从均匀分布中来随机选取小数，但是在实际操作中看起来似乎对最后的表现并没有太大的影响。</p>
<p>​    备注：并不是数字越小就会表现的越好。比如，如果一个神经网络层的权重非常小，那么在反向传播算法就会计算出很小的梯度(因为梯度 gradient 是与权重成正比的)。在网络不断的反向传播过程中将极大地减少“梯度信号”，并可能成为深层网络的一个需要注意的问题。</p>
<h3 id="3-8-4-用-1-sqrt-n-校准方差"><a href="#3-8-4-用-1-sqrt-n-校准方差" class="headerlink" title="3.8.4 用 $ 1/\sqrt n $ 校准方差"></a>3.8.4 用 $ 1/\sqrt n $ 校准方差</h3><p>​    上述建议的一个问题是，随机初始化神经元的输出的分布有一个随输入量增加而变化的方差。结果证明，我们可以通过将其权重向量按其输入的平方根(即输入的数量)进行缩放，从而将每个神经元的输出的方差标准化到 1。也就是说推荐的启发式方法 (heuristic) 是将每个神经元的权重向量按下面的方法进行初始化: $ w=np.random.randn(n)/\sqrt n $，其中 n 表示输入的数量。这保证了网络中所有的神经元最初的输出分布大致相同，并在经验上提高了收敛速度。</p>
<h3 id="3-8-5-稀疏初始化-Sparse-Initialazation"><a href="#3-8-5-稀疏初始化-Sparse-Initialazation" class="headerlink" title="3.8.5 稀疏初始化(Sparse Initialazation)"></a>3.8.5 稀疏初始化(Sparse Initialazation)</h3><p>​    另一种解决未校准方差问题的方法是把所有的权重矩阵都设为零，但是为了打破对称性，每个神经元都是随机连接地(从如上面所介绍的一个小的高斯分布中抽取权重)到它下面的一个固定数量的神经元。一个典型的神经元连接的数目可能是小到 10 个。</p>
<h3 id="3-8-6-初始化偏差"><a href="#3-8-6-初始化偏差" class="headerlink" title="3.8.6 初始化偏差"></a>3.8.6 初始化偏差</h3><p>​    将偏差初始化为零是可能的，也是很常见的，因为非对称性破坏是由权重的小随机数导致的。因为 ReLU 具有非线性特点，所以有些人喜欢使用将所有的偏差设定为小的常数值如 0.01，因为这样可以确保所有的 ReLU 单元在最开始就激活触发(fire)并因此能够获得和传播一些梯度值。然而，这是否能够提供持续的改善还不太清楚(实际上一些结果表明这样做反而使得性能更加糟糕)，所以更通常的做法是简单地将偏差初始化为 0.</p>
<h2 id="3-9-学习率"><a href="#3-9-学习率" class="headerlink" title="3.9 学习率"></a>3.9 学习率</h2><h3 id="3-9-1-学习率的作用"><a href="#3-9-1-学习率的作用" class="headerlink" title="3.9.1 学习率的作用"></a>3.9.1 学习率的作用</h3><p>​    在机器学习中，监督式学习通过定义一个模型，并根据训练集上的数据估计最优参数。梯度下降法是一个广泛被用来最小化模型误差的参数优化算法。梯度下降法通过多次迭代，并在每一步中最小化成本函数（cost 来估计模型的参数。学习率 (learning rate)，在迭代过程中会控制模型的学习进度。</p>
<p>​    在梯度下降法中，都是给定的统一的学习率，整个优化过程中都以确定的步长进行更新， 在迭代优化的前期中，学习率较大，则前进的步长就会较长，这时便能以较快的速度进行梯度下降，而在迭代优化的后期，逐步减小学习率的值，减小步长，这样将有助于算法的收敛，更容易接近最优解。故而如何对学习率的更新成为了研究者的关注点。<br>​    在模型优化中，常用到的几种学习率衰减方法有：分段常数衰减、多项式衰减、指数衰减、自然指数衰减、余弦衰减、线性余弦衰减、噪声线性余弦衰减</p>
<h3 id="3-9-2-学习率衰减常用参数有哪些"><a href="#3-9-2-学习率衰减常用参数有哪些" class="headerlink" title="3.9.2 学习率衰减常用参数有哪些"></a>3.9.2 学习率衰减常用参数有哪些</h3><div class="table-container">
<table>
<thead>
<tr>
<th>参数名称</th>
<th>参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>learning_rate</td>
<td>初始学习率</td>
</tr>
<tr>
<td>global_step</td>
<td>用于衰减计算的全局步数，非负，用于逐步计算衰减指数</td>
</tr>
<tr>
<td>decay_steps</td>
<td>衰减步数，必须是正值，决定衰减周期</td>
</tr>
<tr>
<td>decay_rate</td>
<td>衰减率</td>
</tr>
<tr>
<td>end_learning_rate</td>
<td>最低的最终学习率</td>
</tr>
<tr>
<td>cycle</td>
<td>学习率下降后是否重新上升</td>
</tr>
<tr>
<td>alpha</td>
<td>最小学习率</td>
</tr>
<tr>
<td>num_periods</td>
<td>衰减余弦部分的周期数</td>
</tr>
<tr>
<td>initial_variance</td>
<td>噪声的初始方差</td>
</tr>
<tr>
<td>variance_decay</td>
<td>衰减噪声的方差</td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-9-3-分段常数衰减"><a href="#3-9-3-分段常数衰减" class="headerlink" title="3.9.3 分段常数衰减"></a>3.9.3 分段常数衰减</h3><p>​    分段常数衰减需要事先定义好的训练次数区间，在对应区间置不同的学习率的常数值，一般情况刚开始的学习率要大一些，之后要越来越小，要根据样本量的大小设置区间的间隔大小，样本量越大，区间间隔要小一点。下图即为分段常数衰减的学习率变化图，横坐标代表训练次数，纵坐标代表学习率。</p>
<p><img src="/img/ch3/learnrate1.png" alt=""></p>
<h3 id="3-9-4-指数衰减"><a href="#3-9-4-指数衰减" class="headerlink" title="3.9.4 指数衰减"></a>3.9.4 指数衰减</h3><p>​    以指数衰减方式进行学习率的更新，学习率的大小和训练次数指数相关，其更新规则为：</p>
<script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =learning{\_}rate*decay{\_}rate^{\frac{global{\_step}}{decay{\_}steps}}</script><p>​    这种衰减方式简单直接，收敛速度快，是最常用的学习率衰减方式，如下图所示，绿色的为学习率随<br>训练次数的指数衰减方式，红色的即为分段常数衰减，它在一定的训练区间内保持学习率不变。</p>
<p><img src="/img/ch3/learnrate2.png" alt=""></p>
<h3 id="3-9-5-自然指数衰减"><a href="#3-9-5-自然指数衰减" class="headerlink" title="3.9.5 自然指数衰减"></a>3.9.5 自然指数衰减</h3><p>​    它与指数衰减方式相似，不同的在于它的衰减底数是$e$，故而其收敛的速度更快，一般用于相对比较<br>容易训练的网络，便于较快的收敛，其更新规则如下</p>
<script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =learning{\_}rate*e^{\frac{-decay{\_rate}}{global{\_}step}}</script><p>​    下图为为分段常数衰减、指数衰减、自然指数衰减三种方式的对比图，红色的即为分段常数衰减图，阶梯型曲线。蓝色线为指数衰减图，绿色即为自然指数衰减图，很明可以看到自然指数衰减方式下的学习率衰减程度要大于一般指数衰减方式，有助于更快的收敛。</p>
<p><img src="/img/ch3/learnrate3.png" alt=""></p>
<h3 id="3-9-6-多项式衰减"><a href="#3-9-6-多项式衰减" class="headerlink" title="3.9.6 多项式衰减"></a>3.9.6 多项式衰减</h3><p>​    应用多项式衰减的方式进行更新学习率，这里会给定初始学习率和最低学习率取值，然后将会按照<br>给定的衰减方式将学习率从初始值衰减到最低值,其更新规则如下式所示。</p>
<script type="math/tex; mode=display">
global{\_}step=min(global{\_}step,decay{\_}steps)</script><script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =(learning{\_}rate-end{\_}learning{\_}rate)* \left( 1-\frac{global{\_step}}{decay{\_}steps}\right)^{power} \\
 +end{\_}learning{\_}rate</script><p>​    需要注意的是，有两个机制，降到最低学习率后，到训练结束可以一直使用最低学习率进行更新，另一个是再次将学习率调高，使用 decay_steps 的倍数，取第一个大于 global_steps 的结果，如下式所示.它是用来防止神经网络在训练的后期由于学习率过小而导致的网络一直在某个局部最小值附近震荡，这样可以通过在后期增大学习率跳出局部极小值。</p>
<script type="math/tex; mode=display">
decay{\_}steps = decay{\_}steps*ceil \left( \frac{global{\_}step}{decay{\_}steps}\right)</script><p>​    如下图所示，红色线代表学习率降低至最低后，一直保持学习率不变进行更新，绿色线代表学习率衰减到最低后，又会再次循环往复的升高降低。</p>
<p><img src="/img/ch3/learnrate4.png" alt=""></p>
<h3 id="3-9-7-余弦衰减"><a href="#3-9-7-余弦衰减" class="headerlink" title="3.9.7 余弦衰减"></a>3.9.7 余弦衰减</h3><p>​    余弦衰减就是采用余弦的相关方式进行学习率的衰减，衰减图和余弦函数相似。其更新机制如下式所示：</p>
<script type="math/tex; mode=display">
global{\_}step=min(global{\_}step,decay{\_}steps)</script><script type="math/tex; mode=display">
cosine{\_}decay=0.5*\left( 1+cos\left( \pi* \frac{global{\_}step}{decay{\_}steps}\right)\right)</script><script type="math/tex; mode=display">
decayed=(1-\alpha)*cosine{\_}decay+\alpha</script><script type="math/tex; mode=display">
decayed{\_}learning{\_}rate=learning{\_}rate*decayed</script><p>​    如下图所示，红色即为标准的余弦衰减曲线，学习率从初始值下降到最低学习率后保持不变。蓝色的线是线性余弦衰减方式曲线，它是学习率从初始学习率以线性的方式下降到最低学习率值。绿色噪声线性余弦衰减方式。</p>
<p><img src="/img/ch3/learnrate5.png" alt=""></p>
<h2 id="3-12-Dropout-系列问题"><a href="#3-12-Dropout-系列问题" class="headerlink" title="3.12 Dropout 系列问题"></a>3.12 Dropout 系列问题</h2><h3 id="3-12-1-为什么要正则化？"><a href="#3-12-1-为什么要正则化？" class="headerlink" title="3.12.1 为什么要正则化？"></a>3.12.1 为什么要正则化？</h3><ol>
<li>深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少你的网络误差。  </li>
<li>如果你怀疑神经网络过度拟合了数据，即存在高方差问题，那么最先想到的方法可能是正则化，另一个解决高方差的方法就是准备更多数据，这也是非常可靠的办法，但你可能无法时时准备足够多的训练数据，或者，获取更多数据的成本很高，但正则化有助于避免过度拟合，或者减少网络误差。</li>
</ol>
<h3 id="3-12-2-为什么正则化有利于预防过拟合？"><a href="#3-12-2-为什么正则化有利于预防过拟合？" class="headerlink" title="3.12.2 为什么正则化有利于预防过拟合？"></a>3.12.2 为什么正则化有利于预防过拟合？</h3><p><img src="/img/ch3/3.12.2.1.png" alt=""><br><img src="/img/ch3/3.12.2.2.png" alt=""> </p>
<p>左图是高偏差，右图是高方差，中间是Just Right，这几张图我们在前面课程中看到过。  </p>
<h3 id="3-12-3-理解dropout正则化"><a href="#3-12-3-理解dropout正则化" class="headerlink" title="3.12.3 理解dropout正则化"></a>3.12.3 理解dropout正则化</h3><p>​    Dropout可以随机删除网络中的神经单元，它为什么可以通过正则化发挥如此大的作用呢？  </p>
<p>​    直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施dropout的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；L2对不同权重的衰减是不同的，它取决于激活函数倍增的大小。  </p>
<h3 id="3-12-4-dropout率的选择"><a href="#3-12-4-dropout率的选择" class="headerlink" title="3.12.4 dropout率的选择"></a>3.12.4 dropout率的选择</h3><ol>
<li>经过交叉验证，隐含节点 dropout 率等于 0.5 的时候效果最好，原因是 0.5 的时候 dropout 随机生成的网络结构最多。</li>
<li>dropout 也可以被用作一种添加噪声的方法，直接对 input 进行操作。输入层设为更接近 1 的数。使得输入变化不会太大（0.8） </li>
<li>对参数 $ w $ 的训练进行球形限制 (max-normalization)，对 dropout 的训练非常有用。</li>
<li>球形半径 $ c $ 是一个需要调整的参数，可以使用验证集进行参数调优。</li>
<li>dropout 自己虽然也很牛，但是 dropout、max-normalization、large decaying learning rates and high momentum 组合起来效果更好，比如 max-norm regularization 就可以防止大的learning rate 导致的参数 blow up。</li>
<li>使用 pretraining 方法也可以帮助 dropout 训练参数，在使用 dropout 时，要将所有参数都乘以 $ 1/p $。</li>
</ol>
<h3 id="3-12-5-dropout有什么缺点？"><a href="#3-12-5-dropout有什么缺点？" class="headerlink" title="3.12.5 dropout有什么缺点？"></a>3.12.5 dropout有什么缺点？</h3><p>​    dropout一大缺点就是代价函数J不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。定义明确的代价函数J每次迭代后都会下降，因为我们所优化的代价函数J实际上并没有明确定义，或者说在某种程度上很难计算，所以我们失去了调试工具来绘制这样的图片。我通常会关闭dropout函数，将keep-prob的值设为1，运行代码，确保J函数单调递减。然后打开dropout函数，希望在dropout过程中，代码并未引入bug。我觉得你也可以尝试其它方法，虽然我们并没有关于这些方法性能的数据统计，但你可以把它们与dropout方法一起使用。  </p>
<h2 id="3-13-深度学习中常用的数据增强方法？"><a href="#3-13-深度学习中常用的数据增强方法？" class="headerlink" title="3.13 深度学习中常用的数据增强方法？"></a>3.13 深度学习中常用的数据增强方法？</h2><p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<ul>
<li><p>Color Jittering：对颜色的数据增强：图像亮度、饱和度、对比度变化（此处对色彩抖动的理解不知是否得当）；</p>
</li>
<li><p>PCA  Jittering：首先按照RGB三个颜色通道计算均值和标准差，再在整个训练集上计算协方差矩阵，进行特征分解，得到特征向量和特征值，用来做PCA Jittering；</p>
</li>
<li><p>Random Scale：尺度变换；</p>
</li>
<li><p>Random Crop：采用随机图像差值方式，对图像进行裁剪、缩放；包括Scale Jittering方法（VGG及ResNet模型使用）或者尺度和长宽比增强变换；</p>
</li>
<li><p>Horizontal/Vertical Flip：水平/垂直翻转；</p>
</li>
<li><p>Shift：平移变换；</p>
</li>
<li><p>Rotation/Reflection：旋转/仿射变换；</p>
</li>
<li><p>Noise：高斯噪声、模糊处理；</p>
</li>
<li><p>Label Shuffle：类别不平衡数据的增广；</p>
</li>
</ul>
<h2 id="3-14-如何理解-Internal-Covariate-Shift？"><a href="#3-14-如何理解-Internal-Covariate-Shift？" class="headerlink" title="3.14 如何理解 Internal Covariate Shift？"></a>3.14 如何理解 Internal Covariate Shift？</h2><p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<p>​    深度神经网络模型的训练为什么会很困难？其中一个重要的原因是，深度神经网络涉及到很多层的叠加，而每一层的参数更新会导致上层的输入数据分布发生变化，通过层层叠加，高层的输入分布变化会非常剧烈，这就使得高层需要不断去重新适应底层的参数更新。为了训好模型，我们需要非常谨慎地去设定学习率、初始化权重、以及尽可能细致的参数更新策略。</p>
<p>​    Google 将这一现象总结为 Internal Covariate Shift，简称 ICS。 什么是 ICS 呢？</p>
<p>​    大家都知道在统计机器学习中的一个经典假设是“源空间（source domain）和目标空间（target domain）的数据分布（distribution）是一致的”。如果不一致，那么就出现了新的机器学习问题，如 transfer learning / domain adaptation 等。而 covariate shift 就是分布不一致假设之下的一个分支问题，它是指源空间和目标空间的条件概率是一致的，但是其边缘概率不同。</p>
<p>​    大家细想便会发现，的确，对于神经网络的各层输出，由于它们经过了层内操作作用，其分布显然与各层对应的输入信号分布不同，而且差异会随着网络深度增大而增大，可是它们所能“指示”的样本标记（label）仍然是不变的，这便符合了covariate shift的定义。由于是对层间信号的分析，也即是“internal”的来由。</p>
<p><strong>那么ICS会导致什么问题？</strong></p>
<p>简而言之，每个神经元的输入数据不再是“独立同分布”。</p>
<p>其一，上层参数需要不断适应新的输入数据分布，降低学习速度。</p>
<p>其二，下层输入的变化可能趋向于变大或者变小，导致上层落入饱和区，使得学习过早停止。</p>
<p>其三，每层的更新都会影响到其它层，因此每层的参数更新策略需要尽可能的谨慎。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Rosenblatt, F. The perceptron: A probabilistic model for information storage and organization in the brain.[J]. Psychological Review, 1958, 65(6):386-408.</p>
<p>[2] Duvenaud D , Rippel O , Adams R P , et al. Avoiding pathologies in very deep networks[J]. Eprint Arxiv, 2014:202-210.</p>
<p>[3] Rumelhart D E, Hinton G E, Williams R J. Learning representations by back-propagating errors[J]. Cognitive modeling, 1988, 5(3): 1.</p>
<p>[4] Hecht-Nielsen R. Theory of the backpropagation neural network[M]//Neural networks for perception. Academic Press, 1992: 65-93.</p>
<p>[5] Felice M. Which deep learning network is best for you?| CIO[J]. 2017.</p>
<p>[6] Conneau A, Schwenk H, Barrault L, et al. Very deep convolutional networks for natural language processing[J]. arXiv preprint arXiv:1606.01781, 2016, 2.</p>
<p>[7] Ba J, Caruana R. Do deep nets really need to be deep?[C]//Advances in neural information processing systems. 2014: 2654-2662.</p>
<p>[8] Nielsen M A. Neural networks and deep learning[M]. USA: Determination press, 2015.</p>
<p>[9] Goodfellow I, Bengio Y, Courville A. Deep learning[M]. MIT press, 2016.</p>
<p>[10] 周志华. 机器学习[M].清华大学出版社, 2016.</p>
<p>[11] Kim J, Kwon Lee J, Mu Lee K. Accurate image super-resolution using very deep convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 1646-1654.</p>
<p>[12] Chen Y, Lin Z, Zhao X, et al. Deep learning-based classification of hyperspectral data[J]. IEEE Journal of Selected topics in applied earth observations and remote sensing, 2014, 7(6): 2094-2107.</p>
<p>[13] Domhan T, Springenberg J T, Hutter F. Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves[C]//Twenty-Fourth International Joint Conference on Artificial Intelligence. 2015.</p>
<p>[14] Maclaurin D, Duvenaud D, Adams R. Gradient-based hyperparameter optimization through reversible learning[C]//International Conference on Machine Learning. 2015: 2113-2122.</p>
<p>[15] Srivastava R K, Greff K, Schmidhuber J. Training very deep networks[C]//Advances in neural information processing systems. 2015: 2377-2385.</p>
<p>[16] Bergstra J, Bengio Y. Random search for hyper-parameter optimization[J]. Journal of Machine Learning Research, 2012, 13(Feb): 281-305.</p>
<p>[17] Ngiam J, Khosla A, Kim M, et al. Multimodal deep learning[C]//Proceedings of the 28th international conference on machine learning (ICML-11). 2011: 689-696.</p>
<p>[18] Deng L, Yu D. Deep learning: methods and applications[J]. Foundations and Trends® in Signal Processing, 2014, 7(3–4): 197-387.</p>
<p>[19] Erhan D, Bengio Y, Courville A, et al. Why does unsupervised pre-training help deep learning?[J]. Journal of Machine Learning Research, 2010, 11(Feb): 625-660.</p>
<p>[20] Dong C, Loy C C, He K, et al. Learning a deep convolutional network for image super resolution[C]//European conference on computer vision. Springer, Cham, 2014: 184-199.</p>
<p>[21] 郑泽宇，梁博文，顾思宇.TensorFlow：实战Google深度学习框架（第2版）[M].电子工业出版社,2018.</p>
<p>[22] 焦李成. 深度学习优化与识别[M].清华大学出版社,2017.</p>
<p>[23] 吴岸城. 神经网络与深度学习[M].电子工业出版社,2016.</p>
<p>[24] Wei, W.G.H., Liu, T., Song, A., et al. (2018) An Adaptive Natural Gradient Method with Adaptive Step Size in Multilayer Perceptrons. Chinese Automation Congress, 1593-1597.</p>
<p>[25] Y Feng, Y Li.An Overview of Deep Learning Optimization Methods and Learning Rate Attenuation Methods[J].Hans Journal of Data Mining,2018,8(4),186-200.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Kay</p>
  <div class="site-description" itemprop="description">千里之行，始于足下</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kay</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.1
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
