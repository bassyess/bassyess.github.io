<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"bassyess.github.io","root":"/","scheme":"Pisces","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="千里之行，始于足下">
<meta property="og:type" content="website">
<meta property="og:title" content="Home">
<meta property="og:url" content="https://bassyess.github.io/page/3/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="千里之行，始于足下">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Kay">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://bassyess.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Home</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Home</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/25/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/25/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD%E7%9F%A5%E8%AF%86/" class="post-title-link" itemprop="url">基础技能知识</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-25 21:29:48" itemprop="dateCreated datePublished" datetime="2020-02-25T21:29:48+08:00">2020-02-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-04-06 19:05:24" itemprop="dateModified" datetime="2020-04-06T19:05:24+08:00">2020-04-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><h3 id="常用的Python标准库有哪些？"><a href="#常用的Python标准库有哪些？" class="headerlink" title="常用的Python标准库有哪些？"></a>常用的Python标准库有哪些？</h3><p>常用的标准库：os操作系统，time时间，random随机，pymysql连接数据库，math数学，threading线程，multiprocessing进程，queue队列<br>第三方库：django和flask，requests，virtualenv，hashlib，md5<br>常用的科学计算库：Numpy,Scipy,Pandas等。</p>
<h3 id="Python有哪些特点和优点？"><a href="#Python有哪些特点和优点？" class="headerlink" title="Python有哪些特点和优点？"></a>Python有哪些特点和优点？</h3><p>作为一门编程入门语言，Python主要有以下特点和优点：<br>1）可解释<br>2）具有动态特性<br>3）面向对象<br>4）简明简单<br>5）开源<br>6）具有强大的社区支持</p>
<h3 id="深拷贝和浅拷贝之间的区别是什么？"><a href="#深拷贝和浅拷贝之间的区别是什么？" class="headerlink" title="深拷贝和浅拷贝之间的区别是什么？"></a>深拷贝和浅拷贝之间的区别是什么？</h3><p>深拷贝就是将一个对象拷贝到另一个对象中，这意味着如果你对一个对象的拷贝做出改变时，不会影响原对象。在Python中，我们使用函数deepcopy()执行深拷贝。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">b = copy.deepcopy(a)</span><br></pre></td></tr></table></figure><br>浅拷贝则是将一个对象的引用拷贝到另一个对象上，所以如果我们在拷贝中改动，会影响到原对象。我们使用函数function()执行浅拷贝。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b = copy.copy(a)</span><br></pre></td></tr></table></figure></p>
<h3 id="列表和元组之间的区别是？"><a href="#列表和元组之间的区别是？" class="headerlink" title="列表和元组之间的区别是？"></a>列表和元组之间的区别是？</h3><p>二者的主要区别是列表是可变的，而元组是不可变的。</p>
<h3 id="在Python中如何实现多线程？"><a href="#在Python中如何实现多线程？" class="headerlink" title="在Python中如何实现多线程？"></a>在Python中如何实现多线程？</h3><p>Python中的GIL（全局解释器锁）确保一次执行单个线程。一个线程保存GIL并在将其传递给下个线程之前执行一些操作，这会让我们产生并行运行的错觉。但实际上，只是线程在CPU上轮流运行。</p>
<h3 id="在Python中是如何管理内存的？"><a href="#在Python中是如何管理内存的？" class="headerlink" title="在Python中是如何管理内存的？"></a>在Python中是如何管理内存的？</h3><p>Python有一个私有堆空间来保存所有的对象和数据结构。作为开发者，我们无法访问它，是解释器在管理它。但是有了核心API后，我们可以访问一些工具。Python内存管理器控制内存分配。另外，内置垃圾回收器会回收使用所有的未使用内存，所以使其适用于堆空间。</p>
<h3 id="当退出Python时，是否释放全部内存？"><a href="#当退出Python时，是否释放全部内存？" class="headerlink" title="当退出Python时，是否释放全部内存？"></a>当退出Python时，是否释放全部内存？</h3><p>不会。循环引用其它对象或引用自全局命名空间的对象的模块，在Python退出时并非完全释放。另外，也不会释放C库保留的内存部分。</p>
<h3 id="Python中的命名空间是什么？"><a href="#Python中的命名空间是什么？" class="headerlink" title="Python中的命名空间是什么？"></a>Python中的命名空间是什么？</h3><p>命名空间是一个命名系统，用于确保名称是唯一性，以避免命名冲突。</p>
<h3 id="什么是PYTHONPATH？"><a href="#什么是PYTHONPATH？" class="headerlink" title="什么是PYTHONPATH？"></a>什么是PYTHONPATH？</h3><p>它是导入模块时使用的环境变量。每当导入模块时，也会查找PYTHONPATH以检查各个目录中是否存在导入的模块。解释器使用它来确定要加载的模块。</p>
<h3 id="什么是init"><a href="#什么是init" class="headerlink" title="什么是init?"></a>什么是<strong>init</strong>?</h3><p><strong>init</strong>是Python中的方法或者结构。在创建类的新对象/实例时，将自动调用此方法来分配内存。所有类都有<strong>init</strong>方法。</p>
<h3 id="Python中的self是什么？"><a href="#Python中的self是什么？" class="headerlink" title="Python中的self是什么？"></a>Python中的self是什么？</h3><p>self是类的实例或对象。在Python中，self包含在第一个参数中。但是，Java中的情况并非如此，它是可选的。它有助于区分具有局部变量的类的方法和属性。init方法中的self变量引用新创建的对象，而在其他方法中，它引用其方法被调用的对象。</p>
<h3 id="什么是python迭代器？"><a href="#什么是python迭代器？" class="headerlink" title="什么是python迭代器？"></a>什么是python迭代器？</h3><p>迭代器是可以遍历或迭代的对象。</p>
<h3 id="什么是python中的装饰器？"><a href="#什么是python中的装饰器？" class="headerlink" title="什么是python中的装饰器？"></a>什么是python中的装饰器？</h3><p>装饰器本质上是一个 Python 函数或类，它可以让其他函数或类在不需要做任何代码修改的前提下增加额外功能，装饰器的返回值也是一个函数/类对象。它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景。有了装饰器，我们就可以抽离出大量与函数功能本身无关的雷同代码到装饰器中并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。</p>
<h3 id="os和sys的区别"><a href="#os和sys的区别" class="headerlink" title="os和sys的区别"></a>os和sys的区别</h3><p>os模块负责程序与操作系统的交互，提供了访问操作系统底层的接口;sys模块负责程序与python解释器的交互，提供了一系列的函数和变量，用于操控python的运行时环境。</p>
<h3 id="什么是负指数，功能是什么？"><a href="#什么是负指数，功能是什么？" class="headerlink" title="什么是负指数，功能是什么？"></a>什么是负指数，功能是什么？</h3><p>Python中的序列是索引的，它由正数和负数组成。积极的数字使用’0’作为第一个索引，’1’作为第二个索引，进程继续使用。<br>负数的索引从’-1’开始，表示序列中的最后一个索引，’ - 2’作为倒数第二个索引，序列像正数一样前进。</p>
<h3 id="什么是猴子补丁？"><a href="#什么是猴子补丁？" class="headerlink" title="什么是猴子补丁？"></a>什么是猴子补丁？</h3><p>在运行期间动态修改一个类或模块。</p>
<h3 id="请解释使用args和-kwargs的含义"><a href="#请解释使用args和-kwargs的含义" class="headerlink" title="请解释使用args和*kwargs的含义"></a>请解释使用<em>args和*</em>kwargs的含义</h3><p>当我们不知道向函数传递多少参数时，比如我们向传递一个列表或元组，我们就使用<em>args。<br>在我们不知道该传递多少关键字参数时，使用*</em>kwargs来收集关键字参数。</p>
<h3 id="解释一下Python中的身份运算符"><a href="#解释一下Python中的身份运算符" class="headerlink" title="解释一下Python中的身份运算符"></a>解释一下Python中的身份运算符</h3><p>通过身份运算符‘is’和‘is not’，我们可以确认两个值是否相同。</p>
<h3 id="为何不建议以下划线作为标识符的开头"><a href="#为何不建议以下划线作为标识符的开头" class="headerlink" title="为何不建议以下划线作为标识符的开头"></a>为何不建议以下划线作为标识符的开头</h3><p>因为Python并没有私有变量的概念，所以约定速成以下划线为开头来声明一个变量为私有。所以如果你不想让变量私有，就不要使用下划线开头。</p>
<h3 id="range＆xrange有什么区别？"><a href="#range＆xrange有什么区别？" class="headerlink" title="range＆xrange有什么区别？"></a>range＆xrange有什么区别？</h3><p>在大多数情况下，xrange和range在功能方面完全相同。它们都提供了一种生成整数列表的方法，唯一的区别是range返回一个Python列表对象，x range返回一个xrange对象。这就表示xrange实际上在运行时并不是生成静态列表。它使用称为yielding的特殊技术根据需要创建值。该技术与一种称为生成器的对象一起使用。因此如果你有一个非常巨大的列表，那么就要考虑xrange。</p>
<h2 id="Pytorch、Tensorflow"><a href="#Pytorch、Tensorflow" class="headerlink" title="Pytorch、Tensorflow"></a>Pytorch、Tensorflow</h2><p><a href="https://blog.csdn.net/weixin_31866177/article/details/87974664" target="_blank" rel="noopener">tensorflow</a></p>
<h2 id="Linux系统"><a href="#Linux系统" class="headerlink" title="Linux系统"></a>Linux系统</h2><p><a href="https://blog.csdn.net/qq_40910541/article/details/80686362?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">linux常用指令</a></p>
<h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><p><a href="https://blog.csdn.net/qq_26768741/article/details/66975516" target="_blank" rel="noopener">git常见问题</a></p>
<h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><p><a href="https://www.jianshu.com/p/0fc161b9bcc7" target="_blank" rel="noopener">Java常见问题</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/25/%E9%9D%A2%E7%BB%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/25/%E9%9D%A2%E7%BB%8F/" class="post-title-link" itemprop="url">面经</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-25 08:52:11" itemprop="dateCreated datePublished" datetime="2020-02-25T08:52:11+08:00">2020-02-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-18 11:15:46" itemprop="dateModified" datetime="2020-03-18T11:15:46+08:00">2020-03-18</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="2020年快手Y-tech面经"><a href="#2020年快手Y-tech面经" class="headerlink" title="2020年快手Y-tech面经"></a>2020年快手Y-tech面经</h1><h2 id="一面"><a href="#一面" class="headerlink" title="一面:"></a>一面:</h2><p>1、PCA原理，应用<br>PCA原理是在原有n维特征的基础上重新构造出k维全新的正交特征，PCA的工作就是从原始空间顺序中到一组互相正交的坐标轴，第一个坐标轴选择就是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使方差最大的，第三个轴是与第1、2个轴正交的平面中方差最大的。依次类推可以得到n个这样的坐标轴。通过这种方式获得的新坐标轴，我们发现大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。于是我们可以忽略余下的坐标轴，只保留前面k个含有大部分方差的坐标轴。<br>PCA的应用范围有：1）数据压缩。数据压缩或者数据降维首先能够减少内存的使用，其次，数据降维能够加快机器学习的速度。2）数据可视化。在很多情况下，可能我们需要查看样本特征，但是高维度的特征根本无法观察，这个时候我们可以将样本的特征维数降到2个特征或3个特征，这样就可以采用可视化观察数据。3）去除数据噪声。<br>如何得到这些包含最大差异性的主成分方向呢？通过计算数据矩阵的协方差矩阵，然后得到协方差矩阵的特征值特征向量，选择特征值最大（即方差最大）的k个特征所对应的特征向量组成的矩阵。这样就可以将数据矩阵转换到新的空间中，实现数据特征的降维。得到协方差矩阵的特征值向量有两种方法：特征值分解协方差矩阵、奇异值分解协方差矩阵。<br>2、SVD原理，应用<br><a href="https://blog.csdn.net/weixin_31866177/article/details/88079612?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">SVD推导过程</a><br>3、SVM<br>SVM是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔大使它有别于普通的感知机，通过核技巧隐式的在输入空间直接求解映射空间中特征向量的内积，使其成为一个非线性分类器。SVM的学习策略是间隔最大化，可形式化为一个求解凸二次规划问题。<br>（重点）<a href="https://blog.csdn.net/cppjava_/article/details/68060439" target="_blank" rel="noopener">SVM算法推导过程</a><br>4、BN 优缺点 IN<br>BN的基本思想相当直观：因为深层神经网络在做非线性变换前的激活输入值随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或变动，之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区域的上下限两端靠近，所以这导致反向传播时低层神经网络的梯度消失，这是训练深层神经网络收敛越来越慢的本质原因。而BN就是通过一定的规范化手段，把层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，其实就是把越来越偏的分布强制拉回到标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就是导致损失函数较大的变化。<br>BatchNorm的优点：1）极大提升了训练速度，使得收敛过程大大加快；2）还能增加分类效果，一种解释是这类似于Dropout的一种防止过拟合的正则化表达方式，所以不用Dropout也能达到相当的效果；3）调参过程也简单了，对于初始化要求没那么高，可以使用大的学习率。4）可以代替LRN<br>缺点：需要计算均值与方差，不适合动态网络或者RNN。计算均值方差依赖每批次，因此数据最好足够打乱。<br>IN的计算就是把每张图片的HW维度单独拿出来归一化处理，不受通道和batchsize 的影响<br>5、cross entropy和mse区别，求导<br>交叉熵是用来评估当前训练得到的概率分布于真实分布的差异情况，减少交叉熵损失就是在提高模型的预测准确率。交叉熵通常用作分类问题的代价函数。<br>均方误差是指参数估计值与真实值之差的平方的期望值，MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精度。通常用来做回归问题的代价函数。<br>6、sigmoid, softmax用途，区别<br>Sigmoid函数或Softmax函数可以将分类器的原始输出值映射为概率。Sigmoid函数会分别处理各个原始输出值，因此其结果相互独立，概率总和不一定为1。相反，Softmax函数的输出值相互关联，其概率的总和始终为1。<br>Sigmoid = 多标签分类问题 = 多个正确答案 = 非独占输出<br>Softmax = 多类别分类问题 = 只有一个正确答案 = 互斥输出<br>如果模型输出为非互斥类别，且可以同时选择多个类别，则采用Sigmoid函数计算该网络的原始输出值。<br>如果模型输出为互斥类别，且只能选择一个类别，则采用Softmax函数计算该网络的原始输出值。<br>7、单链表快排思想<br>8、概率题，a服从均匀分布(0,1)，b服从均匀分布(0,1),求max(a,b)的期望，拓展为n个独立变量，求max期望</p>
<h2 id="二面"><a href="#二面" class="headerlink" title="二面:"></a>二面:</h2><p>1、cross entropy和mse能否互相替换？<br>不能。参见问题（为什么分类问题用 cross entropy，而回归问题用 MSE?）<br>2、多标签分类是否了解, 多标签分类激活函数?<br><a href="https://blog.csdn.net/rocling/article/details/89165463" target="_blank" rel="noopener">解答</a><br>3、单链表快排实现</p>
<h1 id="2019-海康威视"><a href="#2019-海康威视" class="headerlink" title="2019 海康威视"></a>2019 海康威视</h1><h2 id="一面-1"><a href="#一面-1" class="headerlink" title="一面"></a>一面</h2><p>1、faster-rcnn的整个从输入到输出的框架流程？<br>参见深度学习基础知识.faster rcnn<br>2、说一下rpn的原理<br>参见深度学习基础知识.faster rcnn<br>3、针对小目标的解决措施<br>（待解决）<br>4、如何解决样本不均衡的问题<br><a href="https://zhuanlan.zhihu.com/p/60612064" target="_blank" rel="noopener">参考答案</a><br>5、focal loss原理<br><a href="https://blog.csdn.net/hejin_some/article/details/100600663" target="_blank" rel="noopener">参考解答</a></p>
<h1 id="2019-旷视"><a href="#2019-旷视" class="headerlink" title="2019 旷视"></a>2019 旷视</h1><h2 id="一面-2"><a href="#一面-2" class="headerlink" title="一面"></a>一面</h2><p>1、讲一下SENet的模块，为什么有性能提升，有什么好处<br>2、讲一下Focal loss 的2个参数有什么作用<br>3、讲一下FPN为什么能提升小目标的准确率<br>4、对One-stage的模型有没有了解<br>5、说一说One-stage和Two-stage两者有什么特点<br>6、说一说SSD具体是怎么操作的<br>7、算法题：leetcode.754。一个人从原点出发，可以往左走可以往右走，每次走的步数递增1，问能不能到达一个位置x？如果能，给出走的步数最少的方案？</p>
<h1 id="蚂蚁金服"><a href="#蚂蚁金服" class="headerlink" title="蚂蚁金服"></a>蚂蚁金服</h1><h2 id="二面-1"><a href="#二面-1" class="headerlink" title="二面"></a>二面</h2><p>1、分类和定位的不一致具体是什么<br>分类是给定一张图片或一段视频判断里面是否包含某种类别的目标<br>定位是标注出图片中这个目标的位置<br>检测是标注出这个目标的位置并知道目标的类别是什么<br>分割是解决每一个像素属于哪个目标物体或场景。<br>2、Faster-RCNN比起RCNN有什么改进的地方<br>3、Faster-RCNN如何进行一次计算<br>4、RoI Pooling如何操作<br>根据输入的图片，将ROI映射到feature map对应的位置，映射的规则就是把各个坐标除以输入图片与feature map的大小比值，得到feature map上的box坐标。然后将映射的区域划分为相同大小的sections，对每个sections进行max pooling的操作。<br>5、如果有很长，很小，或者很宽的目标，应该如何处理<br>采用FPN网络的多尺度预测方式，将高层特征和低层特征进行融合，增强特征的表达能力。<br>6、FPN具体是怎么操作的<br>将高层的特征进行两倍上采样和前一层的特征进行逐元素求和，然后将融合的特征输入3x3卷积（消除上采样的混叠效应）得到最后的特征。<br>7、FPN的特征融合具体是怎么做的<br>element-wise逐元素求和<br>8、FPN的特征融合为什么是相加操作呢<br>add操作可以看做是加入一种先验知识，通过add操作，网络会得到新的特征，这个心特征会反映原始特征的一些特性，但是原始特征的一些信息也会在这个过程中损失。但是concate就是讲原始的特征直接拼接，让网络学习如何融合特征，这个过程中信息不会损失，但是concate会带来的计算量较大，在明确原始特征的关系可以使用add操作，可以节省计算资源。<br>9、Soft-NMS是如何操作的<br>10、Softmax是什么，公式是什么样的<br><a href="https://blog.csdn.net/weixin_37142859/article/details/95534590" target="_blank" rel="noopener">参考答案</a><br>11、Softmax的梯度是什么<br>12、BN原理<br>13、Pytorch的卷积是如何实现的<br><a href="https://blog.csdn.net/qq_37541097/article/details/102926037" target="_blank" rel="noopener">解答</a><br>14、还知道哪些传统计算机视觉的算法<br>(待解决)<br>15、SIFT原理，SIFT如何保持尺度不变性的<br>(待解决)</p>
<h2 id="三面"><a href="#三面" class="headerlink" title="三面"></a>三面</h2><p>1、说一个比较熟悉的网络<br>（项目中需准备）<br>2、对移动端的网络有没有什么了解<br>（待解决）<br>3、Focal loss怎么操作的<br>4、IoUNet怎么操作的<br>（待解决）<br>5、Soft-NMS怎么操作的<br>6、FPN的相加操作有没有尝试其他操作<br>7、对SSD和YOLO有没有什么了解？对SSD做过什么实验<br>8、对attention有什么了解<br>9、对跟踪有没有什么了解</p>
<h2 id="四面"><a href="#四面" class="headerlink" title="四面"></a>四面</h2><p>1、说一下focal loss的原理<br>2、介绍一下目标检测有哪些方向，最近的一些新的进展<br>3、说一下Soft-NMS的原理<br>4、说一下视觉的attention<br>5、平常是如何学习的<br>6、python多线程有了解吗<br>（待解决）<br>7、引用和指针的区别<br>（待解决）整理python相关问题<br>8、有什么想问的</p>
<h2 id="五面"><a href="#五面" class="headerlink" title="五面"></a>五面</h2><p>1、说比赛<br>2、比赛的数据集数量是怎么分布的<br>3、小目标占比如何<br>4、为什么说SENet泛化性好<br>5、SENet为什么效果好<br>6、FPN是怎么提升小目标检出率的<br>7、项目是一个什么问题呢<br>8、大目标如果有2个候选框和gt重合应该怎么处理<br>9、BN是解决什么问题的<br>10、BN为什么有效<br>11、什么时候开始接触这个方向的<br>12、学过哪些课程<br>13、学过机器学习吗</p>
<h1 id="商汤"><a href="#商汤" class="headerlink" title="商汤"></a>商汤</h1><h2 id="一面-3"><a href="#一面-3" class="headerlink" title="一面"></a>一面</h2><p>1、InceptionV1为什么能提升性能<br>2、RPN哪里也可以提升小目标检出率<br>3、为什么说resnet101不适用于目标检测<br>4、小目标在FPN的什么位置检测<br>5、sigmoid和softmax的区别<br>6、detnet原理<br>7、一道算法题：输入一个文件，等概率输出某一行，只能顺序遍历<br>8、手写nms<br>(参考答案)[<a href="https://zhuanlan.zhihu.com/p/64423753" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/64423753</a>]</p>
<h2 id="二面-2"><a href="#二面-2" class="headerlink" title="二面"></a>二面</h2><p>1、项目：最大的创新点是什么<br>2、SENet原理<br>3、Focal Loss 原理<br>4、Faster RCNN原理<br>5、用的roi pooling 还是roi align<br>6、IoUNet的原理<br>7、有了解过单阶段的检测器<br>8、说一下SSD的原理<br>9、还知道哪些轻量级的检测器<br>10、知道大网络用来学习小网络的方法吗<br>11、对分割有没有了解<br>12、用的什么机器(GPU)<br>13、比赛排名多少<br>14、用的什么模型</p>
<h2 id="三面-1"><a href="#三面-1" class="headerlink" title="三面"></a>三面</h2><p>1、什么时候开始接触CV课程<br>2、有没有上过CV的相关课程<br>3、SENet原理<br>4、SENet接在ResNet还有Inception的什么位置呢<br>5、IOUNet能有多少提升<br>6、NMS和soft-NMS原理<br>7、比赛遇到了什么不work的地方<br>8、假如一个图片中有一个很大的目标还有一个很小的目标，你会怎么处理呢<br>9、多尺度训练如何设置<br>10、为什么设置长边为固定的1600呢<br>11、介绍一下SSD和Faster-RCNN，说一下异同点<br>12、Faster-RCNN的回归目标是如何定义的<br>13、Faster-RCNN用的什么loss<br>14、smooth L1 loss为什么更有效<br>15、SGD、Adam之类优化的原理<br>16、BN、IN、LN、GN原理，BN为什么有效<br>17、Python有哪些常用的库报一遍<br>18、说一下使用Pytorch对cifar10数据集分类的整个代码流程，构建模型的过程是怎么样的<br>19、会C++吗<br>20、github的常用操作：上传、合并、分支之类的<br>（待整理）<br>21、linux的常用操作：查看文件大小、删除文件、查看文件行数、假如文件中有很多文件，每个文件中又有很多文件，如何删除全部文件<br>（待整理）<br>22、SiamRPN原理<br>23、轻量级模型<br>（待解决）</p>
<h1 id="精锐视觉上海研究院"><a href="#精锐视觉上海研究院" class="headerlink" title="精锐视觉上海研究院"></a>精锐视觉上海研究院</h1><h2 id="二面-3"><a href="#二面-3" class="headerlink" title="二面"></a>二面</h2><p>算法题：1、给定一个乱序的数组，给定一个整数target，要求找出数组中所有和为该target的两个数。2、给定一张100元纸币，兑换为20，5，1元的纸币，要求将100元纸币正好兑换为上述面额的纸币，且每种面额不少于一张，写代码实现总共有多少种兑换方法。<br>2、生成式模型和判别式模型<br>（待解决）<br>3、解释最大似然估计和最大后验概率以及区别<br>4、神经网络中激活层的作用<br>5、faster rcnn中为什么要用3x3的巻积核代替5x5和7x7的巻积核。<br>6、防止过拟合的方式有哪些，请写出不少于五种。<br>7、请用深度学习的方法设计一套手写签名的识别方案。（不会）<br>8、请自主设计一套人脸识别方案，详述数据集、backbone、训练策略、模型测试等。<br>9、opencv的cascade级联分类器的工作原理以及具体的实现方式，训练级联分类器的注意事项。<br>（待解决）<br>10、HOG，LBP，Haar特征<br>（待解决）<br>11、简单介绍一下deep_sort算法</p>
<h2 id="三面-2"><a href="#三面-2" class="headerlink" title="三面"></a>三面</h2><p>1、问了一个深度学习的项目，项目简介，自己负责的部分，技术原理细节，创新点，难点。后续改进方案。<br>2、详细介绍一下deepsort算法，以及和传统跟踪方法的区别。<br>3、faster rcnn原理<br>4、详细解释deep_sort算法，与online track的方法有什么区别，目标跟踪丢失怎么办</p>
<h1 id="聚时科技"><a href="#聚时科技" class="headerlink" title="聚时科技"></a>聚时科技</h1><h2 id="一面-4"><a href="#一面-4" class="headerlink" title="一面"></a>一面</h2><p>1、图像处理，中值滤波和平滑滤波的区别<br>2、说几个机器学习常用的算法，SVM的目标函数是什么，是如何实现分类的，KNN的原理以及分类流程<br>3、常见的目标分类的基础网络有哪些，mobilenet和shufflenet是如何实现卷积加速的。</p>
<h2 id="二面-4"><a href="#二面-4" class="headerlink" title="二面"></a>二面</h2><p>1、给了一个7x7的灰度图像和一个2x2的卷积核，分别写出腐蚀和膨胀运算后的图像。<br>2、手写代码实现二维卷积过程，不得调用TF、Keras等深度学习库。<br>3、手写代码实现一个8邻接连通域算法，不得调用opencv等图像处理库。<br>4、写出三个常用的机器学习算法，并介绍其原理和使用场景。<br>5、请写出如些解决样本不平衡问题。</p>
<h1 id="腾讯"><a href="#腾讯" class="headerlink" title="腾讯"></a>腾讯</h1><p>1、YOLO V2 V3你对哪个熟悉，讲一下细节实现<br>2、多尺度问题<br>3、anchor基础知识<br>4、人脸识别现在常用算法<br>5、语义分割到实例分割怎么做<br>6、GAN是否了解，如何通俗的讲其原理<br>7、PCA原理LDA原理<br>8、SVM+HOG<br>9、XGBoost<br>10、CNN、RCNN、FRCNN，有可能问你其中一个细节的关键<br>11、TensorFlow这些框架你谈一下看法以及对其他框架的了解<br>12、现在机器学习、深度学习这么火，你有什么看法<br>13、机器学习、深度学习你对他们的理解是什么<br>14、Relu比Sigmoid使用多的原因<br>15、Loss不升反降的原因，如何解决<br>16、SSD细节<br>17、Linux 权限的意义<br>18、块操作的操作的步骤以及快捷方式</p>
<h1 id="搜狗"><a href="#搜狗" class="headerlink" title="搜狗"></a>搜狗</h1><h2 id="一面-5"><a href="#一面-5" class="headerlink" title="一面"></a>一面</h2><p>1、RCNN系列的算法流程和区别；<br>2、Fast RCNN中 bbox 回归的损失函数什么；<br>3、解释 ROI Pooling 和 ROI Align；<br>4、Mask RCNN中 mask branch 如何接入 Faster RCNN中；<br>5、解释 FPN （没细看，面完补的）；<br>6、优化算法举例和他们的区别（SGD、SGDM、RMSprop、Adam）；<br>7、训练不收敛的原因有哪些；<br>8、简述 Inception v1-v4；<br>9、简述 CNN 的演变；<br>10、BN 的作用和缺陷，以及针对batch_size小的情况的改进（GN）</p>
<h1 id="旷世CV岗"><a href="#旷世CV岗" class="headerlink" title="旷世CV岗"></a>旷世CV岗</h1><p>1.自我介绍，项目介绍<br>2.FCN结构介绍，上采样的具体操作<br>3.空洞卷积原理，deeplab v1 v2的改进<br>4.focal loss介绍, lovasz loss数学原理<br>5.一道题，计算卷积操作的浮点计算量，比较简单<br>6.介绍下RPN的原理<br>7.mobile net<br>8.unet的缺点</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/21/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/21/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">排序算法</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-21 19:41:40" itemprop="dateCreated datePublished" datetime="2020-02-21T19:41:40+08:00">2020-02-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-24 23:38:43" itemprop="dateModified" datetime="2020-02-24T23:38:43+08:00">2020-02-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><img src="/images/排序算法.png" alt="排序算法比较"></p>
<h1 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h1><p>算法过程：首先，找到数组中最小的那个元素，其次，将它和数组的第一个元素交换位置（如果第一个元素就是最小元素就和自己交换）。然后在剩下的元素中找到最小的元素，将它与数组的第二个元素交换位置。如此往复，知道整个数组排序。<br><img src="https://images2017.cnblogs.com/blog/849589/201710/849589-20171015224719590-1433219824.gif" alt="选择排序过程"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectionSort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)<span class="number">-1</span>):</span><br><span class="line">        minIndex = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, len(nums)):</span><br><span class="line">            <span class="keyword">if</span> nums[j]&lt;nums[minIndex]:</span><br><span class="line">                minIndex = j</span><br><span class="line">        nums[i], nums[minIndex] = nums[minIndex], nums[i]</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><br>性质：时间复杂度：$O(n^2)$，空间复杂度：$O(1)$，非稳定排序，原地排序</p>
<h1 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h1><p>算法过程：1）从数组第2个元素开始抽取元素。2）把它与左边第一个元素比较，如果左边第一个元素比它大，则继续与左边第二个元素比较，知道遇到不必它大的元素，然后插入到这个元素的右边。3）继续选取第3,4,…,n个元素，重复步骤2，选择适当的位置插入。<br><img src="http://wuchong.me/img/Insertion-sort-example-300px.gif" alt="插入排序过程"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertionSort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)<span class="number">-1</span>):</span><br><span class="line">        curNum, preIndex = nums[i+<span class="number">1</span>], i</span><br><span class="line">        <span class="keyword">while</span> preIndex&gt;=<span class="number">0</span> <span class="keyword">and</span> curNum&lt;nums[preIndex]:</span><br><span class="line">            nums[preIndex+<span class="number">1</span>] = nums[preIndex]</span><br><span class="line">            preIndex -= <span class="number">1</span></span><br><span class="line">        nums[preIndex+<span class="number">1</span>] = curNum</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><br>性质：时间复杂度：$O(n^2)$，空间复杂度：$O(1)$，稳定排序，原地排序。</p>
<h1 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h1><p>算法过程：1）把第一个元素和第二个元素比较，如果第一个比第二个大，则交换他们的位置。接着比较第二个与第三个元素，如果第二个比第三个大，则交换它们的位置…。这样一趟比较交换之后，排在最右的就会是最大的数。2）除去最右的数，我们对剩余的元素做同样的工作，如此重复下去，直到排序完成。<br><img src="https://images2017.cnblogs.com/blog/849589/201710/849589-20171015223238449-2146169197.gif" alt="冒泡排序过程"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubblesort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)<span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, i):</span><br><span class="line">            <span class="keyword">if</span> nums[j]&gt;nums[j+<span class="number">1</span>]:</span><br><span class="line">                nums[j], nums[j+<span class="number">1</span>] = nums[j+<span class="number">1</span>], nums[j]</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><br>性质：时间复杂度：$O(n^2)$，空间复杂度：$O(1)$，稳定排序，原地排序。<br><strong>优化冒泡排序算法:</strong>假如开始的第一队到结尾的最后一对，相邻的元素之间都没有发生交换的操作，这意味着右边的元素总是大于等于左边的元素，此时数组已经是有序的，无须再对剩余的元素重复比较下去。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubblesort2</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> nums:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)<span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        swapped = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, i):</span><br><span class="line">            <span class="keyword">if</span> nums[j]&gt;nums[j+<span class="number">1</span>]:</span><br><span class="line">                nums[j], nums[j+<span class="number">1</span>] = nums[j+<span class="number">1</span>], nums[j]</span><br><span class="line">                swapped = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> swapped:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure></p>
<h1 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h1><p>希尔排序可以说是插入排序的一种变种，无论是插入排序还是冒泡排序，如果数组的最大值刚好是在第一位，要将它挪到正确的位置就需要n-1次移动。也就是说原数组的一个元素如果距离它正确的位置很远，则需要与相邻元素交换很多次才能到达正确的位置，这是相对比较花时间了。<br>希尔排序就是为了加快速度简单地改进插入排序，交换不相邻的元素对数组的局部进行排序。基本思想是：先将整个待排序列分割成为若干子序列分别进行插入排序，待整个序列中的记录基本有序时再对全体记录进行一次直接插入排序。希尔排序的核心在于间隔序列的设定，既可以提前设定好间隔序列，也可以动态地定义间隔序列。<br><img src="https://images2018.cnblogs.com/blog/849589/201803/849589-20180331170017421-364506073.gif" alt="希尔排序过程"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shellSort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    gap = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> gap&lt;len(nums)//<span class="number">3</span>:</span><br><span class="line">        gap = gap*<span class="number">3</span>+<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> gap&gt;<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(gap, len(nums)):</span><br><span class="line">            curNum, preIndex = nums[i], i-gap</span><br><span class="line">            <span class="keyword">while</span> preIndex&gt;=<span class="number">0</span> <span class="keyword">and</span> curNum&lt;nums[preIndex]:</span><br><span class="line">                nums[preIndex+gap] = nums[preIndex]</span><br><span class="line">                preIndex -= gap</span><br><span class="line">            nums[preIndex+gap] = curNum</span><br><span class="line">        gap //= <span class="number">3</span></span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><br>性质：时间复杂度：$O(nlogn)$，空间复杂度：$O(1)$，非稳定排序，原地排序。</p>
<h1 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h1><p>归并排序使用递归分治的思想，其基本思想是：把待排序列看成两个有序的子序列，然后合并两个子序列，接着把子序列再看成两个有序的子子序列，…，以此类推。<br><img src="http://wuchong.me/img/Insertion-sort-example-300px.gif" alt="归并排序过程"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mergeSort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(nums)&lt;=<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> nums</span><br><span class="line">    <span class="comment"># 归并过程</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge</span><span class="params">(left, right)</span>:</span></span><br><span class="line">        result = []</span><br><span class="line">        i = j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i&lt;len(left) <span class="keyword">and</span> j&lt;len(right):</span><br><span class="line">            <span class="keyword">if</span> left[i]&lt;=right[j]:</span><br><span class="line">                result.append(left[i])</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                result.append(right[j])</span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">        result = result + left[i:] + right[j:]</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="comment"># 递归过程</span></span><br><span class="line">    mid = len(nums)//<span class="number">2</span></span><br><span class="line">    left = mergeSort(nums[:mid])</span><br><span class="line">    right = mergeSort(nums[mid:])</span><br><span class="line">    <span class="keyword">return</span> merge(left, right)</span><br></pre></td></tr></table></figure><br>非递归做法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mergeSort2</span><span class="params">(nums)</span>:</span></span><br><span class="line">    i = <span class="number">1</span>  <span class="comment"># i是步长</span></span><br><span class="line">    <span class="keyword">while</span> i&lt;len(nums):</span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> left&lt;len(nums):</span><br><span class="line">            mid = left+i</span><br><span class="line">            right = min(left+<span class="number">2</span>*i, len(nums))</span><br><span class="line">            <span class="keyword">if</span> mid&lt;right:</span><br><span class="line">                nums[left:right]=merge(nums[left:mid], nums[mid:right])</span><br><span class="line">            left += <span class="number">2</span>*i</span><br><span class="line">        i *= <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure></p>
<h1 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h1><p>快速排序通常明显比同为$O(nlogn)$的其他算法更快，因此常被采用，而且快排采用了分治的思想，所以在面试中经常看到快排的影子。<br>步骤：<br>1）从数列中跳出一个元素作为基准数。<br>2）分区过程，将比基准数大的放在右边，小于或等于它的数都放在左边。<br>3）再对左右分区递归执行第二步，直至各区间只有一个数。<br><a href="http://wuchong.me/img/Quicksort-example.gif" target="_blank" rel="noopener">快排过程</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 划分策略，适用于链表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partition</span><span class="params">(nums, left, right)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> left == right:</span><br><span class="line">        <span class="keyword">return</span> left</span><br><span class="line">    pivot = left</span><br><span class="line">    slow, fast = left, left+<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> fast&lt;=right:</span><br><span class="line">        <span class="keyword">if</span> nums[fast]&lt;nums[pivot]:</span><br><span class="line">            slow += <span class="number">1</span></span><br><span class="line">            nums[slow], nums[fast] = nums[fast], nums[slow]</span><br><span class="line">        fast += <span class="number">1</span></span><br><span class="line">    nums[pivot], nums[slow] = nums[slow], nums[pivot]</span><br><span class="line">    <span class="keyword">return</span> slow</span><br><span class="line"></span><br><span class="line"><span class="comment"># 递归方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quickSort</span><span class="params">(nums, left, right)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> left&lt;=right:</span><br><span class="line">        midIndex = partition(nums, left, right)</span><br><span class="line">        quickSort(nums, left, midIndex<span class="number">-1</span>)</span><br><span class="line">        quickSort(nums, midIndex+<span class="number">1</span>, right)</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><br>非递归方式，利用栈的思想将需要继续排序的首尾下标存入栈中，不断弹栈进行分区操作。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partition2</span><span class="params">(nums, left, right)</span>:</span></span><br><span class="line">    mid = nums[left]</span><br><span class="line">    <span class="keyword">while</span> left&lt;right:</span><br><span class="line">        <span class="keyword">while</span> left&lt;right <span class="keyword">and</span> nums[right]&gt;mid:</span><br><span class="line">            right -= <span class="number">1</span></span><br><span class="line">        nums[left] = nums[right]</span><br><span class="line">        <span class="keyword">while</span> left&lt;right <span class="keyword">and</span> nums[left]&lt;=mid:</span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line">        nums[right] = nums[left]</span><br><span class="line">    nums[left] = mid</span><br><span class="line">    <span class="keyword">return</span> left</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quickSort2</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(nums)&lt;=<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> nums</span><br><span class="line">    stack = []</span><br><span class="line">    left, right = <span class="number">0</span>, len(nums)<span class="number">-1</span></span><br><span class="line">    stack.append(left)</span><br><span class="line">    stack.append(right)</span><br><span class="line">    <span class="keyword">while</span> stack:</span><br><span class="line">        r = stack.pop()</span><br><span class="line">        l = stack.pop()</span><br><span class="line">        midIndex = partition2(nums, l, r)</span><br><span class="line">        <span class="keyword">if</span> l&lt;midIndex:</span><br><span class="line">            stack.append(l)</span><br><span class="line">            stack.append(midIndex<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">if</span> r&gt;midIndex:</span><br><span class="line">            stack.append(midIndex+<span class="number">1</span>)</span><br><span class="line">            stack.append(r)</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure></p>
<h1 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h1><p>堆排序是借助堆来实现的选择排序，思想同选择排序，以下以大根堆为例。注意：如果想升序排序就使用大根堆，反之使用小根堆。原因是堆顶元素需要交换到序列尾部。<br>首先，实现堆排序需要解决两个问题：<br>1）如何由一个无序序列建成一个堆？<br>2）如何在输出堆顶元素之后，调整剩余元素成为一个新的堆？<br>第一个问题，可以直接使用线性数组来表示一个堆，由初始的无序序列建成一个堆就需要自底向上从第一个非叶元素开始按个调整成一个堆。<br>第二个问题，怎么调整成堆？首先是将堆顶元素和最后一个元素交换，然后比较当前堆顶元素的左右孩子节点，因为除了当前的堆顶元素，左右孩子均满足条件，这时需要选择当前堆顶元素与左右孩子节点的较大者（大根堆）交换，直到叶子节点。我们称这个自堆顶至叶子节点的调整为筛选。<br>从一个无序序列建堆的过程就是一个反复筛选的过程。若将此序列看成是一个完全二叉树，则最后一个非终端节点是n/2（取底）个元素，由此筛选即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 大根堆</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapSort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">adjustHeap</span><span class="params">(nums, i, size)</span>:</span></span><br><span class="line">        lchild = <span class="number">2</span>*i+<span class="number">1</span></span><br><span class="line">        rchild = <span class="number">2</span>*i+<span class="number">2</span></span><br><span class="line">        largest = i</span><br><span class="line">        <span class="keyword">if</span> lchild&lt;size <span class="keyword">and</span> nums[lchild]&gt;nums[largest]:</span><br><span class="line">            largest = lchild</span><br><span class="line">        <span class="keyword">if</span> rchild&lt;size <span class="keyword">and</span> nums[rchild]&gt;nums[largest]:</span><br><span class="line">            largest = rchild</span><br><span class="line">        <span class="keyword">if</span> largest != i:</span><br><span class="line">            nums[largest], nums[i] = nums[i], nums[largest]</span><br><span class="line">            adjustHeap(nums, largest, size)</span><br><span class="line">    <span class="comment"># 建立堆</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">buildHeap</span><span class="params">(nums, size)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)//<span class="number">2</span>)[::<span class="number">-1</span>]:  <span class="comment"># 从倒数第一个非叶子节点开始建立大根堆</span></span><br><span class="line">            adjustHeap(nums, i, size)        <span class="comment"># 对所有非叶子节点进行堆的调整</span></span><br><span class="line">    <span class="comment"># 堆排序</span></span><br><span class="line">    size = len(nums)</span><br><span class="line">    buildHeap(nums, size)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums))[::<span class="number">-1</span>]:</span><br><span class="line">        nums[<span class="number">0</span>], nums[i] = nums[i], nums[<span class="number">0</span>]</span><br><span class="line">        adjustHeap(nums, <span class="number">0</span>, i)</span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure></p>
<h1 id="计数排序"><a href="#计数排序" class="headerlink" title="计数排序"></a>计数排序</h1><p>（待补充）</p>
<h1 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h1><p>（待补充）</p>
<h1 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h1><p>（待补充）</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="post-title-link" itemprop="url">深度学习基础知识</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-18 21:13:44" itemprop="dateCreated datePublished" datetime="2020-02-18T21:13:44+08:00">2020-02-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-04-16 19:04:09" itemprop="dateModified" datetime="2020-04-16T19:04:09+08:00">2020-04-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><h2 id="SGD-Momentum-Adagard-Adam原理"><a href="#SGD-Momentum-Adagard-Adam原理" class="headerlink" title="SGD,Momentum,Adagard,Adam原理"></a>SGD,Momentum,Adagard,Adam原理</h2><h3 id="1-SGD、BGD和Mini-BGD"><a href="#1-SGD、BGD和Mini-BGD" class="headerlink" title="1. SGD、BGD和Mini-BGD:"></a>1. SGD、BGD和Mini-BGD:</h3><p>SGD(stochastic gradient descent):随机梯度下降，算法在每读入一个数据都会立刻计算loss function的梯度来更新参数，假设loss function为L(w),下同。</p>
<script type="math/tex; mode=display">w-=\eta \bigtriangledown_{w_{i}}L(w_{i})</script><p>优点：收敛的速度快，可以实现在线更新<br>缺点：很容易陷入到局部最优，困在马鞍点<br>BGD(batch gradient decent):批量梯度下降，算法在读取整个数据集后累加来计算损失函数的梯度。</p>
<script type="math/tex; mode=display">w-=\eta \bigtriangledown_{w}L(w)</script><p>优点：如果loss function为convex(凸函数)，则基本可以找到全局最优解<br>缺点：数据处理量大，导致梯度下降慢；不能实时增加实例，在线更新；训练占内存<br>Mini-BGD(mini-batch gradient descent):选择小批量数据进行梯度下降，这是一个折中的方法，采用训练集的子集(mini-batch)来计算loss function的梯度：</p>
<script type="math/tex; mode=display">w-=\eta \bigtriangledown_{w_{i:i+n}}L(w_{i:i+n})</script><p>这个优化方法用的比较多，计算效率高且收敛稳定，是现在深度学习的主流方法。当使用小批量样本来估计梯度时，由于估计的梯度往往会偏离真实的梯度，这可以视作在学习的过程中加入了噪声扰动，这种扰动会带来一些正则化的效果。<br>batch size越大，则小批量样本估计总体梯度约可靠，则每次参数更新沿总体梯度的负方向的概率越大。但是，训练误差收敛速度快，并不意味着模型的泛化性能强，此时的噪声太小，不足以将参数推出尖锐极小值的吸引区域。解决方案是：提高学习率，从而放大梯度噪声的贡献。<br>上面的方法都存在一个问题，就是update更新的方向完全依赖计算出来的梯度，很容易陷入局部最优的马鞍点。能不能改变其走向，又保证原本的梯度方向，就像向量变换一样，我们模拟物理中物体流动的动量概念（惯性），引入Momentum的概念。</p>
<h3 id="2-Momentum"><a href="#2-Momentum" class="headerlink" title="2. Momentum"></a>2. Momentum</h3><p>在更新方向的时候保留之前的方向，增加稳定性而且还有摆脱局部最优的能力。</p>
<script type="math/tex; mode=display">\Delta w=\alpha \Delta w- \eta \bigtriangledown L(w)</script><script type="math/tex; mode=display">w=w+\Delta w</script><p>若当前梯度的方向与历史梯度方向一致（表明当前样本不太可能为异常点），则会增强这个方向的梯度，若当前梯度与历史梯度方向不一致，则梯度会衰减。一种形象的解释是：我们把一个球推下山，球在下坡时积聚动量，在途中变得越来越快，<script type="math/tex">\eta</script>可视为空气阻力，若球的方向发生变化，则动量会衰减。</p>
<h3 id="3-Adagrad"><a href="#3-Adagrad" class="headerlink" title="3. Adagrad"></a>3. Adagrad</h3><p>Adagrad(adaptive gradient)自适应梯度算法，是一种改进的随机梯度下降算法。以前的算法中，每一个参数都使用相同的学习率<script type="math/tex">\alpha</script>,而Adagrad算法能够在训练中自动对learning_rate进行调整，出现频率较低参数采用较大的<script type="math/tex">\alpha</script>更新，出现频率较高的参数采用较小的<script type="math/tex">\alpha</script>更新，根据描述这个优化方法很适合处理稀疏数据。</p>
<script type="math/tex; mode=display">G=\sum ^{t}_{\tau=1}g_{\tau} g_{\tau}^{T} \quad s.t. \ g_{\tau}=\bigtriangledown L(w_{i})</script><script type="math/tex; mode=display">G_{j,j}=\sum _{\tau=1}^{t} g_{\tau,j\cdot}^{2}</script><p>这个对角线矩阵的元素代表的是参数的出现频率，每个参数的更新：</p>
<script type="math/tex; mode=display">w_{j}=w_{j}-\frac{\eta}{\sqrt{G_{j,j}}}g_{j}</script><h3 id="4-RMSprop"><a href="#4-RMSprop" class="headerlink" title="4. RMSprop"></a>4. RMSprop</h3><p>RMSprop(root mean square propagation)也是一种自适应学习率方法，不同之处在于，Adagrad会累加之前所有的梯度平方，RMSprop仅仅是计算对应的平均值，可以缓解Adagrad算法学习率下降较快的问题。</p>
<script type="math/tex; mode=display">v(w,t)=\gamma v(w,t-1)+(1-\gamma)(\bigtriangledown L(w_{i}))^{2}</script><p>其中 $\gamma$ 是遗忘因子</p>
<p>参数更新</p>
<script type="math/tex; mode=display">w=w-\frac{\eta}{\sqrt{v(w,t)}}\bigtriangledown L(w_{i})</script><h3 id="5-Adam"><a href="#5-Adam" class="headerlink" title="5. Adam"></a>5. Adam</h3><p>Adam(adaptive moment estimation)是对RMSprop优化器的更新，利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。优点：每一次迭代学习率都有一个明确的范围，使得参数变化很平稳。Adam记录梯度的一阶矩（first moment），即过往梯度与当前梯度的平均，这体现了惯性保持；另一方面，Adam还记录梯度的二阶矩（second moment），即过往梯度平方与当前梯度平方的平均，这类似AdaGrad方法，为不同参数产生自适应的学习速率。</p>
<script type="math/tex; mode=display">m_{w}^{t+1}=\beta_{1}m_{w}^{t}+(1-\beta_{1}) \bigtriangledown L^{t}</script><script type="math/tex; mode=display">v_{w}^{t+1}=\beta_{2}m_{w}^{t}+(1-\beta_{2}) (\bigtriangledown L^{t})^{2}</script><p>其中，m为一阶矩估计，v为二阶矩估计，然后进行估计校正，实现无偏估计</p>
<script type="math/tex; mode=display">\hat{m}_{w}=\frac{m_{w}^{t+1}}{1-\beta_{1}^{t+1}}</script><script type="math/tex; mode=display">\hat{v}_{w}=\frac{v_{w}^{t+1}}{1-\beta_{2}^{t+1}}</script><script type="math/tex; mode=display">w^{t+1} \leftarrow=w^{t}-\eta \frac{\hat{m}_{w}}{\sqrt{\hat{v}_{w}}+\epsilon}</script><h3 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h3><p>牛顿法的基本思想是在现有极小点估计值的附近对$f(x)$做二阶泰勒展开，进而找到极小点的一个估计值。这个方法需要目标函数是二阶连续可微的。由于牛顿法中需要求解二阶偏导，这个计算量会比较大，而且又是目标函数求出的海森矩阵无法保持正定，因此提出了拟牛顿法。拟牛顿法是一些算法的总称，它们的目的是通过某种方式来近似表示海森矩阵（或者它的逆矩阵）。和牛顿法的区别是，它在更新参数$w$之后更新一下近似海森矩阵的值，而牛顿法是在更新$w$之前完全的计算一遍海森矩阵。<br>梯度下降和拟牛顿法的异同？<br>1）参数更新模式相同。<br>2）梯度下降法利用误差的梯度来更新参数，拟牛顿法利用海森矩阵的近似来更新参数。<br>3）梯度下降是泰勒级数的一阶展开，而拟牛顿法是泰勒级数的二阶展开。<br>4）SGD能保证收敛，但是L-BFGS在非凸时不收敛。</p>
<h2 id="Batch-Size"><a href="#Batch-Size" class="headerlink" title="Batch Size"></a>Batch Size</h2><h3 id="在合理的范围内，增大batch-size的好处"><a href="#在合理的范围内，增大batch-size的好处" class="headerlink" title="在合理的范围内，增大batch size的好处"></a>在合理的范围内，增大batch size的好处</h3><p>1）内存利用率提高了，大矩阵乘法的并行化效率提高<br>2）跑完一次epoch所需的迭代次数减少，对于相同数据量的处理速度进一步加快。<br>3）在一定范围内，一般来说batch size越大，其确定的下降方向越准，引起训练振荡越小。</p>
<h3 id="盲目增大batch-size的坏处"><a href="#盲目增大batch-size的坏处" class="headerlink" title="盲目增大batch size的坏处"></a>盲目增大batch size的坏处</h3><p>1）内存利用率提高，但是内存容量可能撑不住<br>2）跑完一次epoch所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加，从而对参数的修正也就显得更加缓慢。<br>3）batch size增大到一定程度，其确定的下降方向已经基本不再改变。</p>
<h3 id="调节batch-size对训练效果的影响"><a href="#调节batch-size对训练效果的影响" class="headerlink" title="调节batch size对训练效果的影响"></a>调节batch size对训练效果的影响</h3><p>1）batch size太小，模型表现效果很差（error增大）<br>2）随着batch size增大，处理相同数据量的速度越快<br>3）随着batch size增大，达到相同精度所需的epoch数量越多。<br>4）由于上述两种因素的矛盾，batch size增大到某个时候，达到时间上的最优。<br>5）由于最终收敛精度会陷入不同的局部极值，因此batch size增大到某些时候，达到最终收敛精度上的最优。</p>
<h2 id="L1、L2范数"><a href="#L1、L2范数" class="headerlink" title="L1、L2范数"></a>L1、L2范数</h2><p>在机器学习中几乎可以看到在损失函数后面都会添加一个额外项，常用的额外项一般有两种，称为L1正则化和L2正则化，或者L1范数和L2范数。L1范数和L2范数可以看做是损失函数的惩罚项，所谓“惩罚”是指对损失函数中的某些参数做些限制。对于现在的回归模型，使用L1范数的模型叫做Lasso回归，使用L2范数的模型叫做Ridge回归（岭回归）。</p>
<h3 id="L1范数"><a href="#L1范数" class="headerlink" title="L1范数"></a>L1范数</h3><p>L1范数是指向量中各个元素绝对值之和，也叫“稀疏规则算子”(Lasso regularization)。稀疏的意思是可以让权重矩阵的一部分值等于0。为什么L1范数会使权值稀疏？有一种回答“它是L0范数的最优凸近似”，还存在一种更优雅的回答：任何的规则算子，如果他在$w_{i}=0$处不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子可以实现稀疏。</p>
<script type="math/tex; mode=display">||x||_{1}=\sum_{i}|x_{i}|</script><p>L1范数可以实现稀疏，而实现稀疏的作用为：<br>1) 可解释性：可以看到到底是哪些特征和预测的信息有关<br>2) 特征选择：输入的x的大部分特征与输出y是没有关系的，如果让参数矩阵w中出现许多0，则可以直接干掉与y无关的元素，也就是选择出于y真正相关的特征。如果不这么做，那么x中本来与y无关的特征也加入到模型中，虽然会更好的减小训练误差，但是在预测新样本时会考虑到无关的信息，干扰了预测。</p>
<h3 id="L2范数"><a href="#L2范数" class="headerlink" title="L2范数"></a>L2范数</h3><p>L2范数是指向量中各元素的平方和然后再求平方根，也叫做“岭回归(Ridge Regression)”，或叫做“权值衰减(weight decay)”。</p>
<script type="math/tex; mode=display">||x||_{2}=\sqrt{\sum_{i}x_{i}^2}</script><p>L2范数与L1范数不同，它不会让参数等于0，而是让每个参数都接近于0。L2范数的优点是：<br>1) 防止过拟合。一般的用法是在损失函数后面加上w的L2范数，即$||x||_{2}$，这是一种规则。<br>2) 优化求解变得稳定快速。简单地说它可以让$w$在接近全局最优点$w^*$的时候，还保持较大的梯度。这样可以跳出局部最优，也使得收敛速度变快。</p>
<h3 id="L1和L2正则分别有什么特点？为何L1稀疏？"><a href="#L1和L2正则分别有什么特点？为何L1稀疏？" class="headerlink" title="L1和L2正则分别有什么特点？为何L1稀疏？"></a>L1和L2正则分别有什么特点？为何L1稀疏？</h3><p>L1范数对异常值更鲁棒，在0点不可导计算不方便，且没有唯一解，L1范数输出稀疏，会把不重要的特征值置0。<br>L2范数计算方便，对异常值敏感，且有唯一解。<br><img src="/images/L1范数求导.png" alt="L1范数求导"><br>加入L1正则项后，对带正则项的目标函数求导，正则项部分产生的导数在原点左边部分是−C，在原点右边部分是C，因此，只要原目标函数的导数绝对值小于C，那么带正则项的目标函数在原点左边部分始<br>终是递减的，在原点右边部分始终是递增的，最小值点自然在原点处。相反，L2正则项在原点处的导数是0，只要原目标函数在原点处的导数不为0，那么最小值点就不会在原点，所以L2只有减小w绝对值的作用，对解空间的稀疏性没有贡献。</p>
<h3 id="L1不可导的时候该怎么办"><a href="#L1不可导的时候该怎么办" class="headerlink" title="L1不可导的时候该怎么办"></a>L1不可导的时候该怎么办</h3><p>当损失函数不可导，梯度下降不再有效，可以使用坐标轴下降法。梯度下降是沿着当前点的负梯度方向进行参数更新，而坐标轴下降法是沿着坐标轴的方向。假设有m个特征个数，坐标轴下降法进行参数更新的时候，先固定m-1个值，然后再求另外一个的局部最优解，从而避免损失函数不可导问题。坐标轴下降法每轮迭代都需要O(mn)的计算，和梯度下降算法相同。</p>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>神经网络的每个神经元接受上一层神经元的输出值作为本神经元的输入值，并将输入值传递给下一层，输入神经元节点会将输入属性值直接传递给下一层（隐藏层或输出层）。上层函数的输出和下层节点的输入之间具有一个函数关系，这个函数称为激活函数。如果不用激活函数，在这种情况下每一层节点的输入都是上一层输出的线性函数，很容易验证，无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，这种情况就是最原始的感知机（Perceptron），那么网络的逼近能力就相当有限。我们引入非线性函数作为激励函数，这样深层神经网络表达能力就更加强大，几乎可以逼近任意函数。</p>
<h3 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h3><p>Signoid是常用的非线性的激活函数，它的数学形式如下：</p>
<script type="math/tex; mode=display">f(z)=\frac{1}{1+e^{-z}}</script><p>其导数为：</p>
<script type="math/tex; mode=display">\frac{df}{dz}=f(z)(1-f(z))</script><p>Sigmoid的几何如下：<br><img src="/images/Sigmoid.png" alt="Sigmoid函数"><br>特点：它能够把输入的连续实值变换为0和1之间的输出，对于非常大的负数则输出为0，非常大的正数则输出为1.<br>缺点：<br>1) 在深度神经网络中梯度反向传递时导致梯度爆炸和梯度消失，其中梯度爆炸发生的概率非常小，而梯度消失发生的概率比较大。Sigmoid函数的倒数如下所示：<br><img src="/images/Sigmoid导数.png" alt="Sigmoid的导数"><br>如果我们初始化神经网络的权值为[0,1]之间的随机值，由反向传播算法的数学推导可知，梯度从后向前传播时，每传递一层梯度值都会减少为原来的0.25倍，如果神经网络隐藏层特别多时，那么梯度在多层传递之后就变得非常小接近于0，即出现梯度消失现象；当网络权值初始化为$(1,+\infty)$区间的值，则会出现梯度爆炸情况。<br>2) Sigmoid的输出不是0均值，这会导致后一层的神经元将上一层的神经元输出的非0均值的信号作为输入。产生的结果是：如果$x&gt;0, f=w^Tx+b$，那么对$w$求局部梯度则都为正，这样反向传播的过程中$w$要么都向正方向更新，要么都往负方向更新，使得收敛缓慢。当然，如果按batch训练，那么那个batch可能会得到不同的信号，这个问题可以缓解一下。非0均值问题虽然会产生一些不好的影响，不过跟梯度消失问题相比还是要好很多。<br>3) 其解析式中含有幂运算，计算求解时相对比较耗时。对于规模较大的深度网络，这回较大地增加训练时间。</p>
<h3 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h3><p>tanh函数的解析式：</p>
<script type="math/tex; mode=display">tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}</script><p>其导数为：</p>
<script type="math/tex; mode=display">tanh'(x)=1-tanh^2(x)</script><p>tanh函数及其导数的几何图像如下：<br><img src="/images/tanh函数.png" alt="tanh函数及其导数"><br>tanh函数解决了Sigmoid函数不是zero-centered输出的问题，然而，梯度消失的问题和幂运算的问题仍然存在。</p>
<h3 id="Relu函数"><a href="#Relu函数" class="headerlink" title="Relu函数"></a>Relu函数</h3><p>Relu函数的解析式：</p>
<script type="math/tex; mode=display">Relu=max(0, x)</script><p>Relu函数及其导数的图像如下图所示：<br><img src="/images/Relu函数.png" alt="Relu函数及其导数"><br>ReLU其实是一个取最大值函数，注意这并不是全区间可导的，但是我们可以取sub-gradient，如上图所示。<br>优点：1）解决了梯度消失问题(gradient vanishing)问题（在正区间）。 2）计算速度非常快，只需要判断输入是否大于0。 3）收敛速度远快于sigmoid和tanh函数。<br>ReLU也有几个需要注意的问题：<br>1) ReLU的输出不是zero-centered。<br>2) Dead ReLU Problem，指的是某些神经元可能永远不会被激活，导致相应的参数永远不会被更新。有两个主要原因可能会导致这种情况：参数的初始化或learning_rate太大导致训练过程中参数更新太大进入这种状态。<br>解决的方法是采用Xavier初始化方法，以及避免将learning rate设置太大或使用adagrad等自动调节learning rate的算法。Xavier初始化方法是一种很有效的神经网络初始化方法，为了使得网络中信息更好的流动，每一层输出的方法应该尽量相等。</p>
<h3 id="Leaky-ReLU函数"><a href="#Leaky-ReLU函数" class="headerlink" title="Leaky ReLU函数"></a>Leaky ReLU函数</h3><p>函数表达式：</p>
<script type="math/tex; mode=display">f(x)=max(\alpha x, x)</script><p>Leaky Relu函数及其导数的图像如下图所示：<br><img src="/images/LeakyRelu函数.png" alt="Leaky ReLU函数及其导数"><br>图中左半边直线斜率非常接近于0，所以看起来像是平的。为了解决Dead ReLU Problem，通过将ReLU的前半段设为$\alpha x$而不是0，通常$\alpha =0.01$。理论上讲，Leaky ReLU有ReLU的所有优点，外加不会有Dead ReLU问题，但在实际操作中，并没有完全证明Leaky ReLU总是好于ReLU。</p>
<h3 id="ELU函数"><a href="#ELU函数" class="headerlink" title="ELU函数"></a>ELU函数</h3><p>函数表达式为：</p>
<script type="math/tex; mode=display">
f(x)=
\begin{cases}
x &\text(if\ x>0)\\
\alpha(e^x-1) &\text{otherwise}
\end{cases}</script><p>函数及其导数的图像如下：<br><img src="/images/ELU函数.png" alt="ELU函数及导数图像"><br>显然，ELU有ReLU的基本所有优点，以及不会有Dead ReLU问题，输出的均值接近于0，是zero-centered。它的一个小问题在于计算量稍大。</p>
<h2 id="神经网络权重初始化方式"><a href="#神经网络权重初始化方式" class="headerlink" title="神经网络权重初始化方式"></a>神经网络权重初始化方式</h2><p>在深度学习找那个，神经网络的权重初始化方法(weight initialization)对模型的收敛速度和性能有着至关重要的影响。神经网络其实就是对权重参数w的不停迭代更新，以期达到较好的性能。在深度神经网络中，随着层数的增多，在梯度下降的过程中，极易出现梯度消失或者梯度爆炸。因此，对权重w的初始化显得至关重要，一个好的权重初始化虽然不能完全解决梯度消失和梯度爆炸问题，但是对于处理这两个问题是由很大的帮助的，并且十分有利于模型性能和收敛速度。</p>
<h3 id="初始化为0"><a href="#初始化为0" class="headerlink" title="初始化为0"></a>初始化为0</h3><p>在线性回归和logistics回归中可以使用，因为隐藏层只有一层。在超过一层的神经网络中就不能够使用了。因为如果所有的权重参数都为0，那么所有的神经元输出都是一样的，在反向传播时向后传递的梯度也是一致，将无法发挥多层的效果，实际上相当于一层隐藏层。</p>
<h3 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h3><p>卷积层的方差为：</p>
<script type="math/tex; mode=display">Var(w_ix_i)=E[w_i]^2Var(x_i)+E[x_i]^2Var(w_i)+Var(w_i)Var(x_i)</script><p>使用高斯随机初始化时要把W随机初始化到一个相对较小的值，因为如果X很大的话，W又相对较大，会导致输出值特别大，这样如果激活函数是sigmoid，就会导致sigmoid的输出值为1或0，导致更多的问题。但是随机初始化也有缺点，在均值为0，方差为1的高斯分布中，当神经网络层数增加时，会发现越往高层的激活函数（tanh函数）的输出值几乎都接近于0，使得神经元不被激活。</p>
<h3 id="Xavier初始化"><a href="#Xavier初始化" class="headerlink" title="Xavier初始化"></a>Xavier初始化</h3><p>每层的权重初始化为：</p>
<script type="math/tex; mode=display">W\sim U[-\frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}}, \frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}}]</script><p>服从均匀分布，$n_j$为输入层的参数，$n_{j+1}$为输出层参数。<br>Xavier是为了解决随机初始化问题而提出的一种初始化方式，其思想是尽可能让输入和输出服从相同的分布，这样能够避免高层的激活函数的输出值趋向于0。虽然Xavier初始化能很好地用于tanh函数，但是对于目前最常用的ReLU激活函数，还是无能为力，因此引出He initialization。</p>
<h3 id="MSRA-He-initialization"><a href="#MSRA-He-initialization" class="headerlink" title="MSRA/He initialization"></a>MSRA/He initialization</h3><p>Xavier初始化对于Relu激活函数表现非常不好，因此何恺明针对ReLU重新推导，每层的初始化公式为：</p>
<script type="math/tex; mode=display">W\sim U[0, \sqrt{\frac{2}{n}}]</script><p>是一个均值为0，方差为$\frac{2}{n}$的高斯分布。<br>缺点是：MSRA方法只考虑一个方向，无法使得正向反向传播时方差变化都很小。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><h3 id="损失函数、代价函数与目标函数"><a href="#损失函数、代价函数与目标函数" class="headerlink" title="损失函数、代价函数与目标函数"></a>损失函数、代价函数与目标函数</h3><p>损失函数(Loss Function)：是定义在单个样本上的，是指一个样本的误差。<br>代价函数(Cost Function)：是定义在整个训练集上，是所有样本误差的平均值，也就是所有损失函数值的平均。<br>目标函数(Object Function)：是指最终需要优化的函数，一般来说是代价函数+正则化项。</p>
<h3 id="常用的损失函数"><a href="#常用的损失函数" class="headerlink" title="常用的损失函数"></a>常用的损失函数</h3><p>（1）0-1损失函数(0-1 loss function)</p>
<script type="math/tex; mode=display">
L(y, f(x))=
\begin{cases}
1, &\text{y}\ne\text{f(x)}\\
0, &\text{y}=\text{f(x)}
\end{cases}</script><p>即，当预测错误时，损失函数为1，当预测正确时，损失函数值为0.该损失函数不考虑预测值与真实值之间的误差程度。<br>（2）平方损失函数（quadratic loss function）</p>
<script type="math/tex; mode=display">L(y,f(x))=(y-f(x))^2</script><p>是指预测值与实际值差的平方。<br>（3）绝对值损失函数（absolute loss function）</p>
<script type="math/tex; mode=display">L(y,f(x))=|y-f(x)|</script><p>该损失函数只是取了绝对值而不是求平方值，差距不会被平方放大。<br>（4）对数损失函数(logarithmic loss function)</p>
<script type="math/tex; mode=display">L(y, p(y|x))=-logp(y|x)</script><p>该损失函数用到了极大似然估计思想。P(Y|X)通俗的解释是：在当前模型的基础上，对于样本X，其预测值为Y，也就是预测正确的概率。由于概率之间同时满足需要使用乘法，为了将其转化为加法，我们将其取对数。最后由于是损失函数，所以预测正确的概率越高，其损失值应该越小，因此再加个符号取反。<br>（5）Hinge loss<br>Hinge loss一般分类算法中的损失函数，尤其是SVM，其定义为：</p>
<script type="math/tex; mode=display">L(w,b)=max(0, 1-yf(x))</script><p>其中$y=+1$或$y=-1$，$f(x)=wx+b$，当为SVM的线性核时。</p>
<h3 id="常用的代价函数"><a href="#常用的代价函数" class="headerlink" title="常用的代价函数"></a>常用的代价函数</h3><p>（1）均方误差(Mean Squared Error)</p>
<script type="math/tex; mode=display">MSE=\frac{1}{N}\sum_{i=1}^N(y^{(i)}-f(x^{(i)}))^2</script><p>均方误差是指参数估计值与真实值之差的平方的期望值，MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精度。（i表示第i个样本，N表示样本总数）。<br>通常用来做回归问题的代价函数。<br>（2）均方根误差</p>
<script type="math/tex; mode=display">RMSE=\sqrt{\frac{1}{N}\sum_{i=1}^N(y^{(i)}-f(x^{(i)}))^2}</script><p>均方根误差是均方误差的算术平方根，能够直观观测预测值与真实值的离散程度。通常用来作为回归算法的性能指标。<br>（3）平均绝对误差（Mean Absolute Error）</p>
<script type="math/tex; mode=display">MAE=\frac{1}{N}\sum_{i=1}^N|y^{(i)}-f(x^{(i)})|</script><p>平均绝对误差是绝对误差的平均值，平均绝对误差能更好地反映预测值误差的实际情况。通常用来作为回归算法的性能指标。<br>（4）交叉熵代价函数(Cross Entry)</p>
<script type="math/tex; mode=display">H(p,q)=-\frac{1}{N}\sum_{i=1}^Np(x^{(i)})log(x^{(-i)})</script><p>交叉熵是用来评估当前训练得到的概率分布于真实分布的差异情况，减少交叉熵损失就是在提高模型的预测准确率。其中p(x)是指真实分布的概率，q(x)是模型通过数据计算出来的概率估计。<br>对于二分类模型的交叉熵代价函数：</p>
<script type="math/tex; mode=display">L(w,b)=-\frac{1}{N}\sum_{i=1}^N(y^{(i)}logf(x^{(i)})+(1-y^{(i)})log(1-f(x^{(i)})))</script><p>其中f(x)可以是sigmoid函数或深度学习中的其他激活函数，而$y{(i)}\in 0,1$。<br>交叉熵通常用作分类问题的代价函数。<br><a href="https://zhuanlan.zhihu.com/p/37217242" target="_blank" rel="noopener">常用损失函数</a></p>
<h3 id="为什么分类问题用-cross-entropy，而回归问题用-MSE"><a href="#为什么分类问题用-cross-entropy，而回归问题用-MSE" class="headerlink" title="为什么分类问题用 cross entropy，而回归问题用 MSE?"></a>为什么分类问题用 cross entropy，而回归问题用 MSE?</h3><p><a href="https://blog.csdn.net/weixin_41888969/article/details/89450163" target="_blank" rel="noopener">优秀解答</a><br>当sigmoid函数和MSE一起使用时会出现梯度消失。原因如下：<br>1）MSE对参数w,b的偏导，其中预测值为a，真实值为y，则$z=wx+b$，$a=\sigma(z)$，$\sigma$是sigmoid函数，损失函数$J=(y-a)^2$。</p>
<script type="math/tex; mode=display">\frac{\partial J}{\partial w}=(a-y)\sigma(z)'x</script><script type="math/tex; mode=display">\frac{\partial J}{\partial b}=(a-y)\sigma(z)'</script><p>2）cross-entry对参数的偏导</p>
<script type="math/tex; mode=display">\frac{\partial J}{\partial w}=\frac{1}{n}\sum(a-y)x</script><script type="math/tex; mode=display">\frac{\partial J}{\partial b}=\frac{1}{n}\sum(a-y)</script><p>使用MSE时，w、b的梯度均与sigmoid函数对z的偏导有关系，而sigmoid函数的偏导在自变量非常大或者非常小时，偏导数的值接近于零，这将导致w、b的梯度将不会变化，也就是出现所谓的梯度消失现象。而使用cross-entropy时，w、b的梯度就不会出现上述的情况。<br>当MSE和交叉熵同时应用到多分类场景下时，（标签的值为1时表示属于此分类，标签值为0时表示不属于此分类），MSE对于每一个输出的结果都非常看重，而交叉熵只对正确分类的结果看重。交叉熵的损失函数只和分类正确的预测结果有关系，而MSE的损失函数还和错误的分类有关系，该分类函数除了让正确的分类尽量变大，还会让错误的分类变得平均，但实际在分类问题中这个调整是没有必要的。但是对于回归问题来说，这样的考虑就显得很重要了。所以，回归问题熵使用交叉熵并不合适。</p>
<h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p><a href="https://blog.csdn.net/e01528/article/details/89313518" target="_blank" rel="noopener">BN归纳</a><br>Batch Normalization就是在训练过程中使得每一层神经网络的输入保持相同分布的。BN的基本思想相当直观：随着网络深度加深或者在训练过程中，神经元的输入值分布逐渐发生偏移或变动，使得整体分布逐渐往非线性函数的取值区域的上下限两端靠近，所以这导致反向传播时低层神经网络的梯度消失，这是训练深层神经网络收敛越来越慢的本质原因。而BN就是通过一定的规范化手段，把该层任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，其实就是把越来越偏的分布强制拉回到标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就是导致损失函数较大的变化，使得梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。<br>如果都通过BN，那么不就跟把非线性函数替换成线性函数效果相同吗？这意味着什么？我们知道，如果是多层的线性函数变换其实这个深层网络就没有意义，因为多层线性网络跟一层线性网络是等价的。这意味着网络的表达能力又下降了。所以BN为了保证非线性的获得，对变换后的满足均值为0方差为1的$x$又进行了scale加上shift操作($y=scale*x+shift$)，每个神经元增加了两个参数scale和shift参数，这两个参数是通过训练学习到的，意思是通过scale和shift把输入值从标准正太分布左移或右移一点并拉伸或缩短一点，每个实例的挪动情况不一样，来找到一个线性和非线性的较好平衡点，使得既能享受非线性的较强表达能力的好处，又避免太靠近非线性区两头使得网络的收敛速度太慢。<br>BatchNorm在网络中的作用：BN层添加在激活函数前，对输入激活函数的输入进行归一化，这样解决了输入数据发生偏移和增大的影响。</p>
<h3 id="BatchNorm的优缺点"><a href="#BatchNorm的优缺点" class="headerlink" title="BatchNorm的优缺点"></a>BatchNorm的优缺点</h3><p>优点：1）极大提升了训练速度，使得收敛过程大大加快；2）还能增加分类效果，一种解释是这类似于Dropout的一种防止过拟合的正则化表达方式，所以不用Dropout也能达到相当的效果；3）调参过程也简单了，对于初始化要求没那么高，可以使用大的学习率。<br>缺点：1）高度依赖于batch size的大小，它要求batch size都比较大，因此不适合batch size较小的场景。2）不适合RNN网络，因为不同样本的长度不同，RNN的深度是不固定的。同一个batch中多个样本会产生不同深度的RNN，因此很难对同一层的样本进行归一化。</p>
<h3 id="BN的计算流程"><a href="#BN的计算流程" class="headerlink" title="BN的计算流程"></a>BN的计算流程</h3><p>首先，对(B,W,H)通道计算样本的均值和方差，将样本数据进行标准化处理，然后引入$\gamma$和$\beta$两个参数进行平移和缩放处理，让网络可以学习恢复出原始网络所要学习的特征分布。</p>
<h3 id="BN的训练和测试"><a href="#BN的训练和测试" class="headerlink" title="BN的训练和测试"></a>BN的训练和测试</h3><p>对于BN，在训练时，是对每一批的训练数据进行归一化，也即用每一批数据的均值和方差。<br>而在测试时，比如进行一个样本的预测，就并没有batch的概念，因此，这个时候用的均值和方差是全量训练数据的均值和方差，这个可以通过移动平均法求得。<br>BN训练时为什么不用全量训练集的均值和方差呢？<br>因为用全量训练集的均值和方差容易过拟合，对于BN，其实就是对每一批数据进行归一化到一个相同的分布，而每一批数据的均值和方差会有一定的差别，而不是用固定的值，这个差别实际上能够增加模型的鲁棒性，也会在一定程度上减少过拟合。</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>Dropout指的是让这些神经元失效或者状态抑制，可以防止参数过分依赖训练数据，增加参数对数据集的泛化能力。<br>在训练阶段，以概率p主动临时性地忽略掉部分隐藏节点。这一操作的好处在于，在较大程度上减小了网络的大小（解决了耗时的问题），而且多个这样的抑制不同隐藏神经元的网络组合可以解决过拟合问题。<br>在预测阶段，将参与学习的节点和那些被隐藏的节点以一定的概率p加权求和，综合计算得到网络的输出。对于这样的类似融合不同模型的学习过程，有学者认为，Drop out可视为一种集成学习。</p>
<h3 id="Dropout-在训练和测试时都需要嘛？"><a href="#Dropout-在训练和测试时都需要嘛？" class="headerlink" title="Dropout 在训练和测试时都需要嘛？"></a>Dropout 在训练和测试时都需要嘛？</h3><p>Dropout 在训练时采用，是为了减少神经元对部分上层神经元的依赖，类似将多个不同网络结构的模型集成起来，减少过拟合的风险。<br>而在测试时，应该用整个训练好的模型，因此不需要dropout。</p>
<h3 id="Dropout-如何平衡训练和测试时的差异呢？"><a href="#Dropout-如何平衡训练和测试时的差异呢？" class="headerlink" title="Dropout 如何平衡训练和测试时的差异呢？"></a>Dropout 如何平衡训练和测试时的差异呢？</h3><p>Dropout ，在训练时以一定的概率使神经元失活，实际上就是让对应神经元的输出为0<br>假设失活概率为 p ，就是这一层中的每个神经元都有p的概率失活，如下图的三层网络结构中，如果失活概率为0.5，则平均每一次训练有3个神经元失活，所以输出层每个神经元只有3个输入，而实际测试时是不会有dropout的，输出层每个神经元都有6个输入，这样在训练和测试时，输出层每个神经元的输入和的期望会有量级上的差异。<br>因此在训练时还要对第二层的输出数据除以（1-p）之后再传给输出层神经元，作为神经元失活的补偿，以使得在训练时和测试时每一层输入有大致相同的期望。</p>
<h2 id="深度学习几种归一化（BN、LN、IN、GN）"><a href="#深度学习几种归一化（BN、LN、IN、GN）" class="headerlink" title="深度学习几种归一化（BN、LN、IN、GN）"></a>深度学习几种归一化（BN、LN、IN、GN）</h2><p> BN、LN、IN和GN这四个归一化的计算流程几乎是一样的，可以分为四步：1）计算出均值；2）计算出方差；3）归一化处理到均值为0，方差为1；4）变化重构，恢复出这一层网络所要学到的分布。<br> 我们先用一个示意图来形象的表现BN、LN、IN和GN的区别，在输入图片的维度为（NCHW）中，HW是被合成一个维度，这个是方便画出示意图，C和N各占一个维度。<br> <img src="/images/归一化区别.png" alt="BN,LN,IN,GN的区别"><br> Batch Normalization：<br>1)BN的计算就是把每个通道的NHW单独拿出来归一化处理<br>2)针对每个channel我们都有一组γ,β，所以可学习的参数为2*C<br>3)当batch size越小，BN的表现效果也越不好，因为计算过程中所得到的均值和方差不能代表全局。<br>Layer Normalizaiton：<br>1)LN的计算就是把每个CHW单独拿出来归一化处理，不受batchsize 的影响<br>2)常用在RNN网络，但如果输入的特征区别很大，那么就不建议使用它做归一化处理<br>Instance Normalization:<br>1)IN的计算就是把每个HW单独拿出来归一化处理，不受通道和batchsize 的影响。<br>2)常用在风格化迁移，IN的效果优于BN，因为在这类生成式方法中，每张图片自己的风格比较独立，不应该与batch中其他图片产生太大联系。但如果特征图可以用到通道之间的相关性，那么就不建议使用它做归一化处理。<br>Group Normalization:<br>1)GN的计算就是把先把通道C分成G组，然后把每个gHW单独拿出来归一化处理，最后把G组归一化之后的数据合并成CHW。<br>2)GN介于LN和IN之间，当然可以说LN和IN就是GN的特列，比如G的大小为1或者为C。</p>
<h2 id="解决模型欠拟合与过拟合常用方法"><a href="#解决模型欠拟合与过拟合常用方法" class="headerlink" title="解决模型欠拟合与过拟合常用方法"></a>解决模型欠拟合与过拟合常用方法</h2><h3 id="欠拟合"><a href="#欠拟合" class="headerlink" title="欠拟合"></a>欠拟合</h3><p>欠拟合：欠拟合的原因大多是模型不够复杂、拟合函数的能力不够。<br>因此，从数据层面考虑，可以增加新特征，例如：组合、泛化、相关性、高次特征等；从模型层面考虑，可以增加模型的复杂度，例如SVM的核函数、DNN等更复杂模型，去掉正则化或减少正则化参数，加深训练轮数等。</p>
<h3 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h3><p>过拟合：成因是给定的数据集相对过于简单，使得模型在拟合函数时过分考虑了噪声等不必要的数据间关联。<br>解决方法：<br>1）数据扩增：人为增加数据量，可以用重采样、上采样、增加随机噪声、GAN、图像数据的空间变换（平移旋转镜像）、尺度变换（缩放裁剪）、颜色变换、改变分辨率、对比度、亮度等。<br>2）针对神经网络，采用dropout的方法：dropout的思想是当一组参数经过某一层神经元的时候，去掉这一层上的部分神经元，让参数只经过一部分神经元进行计算。这里的去掉不是真正意义上的去除，只是让参数不经过一部分神经元计算，从而减少了神经网络的规模（深度）。<br>3）提前停止训练<br>也就是减少训练的迭代次数。从上面的误差率曲线图，理论上可以找到有个训练程度，此时验证集误差率最低，视为拟合效果最好的点。<br>4）正则化<br>在所定义的损失函数后面加入一项永不为0的部分，那么经过不断优化损失函数还是会存在的。<br>L0正则化：损失函数后面加入L0范数，也就是权重向量中非零参数的个数。特点是可以实现参数的稀疏性，使尽可能多的参数都为0；缺点是在优化时是NP难问题，很难优化。<br>L1正则化：在损失函数后面加入权重向量的L1范数。L1范数是L0范数的最优凸近似，比L0范数容易优化，也可以很好地实现参数稀疏性。<br>L2正则化：在损失函数后面加入参数L2范数的平方项。与L0、L1不同的是，L2很难使某些参数达到0，它只能是参数接近0。<br>5）针对DNN，采用batch normalization：即BN，既能提高泛化能力，又大大提高训练速度，现被广泛应用于DNN的激活层之前。主要优势：减少了梯度对参数大小和初始值的依赖，将参数值（特征）缩放在[0,1]区间（若针对Relu还限制了输出的范围），这样反向传播时梯度控制在1左右，使得网络在较高的学习率之下也不易发生梯度爆炸或弥散（也防止了在使用sigmoid作为激活函数时训练容易陷入梯度极小饱和或极大的极端情况）。</p>
<h2 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h2><h3 id="one-vs-rest"><a href="#one-vs-rest" class="headerlink" title="one vs rest"></a>one vs rest</h3><p>由于概率函数$h_{\theta}(x)$所表示的是样本标记为某一类型的概率，但可以将一对一（二分类）扩展为一对多(one vs rest)：<br>1）将类型$class_1$看作正样本，其他类型全部看作负样本，然后我们就可以得到样本类型为该类型的概率$p_1$；<br>2）然后再讲另外类型$class_2$看作正样本，其他类型全部看作负样本，同理得到$p_2$；<br>3）以此循环，我们可以得到该待预测样本的标记类型分别为类型$class_i$时的概率$p_i$，最后我们取$p_i$中最大的那个概率对应的样本标记类型为我们的待预测样本类型。</p>
<h3 id="softmax函数"><a href="#softmax函数" class="headerlink" title="softmax函数"></a>softmax函数</h3><p>使用softmax函数构造模型解决多分类问题，与logistic回归不同的是，softmax回归分类模型会有多个的输出，且输出个数与类别个数相等，输出为样本$X$的各个类别的概率，最后对样本进行预测的类型为概率最高的那个类别。<br><img src="/images/softmax.jpg" alt="softmax反向传播推导"></p>
<h2 id="反向传播原理"><a href="#反向传播原理" class="headerlink" title="反向传播原理"></a>反向传播原理</h2><p>反向传播过程：将训练集的数据输入到神经网络的输入层，经过隐藏层最终到达输出层输出结果，这是神经网络的前向传播过程；由于神经网络的输出结果和实际结果存在误差，计算估计值和实际值之间的误差，并将误差从输出层向隐藏层反向传播，直至传播至输入层；在反向传播过程中，根据误差调整各种参数的值，不断迭代上述的过程，直至收敛。<br><a href="https://blog.csdn.net/u014313009/article/details/51039334?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">推导过程</a></p>
<h3 id="什么是梯度消失和梯度爆炸"><a href="#什么是梯度消失和梯度爆炸" class="headerlink" title="什么是梯度消失和梯度爆炸"></a>什么是梯度消失和梯度爆炸</h3><p>在反向传播过程中需要对激活函数进行求导，如果导数大于1，那么随着网络层数的增加梯度更新将会朝着指数爆炸的方式增加这就是梯度爆炸。同样如果导数小于1，那么随着网络层数的增加梯度更新信息会朝着指数衰减的方式减少这就是梯度消失。因此，梯度消失、爆炸，其根本原因在于反向传播训练法则，属于先天不足。</p>
<h3 id="梯度消失的原因"><a href="#梯度消失的原因" class="headerlink" title="梯度消失的原因"></a>梯度消失的原因</h3><p>1）在反向传播过程中梯度呈指数衰减，随着网络层数的加深，梯度减小为0；2）在反向传播过程中，神经元的输入值位于激活函数的非线性区域的上下限两端，使得梯度消失。<br>而梯度爆炸一般出现在深层网络和权值初始化太大的情况下。</p>
<h3 id="梯度消失解决方案"><a href="#梯度消失解决方案" class="headerlink" title="梯度消失解决方案"></a>梯度消失解决方案</h3><p>1）预训练加微调<br>2）添加正则项<br>3）使用relu、leakrelu、elu等激活函数<br>4）使用batch normalization<br>5）使用残差结构<br>6）使用LSTM</p>
<h2 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h2><h3 id="召回率、精确率、准确率"><a href="#召回率、精确率、准确率" class="headerlink" title="召回率、精确率、准确率"></a>召回率、精确率、准确率</h3><p>精确率是针对预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能，一种是把正类预测为正类（TP），另一种就是把负类预测为正类（FP），也就是：</p>
<script type="math/tex; mode=display">P=\frac{TP}{TP+FP}</script><p>而召回率是针对原来的样本而言，它表示的是样本中的正例有多少被预测正确，也有两种可能，一种是把原来的正类预测成正类（TP），另一种就是把原来的正类预测为负类（FN）。</p>
<script type="math/tex; mode=display">R=\frac{TP}{TP+FN}</script><p>准确率就是所有样本中预测出正例的概率。</p>
<script type="math/tex; mode=display">A=\frac{TP+TN}{TP+FN+FP+TN}</script><h3 id="Accuracy的局限性"><a href="#Accuracy的局限性" class="headerlink" title="Accuracy的局限性"></a>Accuracy的局限性</h3><p>当正负样本极度不均衡时存在问题！比如，正样本有99%时，分类器只要将所有样本划分为正样本就可以达到99%的准确率。但显然这个分类器是存在问题的。当正负样本不均衡时，常用的评价指标为ROC曲线和PR曲线。</p>
<h3 id="ROC曲线和PR曲线"><a href="#ROC曲线和PR曲线" class="headerlink" title="ROC曲线和PR曲线"></a>ROC曲线和PR曲线</h3><p>定义真正例率（True Positive Rate）为：$TPR=\frac{TP}{TP+FN}$，其刻画真正的正类中，有多少样本预测为正类的概率。定义假正例率（False Positive Rate）为：$FPR=\frac{FP}{TN+FP}$，其刻画了真正的负类中，有多少样本被预测为正类的概率。以真正例率为纵轴、假正例率为横轴作图，就得到ROC曲线。<br><img src="/images/ROC.png" alt="ROC曲线"><br>具体方法是在不同的分类阈值 (threshold) 设定下分别以TPR和FPR为纵、横轴作图。曲线越靠近左上角，意味着越多的正例优先于负例，模型的整体表现也就越好。<br>优点:1）兼顾正例和负例的权衡。因为TPR聚焦于正例，FPR聚焦于负例，使其成为一个比较均衡的评估方法。2）ROC曲线选用的两个指标， TPR和FPR，都不依赖于具体的类别分布。<br>缺点:1）ROC曲线的优点是不会随着类别分布的改变而改变，但这在某种程度上也是其缺点。因为负例N增加了很多，而曲线却没变，这等于产生了大量FP。像信息检索中如果主要关心正例的预测准确性的话，这就不可接受了。<br>2）在类别不平衡的背景下，负例的数目众多致使FPR的增长不明显，导致ROC曲线呈现一个过分乐观的效果估计。ROC曲线的横轴采用FPR，根据公式 ，当负例N的数量远超正例P时，FP的大幅增长只能换来FPR的微小改变。结果是虽然大量负例被错判成正例，在ROC曲线上却无法直观地看出来。（当然也可以只分析ROC曲线左边一小段）<br>PR曲线以查准率（精确率P）为纵轴，查全率（召回率R）为横轴作图，就得到查准率-查全率曲线，简称P-R曲线。<br>PR曲线与ROC曲线的相同点是都采用了TPR (Recall)，都可以用AUC来衡量分类器的效果。不同点是ROC曲线使用了FPR，而PR曲线使用了Precision，因此PR曲线的两个指标都聚焦于正例。类别不平衡问题中由于主要关心正例，所以在此情况下PR曲线被广泛认为优于ROC曲线。<br><img src="/images/PR.png" alt="PR曲线"><br>使用场景：<br>ROC曲线由于兼顾正例与负例，所以适用于评估分类器的整体性能，相比而言PR曲线完全聚焦于正例。<br>如果有多份数据且存在不同的类别分布，比如信用卡欺诈问题中每个月正例和负例的比例可能都不相同，这时候如果只想单纯地比较分类器的性能且剔除类别分布改变的影响，则ROC曲线比较适合，因为类别分布改变可能使得PR曲线发生变化时好时坏，这种时候难以进行模型比较；反之，如果想测试不同类别分布下对分类器的性能的影响，则PR曲线比较适合。<br>如果想要评估在相同的类别分布下正例的预测情况，则宜选PR曲线。<br>类别不平衡问题中，ROC曲线通常会给出一个乐观的效果估计，所以大部分时候还是PR曲线更好。<br>最后可以根据具体的应用，在曲线上找到最优的点，得到相对应的precision，recall，f1 score等指标，去调整模型的阈值，从而得到一个符合具体应用的模型。</p>
<h3 id="AUC曲线"><a href="#AUC曲线" class="headerlink" title="AUC曲线"></a>AUC曲线</h3><p>AUC（Area Under the Curve）可解读为：从所有正例中随机选取一个样本A，再从所有负例中随机选取一个样本B，分类器将A判为正例的概率比将B判为正例的概率大的可能性。<br>我们最直观的有两种计算AUC的方法：1）绘制ROC曲线，ROC曲线下面的面积就是AUC的值。2）假设总共有（m+n）个样本，其中正样本m个，负样本n个，总共有mn个样本对，计数，正样本预测为正样本的概率值大于负样本预测为正样本的概率值记为1，累加计数，然后除以（mn）就是AUC的值。<br>AUC指标有什么特点？放缩结果对AUC是否有影响？<br>AUC（Area under Curve）指的是ROC曲线下的面积，介于0和1之间。AUC作为数值可以直观地评价分类器的好坏，值越大越好。它的统计意义是从所有正样本随机抽取一个正样本，从所有负样本随机抽取一个负样本，当前score使得正样本排在负样本前面的概率。放缩结果对AUC没有影响。</p>
<h2 id="训练集、验证集和测试集"><a href="#训练集、验证集和测试集" class="headerlink" title="训练集、验证集和测试集"></a>训练集、验证集和测试集</h2><p>1）通常80%为训练集，20%为测试集。<br>2）当数据量较小时（万级别及以下）的时候将训练集、验证集以及测试集划分为6：2：2；若是数据很大，可以将训练集、验证集、测试集比例调整为98：1：1。<br>3）当数据量很小时，可以采用K折交叉验证。K折交叉验证将数据集A随机分为k个子集，每个子集均做一次测试集，其余的作为训练集。交叉验证重复k次，每次选择一个子集作为测试集，并将k次的平均交叉验证识别正确率作为结果。<br>4）划分数据集时可采用随机划分法（当样本比较均衡时），分层采样法（当样本分布极度不均衡时）。分层抽样是指在抽样时，将总体分成互不相交的层，然后按照一定的比例，从各层独立地抽取一定数量的个体，将各层取出的个体合在一起作为样本的方法。</p>
<h2 id="偏差和方差"><a href="#偏差和方差" class="headerlink" title="偏差和方差"></a>偏差和方差</h2><p>偏差：描述预测值的期望与真实值之间的差别，偏差越大说明模型的预测结果越差，刻画了学习算法本身的拟合能力。<br>方差：描述预测值的变化范围，方差越大说明模型的预测越不稳定，刻画了数据扰动造成的影响。<br>高方差过拟合，高偏差欠拟合。常用交叉验证来权衡模型的方差和偏差。也可以比较均方误差$MSE=E[(\hat{\theta_m}-\theta)^2]=Bias(\hat{\theta_m})^2+Var(\hat{\theta_m})^2$<br>给定学习任务：<br>1)在训练不足时模型的拟合能力不够强，训练数据的扰动不足以使模型产生显著变化，此时偏差主导了泛化误差。<br>2)随着训练程度的加深模型的拟合能力逐渐增强，训练数据发生的扰动逐渐被模型学习到，方差逐渐主导了泛化误差。<br>3)在训练充分后模型的拟合能力非常强，训练数据发生的轻微扰动都会导致模型发生显著变化。若训练数据自身的、非全局的特性被模型学到了，则将发生过拟合。</p>
<h2 id="深度模型参数调整的一般方法论"><a href="#深度模型参数调整的一般方法论" class="headerlink" title="深度模型参数调整的一般方法论"></a>深度模型参数调整的一般方法论</h2><p>1）学习率：遵循小-&gt;大-&gt;小原则<br>2）初始化：选择合适的初始化方式，有预训练模型更好<br>3）优化器选择：adam比较快，sgd较慢<br>4）loss：回归问题选L2 loss，分类问题选交叉熵<br>5）从小数据大模型入手，先过拟合，再增加数据并根据需要调整模型复杂度。<br>6）可视化</p>
<h2 id="pytorch与tensorflow的区别"><a href="#pytorch与tensorflow的区别" class="headerlink" title="pytorch与tensorflow的区别"></a>pytorch与tensorflow的区别</h2><p>创建和运行计算图可能是两个框架最不同的地方。在PyTorch中，图结构是动态的，这意味着图在运行时构建。而在TensorFlow中，图结构是静态的，这意味着图先被“编译”然后再运行。<br>动态图的还有一个好处就是比较容易调试, 在 PyTorch 中, 代码报错的地方, 往往就是代码错写的地方, 而静态图需要先根据代码生成 Graph 对象, 然后在 session.run() 时报错, 但是这种报错几乎很难直接找到代码中对应的出错段落。<br><a href="https://blog.csdn.net/zzlyw/article/details/78768991" target="_blank" rel="noopener">pytorch基础知识</a></p>
<h1 id="卷积神经网络模型"><a href="#卷积神经网络模型" class="headerlink" title="卷积神经网络模型"></a>卷积神经网络模型</h1><h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>输入图像的维数通常很高，例如，1000x1000大小的彩色图像对应于三百万维特征。因此，继续沿用多层感知机中全连接层会导致庞大的参数量。大参数量需要繁重的计算，而更重要的是大参数量会有更高的过拟合风险。卷积是局部连接、共享参数的全连接层。这两个特征使参数量大大降低。卷积层中的权值通常被称为滤波器(filter)或卷积核(convolution kernel)。<br><strong>局部连接</strong>：所谓局部连接，就是卷积层的节点仅仅和前一层的部分节点相连接，只用来学习局部特征，而全连接层中，每个输出通过权值(weight)和所有输入相连。在计算机视觉中，图像中的某一块区域中，像素之间的相关性与像素之间的距离同样相关，距离较近的像素之间相关性强，距离较远则相关性比较弱，所以局部相关性理论同样适用于计算机视觉的图像处理领域。在卷积层中，每个输出神经元在通道方向保持全连接，在空间方向上只和上一层一部分输入神经元相连。局部感知采用部分神经元接收图像信息，再通过综合全部的图像信息达到增强图像信息的目的。这种局部连接的方式大大减少了参数数量，加快了学习速率，同时也在一定程度上减少过拟合的可能。<br><strong>共享参数</strong>：如果一组权值可以在图像中某个区域提取出有效的表示，那么它们也能在图像中的另外区域提取出有效的表示。也就是说，如果一个模式(pattern)出现在图像中的某个区域，那么它们也可以出现在图像中的其他任何区域。因此，卷积层不同空间位置的神经元共享权值，用于发现图像中不同空间位置的模式。权值共享其实就是整张图片在使用同一个卷积核内的参数提取特征，但是不同的卷积核提取的是不同特征，因此不同卷积核间的神经元权值是不共享的。卷积层在空间方向共享参数，而循环神经网络在时间方向共享参数。<br><strong>描述卷积的四个量</strong>：一个卷积层的配置由如下四个量确定。1）卷积核个数。使用一个卷积核进行卷积可以得到一个二维的特征图(feature map)。使用多个卷积核进行卷积，可以得到不同特征的feature map。2）感受野（receptive field）F，即卷积核的大小。3）零填充(zero-padding)P，随着卷积的进行，图像的大小将缩小，图像边缘的信息将逐渐丢失，因此在卷积前，我们在图像上下左右填补一些0，使得我们可以控制输出特征图的大小。4）步长(stride)S，卷积核在输入图像上每移动S个位置计算一个输出神经元。<br>假设输入图片大小为$I\times I$，卷积核大小为$K\times K$，步长为S，填充的像素为P，则卷积层输出的特征图大小为：</p>
<script type="math/tex; mode=display">O=(I-K+2P)/S+1</script><h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>池化层根据特征图上的局部统计信息进行下采样，在保留有用信息的同时减少特征图的大小。和卷积层不同，池化层不包含需要学习的参数，最大池化层(max-pooling)在一个局部区域选最大值输出，而平均池化(average pooling)计算一个区域的均值作为输出。<br><img src="/images/pooling.png" alt="池化层"><br><strong>池化层的作用</strong>：1）增加特征平移不变性，池化可以提高网络对微小位移的容忍能力。2）减小特征图大小，池化层对空间局部区域进行下采样，使下一层需要的参数量和计算量减少，并降低过拟合风险。3）最大池化可以带来非线性，这是目前最大池化更常使用的原因。<br>平均池化和最大池化的区别：最大池化保留了纹理特征，平均池化保留整体的数据特征。最大池化提取边缘等“最重要”的特征，而平均池化提取的特征更加smoothly。</p>
<h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>全连接层（fully connected layers，FC）在整个卷积神经网络中起到“分类器”的作用。如果说卷积层、池化层和激活函数层等操作是将原始数据映射到隐层特征空间的话，全连接层则起到将学到的“分布式特征表示”映射到样本标记空间的作用。在实际使用中，全连接层可由卷积操作实现：对前层是全连接的全连接层可以转化为卷积核为1×1的卷积；而前层是卷积层的全连接层可以转化为卷积核为hxw的全局卷积，h和w分别为前层卷积结果的高和宽</p>
<h3 id="分组卷积"><a href="#分组卷积" class="headerlink" title="分组卷积"></a>分组卷积</h3><p>分组卷积 Group convolution ：将多个卷积核拆分为分组，每个分组单独执行一系列运算之后，最终在全连接层再拼接在一起。<br>通常每个分组会在单独的GPU 中训练，从而利用多GPU 来训练。<br>分组卷积的重点不在于卷积，而在于分组：在执行卷积之后，将输出的feature map 执行分组。然后在每个组的数据会在各个GPU 上单独训练。<br><img src="/images/cnn_group.png" alt="分组卷积"><br>分组卷积在网络的全连接层才进行融合，这使得每个GPU 中只能看到部分通道的数据，这降低了模型的泛化能力。如果每次分组卷积之后，立即融合卷积的结果则可以解决这个问题。<br>分组卷积降低了模型的参数数量以及计算量。<br>假设输入feature map具有$C_I$的输入通道、宽/高分别为$W_I,H_I$，假设卷积核的宽/高分别为$W_K,H_K$，有$C_O$个卷积核。则：<br>参数数量为：$W_K\times H_K\times C_I\times C_O$<br>计算量为：$W_K\times H_K\times C_I\times W_O\times H_O\times C_O$。<br>假设采用分组卷积，将输入通道分成G组，则分组后：<br>参数数量为：$W_K\times H_K\times \frac{C_I}{G}\times \frac{C_O}{G}$<br>计算量为：$W_K\times H_K\times \frac{C_I}{G}\times W_O\times H_O\times \frac{C_O}{G}$<br>因此分组卷积的参数数量、计算量均为标准卷积计算的$\frac{1}{G}$。</p>
<h3 id="小卷积核替代"><a href="#小卷积核替代" class="headerlink" title="小卷积核替代"></a>小卷积核替代</h3><p>在AlexNet 中用到了一些非常大的卷积核，如11x11、5x5 等尺寸的卷积核。卷积核的尺寸越大，则看到的图片信息越多，因此获得的特征会越好。但是卷积核的尺寸越大，模型的参数数量会爆涨，不利于模型的深度的增加，计算量和存储量也大幅上升。卷积核的尺寸越小，模型的参数数量越少，模型可以越深。但是卷积核的尺寸太小，则只能看到图片的一个非常小的局部区域，获得的特征越差。<br>解决方案是：用多个小卷积层的堆叠来代替较大的卷积核。<br>假设大卷积核的宽度是$k$，则每经过一层，输出的宽度减少了$k-1$。假设希望通过$n$个宽度为$k’$的小卷积核来代替，则为了保持输出的大小一致，需要满足：</p>
<script type="math/tex; mode=display">k-1=n(k'-1)</script><p>如：用 2 个 3x3 的卷积核来代替1个 5x5 的卷积核。假设输入通道数为$C_I$，输出通道数为$C_O$，则5x5 卷积核的参数数量为$C_O\times C_I\times 5\times 5$；而 2个 3x3 卷积核的参数数量为$2\times C_O\times C_I\times 3\times 3$，是前者的 72% 。<br>用多个小卷积层的堆叠代替一个大卷积层的优点：<br>1）可以实现与大卷积层相同的感受野。<br>2）具有更大的非线性，网络表达能力更强。虽然卷积是线性的，但是卷积层之后往往跟随一个ReLU 激活函数。这使得多个小卷积层的堆叠注入了更大的非线性。<br>3）具有更少的参数数量。<br>小卷积层堆叠的缺点是：加深了网络的深度，容易引发梯度消失等问题，从而使得网络的训练难度加大。<br>通常选择使用3x3 卷积核的堆叠：<br>1）1x1 的卷积核：它无法提升感受野，因此多个1x1 卷基层的堆叠无法实现大卷积层的感受野。<br>2）2x2 的卷积核：如果希望输入的feature map 尺寸和输出的feature map 尺寸不变，则需要对输入执行非对称的padding。此时有四种padding 方式，填充方式的选择又成了一个问题。<br>3）3x3 的卷积核：可以提升感受野，对称性填充（不需要考虑填充方式），且尺寸足够小。</p>
<h3 id="多尺度卷积核"><a href="#多尺度卷积核" class="headerlink" title="多尺度卷积核"></a>多尺度卷积核</h3><p>图像中目标对象的大小可能差别很大。由于信息区域的巨大差异，为卷积操作选择合适的卷积核尺寸就非常困难。信息分布更具有全局性的图像中，更倾向于使用较大的卷积核。信息分布更具有局部性的图像中，更倾向于使用较小的卷积核。<br>一个解决方案是：分别使用多个不同尺寸的卷积核从而获得不同尺度的特征，然后将这些特征拼接起来。通过多种尺度的卷积核，无论感兴趣的信息区域尺寸多大，总有一种尺度的卷积核与之匹配。这样总可以提取到合适的特征。<br>多尺寸卷积核存在一个严重的问题：参数数量比单尺寸卷积核要多很多，这就使得计算量和存储量都大幅增长。<br><img src="/images/cnn_multi_kernel.png" alt="多尺度卷积"></p>
<h3 id="1x1卷积核"><a href="#1x1卷积核" class="headerlink" title="1x1卷积核"></a>1x1卷积核</h3><p>1x1 卷积并不是复制输入，它会进行跨通道的卷积。它有三个作用：<br>1）实现跨通道的信息整合。<br>2）进行通道数的升维和降维。<br>3）在不损失分辨率的前提下（即：feature map 尺寸不变），大幅增加非线性。事实上1x1 卷积本身是通道的线性组合，但是通常会在1x1卷积之后跟随一个ReLU 激活函数。<br>在前文中，输入feature map 先经过1x1 卷积的压缩，这会导致该段信息容量的下降；然后经过常规卷积，此段信息容量不变；最后经过1x1 卷积的膨胀，恢复了信息容量。整体而言模型的信息容量很像一个bottleneck，因此1x1 卷积层也被称作瓶颈层。</p>
<h3 id="DepthWise卷积"><a href="#DepthWise卷积" class="headerlink" title="DepthWise卷积"></a>DepthWise卷积</h3><p>标准的卷积会考虑所有的输入通道，而DepthWise 卷积会针对每一个输入通道进行卷积操作，然后接一个1x1 的跨通道卷积操作。<br><img src="/images/cnn_depthwise.png" alt="Depthwise卷积"><br>DepthWise 卷积与分组卷积的区别在于：<br>1）分组卷积是一种通道分组的方式，它改变的是对输入的feature map 处理的方式。Depthwise 卷积是一种卷积的方式，它改变的是卷积的形式。<br>2）Depthwise 分组卷积结合了两者：首先沿着通道进行分组，然后每个分组执行DepthWise 卷积。<br>假设使用标准卷积，输入通道的数量为$C_I$，输出通道的数量为$C_O$，卷积核的尺寸为$W_K\times W_K$。则需要的参数数量为$C_I\times W_K\times H_K\times C_O$。<br>使用Depthwise卷积时，图像的每个通道先通过一个$W_K\times H_K$的depthwise卷积层，再经过一个1x1、输出为$C_O$的卷积层。<br>参数量为：</p>
<script type="math/tex; mode=display">C_I\times W_K\times H_K+C_I\times 1\times 1\times C_O=W_KH_KC_I+C_IC_O</script><p>其参数数量是标准卷积的$\frac{1}{C_O}+\frac{1}{W_KH_K}$。因此depthwise 卷积的参数数量远远小于标准卷积。</p>
<h2 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h2><p>给定一张图像，图像分类任务旨在判断该图像所属类别。</p>
<h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><p>LeCun等将BP算法应用到多层神经网络中，提出了LeNet5模型，并将其用于手写数字识别，卷积神经网络才算正式提出。<br><img src="/images/LeNet5.png" alt="LeNet5网络模型"><br><img src="/images/LeNet5参数.png" alt="LeNet5网络模型参数"><br>网络输入32*32的手写字体图片，这些手写字体包含0~9数字，也就是相当于10个类别的图片；输出：分类结果在0~9之间。LeNet的网络结构十分简单且单一，卷积层C1、C3和C5除了输出维数外采用的是相同的参数，池化层S2和S4采用的也是相同的参数。</p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>2012年Krizhevsky使用卷积神经网络在ILSRC 2012图像分类大赛上夺冠，提出了AlexNet模型。AlexNet网络的提出对于卷积神经网络具有里程碑式的意义，相较于LeNet5的改进有以下几点：<br>1）数据增强：水平翻转、随机裁剪（平移变换）、颜色光照变换<br>2）Dropout:Dropout方法和数据增强一样，都是防止过拟合。dropout能按照一定的概率将神经元从网络中丢弃，dropout能在一定程度上防止过拟合，并且加快网络的训练速度。<br>3）ReLU激活函数：ReLU具有一些优良的特性，在为网络引入非线性的同时，也能引入稀疏性。稀疏性可以选择性激活和分布式激活神经元，能学习到相对稀疏的特征，起到自动化解离的效果。此外，ReLU的导数曲线在输入大于0时，函数的导数为1，这种特性能保证在其输入大于0时梯度不衰减，从而避免或抑制网络训练时梯度消失现象，网络模型的收敛速度会相对稳定。4）Local Response Normalization:局部响应归一化，简称LRN，实际就是利用临近的数据做归一化。5）Overlapping Pooling：即Pooling的步长比Pooling Kernel对应边要小。6）多GPU并行：极大加快网络训练。<br><img src="/images/AlexNet.png" alt="AlexNet网络模型"><br><img src="/images/AlexNet.png" alt="AlexNet网络模型参数"></p>
<h3 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h3><p>VGGNet是由牛津大学计算机视觉组合Google DeepMind项目的研究员共同研发的卷积神经网络模型，包含VGG16和VGG19两种模型。<br><img src="/images/VGG16.png" alt="VGG16网络模型"><br>从网络模型中可以看出，VGG16相比于AlexNet类的模型具有较深的深度，通过反复堆叠$3\times 3$的卷积层和$2\times 2$的池化层，VGG16构建了较深层次的网络结构。与AlexNet主要有以下不同：<br>1）Vgg16有16层网络，AlexNet只有8层；<br>2）在训练和测试时使用了多尺度做数据增强。</p>
<h3 id="GoogleNet-22层"><a href="#GoogleNet-22层" class="headerlink" title="GoogleNet(22层)"></a>GoogleNet(22层)</h3><p>GoogleNet进一步增加了网络模型的深度，但是单纯的在VGG16的基础上增加网络的宽度会带来以下的缺陷：1）过多的参数容易引起过拟合；2）层数的过深，容易引起梯度消息现象。<br>GoogleNet的提出受到论文Network in Network(NIN)的启发，NIN有两个贡献：1）提出多层感知卷积层，使用卷积层后加上多层感知机，增强网络提取特征的能力。普通的卷积层和多层感知卷积层结构如图所示，Mlpconv相当于在一般卷积层后加一个1*1的卷积层。2）提出了全局平均池化代替全连接层，全连接层具有大量的参数，使用全局平均池化代替全连接层，能很大程度减少参数空间，便于加深网络，还能防止过拟合。<br><img src="/images/多层感知卷积层.png" alt="普通卷积层和多层感知卷积层结构图"><br>GoogleNet根据Mlpconv的思想提出了Inception结构，该结构有两个版本，下图是Inception的naive版，该结构巧妙的将$1\times 1$、$3\times 3$和$5\times 5$三种卷积核和最大池化层结合起来作为一层结构。<br><img src="/images/Inception1.png" alt="Inception结构的native版"><br>而Inception的native版中$5\times 5$的卷积核会带来很大的计算量，因此采用了与NIN类似的结构，在原始的卷积层之后加上$1\times 1$卷积层，最终版本的Inception如下图所示：<br><img src="/images/Inception.png" alt="降维后的Inception模块"></p>
<h3 id="Inception-v3-v4"><a href="#Inception-v3-v4" class="headerlink" title="Inception v3/v4"></a>Inception v3/v4</h3><p>在GoogleNet的基础上进一步降低参数，其和GoogleNet有相似的Inception模块，但将$7\times 7$和$5\times 5$卷积分解为若干等效$3\times 3$卷积，并在网络中后部分把$3\times 3$卷积分解为$1\times 3$和$3\times 1$卷积，这使得在相似的网络参数下网络可以部署到42层。此外，Inception v3使用了批量归一化层。Inception v3是GoogleNet计算量的2.5倍，而错误率较后者下降了3%。Inception v4在Inception模块基础上结合residual模块，进一步降低了0.4%的错误率。<br><img src="/images/Inceptionv3.png" alt="Inceptionv3模块"></p>
<h3 id="Inception-v1-v2-v3-v4"><a href="#Inception-v1-v2-v3-v4" class="headerlink" title="Inception v1/v2/v3/v4"></a>Inception v1/v2/v3/v4</h3><p><a href="https://blog.csdn.net/langb2014/article/details/52787095?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">Inception v1/v2/v3/v4对比</a></p>
<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p>卷积神经网络模型的发展历程一次次证明加深网络的深度和宽度能得到更好的效果，但是后来的研究发现，网络层次较深的网络模型的效果反而不如较浅层的网络，称为“退化”现象。退化现象产生的原因在于当模型的结构变得复杂随机梯度下降的优化变得更加困难，导致网络模型的效果反而不如浅层网络。针对这个问题，MSRA何凯明团队提出Residual Network，该网络具有Residual结构如下所示：<br><img src="/images/Residual.png" alt="Residual结构"><br>ResNet的基本思想是引入了能够跳过一层或多层的“shortcut connection”，即增加一个identity mapping（恒等映射），将原始所需要学的函数H(x)转换为F(x)+x，作者认为这两种表达的效果相同，但是优化的难度却并不相同。这个Residual block通过将shortcut connection实现，通过shortcut将这个block的输入和输出进行一个element-wise的叠加，这个简单地加法并不会给网络增加额外的参数和计算量，同时却可以大大增加模型的训练速度，提高训练效果，并且当模型的层数加深时，这个简单的结构能够很好的解决退化问题。对于shortcut的方式，作者提出了三个策略：1）使用恒等映射，如果residual block的输入和输出维度不一致，对增加的维度用0来填充；2）在block输入输出维度一致时使用恒等映射，不一致时使用线性投影以保证维度一致；3）对于所有的block使用线性投影。论文最后用三个$1\times 1,3\times 3, 1\times 1$的卷积层代替前面说的两个$3\times 3$卷积层，第一个$1\times 1$用来降低维度，第三个$1\times 1$用来增加维度，这样可以保证中间的$3\times 3$卷积层拥有比较小的输入输出维度。<br><img src="/images/bottleneck.png" alt="更深的residual block"></p>
<h4 id="ResNet提出的背景和核心理论是什么？"><a href="#ResNet提出的背景和核心理论是什么？" class="headerlink" title="ResNet提出的背景和核心理论是什么？"></a>ResNet提出的背景和核心理论是什么？</h4><p>提出背景：解决或缓解深层的神经网络训练中梯度消失的问题<br>ResNet的一个重要假设：假设有一个L层的深度神经网络, 如果我们在上面加入一层, 直观来讲得到的L+1层深度神经网络的效果应该至少不会比L层的差。因为可以简单的设最后一层为前一层的拷贝(相当于恒等映射), 并且其它层参数设置不变。<br>但是最终实验发现: 层数更深的神经网络反而会具有更大的训练误差, 因此, 作者认为深层网络效果差的原因很大程度上也许不在于过拟合, 而在于梯度消失问题。<br>解决办法：<br>根据梯度消失问题的根本原因所在(链式法则连乘), ResNet通过调整网络结构来解决上述问题。ResNet的结构设计思想为: 既然离输入近的神经网络层比较难训练, 那么我们可以将它短接到更靠近输出的层。输入x经过两个神经网络的变换得到F(x)， 同时也短接到两层之后， 最后这个包含两层的神经网络模块输出H(x)=F(x)+x。这样一来， F(x)被设计为只需要拟合输入x与目标输出H(x)的残差H(x)-x。在梯度更新期间，梯度的相关性会随着层数的变深呈指数性衰减，导致梯度趋近于白噪声，而skip-connections 可以减缓衰减速度，使相关性和之前比起来变大。</p>
<h3 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h3><p><a href="https://blog.csdn.net/xiaohu2022/article/details/85560788" target="_blank" rel="noopener">DenseNet网络介绍</a><br>DenseNet脱离了加深网络层数(ResNet)和旁路网络结构(Inception)来提升网络性能的定式思维，从特征的监督考虑，通过特征重用和旁路（Bypass）设置，既大幅度减少了网络的参数量，又在一定程度上缓解了梯度消失问题的产生。DenseNet作为另一种较深层数的卷积神经网络，具有如下优点：<br>1）相比于ResNet拥有更少的参数数量；2）旁路加强了特征的重用；3）网络更容易训练，并具有一定的正则效果；4）缓解了gradient vanishing和model degradation的问题。<br><img src="/images/DenseNet.jpg" alt="DenseNet网络结构图"><br>如图所示，第i层的输入不仅与i-1层的输出相关，还与所有之前层的输出相关。记作：<br>$X_l=H_l([X_0,X_1,…,X_{l-1}])$<br>其中[]代表concatenation（拼接），既将$X_0$到$X_{l-1}$层的所有输出feature map按Channel组合在一起，这里所用到的非线性变换H为BN+ReLU+Conv(3x3)的组合。<br>由于在DenseNet中需要对不同层的feature map进行cat操作，所以需要不同层的feature map保持相同的feature size，这就限制了网络中的down sampling的实现。为了使用down sampling在实验中transition layer由BN+Conv(1x1)+average-pooling(2x2)组成。<br><img src="/images/Denseblock.jpg" alt="Denseblock网络图"></p>
<h3 id="SENet"><a href="#SENet" class="headerlink" title="SENet"></a>SENet</h3><p>Squeeze-and-Excitation Networks（SENet）是由自动驾驶公司Momenta在2017年公布的一种全新的图像识别结构，它通过对特征通道间的相关性进行建模，把重要的特征进行强化来提升准确率。<br><img src="/images/SEblock.jpg" alt="SE Bolck结构"><br>上图是SENet的Block单元，图中的$F_{tr}$是传统的卷积结构，X和U是$F_{tr}$的输入（C’xH’xW’）和输出（CxHxW），这些都是以往结构中已存在的。SENet增加的部分是U后的结构：对U先做一个Global Average Pooling（图中的$F_{sq(.)}$，作者称为Squeeze过程），输出的1x1xC数据再经过两级全连接（图中的$F_{ex(.)}$，作者称为Excitation过程），最后用sigmoid限制到[0，1]的范围，把这个值作为scale乘到U的C个通道上， 作为下一级的输入数据。这种结构的原理是想通过控制scale的大小，把重要的特征增强，不重要的特征减弱，从而让提取的特征指向性更强。<br>先是Squeeze部分。GAP有很多算法，作者用了最简单的求平均的方法，将空间上所有点的信息都平均成了一个值。这么做是因为最终的scale是对整个通道作用的，这就得基于通道的整体信息来计算scale。另外作者要利用的是通道间的相关性，而不是空间分布中的相关性，用GAP屏蔽掉空间上的分布信息能让scale的计算更加准确。</p>
<script type="math/tex; mode=display">z_c=F_{sq}(u_c)=\frac{1}{W\times H}\sum_{i=1}^W\sum_{j=1}^Hu_c(i,j)</script><p>Excitation部分是用2个全连接来实现 ，第一个全连接把C个通道压缩成了C/r个通道来降低计算量（后面跟了RELU），第二个全连接再恢复回C个通道（后面跟了Sigmoid），r是指压缩的比例。作者尝试了r在各种取值下的性能 ，最后得出结论r=16时整体性能和计算量最平衡。<br>为什么要加全连接层呢？这是为了利用通道间的相关性来训练出真正的scale。一次mini-batch个样本的squeeze输出并不代表通道真实要调整的scale值，真实的scale要基于全部数据集来训练得出，而不是基于单个batch，所以后面要加个全连接层来进行训练。<br>可以拿SE Block和下面3种错误的结构比较来进一步理解：<br>下图最上方的结构，squeeze的输出直接scale到输入上，没有了全连接层，某个通道的调整值完全基于单个通道GAP的结果，事实上只有GAP的分支是完全没有反向计算、没有训练的过程的，就无法基于全部数据集来训练得出通道增强、减弱的规律。<br>下图中间是经典的卷积结构，有人会说卷积训练出的权值就含有了scale的成分在里面，也利用了通道间的相关性，为啥还要多个SE Block？那是因为这种卷积有空间的成分在里面，为了排除空间上的干扰就得先用GAP压缩成一个点后再作卷积，压缩后因为没有了Height、Width的成分，这种卷积就是全连接了。<br>下图最下面的结构，SE模块和传统的卷积间采用并联而不是串联的方式，这时SE利用的是$F_{tr}$输入X的相关性来计算scale，X和U的相关性是不同的，把根据X的相关性计算出的scale应用到U上明显不合适。<br><img src="/images/SEnet2.jpg" alt="三种错误的SE结构"><br>下图是两个SENet实际应用的例子，左侧是SE-Inception的结构，即Inception模块和SENet组和在一起；右侧是SE-ResNet，ResNet和SENet的组合，这种结构scale放到了直连相加之前。<br><img src="/images/SENet3.jpg" alt="SE-Inception和SE-ResNet结构"></p>
<h3 id="历年来所有的网络"><a href="#历年来所有的网络" class="headerlink" title="历年来所有的网络"></a>历年来所有的网络</h3><p>LeNet-5:第一个卷积，用来识别手写数组，使用的卷积大小为5×5,s=1，就是普通的卷积核池化层结合起来，最后加上全连接层。<br>AlexNet:在第一个卷积中使用了11×11卷积，第一次使用Relu，使用了NormLayer，但不是我们经常说的BN。使用了dropout，并在两个GPU上进行了训练。<br>VGGNet:只使用了小卷积3×3(s=1)以及常规的池化层，不过深度比上一个深了一些，最后几层也都是全连接层接一个softmax。为什么使用3×3卷积，是因为三个3×3卷积的有效感受野和7×7的感受野一致，而且更深、更加非线性，卷积层的参数也更加地少，所以速度更快也可以适当加深层数。<br>GoogleNet:没有使用FC层，参数量相比之前的大大减少，提出了Inception module结构，也就是NIN结构(network within a network)。但是原始的Inception module计算量非常大，所以在每一个分支加了1×1 conv “bottleneck”结构。googlenet网络结构中为了避免梯度消失，在中间的两个位置加了两个softmax损失，所以会有三个loss，整个网络的loss是通过三个loss乘上权重相加后得到。<br>inception结构的特点：<br>1）增加了网络的宽度，同时也提高了对于不同尺度的适应程度。<br>2）使用 1×1 卷积核对输入的特征图进行降维处理，这样就会极大地减少参数量，从而减少计算量。<br>3）在V3中使用了多个小卷积核代替大卷积核的方法，除了规整的的正方形，我们还有分解版本的 3×3 = 3×1 + 1×3，这个效果在深度较深的情况下比规整的卷积核更好。<br>4）发明了Bottleneck 的核心思想还是利用多个小卷积核替代一个大卷积核，利用 1×1 卷积核替代大的卷积核的一部分工作。也就是先1×1降低通道然后普通3×3然后再1×1回去。<br>ResNet：其基本思想是引入了能够跳过一层或多层的“shortcut connection”，即增加一个identity mapping（恒等映射），将原始所需要学的函数H(x)转换为F(x)+x，作者认为这两种表达的效果相同，但是优化的难度却并不相同。这个Residual block通过将shortcut connection实现，通过shortcut将这个block的输入和输出进行一个element-wise的叠加，这个简单地加法并不会给网络增加额外的参数和计算量，同时却可以大大增加模型的训练速度，提高训练效果，并且当模型的层数加深时，这个简单的结构能够很好的解决退化问题。<br>DenseNet:ResNet是更一般的模型，DenseNet是更特化的模型。DenseNet用于图像处理可能比ResNet表现更好，本质是DenseNet更能和图像的信息分布特点匹配，是使用了多尺度的Kernel。densenet因为需要重复利用比较靠前的feature map，导致显存占用过大，但正是这种通道特征的concat造成densenet能更密集的连接。<br>SeNet：全称为Squeeze-and-Excitation Networks。核心思想就是去学习每个特征通道的重要程度，然后根据这个重要程度去提升有用的特征并抑制对当前任务用处不大的特征。这个给每一个特征层通道去乘以通过sigmoid得到的重要系数，其实和用bn层去观察哪个系数重要一样。</p>
<h2 id="图像检测"><a href="#图像检测" class="headerlink" title="图像检测"></a>图像检测</h2><p>分类任务关系整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。相比于分类，检测给出的是对图片前景和背景的理解，我们需要从背景中分离出感兴趣的目标，并确定这一目标的描述（类别和位置）。因此，检测模型的输出是一个列表，列表的每一项使用一个数据组给出检测目标的类别和位置（常用矩形检测框的坐标表示）。<br>目前主流的目标检测算法主要是基于深度模型，大致可以分成两大类别：（1）One-Stage目标检测算法，这类检测算法不需要Region Proposal阶段，可以通过一个Stage直接产生物体的类别概率和位置坐标值，比较典型的算法有YOLO、SSD和CornerNet；（2）Two-Stage目标检测算法，这类检测算法将检测问题划分为两个阶段，第一个阶段首先产生候选区域（Region Proposals），包含目标大概的位置信息，然后第二个阶段对候选区域进行分类和位置精修，这类算法的典型代表有R-CNN、Fast R-CNN、Faster R-CNN等。目标检测模型的主要性能是检测准确度和速度，其中准确度主要考虑物体的定位及分类准确度。一般情况下，Two-Stage算法在准确度上有优势，而One-Stage算法在速度上有优势。不过随着研究的发展，两类算法都在两个方面做改进，均能在准确度及速度上取得较好结果。</p>
<h3 id="IOU的定义"><a href="#IOU的定义" class="headerlink" title="IOU的定义"></a>IOU的定义</h3><p><a href="https://blog.csdn.net/sinat_34474705/article/details/80045294?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">手写IOU</a><br>物体检测需要定位出物体的bounding box，对于bounding box的定位精度，存在一个定位精度评价公式：IOU。<br>IOU定义了两个bounding box的重叠度，如下图所示：<br><img src="/images/IOU.png" alt="IOU图像"><br>矩形框A、B的一个重合度计算公式为：</p>
<script type="math/tex; mode=display">IOU=\frac{A\cap B}{A\cup B}</script><p>就是矩形框A、B的重叠面积$S_I$占A、B并集的面积的比例：</p>
<script type="math/tex; mode=display">IOU=\frac{S_I}{S_A+S_B-S_I}</script><h3 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h3><p>在目标检测时一般会采取窗口滑动的方式，在图像上生成很多的候选框，把这些候选框进行特征提取送入到分类器，一般会得到一个得分，然后把这些得分全部排序。选取得分最高的那个框，接下来计算其他框与当前框的重合程度(IOU)，如果重合程度大于一定的阈值就删除，这样不停的迭代下去就会得到所有想要找到的目标物体的区域。</p>
<h3 id="Soft-NMS"><a href="#Soft-NMS" class="headerlink" title="Soft-NMS"></a>Soft-NMS</h3><p><a href="https://blog.csdn.net/lcczzu/article/details/86518615" target="_blank" rel="noopener">非极大值抑制算法改进</a></p>
<h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h3><p>算法摘要：首先输入一张图片，我们先定位出2000个物体候选框，然后采用CNN提取每个候选框中图片的特征向量，特征向量的维度是4096维，接着采用SVM算法对各个候选框中的物体进行分类识别。<br><img src="/images/RCNN.png" alt="R-CNN算法流程"><br>我们采用selective search算法搜索出候选框，由于搜索到的候选框是矩形的，而且大小各不相同，而CNN对输入的图片大小是固定的，因此需要对每个输入的候选框都要缩放到固定的大小。然而人工标注的图片中就只标注了一个正确的bounding box，我们搜索出来的2000个矩形框也不可能会出现一个与人工标注完全匹配的候选框。因此我们需要用IOU为2000个bounding box打标签，以便下一步CNN训练使用。在CNN阶段，如果用selective search挑选出来的候选框与物体的人工标注矩形框的重叠区域大于0.5，我们就把这个候选框标注成物体类别，否则我们就把它当做背景类别。最后，我们需要对上面预训练的CNN模型进行fine-tuning训练。假设需要检测的物体类别有N类，那么我们就需要将上面与训练的CNN模型的最后一层给替换点，替换成N+1个输出的神经元（还有一个背景），然后这一层直接采用参数随机初始化的方法，其他的网络层数不变。<br>R-CNN缺点：<br>1）耗时的selective search，对一帧图像，需要花费2s。<br>2）耗时的串行式CNN前向传播，对于每一个ROI，都需要经过一个AlexNet提取特征，为所有的ROI提供特征需要花费47s。<br>3）三个模块分别训练，并且在训练的时候，对于存储空间的消耗很大。<br><img src="/images/rcnn2.png" alt="RCNN算法流程框图"></p>
<h3 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP-Net"></a>SPP-Net</h3><p><img src="/images/sppnet.png" alt="SPPNet网络流程框图"><br>算法特点：1）通过Spatial Pyramid Pooling解决了深度网络固定输入层尺寸的这个限制，使得网络可以享受不限制输入尺寸带来的好处。2）解决了RCNN速度慢的问题，不需要对每个Proposal(2000个左右)进行wrap或crop输入CNN提取feature map，只需要对整图提一次feature map，然后将proposal区域映射到卷积特征层得到全连接层的输入特征。<br><img src="/images/rcnn_vs_spp.png" alt="RCNN与SPPNet对比"><br>一、ROI在特征图上的对应的特征区域的维度不满足全连接层的输入要求怎么办？<br>事实上，CNN的卷积层不需要固定尺寸的图像，而是全连接层是需要固定大小的输入。根据Pooling规则，每个Pooling bin对应一个输出，所以最终的Pooling后的输出特征由bin的个数来决定。SPP网络就是分级固定bin的个数，调整bin的尺寸来实现多级Pooling固定输出。如图所示，SPP网络中最后一个卷积层的feature map维数为16x24，按照图中所示分为3级：<br><img src="/images/SPP.png" alt="SPP网络结构"><br>其中，第一级bin个数为1，最终对应的window大小为16x24；第二级bin个数为4个，最终对应的window大小为4x8；第三级bin个数为16个，最终对应的window大小为1x1.5(小数需要舍入处理)。通过融合各级bin的输出，最终每一个feature map经过SPP处理后，得到1+4+16维的feature map，经过融合后输入分类器。这样就可以在任意输入size和scale下获得固定的输出；不同的scale下网络可以提取不同尺度的特征，有利于分类。<br>二、原始图像的ROI如何映射到特征图？<br>下面将从感受野、感受野上坐标映射及原始图像的ROI如何映射三方面阐述。<br>1）感受野<br>在卷积神经网络中，感受野的定义是卷积神经网络每一层输出的特征图(feature map)的像素点在原始图像上映射的区域大小。</p>
<script type="math/tex; mode=display">output\ field\ size = (input\ field\ size - kernel size + 2*padding) / stride + 1</script><p>其中output field size是卷积层的输出，input field size是卷积层的输入，反过来卷积层的输入为:</p>
<script type="math/tex; mode=display">input\ field\ size = (output\ field\ size - 1) * stride - 2*padding + kernel size</script><p>2）感受野上的坐标映射<br>对于Convolution/Pooling Layer:</p>
<script type="math/tex; mode=display">p_i=s_i \cdot p_{i+1}+[(k_i-1)/2-padding]</script><p>对于Neuronlayer（ReLU/Sigmoid/…）:</p>
<script type="math/tex; mode=display">p_i=p_{i+1}</script><p>其中$p_i$为第$i$层感受野上的坐标，$s_i$为Stride的大小，$k_i$为感受野的大小。<br>何凯明在SPP-NET中使用的是简化版本，将公式中的Padding都设为$\left \lfloor k_i/2 \right \rfloor$，公式可进一步简化为：<script type="math/tex">p_i=s_i \cdot p_{i+1}</script><br>3）原始图像的ROI如何映射<br>SPP-NET是把原始ROI的左上角和右下角 映射到Feature Map上的两个对应点。 有了Feature Map上的两队角点就确定了对应的Feature Map 区域（下图中橙色）。<br><img src="/images/ROImap.png" alt="ROI映射过程"><br>左上角取$x’=\left \lfloor x/S \right \rfloor+1, y’=\left \lfloor y/S \right \rfloor+1$；右下角的点取$x’=\left \lceil x/S \right \rceil-1, y’=\left \lceil y/S \right \rceil-1$。其中S为坐标映射的简化计算版本，即$S=\prod_{0}^{i}s_i$。<br>ROI pooling具体操作：<br>1）根据输入image，将ROI映射到feature map对应位置。<br>2）将映射后的区域划分为相同大小的sections（sections数量和输出的维度相同）；<br>3）对每个sections进行max pooling操作。<br>这样就可以从不同大小的方框得到固定大小的相应的feature maps。<br><a href="https://zhuanlan.zhihu.com/p/73654026" target="_blank" rel="noopener">ROI原理</a></p>
<h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><p>Fast R-CNN针对R-CNN在训练时multi-state pipeline和训练的过程很耗时间和空间的问题进行了改进，主要改进为：<br>1）在最后一个卷积层加了一个ROI pooling layer。ROI Pooling layer首先可以将image中的ROI定位到feature map，然后用一个单层的SPP layer将这个feature map池化到固定大小的feature map后再传入全连接层。<br>2）损失函数使用多任务损失函数（multi-task loss），将边框回归直接加入到CNN网络进行训练。<br><img src="/images/frcnn.png" alt="Fast R-CNN流程框图"><br>首先还是采用selective search提取2000个候选框，然后对全图进行特征提取，接着使用一个ROI pooling layer在全体特征上获取每一个ROI对应的特征，再通过全连接层进行分类和检测框修正。即最后得到的ROI feature vector被分开，一个经过全连接层后用作softmax回归，用来分类，另一个经过全连接后用作bbox回归。需要注意的是，输入到后面ROI Pooling layer的feature map是在卷积层上的feature map上提取的，故整个特征提取过程只计算一次卷积。虽然在最开始也提取了大量的ROI，但他们还是作为整体输入到卷积网络的，最开始提取的ROI区域只是为了最后的bounding box回归时使用。<br><strong>联合训练</strong>：联合训练（Joint Training）指如何将分类和边框回归联合到一起在CNN阶段训练，主要难点是损失函数的设计。Fast-RCNN中，有两个输出层：第一个是针对每个ROI区域的分类概率预测，$p=(p_0, p_1, \cdots, p_K)$；第二个则是针对每个ROI区域坐标的偏移优化，$t^k = (t^k_x, t^k_y, t^k_w, t^k_h)$，$0 \le k \le K$是多类检测的类别序号。每个训练ROI都对应着真实类别$u$和边框回归目标$v=(v_x,v_y,v_w,v_h)$，对于类别$u$预测边框为$t^u=(t_x^u,t_y^u,t_w^u,t_h^u)$，使用多任务损失$L$来定义ROI上分类和边框回归的损失：</p>
<script type="math/tex; mode=display">L(p,u,t^u,v)=L_{cls}(p,u)+\lambda [u \ge 1]L_{loc}(t^u,v)</script><p>其中$L_{cls}(p,u)=-\log p_u$表示真实类别的log损失，当$u \ge 1$时，$[u \ge 1]$的值为1，否则为0。下面将重点介绍多任务损失中的边框回归部分（对应坐标偏移优化部分）。<br><strong>边框回归</strong>：假设对于类别$u$，在图片中标注的真实坐标和对应的预测值理论上两者越接近越好，相应的损失函数为：</p>
<script type="math/tex; mode=display">L_{loc}(t^u, v) = \sum_{i \in {x, y, w, h}} \text{smooth}_{L_1}(t_i^u- v_i)</script><script type="math/tex; mode=display">\text{smooth}_{L_1}(x) = \left \{ \begin{aligned} & 0.5x^2 & |x| \le 1 \\ &|x|-0.5 & \text{otherwise}\end{aligned} \right.</script><p>Fast-RCNN在上面用到的鲁棒$L_1$函数对外点比RCNN和SPP-NET中用的$L_2$函数更为鲁棒，该函数在$(-1, 1)$之间为二次函数，其他区域为线性函数。<br>存在问题：使用Selective Search提取Region Proposals，没有实现真正意义上的端到端，操作耗时。<br>采用$\text{smooth}_{L_1}$的原因：边框的预测是一个回归问题，通常可以选择平方损失函数（L2损失）$f(x)=x^2$，但这个损失对于比较大的误差的惩罚很高。可以采用稍微缓和一点绝对损失函数（L1损失）$f(x)=|x|$，这个函数在0点处导数不存在，因此可能会影响收敛。因此采用分段函数，在0点附近使用平方函数使得它更加平滑。</p>
<h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><p><img src="/images/faster rcnn.png" alt="Faster R-CNN流程图"><br>算法特点：1）提出了Region Proposal Network(RPN)，将Proposal阶段和CNN分类融合到一起，实现了一个完全的End-To-End的CNN目标检测模型。RPN可以快速提取高质量的Proposal，不仅加快了目标检测速度，还提高了目标检测性能。2）将Fast R-CNN和RPN放在同一个网络结构中训练，共享网络参数。</p>
<h4 id="Region-Proposal-Network"><a href="#Region-Proposal-Network" class="headerlink" title="Region Proposal Network"></a>Region Proposal Network</h4><p>Region Proposal Network(RPN)的核心思想是使用卷积神经网络直接产生Region Proposal，使用的方法本质上就是滑动窗口。RPN的设计比较巧妙，RPN只需要在最后的卷积层上滑动以便，借助Anchor机制和边框回归就可以得到多尺度多长宽比的Region Proposal。下图是RPN的网络结构图。<br><img src="/images/RPN.png" alt="RPN网络结构图"><br>给定输入图像（假设分辨率为$600*1000$），经过卷积操作得到最后一层卷积特征图（大小约为$40\times 60$）。在这个特征图上使用$3\times 3$的卷积核（滑动窗口）与特征图进行卷积，最后一层卷积层共有256个feature map，那么这个$3\times 3$的区域卷积后可以获得一个256维的特征向量，后边接cls layer和reg layer分别用于分类和边框回归（跟Fast R-CNN类似，只不过这里的类别只有目标和背景两个类别）。$3\times 3$滑窗对应的每个特征区域同时预测输入图像的3种尺度（128，256，512），3中长宽比（1：1，1：2，2：1）的Region Proposal，这种映射的机制称为Anchor。所以对于这个$40\times 60$的feature map，总共有约20000（$40\times 60\times 9$）个Anchor，也就是预测20000个Region Proposal。一般来说原始输入图片都要缩放到固定的尺寸才能作为网络的输入，这个尺寸在作者源码里限制成800x600，9种anchor还原到原始图片上基本能覆盖800x600图片上各种尺寸的坐标。<br>Anchor是在原图上的区域而不是在特征图上<br><img src="/images/Anchor.png" alt="Anchor示例"><br>这样设计的好处是什么？虽然现在也是在用的滑动窗口策略，但是滑动串口操作是在卷积特征图上进行的，维度较原始图像降低了$16\times 16$倍；多尺度使用了9中Anchor，对应了三种尺度和三种长宽比，加上后边接了边框回归，所以几遍是这9种Anchor外的窗口也能得到一个跟目标比较接近的Region Proposal。<br><a href="https://www.okcode.net/article/65311" target="_blank" rel="noopener">anchor讲解</a></p>
<h4 id="RPN的损失函数"><a href="#RPN的损失函数" class="headerlink" title="RPN的损失函数"></a>RPN的损失函数</h4><p>损失函数的定义为：</p>
<script type="math/tex; mode=display">L({p_i}{t_i}) = \frac{1}{N_{cls}} \sum_i L_{cls}(p_i, p_i^*) +\lambda \frac{1}{N_{reg}} \sum_i p_i^* L_{reg}(t_i, t_i^*)</script><p>其中$i$表示一次Mini-Batch中Anchor的索引，$p_i$是Anchor $i$是否是一个物体，$L_{reg}$即为上面提到的$\text{smooth}_{L_1}(x)$函数，$N_{cls}$和$N_{reg}$是两个归一化项，分别表示Mini-Batch的大小和Anchor位置的数目。</p>
<h4 id="网络的训练"><a href="#网络的训练" class="headerlink" title="网络的训练"></a>网络的训练</h4><p>作者采用了4-step Alternating Training:<br>1) 用ImageNet模型初始化，独立训练一个RPN网络；<br>2) 仍然用ImageNet模型初始化，但是使用上一步RPN网络产生的Proposal作为输入，训练一个Fast-RCNN网络，至此，两个网络每一层的参数完全不共享；<br>3) 使用第二步的Fast-RCNN网络参数初始化一个新的RPN网络，但是把RPN、Fast-RCNN共享的那些卷积层的Learning Rate设置为0，也就是不更新，仅仅更新RPN特有的那些网络层，重新训练，此时，两个网络已经共享了所有公共的卷积层；<br>4) 仍然固定共享的那些网络层，把Fast-RCNN特有的网络层也加入进来，形成一个Unified Network，继续训练，Fine Tune Fast-RCNN特有的网络层，此时，该网络已经实现我们设想的目标，即网络内部预测Proposal并实现检测的功能。<br>在训练分类器和RoI边框修正时，步骤如下：<br>1）首先通过RPN生成约20000个anchor（40x60x9）<br>2）对20000个anchor进行第一次边框修正，得到修订边框后的proposal；<br>3）对超过图像边界的proposal的边进行clip，使得该proposal不超过图像范围；<br>4）忽略掉长或宽太小的proposal；<br>5）将所有的proposal按照前景分数从高到低排序，选取前12000个proposal；<br>6）使用阈值为0.7的NMS算法排除掉重叠的proposal；<br>7）针对上一步剩下的proposal，选取前2000个proposal进行分类和第二次边框修正。<br><img src="/images/fasterrcnn.png" alt="faster rcnn训练过程"></p>
<h3 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h3><p>ROI Align是在Mask R-CNN这篇论文里提出的一种区域特征聚集方式，很好地解决了ROI Pooling操作中两次量化造成的区域不匹配的问题。在检测阶段将ROI Pooling替换为ROI Align可以提升检测模型的准确性。<br>在常见的两级检测框架中，ROI Pooling的作用是根据候选框的位置坐标在特征图中将相应的区域池化为固定尺寸的特征图，以便后续的分类和bounding box回归操作。由于预选框的位置通常是由模型回归得到的，一般来讲都是浮点数，而池化后的特征图要求尺寸固定，故ROI Pooling这一操作存在两次量化的过程。1）将候选框的边界量化为整数点坐标值。2）将量化后的边界区域平均分割成$k\times k$个单元（bin），对每一个单元的边界进行量化。经过上述的两次量化，此时的候选框已经和最开始回归出来的位置存在一定的偏差，这个偏差会影响检测或分割的精确度。在论文里作者将它归结为“不匹配问题(misalignment)”。<br>下面我们用直观的例子具体分析一下上述区域不匹配问题。如图所示，这是一个Faster-RCNN检测框架。输入一张$800\times 800$的图片，图片上有一个$665\times 665$的包围框(框着一只狗)。图片经过主干网络提取特征后，特征图缩放步长（stride）为32。因此，图像和包围框的边长都是输入时的1/32。800正好可以被32整除变为25。但665除以32以后得到20.78，带有小数，于是ROI Pooling 直接将它量化成20。接下来需要把框内的特征池化$7\times 7$的大小，因此将上述包围框平均分割成$7\times 7$个矩形区域。显然，每个矩形区域的边长为2.86，又含有小数。于是ROI Pooling 再次把它量化到2。经过这两次量化，候选区域已经出现了较明显的偏差（如图中绿色部分所示）。更重要的是，该层特征图上0.1个像素的偏差，缩放到原图就是3.2个像素。那么0.8的偏差，在原图上就是接近30个像素点的差别，这一差别不容小觑。<br><img src="/images/ROIAlign.png" alt="ROIAlign示例"><br>为了解决ROI Pooling的上述缺点，作者提出了ROI Align这一改进的方法。ROI Align的思路很简单：取消量化操作，使用双线性内插的方法获得坐标为浮点数的像素点上的图像数值，从而将整个特征聚集过程转化为一个连续的操作。ROI Align流程如下：<br>1）遍历每一个候选区域，保持浮点数边界不做量化；2）将候选区域分割成$k\times k$个单元，每个单元的边界也不做量化；3）在每个单元中计算出固定的四个坐标位置，用双线性内插的方法计算出这四个位置的值，然后进行最大池化的操作。<br>需要注意的是，这个固定位置是指在每一个矩形单元（bin）中按照固定规则确定的位置。比如，如果采样点数是1，那么就是这个单元的中心点。如果采样点数是4，那么就是把这个单元平均分割成四个小方块以后它们分别的中心点。显然这些采样点的坐标通常是浮点数，所以需要使用插值的方法得到它的像素值。事实上，ROI Align 在遍历取样点的数量上没有ROIPooling那么多，但却可以获得更好的性能，这主要归功于解决了misalignment的问题。<br><img src="/images/ROIAlign2.png" alt="ROIAlign示例2"><br><img src="/images/maskrcnn.jpg" alt="Mask R-CNN结构图"><br>注意的是，在Mask R-CNN中的ROI Align之后有一个“head”部分，主要作用是将ROI Align的输出维度扩大，这样在预测Mask时会更加精确。<br>在Mask Branch的训练环节，作者没有采用FCN式的SoftmaxLoss，反而是输出了K个Mask预测图（为每一个类都输出一张），并采用average binary cross-entropy loss训练，当然在训练Mask branch的时候，输出K个特征图中，也就是对应ground truth类别的哪一个特征图对Mask loss有贡献。也就是说， Mask RCNN定义为多任务损失为$L=L_{class}+L_{boxes}+L_{mask}$。<br>$L_{class}$与$L_{boxes}$与Faster RCNN没区别。$L_{mask}$中，假设一共有K个类别，则mask分割分支的输出维度是$K\times m\times m$，对于$m\times m$中的每个点，都会输出K个二值Mask(每个类别使用sigmoid输出)。需要注意的是，计算loss的时候，并不是每个类别的sigmoid输出都计算二值交叉熵损失，而是该像素属于哪个类，哪个类的sigmoid输出才要计算损失函数，并且在测试的时候，我们通过分类分支预测类别来选择相应的mask预测。这样，mask预测和分类分支预测就彻底解耦了。</p>
<h3 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a>FPN</h3><p><a href="https://www.aiuai.cn/aifarm887.html" target="_blank" rel="noopener">特征金字塔网络FPN</a><br>在物体检测里面，在有限的计算量的情况下，网络的深度（对应到感受野）与 stride 通常是一对矛盾的东西，常用的网络结构对应的 stride 一般会比较大（如 32），而图像中的小物体甚至会小于 stride 的大小，造成的结果就是小物体的检测性能急剧下降。传统解决这个问题的思路包括：<br>（1）多尺度训练和测试，有称图像金字塔，如图（a）所示。目前几乎所有在 ImageNet 和 COCO 检测任务上取得好成绩的方法都使用了图像金字塔方法。然而这样的方法由于很高的时间及计算量消耗，难以在实际中应用。<br>（2）特征分层，即每层分别预测对应的scale分辨率的检测结果，如图（c）所示。SSD检测框架采用了相似的思想，这样的方法的问题在于直接强行让不同层学习同样的语义信息，而对于卷积神经网络而言，不同的深度对应着不同层次的语义特征，浅层网络的分辨率高，学的更多是细节特征，深层网络分辨率低，学的更多是语义特征。<br><img src="/images/FPN.jpg" alt="FPN网络结构"><br>目前多尺度的物体检测主要面临的挑战是：<br>1）如何学习具有强语义信息的多尺度特征表示？<br>2）如何设计通用的特征表示来解决物体检测中的多个子问题？如object proposal,box localization,instance segmentation.<br>3）如何高效计算多尺度的特征表示？<br>本文针对这些问题，提出了特征金字塔FPN，如图（d）所示，网络直接在原来的按网络上做修改，每个分辨率的feature map引入后，将分辨率缩放两倍的feature map做element-wise相加的操作。通过这样的连接，每一层预测所用的feature map都融合了不同分辨率、不同语义强度的特征，融合的不同分辨率的feature map分别做对应分辨率的物体检测。这样保证了每一层都有合适的分辨率以及强语义特征。同事，由于此方法只是在原网络的基础上家里额外的跨层连接，在实际应用中几乎不增加额外的时间和计算量。<br>自下而上的路径<br>CNN的前馈计算就是自下而上的路径，特征图经过卷积核计算，通常是越变越小，也有一些特征层的输出和原来的大小一样，称为“相同网络阶段”。对于本文的特征金字塔，作者为每个阶段定义一个金字塔级别，然后选择每个阶段的最后一层的输出作为特征图的参考集，这是因为每个阶段的最深层应该具有最强的特征。具体来说，对于ResNets，作者使用了每个阶段的最后一个残差结构的特征激活输出。将这些残差模块输出表示为{C2, C3, C4, C5}，对应于conv2，conv3，conv4和conv5的输出，并且注意它们相对于输入图像具有{4, 8, 16, 32}像素的步长。考虑到内存占用，没有将conv1包含在金字塔中。<br>自上而下的路径和横向连接<br>自上而下的路径（the top-down pathway ）是如何去结合低层高分辨率的特征呢？方法就是，把更抽象，语义更强的高层特征图进行上采样，然后把该特征横向连接（lateral connections）至前一层的特征，因此高层特征得到加强。值得注意的是，横向连接的两层特征在空间尺寸上要相同，这样做主要是为了利用底层的定位细节信息。<br>如图（d）所示，把高层特征做2倍上采样（最近邻上采样），然后将其和对应的前一层特征结合（前一层要经过$1\times 1$的卷积核才能用，目的是改变channels,使之和后一层的channels相同），结合方式就是element-wise相加的操作。重复迭代该过程，直至生成$1\times 1$最精细的特征图。迭代开始阶段，作者在C5层后面加了一个$1\times 1$的卷积核来产生最粗略的特征图，最后，作者用$3\times 3$的卷积核去处理已经融合的特征图（为了消除上采样的混叠效应），以生成最后需要的特征图。{C2, C3, C4, C5}层对应的融合特征层为{P2, P3, P4, P5}，对应的层空间尺寸是相通的。<br>FPN的优点：<br>1）低层的特征经过卷积和高层的信息上采样之后进行融合，在卷积神经网络中高层的特征具有较强的语义信息，低层的特征具有结构信息，将高层和低层的信息进行结合，是可以增强特征的表达能力。2）将候选框产生和提取特征的位置分散到特征金字塔的每一层，这样可以增加小目标特征映射的分辨率，对最后的预测是有好处的。</p>
<h3 id="Retinanet"><a href="#Retinanet" class="headerlink" title="Retinanet"></a>Retinanet</h3><p>基于深度学习的目标检测算法有两类经典的结构：Two Stage 和 One Stage。<br>Two Stage：例如Faster-RCNN算法。第一级专注于proposal的提取，第二级对提取出的proposal进行分类和精确坐标回归。两级结构准确度较高，但因为第二级需要单独对每个proposal进行分类/回归，速度上就变慢。<br>One Stage：例如SSD，YOLO算法。此类算法摒弃了提取proposal的过程，只用一级就完成了识别/回归，虽然速度较快但准确率远远比不上两级结构。<br>产生精度差异的主要原因：类别失衡（Class Imbalance）。One Stage方法在得到特征图后，会产生密集的目标候选区域，而这些大量的候选区域中只有很少一部分是真正的目标，这样就造成了机器学习中经典的训练样本正负不平衡的问题。它往往会造成最终算出的training loss为占绝大多数但包含信息量却很少的负样本所支配，少样正样本提供的关键信息却不能在一般所用的training loss中发挥正常作用，从而无法得出一个能对模型训练提供正确指导的loss（而Two Stage方法得到proposal后，其候选区域要远远小于One Stage产生的候选区域，因此不会产生严重的类别失衡问题）。常用的解决此问题的方法就是负样本挖掘，或其它更复杂的用于过滤负样本从而使正负样本数维持一定比率的样本取样方法。该论文中提出了Focal Loss来对最终的Loss进行校正。<br>Focal Loss的目的：消除类别不平衡 + 挖掘难分样本<br>Focal Loss非常简单，就是在原有的交叉熵损失函数上增加了一个因子，让损失函数更加关注hard examples，以下是用于二值分类的交叉熵损失函数。其中$y\in{\pm1}$为类别真实标签，$p\in[0,1]$是模型预测的$y=1$的概率。</p>
<script type="math/tex; mode=display">CE(p,y)=
\begin{cases}
-log(p) & if\ y=1 \\
-log(1-p) & otherwise
\end{cases}</script><p>可以进行如下定义：</p>
<script type="math/tex; mode=display">p_t=
\begin{cases}
p & if\ y=1 \\
1-p & otherwise
\end{cases}</script><p>因此交叉熵可以写成如下形式，即如下loss曲线图中蓝色曲线所示，可以认为当模型预测得到的$p_t\ge 0.6$的样本为容易分类的样本，而$p_t$值预测较小的样本为hard examples，最后整个网络的loss就是所有训练样本经过模型预测得到的值的累加，因为hard examples通常为少数样本，所以虽然其对应的loss值较高，但是最后全部累加后，大部分的loss值来自于容易分类的样本，这样在模型优化的过程中就会将更多的优化放到容易分类的样本中，而忽略hard examples。</p>
<script type="math/tex; mode=display">CE(p,y)=CE(p_t)=-log(p_t)</script><p>对于这种类别不均衡问题常用的方法是引入一个权重因子$\alpha$，对于类别1的使用权重$\alpha$，对于类别-1使用权重$1-\alpha$，公式如下所示。但采用这种加权方式可以平衡正负样本的重要性，但无法区分容易分类的样本与难分类的样本。</p>
<script type="math/tex; mode=display">CE(p_t)=-\alpha_tlog(p_t)</script><p>因此论文中提出在交叉熵前增加一个调节因子$(1-p_t)^{\gamma}$，其中$\gamma$为focusing parameter，且$\gamma \ge 0$，其公式变为如下，当$\gamma$取不同数值时loss曲线如图1所示。通过图中可以看到，当$\gamma$越来越大时，loss函数在容易分类的部分其loss几乎为零，而$p_t$较小的部分（hard examples部分）loss值仍然较大，这样就可以保证在类别不平衡较大时，累加样本loss，可以让hard examples贡献更多的loss，从而可以在训练时给与hard examples部分更多的优化。</p>
<script type="math/tex; mode=display">FL(p_t)=-(1-p_t)^{\gamma}log(p_t)</script><p>在实际使用时，论文中提出在上述公式的基础上，增加一个$\alpha$平衡因子，可以产生一个轻微的精度提升，公式如下所示。</p>
<script type="math/tex; mode=display">CE(p_t)=-\alpha_t(1-p_t)^{\gamma}log(p_t)</script><p><img src="/images/focalloss.jpg" alt="focal loss曲线图"><br>下图是RetinaNet的网络结构，整个网络相对Faster-RCNN简单了很多，主要由ResNet+FPN+2xFCN子网络构成。<br><img src="/images/RetinaNet.jpg" alt="RetinaNet网络结构图"><br>首先RetinaNet的Backbone是由ResNet+FPN构成，输入图像经过Backbone的特征提取后，可以得到$P_3~P_7$特征图金字塔，其中下标$l$表示特征金字塔的层数（$P_l$特征图的分辨率比输入图像小$2^l$），得到的特征金字塔的每层$C=256$通道。<br>在得到特征金字塔后，对每层特征金字塔分别使用两个子网络（分类网络+检测框位置回归）。这两个子网络由RPN网络修改得到。<br>与RPN网络类似，也使用anchors来产生proposals。特征金字塔的每层对应一个anchor面积，为了产生更加密集的coverage，增加了三个面积比例$\begin{Bmatrix}2^0,2^{\frac{1}{2}},2^{\frac{2}{3}} \end{Bmatrix}$（即使用当前anchor对应的面积分别乘以相应的比例，形成三个尺度），然后anchors的长宽比仍为$\begin{Bmatrix}1:2,1:1,2:1  \end{Bmatrix}$，因此特征金字塔的每一层对应A = 9种Anchors。原始RPN网络的分类网络只是区分前景与背景两类，此处将其改为目标类别的个数K。<br>特征金字塔每层都相应的产生目标类别与位置的预测，最后再将其融合起来，同时使用NMS来得到最后的检测结果。</p>
<h3 id="Faster-R-CNN-FPN-Focal-loss"><a href="#Faster-R-CNN-FPN-Focal-loss" class="headerlink" title="Faster R-CNN+FPN+Focal loss"></a>Faster R-CNN+FPN+Focal loss</h3><p><a href="https://blog.csdn.net/qq_33547191/article/details/88695405" target="_blank" rel="noopener">Faster R-CNN+FPN结合细节</a><br><a href="https://github.com/jwyang/fpn.pytorch" target="_blank" rel="noopener">代码</a><br><a href="https://blog.csdn.net/dcxhun3/article/details/59055974" target="_blank" rel="noopener">网络结构</a><br><a href="https://www.cnblogs.com/leebxo/p/11291140.html" target="_blank" rel="noopener">优化方案</a></p>
<h3 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h3><p>算法特点：1）将物体检测作为回归问题求解。基于一个单独的End-To-End网络，完成从原始图像的输入到物体位置和类别的输出，输入图像经过一次Inference，便能得到图像中所有物体的位置和其所属类别及相应的置信概率。2）YOLO网络借鉴GoogleNet网络结构，不同的是，YOLO未使用Inception Module，而是使用$1\times 1$卷积层（此处$1\times 1$卷积层的存在是为了跨通道信息整合）+ $3\times 3$卷积层简单代替。3）Fast YOLO使用9个卷积层代替YOLO的24个，网络更轻快，速度从YOLO的45fps提升到155fps，但是同时损失了检测准确率。4）使用全图作为Context信息，背景错误（把背景错认为物体）比较少。5）泛化能力强。在自然图像上训练好的结果在艺术作品中依然具有很好的效果。<br><img src="/images/Yolo.png" alt="YOLO网络结构"><br>一、大致流程<br>1）对于一个输入图像，首先将图像划分成$7\times 7$的网络。<br>2）对于每个网格，我们都预测2个边框（包括每个边框是目标的置信度以及每个边框区域在多个类别上的概率）。<br>3）根据上一步可以预测出$7\times 7\times 2$个目标窗口，然后根据阈值去除可能性比较低的目标窗口，最后NMS去除冗余窗口即可。<br><img src="/images/Yolo2.png" alt="Yolo实例"><br>二、训练<br>1）预训练分类网络：在ImageNet 1000-class Competition Dataset预训练一个分类网络，这个网络时前文网络结构中前20个卷积网络+Average-Pooling Layer+Fully Connected Layer(此时网络的输入是$224\times 224$)。<br>2）训练检测网络：在预训练网络中增加卷积和全连接层可以改善性能。YOLO添加4个卷积层和2个全连接层，随机初始化权重。检测要求细粒度的视觉信息，所以把网络输入也从$224\times 224$变成$448\times 448$。一幅图像分成$7\times 7$个网格，某个物体的中心落在这个网格中此网络就负责预测这个物体。每个网络预测两个Bounding Box。网格负责类别信息，Bounding Box负责坐标信息（4个坐标信息及一个置信度），所以最后一层输出为$7\times 7\times (2\times (4+1) + 20) = 7\times 7\times 30$的维度。Bounding Box的坐标使用图像的大小进行归一化0-1，Confidence使用$P_r(Object) * IOU_{pred}^{truth}$计算，其中第一项表示是否有物体落在网格中，第二项表示预测的框和实际的框之间的IOU值。<br>3）损失函数的确定：损失函数的定义如下，损失函数的设计目标就是让坐标，置信度和类别这三个方面达到很好的平和。简单地全部采用Sum-Squared Error Loss来做这件事会有以下不足：a)8维的Localization Error和20维的Classification Error同等重要显然是不合理的；b)如果一个网格中没有Object（一幅图中这种玩个很多），那么就会将这些网络中的Box的COnfidence降低到0，相对于较少的有Object的网络，这种做法是Overpowering的，这会导致网络不稳定甚至发散。解决方案如下：<br><img src="/images/Yolo3.png" alt="Yolo的损失函数"><br>首先更重视8维的坐标预测，给这些损失前面赋予更大的Loss Weight，记为$\lambda_{coord}$，在Pascal VOC训练中取5（上图蓝色框）。对于没有Object的Bbox的Confidence Loss，赋予小的Loss Weight，记为$\lambda_{noobj}$，在Pascal VOC训练中取0.5（上图橙色框）。有Object的Bbox的Confidence Loss（上图红色框）和类别的Loss（上图紫色框）的Loss Weight正常取1。对于不同大小的Bbox预测中，相比于大Bbox预测偏一点，小Bbox预测偏一点更不能忍受。而Sum-Square Error Loss中对同样的偏移Loss是一样的。为了缓和这个问题，将Bbox的Width和Height取平方根代替原本的Height和Width。如下图所示：Small Bbox的横轴值较小，发生偏移时，反应到y轴上的Loss(下图绿色)比Big Bbox(下图红色)要大。一个网格预测多个Bbox，在训练时我们希望每个Object（Ground True box）只有一个Bbox专门负责（一个Object一个Bbox）。具体做法是与Ground True Box(Object)的IOU最大的Bbox负责该Ground True Box(Object)的预测。这种做法称作Bbox Predictor的Specialization（专职化）。每个预测器会对特定（Size,Aspect Ratio or Classed of Object）的Ground True Box预测的越来越好。<br>三、测试<br>1）计算每个Bbox的Class-Specific Confidence Score:每个网格预测的Class信息($Pr(Class_i|Object)$)和Bbox预测的Confidence信息($Pr(Object)\times IOU_{pred}^{truth}$)相乘，就得到每个Bbox的Class-Specific Confidence Score。</p>
<script type="math/tex; mode=display">Pr(Class_i|Object)\times Pr(Object)\times IOU_{pred}^{truth}=Pr(Class_i)\times IOU_{pred}^{truth}</script><p>2）进行Non-Maximum Suppression(NMS)：得到每个Bbox的Class-Specific Confidence Score以后，设置阈值，滤掉得分低的Bboxes，对保留的Bboxes进行NMS处理就得到最终的检测结果。<br>四、存在问题<br>1）YOLO对相互靠的很近的物体（挨在一起且中点都落在同一个格子上的情况），还有很小的群体检测效果不好，这是因为一个网络中只预测了两个框，并且只属于一类。<br>2）测试图像中，当同一类物体出现的不常见的长宽比和其他情况时泛化能力偏弱。<br>3）由于损失函数的问题，定位误差是影响检测效果的主要原因，尤其是大小物体的处理上，还有待加强。</p>
<h3 id="YOLOV2、YOLOV3"><a href="#YOLOV2、YOLOV3" class="headerlink" title="YOLOV2、YOLOV3"></a>YOLOV2、YOLOV3</h3><h4 id="YOLOV2-YOLO9000-更准、更快、更强"><a href="#YOLOV2-YOLO9000-更准、更快、更强" class="headerlink" title="YOLOV2/YOLO9000 更准、更快、更强"></a>YOLOV2/YOLO9000 更准、更快、更强</h4><p>YOLO v1对于bounding box的定位不是很好，在精度上比同类网络还有一定的差距。作者希望改进的方向是改善 recall，提升定位的准确度，同时保持分类的准确度。YOLO V2在V1基础上做出改进：<br>1）受到Faster RCNN方法的启发，引入了anchor。使用了K-Means方法，对anchor数量进行了讨论。<br>2）修改了网络结构，去掉了全连接层，改成了全卷积结构。<br>3）训练时引入了世界树（WordTree）结构，将检测和分类问题做成了一个统一的框架，并且提出了一种层次性联合训练方法，将ImageNet分类数据集和COCO检测数据集同时对模型训练。<br><strong>更准</strong><br>Batch Normalization<br>使用 Batch Normalization 对网络进行优化，让网络提高了收敛性，同时还消除了对其他形式的正则化（regularization）的依赖。通过对 YOLO 的每一个卷积层增加 Batch Normalization，最终使得 mAP 提高了2%，同时还使模型正则化。使用 Batch Normalization 可以从模型中去掉 Dropout，而不会产生过拟合。<br>High resolution classifier<br>目前业界标准的检测方法，都要先把分类器（classiﬁer）放在ImageNet上进行预训练。从 Alexnet 开始，大多数的分类器都运行在小于 $256\times 256$ 的图片上。而现在 YOLO 从 $224\times 224$ 增加到了 $448\times 448$，这就意味着网络需要适应新的输入分辨率。<br>为了适应新的分辨率，YOLO v2 的分类网络以 $448\times 448$ 的分辨率先在 ImageNet上进行微调，微调 10 个 epochs，让网络有时间调整滤波器（filters），好让其能更好的运行在新分辨率上，还需要调优用于检测的 Resulting Network。最终通过使用高分辨率，mAP 提升了4%。<br>Convolution with anchor boxes<br>YOLOV1包含有全连接层，从而能直接预测 Bounding Boxes 的坐标值。 Faster R-CNN 的方法只用卷积层与 Region Proposal Network 来预测 Anchor Box 偏移值与置信度，而不是直接预测坐标值。作者发现通过预测偏移量而不是坐标值能够简化问题，让神经网络学习起来更容易。<br>收缩网络让其运行在 $416\times 416$ 而不是 $448\times 448$。由于图片中的物体都倾向于出现在图片的中心位置，特别是那种比较大的物体，所以有一个单独位于物体中心的位置用于预测这些物体。YOLO 的卷积层采用 32 这个值来下采样图片，所以通过选择 $416\times 416$ 用作输入尺寸最终能输出一个 $13\times 13$ 的特征图。 使用 Anchor Box 会让精确度稍微下降，但用了它能让 YOLO 能预测出大于一千个框，同时 recall 达到88%，mAP 达到 69.2%。<br>Dimension clusters<br>Anchor boxes的宽高维度往往是精选的先验框（hand-picked priors）也就是说人工选定的先验框。虽然在训练过程中网络也会学习调整框的宽高维度，最终得到准确的bounding boxes。但是，如果一开始就选择了更好的、更有代表性的先验框维度，那么网络就更容易学到准确的预测位置。为了优化，在训练集的 Bounding Boxes 上跑一下 k-means聚类，来找到一个比较好的值。<br>Fine-Grained Features<br>YOLOv1在对于大目标检测有很好的效果，但是对小目标检测上，效果欠佳。为了改善这一问题，作者参考了Faster R-CNN和SSD的想法，在不同层次的特征图上获取不同分辨率的特征。作者将上层的(前面26×26)高分辨率的特征图（feature map）直接连到13×13的feature map上。把26×26×512转换为13×13×2048，并拼接在一起使整体性能提升1%。<br>Multi-Scale Training<br>和GoogleNet训练时一样，为了提高模型的鲁棒性（robust），在训练的时候使用多尺度的输入进行训练。YOLOv2 每迭代几次都会改变网络参数。每 10 个 Batch，网络会随机地选择一个新的图片尺寸，由于使用了下采样参数是 32，所以不同的尺寸大小也选择为 32 的倍数 {320，352,…,608}，最小 320x320，最大 608x608，网络会自动改变尺寸，并继续训练的过程。<br><strong>更快</strong><br>大多数目标检测的框架是建立在VGG-16上的，VGG-16在ImageNet上能达到90%的top-5，但是单张图片需要30.69 billion 浮点运算，YOLO2是依赖于DarkNet-19的结构，该模型在ImageNet上能达到91%的top-5，并且单张图片只需要5.58 billion 浮点运算，大大的加快了运算速度。<br>YOLOv2去掉YOLOv1的全连接层，同时去掉YOLO v1的最后一个池化层，增加特征的分辨率，修改网络的输入，保证特征图有一个中心点，这样可提高效率。并且是以每个anchor box来预测物体种类的。<br>作者将分类和检测分开训练，在训练分类时，以Darknet-19为模型在ImageNet上用随机梯度下降法（Stochastic gradient descent）跑了160epochs，跑完了160 epochs后，把输入尺寸从224×224上调为448×448，这时候学习率调到0.001，再跑了10 epochs， DarkNet达到了top-1准确率76.5%，top-5准确率93.3%。<br>在训练检测时，作者把分类网络改成检测网络，去掉原先网络的最后一个卷积层，取而代之的是使用3个3×3x1024的卷积层，并且每个新增的卷积层后面接1×1的卷积层，数量是我们要检测的类的数量。<br><strong>更强</strong><br>论文提出了一种联合训练的机制：使用识别数据集训练模型识别相关部分，使用分类数据集训练模型分类相关部分。<br>众多周知，检测数据集的标注要比分类数据集打标签繁琐的多，所以ImageNet分类数据集比VOC等检测数据集高出几个数量级。所以在YOLOv1中，边界框的预测其实并不依赖于物体的标签，YOLOv2实现了在分类和检测数据集上的联合训练。对于检测数据集，可以用来学习预测物体的边界框、置信度以及为物体分类，而对于分类数据集可以仅用来学习分类，但是其可以大大扩充模型所能检测的物体种类。<br>作者选择在COCO和ImageNet数据集上进行联合训练，遇到的第一问题是两者的类别并不是完全互斥的，比如”Norfolk terrier”明显属于”dog”，所以作者提出了一种层级分类方法（Hierarchical classification），根据各个类别之间的从属关系（根据WordNet）建立一种树结构WordTree，结合COCO和ImageNet建立的词树（WordTree）如下图所示：<br><img src="/images/WordTree.jpg" alt="词树结构"><br>WordTree中的根节点为”physical object”，每个节点的子节点都属于同一子类，可以对它们进行softmax处理。在给出某个类别的预测概率时，需要找到其所在的位置，遍历这个路径，然后计算路径上各个节点的概率之积。<br>在训练时，如果是检测样本，按照YOLOv2的loss计算误差，而对于分类样本，只计算分类误差。在预测时，YOLOv2给出的置信度就是 ，同时会给出边界框位置以及一个树状概率图。在这个概率图中找到概率最高的路径，当达到某一个阈值时停止，就用当前节点表示预测的类别。</p>
<h4 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h4><p>改进之处：<br>1）多尺度预测<br>2）更好的基础网络（类ResNet）和分类器darknet-53<br>多尺度预测<br>原来的YOLO v2有一个层叫：passthrough layer，假设最后提取的feature map的size是$13\times 13$，那么这个层的作用就是将前面一层的$26\times 26$的feature map和本层的$13\times 13$的feature map进行连接，有点像ResNet。这样的操作也是为了加强YOLO算法对小目标检测的精确度。这个思想在YOLO v3中得到了进一步加强，在YOLO v3中采用类似FPN的上采样（upsample）和融合做法（最后融合了3个scale，其他两个scale的大小分别是$26\times 26$和$52\times 52$），在多个scale的feature map上做检测，对于小目标的检测效果提升还是比较明显的。虽然在YOLO v3中每个网格预测3个边界框，看起来比YOLO v2中每个grid cell预测5个边界框要少，但因为YOLO v3采用了多个尺度的特征融合，所以边界框的数量要比之前多很多。<br>darknet-53<br><img src="/images/darknet53.jpg" alt="YOLOv3框图"></p>
<h3 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h3><p><a href="https://blog.csdn.net/xiaohu2022/article/details/79833786?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">SSD模型</a><br>算法特点<br>1）SSD结合了YOLO中的回归思想和Faster R-CNN中的Anchor机制，使用全图各个位置的尺度区域特征进行回归，既保持了YOLO速度快的特性，也保证了窗口预测的跟Faster-RCNN一样比较精准。<br>2）SSD的核心是在特征图上采用卷积核来预测一系列Default Bounding Boxes的类别、坐标偏移。为了提高检测准确率，SSD在不同尺度的特征图上进行预测。<br><img src="/images/SSD.png" alt="SSD网络结构"><br>一、模型结构<br>1、多尺度特征图（Multi-scale Feature Map For Detection）<br>在图像Base Network基础上，将Fc6，Fc7变为Conv6，Conv7两个卷积层，添加了一些卷积层（Conv8,Conv9,Conv10,Conv11），这些层的大小逐渐减小，可以进行多尺度预测。<br>2、卷积预测器（Convolutional Predictors For Detection）<br>每个新添加的卷积层和之前的部分卷积层，使用一系列的卷积核进行预测。对于一个大小为$m\times n$，$p$通道的卷积层，使用$3\times 3$的$p$通道卷积核作为基础预测元素进行预测，在某个位置上预测出一个值，该值可以是某一类别的得分，也可是相对于Default Bounding Boxes的偏移量，并且在图像中每个位置都将产生一个值。<br>3、默认框和比例（Default Boxes And Aspect Ratio）<br>在特征图的每个位置预测K个Box，对于每个Box，预测C个类别得分，以及相对于Default Bounding Box的4个偏移值，这样需要$(C+4)\times k$个预测器，在$m\times n$的特征图上将产生$(C+4)\times k\times m\times n$个预测值。这里，Default Bounding Box类似于Faster R-CNN中Anchor是，下图所示。<br><img src="/images/SSD2.png" alt="SSD默认框"><br>二、模型训练<br>1、监督学习的训练关键是人工标注的label，对于包含Default Box（在Faster R-CNN中叫做Anchor）的网络模型（如:YOLO,Faster R-CNN,MultiBox）关键点就是如何把标注信息（Ground True Box,Ground True Category）映射到（Default Box）上。<br>2、给定输入图像以及每个物体的Ground Truth，首先找到每个Ground True Box对应的Default Box中IOU最大的作为正样本。然后，在剩下的Default Box中找到那些与任意一个Ground truth Box的IOU大于0.5的Default Box作为正样本。其他的作为负样本（每个Default Box要么是正样本Box要么是负样本Box）。如上图中，两个Default Box与猫匹配，一个与狗匹配。在训练过程中，采用Hard Negative Mining 的策略（根据Confidence Loss对所有的Box进行排序，使正负例的比例保持在1:3） 来平衡正负样本的比率。<br>3、损失函数<br>与Faster-RCNN中的RPN是一样的，不过RPN是预测Box里面有Object或者没有，没有分类，SSD直接用的Softmax分类。Location的损失，还是一样，都是用Predict box和Default Box/Anchor的差 与Ground Truth Box和Default Box/Anchor的差进行对比，求损失。<br><img src="/images/SSDloss.png" alt="SSD loss求解"><br>其中，$x_{i,j}^p=1$表示 第i个Default Box与类别p的第j个Ground Truth Box相匹配，否则若不匹配的话，则$x_{i,j}^p=0$<br>4、Default Box的生成<br>对每一张特征图，按照不同的大小（Scale） 和长宽比（Ratio）生成生成k个默认框（Default Boxes）。<br>（1）Scale：每一个Feature Map中Default Box的尺寸大小计算如下：</p>
<script type="math/tex; mode=display">s_k=s_{min}+\frac{s_{max}-s_{min}}{m-1}(k-1), \quad k\in [1, m]</script><p>其中，$S_{min}$取值0.2，$s_{max}$取值0.95，意味着最低层的尺度是0.2，最高层的尺度是0.95。<br>（2）Ratio：使用不同的Ratio值$a_=1,2,3,\frac{1}{2},\frac{1}{3}$计算Default Box的宽度和高度：$w_k^a=s_k\sqrt{a_r},h_k^a=s_k/\sqrt{a_r}$。另外对于Ratio=1的情况，还增加了一个Default Box，这个Box的Scale为$s’_k=\sqrt{s_ks_k+1}$。也就是总共有6种不同的Default Box。<br>（3）Default Box中心：每个Default Box的中心位置设置成$(\frac{i+0.5}{|f_k|},\frac{j+0.5}{|f_k|})$，其中$|f_k|$表示第k个特征图的大小$i,j\in[0,|f_k|]$。<br>5）Data Augmentation：为了模型更加鲁棒，需要使用不同尺寸的输入和形状，作者对数据进行了多种方式的随机采样。</p>
<h3 id="mobile-net"><a href="#mobile-net" class="headerlink" title="mobile net"></a>mobile net</h3><h2 id="图像分割"><a href="#图像分割" class="headerlink" title="图像分割"></a>图像分割</h2><h3 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h3><h3 id="UNet"><a href="#UNet" class="headerlink" title="UNet"></a>UNet</h3><h2 id="目标追踪"><a href="#目标追踪" class="headerlink" title="目标追踪"></a>目标追踪</h2><h3 id="多目标跟踪介绍"><a href="#多目标跟踪介绍" class="headerlink" title="多目标跟踪介绍"></a>多目标跟踪介绍</h3><p>多目标跟踪，即MOT（Multi-Object Tracking），顾名思义，就是在一段视频中同时跟踪多个目标。MOT主要应用场景是安防监控和自动驾驶等，这些场景中我们往往需要对众多目标同时进行追踪。<br>而由于是多目标，自然就会产生新目标进入与旧目标消失的问题，这就是与单目标跟踪算法区别最大的一点。而由于这一点区别，也就导致跟踪策略的不同。在单目标跟踪中，我们往往会使用给定的初始框，在后续视频帧中对初始框内的物体进行位置预测。而多目标跟踪算法，大部分都是不考虑初始框的，原因就是上面的目标消失与产生问题。取而代之，在多目标跟踪领域常用的跟踪策略是TBD（Tracking-by-Detecton），又或者也可叫DBT（Detection-Based-Tracking）。即在每一帧进行目标检测，再利用目标检测的结果来进行目标跟踪，这一步我们一般称之为数据关联（Data Assoiation）。<br>这里自然引出了多目标跟踪算法的一种分类：TBD（Tracking-by-Detecton）与DFT（Detection-Free Tracking），也即基于检测的多目标跟踪与基于初始框无需检测器的多目标跟踪。基于初始化帧的跟踪，在视频第一帧中选择你的目标，之后交给跟踪算法去实现目标的跟踪。这种方式基本上只能跟踪你第一帧选中的目标，如果后续帧中出现了新的物体目标，算法是跟踪不到的。这种方式的优点是速度相对较快。缺点很明显，不能跟踪新出现的目标。基于目标检测的跟踪，在视频每帧中先检测出来所有感兴趣的目标物体，然后将其与前一帧中检测出来的目标进行关联来实现跟踪的效果。这种方式的优点是可以在整个视频中跟踪随时出现的新目标。TBD则是目前学界业界研究的主流。<br><img src="/images/TBDvsDFT.jpg" alt="TBD与DFT对比"><br>不得不提的是另一种多目标跟踪算法的分类方式：在线跟踪（Online）与离线跟踪（Offline）。上文提到，大家往往会使用数据关联来进行多目标跟踪。而数据关联的效果，与你能使用的数据是有着直接的关系的。在Online跟踪中，我们只能使用当前帧及之前帧的信息来进行当前帧的跟踪。而在Offline跟踪中则没有了这个限制，我们对每一帧的预测，都可以使用整个视频的信息，这样更容易获得一个全局最优解。两种方式各有优劣，一般视应用场合而定，Offline算法的效果一般会优于Online算法。而介于这两者之间，还有一种称之为Near-Online的跟踪方式，即可以部分利用未来帧的信息。下图形象解释了Online与Offline跟踪的区别。<br><img src="/images/OnlineAndOffline.jpg" alt="Online与Offline区别"></p>
<h3 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h3><p>Trajectory（轨迹）：一条轨迹对应这一目标在一段时间内的位置序列。<br>Tracklet（轨迹段）：形成Trajectory过程中的轨迹片段。完整的Trajectory是由属于同一物理目标的Tracklets构成。<br>ID switch（ID 切换）：又称ID sw.。对于同一个目标，由于跟踪算法误判，导致其ID发生切换的次数。跟踪算法中理想的ID switch应该为0.<br>对于多目标跟踪，最主要的评价指标就是MOTA。这个指标综合了三点因素：FP、FN、IDsw.。FP即False Postive，为误检测的目标数量；FN即False Negetive，为未检出的真实目标数量；IDsw.即同一目标发生ID切换的次数。</p>
<script type="math/tex; mode=display">MOTA=1-\frac{(FN+FP+IDSW)}{GT}\ \in(-\infty,1]</script><script type="math/tex; mode=display">MOTP=\frac{\sum_{t,i}d_{t,i}}{\sum_tc_t}</script><p>其中$c_t$表示帧t中的匹配数，并且$d_{t,i}$是假设i与分配的真实对象之间的边界框重叠。此度量标准很少考虑有关跟踪的信息，而侧重于检测的质量。</p>
<h3 id="SORT"><a href="#SORT" class="headerlink" title="SORT"></a>SORT</h3><p>现在多目标跟踪算法的效果，与目标检测的结果息息相关。在实际工程中，为了提高多目标跟踪的效果，可以从检测器入手，跟踪效果也会水涨船高。<br>SORT采用的是在线跟踪的方式，不使用未来帧的信息。在保持100fps以上的帧率的同时，也获得了较高的MOTA（在当时16年的结果中）。<br>多目标跟踪中SORT算法思想理解流程：<br>在跟踪之前，对所有目标已经完成检测，实现了特征建模过程。<br>1）对第一帧使用目标检测模型进行目标检测，得到第一帧中所有目标的分类和位置（假设有M个目标），并标注一个独有id。对每个目标初始化卡尔曼滤波跟踪器，预测每个目标在下一帧的位置；<br>2）对第二帧使用目标检测模型进行目标检测，得到第二帧中所有目标的分类和位置（假设有N个目标），求第一帧M个目标和第二帧N个目标两两目标之间的IOU，建立代价矩阵，使用匈牙利匹配算法得到IOU最大的唯一匹配（数据关联部分），再去掉匹配值小于iou_threshold的匹配对；<br>3）用第二帧中匹配到的目标的位置去更新卡尔曼跟踪器，计算第二帧时的卡尔曼增益Kk，状态估计值xk，估计误差协方差Pk。并输出状态估计值xk用来计算下一帧中的预测位置。对于本帧中没有匹配到的目标重新初始化卡尔曼滤波跟踪器；<br>后面每一帧图像都按第一帧和第二帧的做法进行类似处理即可。其中，卡尔曼跟踪器联合了历史跟踪记录，调节历史box与本帧box的残差，更好的匹配跟踪id。<br>匈牙利算法是一种寻找二分图的最大匹配的算法，在多目标跟踪问题中可以简单理解为寻找前后两帧的若干目标的匹配最优解的一种算法。而卡尔曼滤波可以看作是一种运动模型，用来对目标的轨迹进行预测，并且使用确信度较高的跟踪结果进行预测结果的修正。<br>SORT在以往二阶段匹配算法的基础上进行了创新。以往二阶段匹配算法是先使用匈牙利算法对相邻帧之间的目标进行匹配生成很多tracklets，之后使用这些tracklets进行二次匹配，以解决遮挡等问题引起的轨迹中断。但这种二阶段匹配方式弊端也很明显，因为这种方式先天地要求必须以Offline的方法进行跟踪，而无法做到Online。SORT将这种二阶段匹配算法改进为了一阶段方法，并且可以在线跟踪。具体而言，SORT引入了线性速度模型与卡尔曼滤波来进行位置预测，在无合适匹配检测框的情况下，使用运动模型来预测物体的位置。在数据关联的阶段，SORT使用的依旧是匈牙利算法逐帧关联，不过作者还引入了IOU（Intersection-Over-Union）距离。不过SORT用的是带权重的匈牙利算法，其实就是KM算法，用IOU距离作为权重（也叫cost矩阵）。作者代码里是直接用sklearn的linear_assignment实现。并且当IOU小于一定数值时，不认为是同一个目标，理论基础是视频中两帧之间物体移动不会过多。作者在代码中选取的阈值是0.3。<br>预测模型（卡尔曼滤波器）<br>作者近似地认为目标的不同帧间地运动是和其他物体及相机运动无关的线性运动。每一个目标的状态可以表示为：</p>
<script type="math/tex; mode=display">x=[u,v,s,r,\dot u,\dot v,\dot s]^T</script><p>其中u和v分别代表目标的中心坐标，而s和r分别代表目标边界框的比例（面积）和长宽比，长宽比被认为是常数，需要保持不变。<br>当进行目标关联时，使用卡尔曼滤波器，用上一帧中目标的位置信息预测下一帧中这个目标的位置。若上一帧中没有检测到下一帧中的某个目标，则对于这个目标，重新初始化一个新的卡尔曼滤波器。关联完成后，使用新关联的下一帧中该目标的位置来更新卡尔曼滤波器。<br>数据关联（匈牙利匹配）<br>SORT算法中的代价矩阵为上一帧的M个目标与下一帧的N个目标两两目标之间的IOU。当然，小于指定IOU阈值的指派结果是无效的（源码中阈值设置为0.3）。<br>此外，作者发现使用IOU能够解决目标的短时被遮挡问题。这是因为目标被遮挡时，检测到了遮挡物，没有检测到原有目标，假设把遮挡物和原有目标进行了关联。那么在遮挡结束后，因为在相近大小的目标IOU往往较大，因此很快就可以恢复正确的关联。这是建立在遮挡物面积大于目标的基础上的。</p>
<h3 id="deep-SORT"><a href="#deep-SORT" class="headerlink" title="deep SORT"></a>deep SORT</h3><p>之前的SORT算法使用简单的卡尔曼滤波处理逐帧数据的关联性以及使用匈牙利算法进行关联度量，这种简单的算法在高帧速率下获得了良好的性能。但由于SORT忽略了被检测物体的表面特征，因此只有在物体状态估计不确定性较低是才会准确，在Deep SORT中，我们使用更加可靠的度量来代替关联度量，并使用CNN网络在大规模行人数据集进行训练，并提取特征，已增加网络对遗失和障碍的鲁棒性。<br>状态估计<br>使用一个8维空间去刻画轨迹在某时刻的状态：</p>
<script type="math/tex; mode=display">(u,v,\gamma,h,\dot x,\dot y,\dot\gamma,\dot h)</script><p>使用一个kalman滤波器预测更新轨迹，该卡尔曼滤波器采用匀速模型和线性观测模型。通过卡尔曼估计对u,v,r,h进行估计，u，v是物体中心点的位置，r是长宽比，h是高。运动估计对于运动状态变化不是很剧烈和频繁的物体能取得比较好的效果。其观测变量为：</p>
<script type="math/tex; mode=display">(u,v,\gamma,h)</script><p>轨迹处理<br>对于每一个追踪目标，都有一个阈值ak用于记录轨迹从上一次成功匹配到当前时刻的时间（即连续没有匹配的帧数），我们称之为轨迹。当该值大于提前设定的阈值Amax则认为该轨迹终止，直观上说就是长时间匹配不上的轨迹则认为该轨迹已经结束。<br>在匹配时，对于没有匹配成功的目标都认为可能产生新的轨迹。但由于这些检测结果可能是一些错误警告，所以对这种情形新生成的轨迹标注状态’tentative’，然后观查在接下来的连续若干帧（论文中是3帧）中是否连续匹配成功，是的话则认为是新轨迹产生，标注为’confirmed’，否则则认为是假性轨迹,状态标注为’deleted’。<br>分配问题<br>在SORT中，我们直接使用匈牙利算法去解决预测的Kalman状态和新来的状态之间的关联度，现在我们需要将目标运动和表面特征信息相结合，通过融合这两个相似的测量指标。<br>Motion Metric<br>使用马氏距离来评测预测的Kalman状态和新来的状态：</p>
<script type="math/tex; mode=display">d^{(1)}(i,j)=(d_j-y_i)^TS_i^{-1}(d_j-y_i)</script><p>表示第j个detection和第i条轨迹之间的运动匹配度，其中$S_i$是轨迹由kalman滤波器预测得到的在当前时刻观测空间的协方差矩阵， $y_i$是轨迹在当前时刻的预测观测量， $d_i$时第j个detection的状态$(u,v,r,h)$<br>考虑到运动的连续性，可以通过该马氏距离对detections进行筛选，文中使用卡方分布的0.95分位点作为阈值$ t^(1)=0.4877$,我们可以定义一个门限函数。</p>
<script type="math/tex; mode=display">b_{i,j}^{(1)}=\mathbf{1}[d^{(1)}(i,j)\leq t^{(1)}]</script><p>Appearance Metric<br>当目标运动不确定性较低时，马氏距离是一个很好的关联度量，但在实际中，如相机运动时会造成马氏距离大量不能匹配，也就会使这个度量失效，因此，我们整合第二个度量标准，对每一个BBox检测框$d_j$我们计算一个表面特征描述子 $r_j,|r_j|=1$ , 我们会创建一个gallery用来存放最新的$L_k=100$个轨迹的描述子，即$R_k=\begin{Bmatrix}r_k^{(i)}\end{Bmatrix}_{k=1}^{L_k}$，然后我们使用第i个轨迹和第j个轨迹的最小余弦距离作为第二个衡量尺度！</p>
<script type="math/tex; mode=display">d^(2)(i,j)=min{1-r_j^Tr_k^{(i)}|r_k^(i)\in R_i}</script><p>当然，我们也可以用一个门限函数来表示</p>
<script type="math/tex; mode=display">b_{i,j}^{(2)}=\mathbf{d^{(2)}(i,j)\le t^{(2)}}</script><p>接着，我们把这两个尺度相融合为：</p>
<script type="math/tex; mode=display">c_{i,j}=\lambda d^{(1)}(i,j)+(1-\lambda)d^{(2)}(i,j)</script><script type="math/tex; mode=display">b_{i,j}=\prod_{m=1}^2b_{i,j}^{(m)}</script><p>总之，距离度量对于短期的预测和匹配效果很好，而表观信息对于长时间丢失的轨迹而言，匹配度度量的比较有效。超参数的选择要看具体的数据集，比如文中说对于相机运动幅度较大的数据集，直接不考虑运动匹配程度。<br>级联匹配<br>如果一条轨迹被遮挡了一段较长的时间，那么在kalman滤波器的不断预测中就会导致概率弥散。那么假设现在有两条轨迹竞争同一个目标，那么那条遮挡时间长的往往得到马氏距离更小，使目标倾向于匹配给丢失时间更长的轨迹，但是直观上，该目标应该匹配给时间上最近的轨迹。<br>导致这种现象的原因正是由于kalman滤波器连续预测没法更新导致的概率弥散。假设本来协方差矩阵是一个正态分布，那么连续的预测不更新就会导致这个正态分布的方差越来越大，那么离均值欧氏距离远的点可能和之前分布中离得较近的点获得同样的马氏距离值。<br>所以本文中才引入了级联匹配的策略将遮挡时间按等级分层，遮挡时间越小的匹配等级更高，即更容易被匹配。<br>首先是得到追踪框集合T和检测框集合D，设置最大的Amax为轨迹最大允许丢失匹配的帧数。通过计算上面的评价指标（两种度量的加权和）得到成本矩阵，再通过级联条件，设定阈值分别对外观和位置因素进行计算，满足条件则返回1，否则返回0。然后初始化匹配矩阵为空，初始化未匹配矩阵等于D。通过匈牙利算法，对于每个属于追踪框集合的元素T，在检测框里面查找成本最低且满足阈值过滤条件的检测框作为匹配结果，同时更新匹配矩阵和非匹配矩阵。<br>在匹配的最后阶段还对unconfirmed和age=1的未匹配轨迹进行基于IOU的匹配。这可以缓解因为表观突变或者部分遮挡导致的较大变化。当然有好处就有坏处，这样做也有可能导致一些新产生的轨迹被连接到了一些旧的轨迹上。但这种情况较少。<br>深度表观描述子<br>预训练的网络时一个在大规模ReID数据集上训练得到的，这个ReID数据集包含1261个人的1100000幅图像，使得学到的特征很适合行人跟踪。<br>然后使用该预训练网络作为基础网络，构建wide ResNet，用来提取bounding box的表观特征。</p>
<h3 id="匈牙利算法"><a href="#匈牙利算法" class="headerlink" title="匈牙利算法"></a>匈牙利算法</h3><p>（待补充）</p>
<h3 id="卡尔曼滤波器"><a href="#卡尔曼滤波器" class="headerlink" title="卡尔曼滤波器"></a>卡尔曼滤波器</h3><p>（待补充）</p>
<h2 id="姿态估计"><a href="#姿态估计" class="headerlink" title="姿态估计"></a>姿态估计</h2><p><a href="https://zhuanlan.zhihu.com/p/102457223" target="_blank" rel="noopener">姿态估计综述</a></p>
<h3 id="OpenPose"><a href="#OpenPose" class="headerlink" title="OpenPose"></a>OpenPose</h3><h2 id="注意机制"><a href="#注意机制" class="headerlink" title="注意机制"></a>注意机制</h2><h3 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a>self-attention</h3><p>普通卷积将特征图的每个位置作为中心点，对该位置及其周围的位置进行加权求和，得到新的特征图上该位置对应的滤波结果，这一操作可以有效提取图片的局部信息。随着网络加深，卷积层不断堆叠，每个位置的感受域也越来越大，网络提取到的特征也逐渐由一些low-level的特征，如颜色、纹理，转变到一些high-level的结构信息。但是，简单通过加深网络来获取全局感受域，所带来的计算开销是很大的，并且更深的网络会带来更大的优化难度。<br>Self-attention操作可以有效地捕获不同位置之间的long-range dependency，每个位置的特征都由所有位置的加权求和得到，这里的权重就是attention weight，使得每个位置都可以获取全局的感受域。与传统的注意力机制不同，self-attention计算的是同一张图片中不同位置之间的注意力分配，从而提取该图片的特征。Self-attention机制在视觉任务解决了卷积神经网络的局部感受野问题，使得每个位置都可以获得全局的感受野。不过，由于在视觉任务中，像素数目极多，利用所有位置来计算每个位置的attention会导致巨大的计算和显存开销；另一方面，由于self-attention简单将图像当成一个序列进行处理，没有考虑不同位置之间的相对位置关系，使得所得到的attention丧失了图像的结构信息。<br>在NLP任务中，对于Attention机制的整个计算过程，可以总结为以下三个过程：<br>首先根据 Query 与 Key 计算两者之间的相似性或相关性， 即 socre 的计算。通过一个 softmax 来对值进行归一化处理获得注意力权重值， 即$a_{i,j}$的计算。最后通过注意力权重值对value进行加权求和， 即$c_{i,j}$ 的计算。</p>
<script type="math/tex; mode=display">\alpha_{i,j} = \frac{e^{score(Query,Key(j))}}{\sum_{k=1}^te^{score(Query,Key(k))}}</script><script type="math/tex; mode=display">c_i=\sum_{j=1}^n\alpha_{i,j}h_j</script><p>self attention本质上是为序列中每个元素都分配一个权重系数，这也可以理解为软寻址。如果序列中每一个元素都以(K,V)形式存储，那么attention则通过计算Q和K的相似度来完成寻址。Q和K计算出来的相似度反映了取出来的V值的重要程度，即权重，然后加权求和就得到了attention值。<br>引入Self Attention后会更容易捕获句子中长距离的相互依赖的特征，因为如果是RNN或者LSTM，需要依次序序列计算，对于远距离的相互依赖的特征，要经过若干时间步步骤的信息累积才能将两者联系起来，而距离越远，有效捕获的可能性越小。<br>但是Self Attention在计算过程中会直接将句子中任意两个单词的联系通过一个计算步骤直接联系起来，所以远距离依赖特征之间的距离被极大缩短，有利于有效地利用这些特征。除此外，Self Attention对于增加计算的并行性也有直接帮助作用。这是为何Self Attention逐渐被广泛使用的主要原因。</p>
<h3 id="scale-attention"><a href="#scale-attention" class="headerlink" title="scale attention"></a>scale attention</h3><p>视觉任务中另一类注意力机制为scale attention。与self-attention不同，scale attention基于每个位置本身的响应。就分类任务而言，每个位置的响应越大，则其对于最终的分类结果影响越大，那么这个位置本身的重要性就越强。根据响应大小有选择地对特征图进行强化或抑制，就可以在空间（或其他维度）上达到分配attention的目的。例如SENet，就相当于channel-wise的attention。这一类注意力机制仅仅基于图像中每个位置本身，对显著区域进行增强，非显著区域进行抑制，比self-attention机制更接近与人类视觉系统的注意力机制。</p>
<h4 id="Bottom-up-and-top-down形式的scale-attention"><a href="#Bottom-up-and-top-down形式的scale-attention" class="headerlink" title="Bottom-up and top-down形式的scale attention"></a>Bottom-up and top-down形式的scale attention</h4><p>在分类网络中，网络深层比浅层更关注于被分类的物体，也就是图片的主体内容，这是因为，深层网络具有更大的视野域，可以看到更广的范围；而浅层网络只能看到每个位置及其邻域。因此，如果将网络较深层的信息作为一种mask，作用在较浅层的特征上，就能更好的增强浅层特征中对于最终分类结果有帮助的特征，抑制不相关的特征。如图5所示，将attention作为mask作用在原来特征上，得到的输出就会更加集中在对分类有帮助的区域上。<br><img src="/images/attention1.png" alt="attention作用机制"><br>文章提出一种bottom-up top-down的前向传播方法来得到图片的attention map，并且将其作用在原来的特征上，使得输出的特征有更强的区分度。图6展示了这种attention的计算方式。由于更大的视野域可以看到更多的内容，从而获得更多的attention信息，因此，作者设计了一条支路，通过快速下采样和上采样来提前获得更大的视野域，将输出的特征进行归一化后作用在原有的特征上，将作用后的特征以残差的形式加到原来的特征上，就完成了一次对原有特征的注意力增强。文章还提出了一个堆叠的网络结构，即residual attention network，中间多次采用这种attention模块进行快速下采样和上采样。<br><img src="/images/attention2.png" alt="Bottom-up注意力机制"></p>
<h4 id="Squeeze-and-excite形式的注意力"><a href="#Squeeze-and-excite形式的注意力" class="headerlink" title="Squeeze and excite形式的注意力"></a>Squeeze and excite形式的注意力</h4><p>与residual attention不同，squeeze-and-excite通过global pooling来获得全局的视野域，并将其作为一种指导的信息，也就是attention信息，作用到原来的特征上。<br>SENet提出了channel-wise的scale attention。特征图的每个通道对应一种滤波器的滤波结果，即图片的某种特定模式的特征。对于最终的分类结果，这些模式的重要性是不同的，有些模式更重要，因此其全局的响应更大；有些模式不相关，其全局的响应较小。通过对不同通道的特征根据其全局响应值，进行响应的增强或抑制，就可以起到在channel上进行注意力分配的作用。其网络结构如图7所示，首先对输入特征进行global pooling，即为squeeze阶段，对得到的特征进行线性变换，即为excite阶段，最后将变换后的向量通过广播，乘到原来的特征图上，就完成了对不同通道的增强或抑制。<br><img src="/images/SEblock.jpg" alt="SE Bolck结构"><br>作为SENet的一个延续，convolutional block attention module （CBAM）将SENet中提出的channel attention扩展到了spatial attention上，通过一个串行的支路，将channel attention和spatial attention连接起来，对原特征进行增强。其网络结构如图9所示，首先进行channel attention，对通道进行增强和抑制，这一过程与SENet的操作完全相同，然后在每个位置上进行通道的squeeze和excite操作，得到与原特征图一样分辨率的1通道spatial attention，再作用到原特征图上，即为spatial attention操作。最终的输出即为spatial attention module的输出。相比SENet，CBAM带来的性能提升有限，在该模块中其主要作用的还是channel attention模块。<br><img src="/images/attention3.png" alt="CBAM网络结构"></p>
<h2 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h2><h1 id="序列神经网络"><a href="#序列神经网络" class="headerlink" title="序列神经网络"></a>序列神经网络</h1><h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p>RNN相对传统的ANN网络结构实现了信息的保留，具有一定的记忆功能。可以将过去的信息应用到当前的任务中。<br>下图展示了RNN的闭环结构和开环结构<br><img src="/images/RNN.png" alt="闭环和开环结构"><br>完成当前任务如果仅仅需要短期的信息而不需要长期的信息可以使用RNN。但是如果任务需要更多的上下文信息，仅仅依靠少量的过去信息无法完成准确的预测。也就是过去信息和当前任务存在较大的跳动，甚至需要未来的信息才能完成预测。这时经典的RNN就无法满足需要,而需要特殊的时间序列模型LSTM。LSTMs 就是用来解决长期依赖问题，这类模型可以记住长期信息。<br><img src="/images/RNN2.png" alt="RNN和LSTM结构"><br>典的RNN模型中的激活函数可能就是一个简单的tanh函数，但是LSTMs引入了四个门结构，具有增加或者移除信息状态的功能。门限可以有选择的让信息通过，它是由sigmoid神经网络层和pointwise乘法操作构成的。sigmoid层输入数值0-1 代表可以通过的比例，输入为0时代表不允许通过，输出为1时代表允许全部通过。<br>1）forget gate 遗忘门<br><img src="/images/latm1.png" alt="遗忘门结构"><br>遗忘门输入是$h_{t-1}$，输出是$f_t$，$f_t$作用于$C_{t-1}$。当$f_t$为1时，代表保留该值，当$f_t$为0时，代表完全舍去该值。<br>2）input gate 输入门<br><img src="images/lstm2.png" alt="输入门结构"><br>存储什么样的新信息包括两步，第一步输入门决定哪些值可以更新，第二步tanh层创造候选向量。$i_t$是sigmoid函数输出结果表示是否产生输入，其取值范围是0-1。$\tilde{C_t}$是新产生的候选向量。忘记门$f_t$乘$C_{t-1}$：忘掉决定忘掉的早期信息，其结果加上$i_t * \tilde{C_t}$，候选向量通过$i_t$缩放后表示多大程度上更新状态值。<br><img src="/images/lstm3.png" alt="遗忘门和输入门组合"><br>通过忘记门和输入门的组合可以表达出这样的信息：多大程度上忘记旧的信息以及多大程度上更新新的信息。<br>3）Output gate 输出门<br><img src="/images/lstm4.png" alt="输出门"><br>首先sigmoid函数决定输出的缩放比例$o_t$，然后cell 状态通过tanh函数，其结果与$o_t$相乘。</p>
<h3 id="RNN、LSTM、GRU区别"><a href="#RNN、LSTM、GRU区别" class="headerlink" title="RNN、LSTM、GRU区别"></a>RNN、LSTM、GRU区别</h3><p>RNN引入了循环的概念，但是在实际过程中却出现了初始信息随时间消失的问题，即长期依赖（Long-Term Dependencies）问题，所以引入了LSTM。<br>LSTM：因为LSTM有进有出且当前的cell informaton是通过input gate控制之后叠加的，RNN是叠乘，因此LSTM可以防止梯度消失或者爆炸。<br>GRU是LSTM的变体，将忘记门和输入们合成了一个单一的更新门。<br><img src="/images/GRU.jpg" alt="GRU结构"></p>
<h3 id="LSTM防止梯度消失和爆炸"><a href="#LSTM防止梯度消失和爆炸" class="headerlink" title="LSTM防止梯度消失和爆炸"></a>LSTM防止梯度消失和爆炸</h3><p>LSTM用加和的方式取代了乘积，使得很难出现梯度弥散。但是相应的更大的几率会出现梯度爆炸，但是可以通过给梯度加门限解决这一问题。</p>
<h2 id="TCN"><a href="#TCN" class="headerlink" title="TCN"></a>TCN</h2><p>时序问题的建模大家一般习惯性的采用循环神经网络（RNN）来建模，这是因为RNN天生的循环自回归的结构是对时间序列的很好的表示。传统的卷积神经网络一般认为不太适合时序问题的建模，这主要由于其卷积核大小的限制，不能很好的抓取长时的依赖信息。一种特殊的卷积神经网络——时序卷积网络（Temporal convolutional network， TCN）与多种RNN结构相对比，发现在多种任务上TCN都能达到甚至超过RNN模型。</p>
<h3 id="因果卷积-Causal-Convolution"><a href="#因果卷积-Causal-Convolution" class="headerlink" title="因果卷积(Causal Convolution)"></a>因果卷积(Causal Convolution)</h3><p><img src="/images/causalConv.jpg" alt="因果卷积"><br>因果卷积可以用上图直观表示。 即对于上一层t时刻的值，只依赖于下一层t时刻及其之前的值。和传统的卷积神经网络的不同之处在于，因果卷积不能看到未来的数据，它是单向的结构，不是双向的。也就是说只有有了前面的因才有后面的果，是一种严格的时间约束模型，因此被成为因果卷积。</p>
<h3 id="膨胀卷积-Dilated-Convolution"><a href="#膨胀卷积-Dilated-Convolution" class="headerlink" title="膨胀卷积(Dilated Convolution)"></a>膨胀卷积(Dilated Convolution)</h3><p> 单纯的因果卷积还是存在传统卷积神经网络的问题，即对时间的建模长度受限于卷积核大小的，如果要想抓去更长的依赖关系，就需要线性的堆叠很多的层。为了解决这个问题，研究人员提出了膨胀卷积。如下图所示。<br> <img src="/images/dilatedConv.jpg" alt="膨胀卷积"><br> 和传统卷积不同的是，膨胀卷积允许卷积时的输入存在间隔采样，采样率受图中的d控制。 最下面一层的d=1，表示输入时每个点都采样，中间层d=2，表示输入时每2个点采样一个作为输入。一般来讲，越高的层级使用的d的大小越大。所以，膨胀卷积使得有效窗口的大小随着层数呈指数型增长。这样卷积网络用比较少的层，就可以获得很大的感受野。</p>
<script type="math/tex; mode=display">F(s)=\sum_{i=0}^{k-1}f(i)\cdot x_{s-d\cdot i}</script><p> <a href="https://zhuanlan.zhihu.com/p/50369448" target="_blank" rel="noopener">空洞卷积</a></p>
<h3 id="残差连接-Residual-Connections"><a href="#残差连接-Residual-Connections" class="headerlink" title="残差连接(Residual Connections)"></a>残差连接(Residual Connections)</h3><p> <img src="/images/residualConnection.jpg" alt="残差连接"><br> 残差链接被证明是训练深层网络的有效方法，它使得网络可以以跨层的方式传递信息。本文构建了一个残差块来代替一层的卷积。如上图所示，一个残差块包含两层的卷积和非线性映射，在每层中还加入了WeightNorm和Dropout来正则化网络。</p>
<h3 id="TCN优点和缺点"><a href="#TCN优点和缺点" class="headerlink" title="TCN优点和缺点"></a>TCN优点和缺点</h3><p>优点<br>（1）并行性。当给定一个句子时，TCN可以将句子并行的处理，而不需要像RNN那样顺序的处理。<br>（2）灵活的感受野。TCN的感受野的大小受层数、卷积核大小、扩张系数等决定。可以根据不同的任务不同的特性灵活定制。<br>（3）稳定的梯度。RNN经常存在梯度消失和梯度爆炸的问题，这主要是由不同时间段上共用参数导致的，和传统卷积神经网络一样，TCN不太存在梯度消失和爆炸问题。<br>（4）内存更低。RNN在使用时需要将每步的信息都保存下来，这会占据大量的内存，TCN在一层里面卷积核是共享的，内存使用更低。<br>缺点<br>（1）TCN 在迁移学习方面可能没有那么强的适应能力。这是因为在不同的领域，模型预测所需要的历史信息量可能是不同的。因此，在将一个模型从一个对记忆信息需求量少的问题迁移到一个需要更长记忆的问题上时，TCN 可能会表现得很差，因为其感受野不够大。<br>（2）论文中描述的TCN还是一种单向的结构，在语音识别和语音合成等任务上，纯单向的结构还是相当有用的。但是在文本中大多使用双向的结构，当然将TCN也很容易扩展成双向的结构，不使用因果卷积，使用传统的卷积结构即可。<br>（3）TCN毕竟是卷积神经网络的变种，虽然使用扩展卷积可以扩大感受野，但是仍然受到限制，相比于Transformer那种可以任意长度的相关信息都可以抓取到的特性还是差了点。TCN在文本中的应用还有待检验。</p>
<h1 id="图网络"><a href="#图网络" class="headerlink" title="图网络"></a>图网络</h1><p><a href="http://bbs.cvmart.net/articles/281/cong-cnn-dao-gcn-de-lian-xi-yu-qu-bie-gcn-cong-ru-men-dao-jing-fang-tong-qi" target="_blank" rel="noopener">图卷积网络</a><br>卷积是通过计算中心像素点以及相邻像素点的加权和来构成feature map实现空间特征提取。图卷积主要分为空域图卷积和谱域图卷积。<br>空域图卷积，其思想是将每个节点与其相邻节点的特征进行加权，使用领域来确定每个节点的加权平均范围（卷积范围），使用label策略来为参与卷积的节点分配权重，其层间传播矩阵为：</p>
<script type="math/tex; mode=display">X^{l+1}=\delta(W^lX^lA)</script><p>其中A是邻接矩阵，包含邻居节点信息，A中节点相连为1否则为0。通过矩阵乘法可以使得每个节点和其邻居节点特征进行聚合。W是权重矩阵，主要是对边进行加权。这样的传播方法是没有对邻接矩阵进行归一化，这使得A在传播过程中不断扩张（每次乘A会导致特征值越来越大）。此外，由于A对角线元素为0，每个节点自身在进行卷积时不能将自己的特征计算在内。因此，在空域图卷积中引入了谱域图卷积的思想来解决这两个问题。谱域图卷积主要借助图的拉普拉斯矩阵和傅里叶变换来进行的，最后得到的层间传播公式为：</p>
<script type="math/tex; mode=display">X^{l+1}=\delta(\land^{(-\frac{1}{2})}(A+I)\land^{(-\frac{1}{2})}X^lW^l)</script><p>其中矩阵$\land$用于对扩展邻接矩阵(A+I)进行归一化。<br>首先和单纯的空域图卷积相比，对邻接矩阵做了自环操作(A+I)，通过加单位矩阵的方法，使得中心节点自身的特征能参与卷积。然后通过对邻接矩阵实现归一化，解决了A随层数不断增长的问题。其他的部分就和公式(1)完全一致了。因此我们可以说公式(2)是利用谱域图卷积的思想来弥补了空域图卷积的缺点，本质上是两种卷积思想的结合。</p>
<h1 id="图像处理方法"><a href="#图像处理方法" class="headerlink" title="图像处理方法"></a>图像处理方法</h1><h2 id="Canny边缘检测"><a href="#Canny边缘检测" class="headerlink" title="Canny边缘检测"></a>Canny边缘检测</h2><p>Canny边缘检测是通过灰度值的变化（梯度）来判断边缘信息的。主要包含以下四个步骤：<br>1）高斯滤波<br>滤波的主要目的是降噪，一般的图像处理算法都需要先进行降噪。而高斯滤波主要使图像变得平滑（模糊），同时也有可能增大了边缘的宽度。<br>对于一个位置（m,n）的像素点，其灰度值（这里只考虑二值图）为f(m,n)。那么经过高斯滤波后的灰度值将变为：</p>
<script type="math/tex; mode=display">g_{\sigma}(m,n)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{m^2+n^2}{2\sigma^2}}f(m,n)</script><p>简单说就是用一个高斯矩阵乘以每一个像素点及其邻域，取其带权重的平均值作为最后的灰度值。<br>2）计算梯度值和梯度方向<br>边缘就是灰度值变化较大的的像素点的集合。在图像中，用梯度来表示灰度值的变化程度和方向。<br>它可以通过点乘一个sobel或其它算子得到不同方向的梯度值 $g_x(m,n)$ , $g_y(m,n)$ 。<br>综合梯度通过以下公式计算梯度值和梯度方向：</p>
<script type="math/tex; mode=display">G(m,n)=\sqrt{g_x(m,n)^2+g_y(m,n)^2}</script><script type="math/tex; mode=display">\theta=arctan \frac{g_y(m,n)}{g_x(m,n)}</script><p>3）过滤非最大值<br>在高斯滤波过程中，边缘有可能被放大了。这个步骤使用一个规则来过滤不是边缘的点，使边缘的宽度尽可能为1个像素点：如果一个像素点属于边缘，那么这个像素点在梯度方向上的梯度值是最大的。否则不是边缘，将灰度值设为0。</p>
<script type="math/tex; mode=display">M_T(m,n)=\begin{cases}
M(m,n) \ if\ M(m,n)>T \\
0 \ otherwise
\end{cases}</script><p>4）使用上下阈值来检测边缘<br>一般情况下，使用一个阀值来检测边缘，但是这样做未免太武断了。如果能够使用启发式的方法确定一个上阀值和下阀值，位于下阀值之上的都可以作为边缘，这样就可能提高准确度。<br><img src="/images/candy.jpg" alt=""><br>它设置两个阀值（threshold），分别为maxVal和minVal。其中大于maxVal的都被检测为边缘，而低于minval的都被检测为非边缘。对于中间的像素点，如果与确定为边缘的像素点邻接，则判定为边缘；否则为非边缘。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="post-title-link" itemprop="url">机器学习基础知识</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-18 21:13:21" itemprop="dateCreated datePublished" datetime="2020-02-18T21:13:21+08:00">2020-02-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-04-13 10:31:32" itemprop="dateModified" datetime="2020-04-13T10:31:32+08:00">2020-04-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="传统的机器学习算法"><a href="#传统的机器学习算法" class="headerlink" title="传统的机器学习算法"></a>传统的机器学习算法</h2><p>常见的机器学习算法包括：</p>
<ol>
<li>回归算法：回归算法是试图采用对误差的衡量来探索变量之间的关系的一类算法。回归算法是统计机器学习的利器，常见的回归算法包括：最小二乘法（Ordinary Least Square），逻辑回归（Logistic Regression）,逐步式回归（Stepwise Regression），多元自适应回归样条（Multivariate Adaptive Regression Splines）以及本地散点平滑估计（Locally Estimated Scatterplot Smoothing）。</li>
<li>基于实例的算法：基于实例的算法常常用来对决策问题建立模型，这样的模型常常先选择一批样本数据，然后根据某些近似性把新数据与样本数据进行比较通过这种方式来寻找最佳的匹配。因此，基于实例的算法也被称为“基于记忆的学习”。常见的算法包括k-Nearest Neighbor(KNN)，学习矢量量化（Learning Vector Quantization, LVQ）以及自组织映射算法（Self-Organizing Map, SOM）。</li>
<li>决策树学习：决策树算法根据数据的属性采用树状结构建立决策模型，决策树模型常常用来解决分类和回归问题。常见的算法包括：分类及回归树（Classification And Regression Tree, CART），随机森林（Random Forest），多元自适应回归样条（MARS）以及梯度推进及（Gradient Boosting Machine, GBM）。</li>
<li>贝叶斯方法：贝叶斯算法是基于贝叶斯定理的一类算法，主要用来解决分类和回归问题。常见算法包括：朴素贝叶斯算法，平均单依赖估计（Averaged One-Dependence Estimators, AODE）以及Bayesian Belief Network(BBN)。</li>
<li>基于核的算法：基于核的算法中最著名的莫过于支持向量机（SVM）。基于核的算法吧输入数据映射到高阶的向量空间，在这些高阶向量空间里，有些分类或者回归问题能够更容易的解决。常见的基于核的算法包括：支持向量机（Support Vector Machine, SVM），径向基函数（Radial Basis Function, RBF）以及线性判别分析（Linear Discriminate Analysis, LDA）等。</li>
<li>聚类算法：聚类，就像回归一样，有时候人们描述的是一类问题，有时候描述的是一类算法。聚类算法通常按照中心店或者分层的方式对输入数据进行归并。所有的聚类算法都试图找到数据的内在结构，以便按照最大的共同点进行归类。常见的聚类算法包括k-means算法以及期望最大化算法（Expectation Maximization, EM）。</li>
<li>降低维度算法：像聚类算法一样，降低维度算法试图分析数据的内在结构，不过降低维度算法是以非监督学习的方式试图利用较少的信息来归纳或者解释数据。这类数据可以用高维数据的可视化或者用来简化数据以便监督式学习使用。常见的算法包括：主成份分析（Principle Component Analysis, PCA），偏最小二乘回归（Partial Least Square Regression, PLS），Sammon映射，多维尺度（Multi-Dimensional Scaling, MDS），投影追踪（Projection Pursuit）等。</li>
<li>关联规则学习：关联规则学习通过寻找最能够解释数据变量之间关系的规则，来找出大量多元数据集中有用的关联规则。常见算法包括Apriori算法和Eclat算法等。</li>
<li>集成算法：集成算法用一些相对较弱的学习模型队里地就同样的样本进行训练，然后把结果整合起来进行整体预测。集成算法的主要难点在于究竟集成哪些独立的较弱的学习模型以及如何把学习结果整合起来。常见的算法包括：Boosting，Bootstrapped Aggregation(Bagging)，AdaBoost，堆叠泛化（Stacked Generalization, Blending），梯度推进及（Gradient Boosting Machine, GBM），随机森林（Random Forest）。</li>
<li>人工神经网络：人工神经网络算法模拟生物神经网络，是一类模式匹配算法， 通常用于解决分类和回归问题。重要的人工神经网络算法包括：感知器神经网络（Perceptron Neural Network），反向传递（Back Propagation），自组织映射（Self-Organizing Map，SOM）以及学习矢量量化（Learning Vector Quantization, LVQ）。<h2 id="生成模型和判别模型"><a href="#生成模型和判别模型" class="headerlink" title="生成模型和判别模型"></a>生成模型和判别模型</h2>判别模型：由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。典型的判别模型包括k近邻，感知级，决策树，支持向量机等。<br>生成模型：由数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)。基本思想是首先建立样本的联合概率概率密度模型P(X,Y)，然后再得到后验概率P(Y|X)，再利用它进行分类。常见的有HMM模型<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2>本质上来说，呈现给算法的数据应该能拥有基本数据的相关结构或属性。当你做特征工程时，其实是将数据属性转换为数据特征的过程，属性代表了数据的所有维度，在数据建模时，如果对原始数据的所有属性进行学习，并不能很好的找到数据的潜在趋势，而通过特征工程对你的数据进行预处理的话，你的算法模型能够减少受到噪声的干扰，这样能够更好的找出趋势。<br>特征工程分哪几步？1）数据预处理；2）特征选择；3）特征提取。<h3 id="特征选择和特征提取区别"><a href="#特征选择和特征提取区别" class="headerlink" title="特征选择和特征提取区别"></a>特征选择和特征提取区别</h3>都是降维的方法。特征选择：不改变变量的含义，仅仅只是做出筛选，留下对目标影响较大的变量；特征提取：通过映射（变换）的方法，将高维的特征向量变换为低维特征向量。<h3 id="样本不均衡如何处理？"><a href="#样本不均衡如何处理？" class="headerlink" title="样本不均衡如何处理？"></a>样本不均衡如何处理？</h3>简单通用的方式：<br>1）对较多的那个类别进行欠采样(under-sampling)，舍弃一部分数据，使其与较少类别的数据相当。<br>2）对较少的类别进行过采样(over-sampling)，重复使用一部分数据，使其与较多类别的数据相当。<br>3）阈值调整（threshold moving），将原本默认为0.5的阈值调整到 较少类别/（较少类别+较多类别）即可。<br>类别不平衡的处理方式如下：<br>1）采样<br>这里的采样可以分为上采样和下采样，简单说就是从类别少的多采样或者类别多的少采样。<br>2）转化为One-class问题<br>把它看做一分类（One Class Learning）或异常检测（Novelty Detection）问题。这类方法的重点不在于捕捉类间的差别，而是为其中一类进行建模，经典的工作包括One-class SVM等。<br>3）聚类+采样<br>对数据先进行聚类，再将大的簇进行随机欠采样或者小的簇进行数据生成。<br>4）模型惩罚<br>简单说就是对分类器的小类样本数据增加权值，降低大类样本的权值。<br>5）换模型<br>使用一些如Bagging和Boosting的集成方法<h3 id="对于数据异常值，我们一般如何处理？"><a href="#对于数据异常值，我们一般如何处理？" class="headerlink" title="对于数据异常值，我们一般如何处理？"></a>对于数据异常值，我们一般如何处理？</h3>1）视为无效信息（噪声点）： 结合异常值检测算法，检测出后直接丢弃；<br>2）视为有效信息（信号点）：作为缺失值，用缺失值的方式处理；<br>3）用平均值（中位数）等统计特征进行修正，结合前后观测值；<br>4）不处理，直接在具有异常值的数据上进行数据挖掘；<h3 id="简单介绍特征选择"><a href="#简单介绍特征选择" class="headerlink" title="简单介绍特征选择"></a>简单介绍特征选择</h3>当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征：<br>1）特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。<br>2）特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择。除方差法外，下文介绍的其他方法均从相关性考虑。<br>根据特征选择的形式又可以将特征选择方法分为3种：<br>1）Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。如方差选择法，先要计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。<br>2）Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。<br>3）Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。使用带惩罚项L1的基模型，除了筛选出特征外，同时也进行了降维。L1惩罚项降维的原理在于保留多个对目标值具有同等相关性的特征中的一个，所以没选到的特征不代表不重要。<h3 id="简单介绍特征提取"><a href="#简单介绍特征提取" class="headerlink" title="简单介绍特征提取"></a>简单介绍特征提取</h3>可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的。常见的降维方法除了以上提到的基于L1惩罚项的模型以外，另外还有主成分分析法（PCA）和线性判别分析（LDA），线性判别分析本身也是一个分类模型。PCA和LDA有很多的相似点，其本质是要将原始的样本映射到维度更低的样本空间中，但是PCA和LDA的映射目标不一样：PCA是为了让映射后的样本具有最大的发散性；而LDA是为了让映射后的样本有最好的分类性能。所以说PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。<h3 id="特征相关性问题"><a href="#特征相关性问题" class="headerlink" title="特征相关性问题"></a>特征相关性问题</h3>逻辑回归在训练的过程当中，如果有很多特征高度相关或者说有一个特征重复了100遍，会造成怎样的影响？<br>如果在损失函数最终收敛的情况下，就算有很多特征高度相关也不会影响分类器的效果。<br>为什么我们还是会在训练的过程当中将高度相关的特征去除？1）去掉高度相关的特征会让模型的可解释性更好；2）可以大大提高训练的速度。如果模型当中有很多特征高度相关的话，就算损失函数本身收敛了，但实际上参数是没有收敛的，这样会拉低训练的速度。其次是特征多了，本身就会增大训练的时间。<h4 id="特征离散化"><a href="#特征离散化" class="headerlink" title="特征离散化"></a>特征离散化</h4>逻辑回归为什么要对特征进行离散化？<br>在工业界，很少直接将连续值作为特征送入逻辑回归模型，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：<br>1）稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展。<br>2）离散化后的特征对异常数据由很强的鲁棒性，如果特征没有离散化，一个异常数据会给模型造成很大的干扰。<br>3）逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合。<br>4）离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力。<br>5）特征离散化后，模型会更稳定。<br>李沐少帅指出，模型是使用离散特征还是连续特征，其实是一个“海量离散特征+简单模型”同“少量连续特征+复杂模型”的权衡。既可以离散化用线性模型，也可以用连续特征加深学习。<h4 id="特征组合"><a href="#特征组合" class="headerlink" title="特征组合"></a>特征组合</h4>什么是组合特征？<br>为了提高复杂关系的拟合能力，特征工程时候，将两个或两个以上特征通过一定方式组合构成高阶组合特征。<br>在逻辑回归模型中，为什么常常要做特征组合（特征交叉）？<br>逻辑回归模型属于线性模型，线性模型不能很好处理非线性特征，特征组合可以引入非线性特征，提升模型的表达能力。另外，基本特征可以认为是全局建模，组合特征更加精细，是个性化建模，但对全局建模会对部分样本有偏，对每一个样本建模又会导致数据爆炸，过拟合，所以基本特征+特征组合兼顾了全局和个性化。<h2 id="逻辑回归问题"><a href="#逻辑回归问题" class="headerlink" title="逻辑回归问题"></a>逻辑回归问题</h2>（重点）逻辑回归假设数据服从伯努利分布，通过极大似然函数的方法，运用梯度下降来求解参数，达到将数据二分类的目的。<h3 id="逻辑回归的基本假设"><a href="#逻辑回归的基本假设" class="headerlink" title="逻辑回归的基本假设"></a>逻辑回归的基本假设</h3>任何的模型都有自己的假设，在这个假设下模型才是适用的。逻辑回归的第一个假设是假设服从伯努利分布。伯努利分布有一个简单地例子是抛硬币，投中正面的概率为p，抛中负面的概率为1-p。<br>在逻辑回归模型中假设$h_{\theta}(x)$为样本为正的概率，$1-h_{\theta}(x)$为样本为负的概率。那么这个模型可以描述为：<script type="math/tex; mode=display">h_{\theta}(x;\theta)=p</script>逻辑回归的第二个假设是假设样本为正的概率是：<script type="math/tex; mode=display">p=\frac{1}{1+e^{-\theta^Tx}}</script>所以逻辑回归的最终形式：<script type="math/tex; mode=display">h_{\theta}(x;\theta)=\frac{1}{1+e^{-\theta^Tx}}</script><h3 id="逻辑回归的损失函数"><a href="#逻辑回归的损失函数" class="headerlink" title="逻辑回归的损失函数"></a>逻辑回归的损失函数</h3>逻辑回归的损失函数是它的极大似然函数：<script type="math/tex; mode=display">L_{\theta}(x)=\prod_{i=1}^mh_{\theta}(x^i;\theta)^{yi}*(1-h_{\theta}(x^i;\theta))^{1-y^i}</script>逻辑回归的损失函数为什么要使用极大似然函数作为损失函数？<br>将极大似然函数取对数以后等同于对数损失函数。在逻辑回归这个模型下，对数损失函数的训练求参数的速度是比较快的。可以求得这个公式的梯度更新为：<script type="math/tex; mode=display">\theta_j=\theta_j-(y_i-h_{\theta}(x^i;\theta))*x_{ij}</script>梯度的更新速度只和$x_{ij},y_i$相关，和sigmoid函数本身的梯度是无关的，这样的更新速度是可以自始至终都比较稳定。<br>为什么不选平方损失函数呢？其一是因为如果你使用平方损失函数，会发现梯度更新的速度和sigmoid函数本身的梯度是相关的。sigmoid函数在它定义域内梯度都不大于0.25，这样训练会非常慢。<h3 id="逻辑回归的目的"><a href="#逻辑回归的目的" class="headerlink" title="逻辑回归的目的"></a>逻辑回归的目的</h3>目的是将数据二分类，提高准确率。<br>逻辑回归作为一个回归（也就是y值是连续的），如何应用到分类上呢。y值确实是一个连续的变量，逻辑回归的做法是划分一个阈值，y值大于这个阈值的是一类，y值小于这个阈值的是另外一类。阈值具体如何调整根据实际情况选择，一般选择0.5作为阈值来划分。<h3 id="逻辑回归的优缺点"><a href="#逻辑回归的优缺点" class="headerlink" title="逻辑回归的优缺点"></a>逻辑回归的优缺点</h3>这里总结了逻辑回归应用在工业界当中的一些优点：<br>1）形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响，某个特征的权重值比较高，那么这个特征最后对结果的影响比较大。<br>2）模型效果不错。在工程上是可以接受的（作为baseline），如果特征工程做的好，效果不会太差，并且特征工程可以大家并行开发，大大加快开发的速度。<br>3）训练速度快。分类的时候，计算量仅仅只和特征的数目相关，并且逻辑回归的分布式优化sgd发展比较成熟，训练的速度可以通过对机器进一步提高，这样我们可以在短时间内迭代好几个版本的模型。<br>4）资源占用小，尤其是内存。因为只需要存储各个维度的特征值。<br>5）方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值（大于阈值的是一类，小于阈值的是一类）<br>当然逻辑回归本身也有很多的缺点：<br>1）准确率并不是很高。因为形式非常的简单（非常类似线性模型），很难去拟合数据的真实分布。<br>2）很难处理数据不平衡的问题。举个例子：如果我们对于一个正负样本非常不平衡的问题比如正负样本比10000：1，我们把所有样本都预测为正也能使损失函数的值比较小，但是作为一个分类器，它对正负样本的区分能力不会很好。<br>3）处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据，或者进一步说，处理二分类的问题。<br>4）逻辑回归本身无法筛选特征。有时候，我们会有GDBT来筛选特征，然后再上逻辑回归。<h3 id="逻辑回归是线性模型吗？"><a href="#逻辑回归是线性模型吗？" class="headerlink" title="逻辑回归是线性模型吗？"></a>逻辑回归是线性模型吗？</h3>1）逻辑回归是一种广义线性模型，它引入了Sigmoid函数，是非线性模型，但本质上还是一个线性回归模型，因为除去Sigmoid函数映射关系，其他的算法原理、步骤都是线性回归的。<br>2）逻辑回归和线性回归首先都是广义的线性回归，区别在于逻辑回归多了个Sigmoid函数，使样本映射到[0,1]之间的数值，从而来处理分类问题。另外逻辑回归是假设变量服从伯努利分布，线性回归假设变量服从高斯分布。逻辑回归输出的是离散型变量，用于分类，线性回归输出的是连续值，用于预测。逻辑回归是用最大似然法去计算预测函数中最优参数值，而线性回归是用最小二乘法去对自变量因变量关系进行拟合。<h3 id="逻辑回归输出值的意义"><a href="#逻辑回归输出值的意义" class="headerlink" title="逻辑回归输出值的意义"></a>逻辑回归输出值的意义</h3>逻辑回归输出的值是0到1之间的值，这个值是真实的概率吗？<br><a href="https://blog.csdn.net/tunghao/article/details/86480040" target="_blank" rel="noopener">推导过程</a><br>结论：逻辑回归模型之所以是sigmoid的形式，源于我们假设y服从伯努利分布，伯努利分布又属于指数分布族，经过推导，将伯努利分布变为指数分布族的形式后。我们发现伯努利分布的唯一参数$\Phi$与指数分布族中的参数$\eta$具有sigmoid函数关系，于是我们转而求$\eta$与$x$的关系，此时，我们又假设$\eta$与$x$具有线性关系。至此找到了我们要用的模型的样子，也就是逻辑回归。即只有在满足：$y$服从伯努利分布；$n$和$x$之间存在线性关系时，输出值才是概率值。不满足的情况下，得到的输出值，只是置信度。<h3 id="欠拟合和过拟合"><a href="#欠拟合和过拟合" class="headerlink" title="欠拟合和过拟合"></a>欠拟合和过拟合</h3>过拟合：其实就是所建的机器学习模型或者深度学习模型在训练样本中表现过于优越，导致在验证数据集以及测试数据集中表现不佳。<br>欠拟合：由于训练样本被提取的特征比较少，导致训练出来的模型不能很好地匹配，表现很差。<br>判断方法是从训练集中随机选一部分作为验证集，采用K折交叉验证的方式，用训练集训练的同时在验证集上测试算法效果。在缺少有效预防欠拟合和过拟合措施的情况下，随着模型拟合能力的增强，错误率在训练集上逐渐减小，而在验证集上先减小后增大；当两者的误差率都较大时，处于欠拟合状态；当验证集误差率达到最低点，说明拟合效果最好，有最低点增大时，处于过拟合状态。<br>![误差率曲线图])(/images/拟合状态.png)<h4 id="解决模型欠拟合与过拟合常用方法"><a href="#解决模型欠拟合与过拟合常用方法" class="headerlink" title="解决模型欠拟合与过拟合常用方法"></a>解决模型欠拟合与过拟合常用方法</h4>欠拟合：欠拟合的原因大多是模型不够复杂、拟合函数的能力不够。<br>因此，从数据层面考虑，可以增加新特征，例如：组合、泛化、相关性、高次特征等；从模型层面考虑，可以增加模型的复杂度，例如SVM的核函数、DNN等更复杂模型，去掉正则化或减少正则化参数，加深训练轮数等。<br>过拟合：成因是给定的数据集相对过于简单，使得模型在拟合函数时过分考虑了噪声等不必要的数据间关联。<br>解决方法：<br>1）数据扩增：人为增加数据量，可以用重采样、上采样、增加随机噪声、GAN、图像数据的空间变换（平移旋转镜像）、尺度变换（缩放裁剪）、颜色变换、改变分辨率、对比度、亮度等。<br>2）针对神经网络，采用dropout的方法：dropout的思想是当一组参数经过某一层神经元的时候，去掉这一层上的部分神经元，让参数只经过一部分神经元进行计算。这里的去掉不是真正意义上的去除，只是让参数不经过一部分神经元计算，从而减少了神经网络的规模（深度）。<br>3）提前停止训练<br>也就是减少训练的迭代次数。从上面的误差率曲线图，理论上可以找到有个训练程度，此时验证集误差率最低，视为拟合效果最好的点。<br>4）正则化<br>在所定义的损失函数后面加入一项永不为0的部分，那么经过不断优化损失函数还是会存在的。<br>L0正则化：损失函数后面加入L0范数，也就是权重向量中非零参数的个数。特点是可以实现参数的稀疏性，使尽可能多的参数都为0；缺点是在优化时是NP难问题，很难优化。<br>L1正则化：在损失函数后面加入权重向量的L1范数。L1范数是L0范数的最优凸近似，比L0范数容易优化，也可以很好地实现参数稀疏性。<br>L2正则化：在损失函数后面加入参数L2范数的平方项。与L0、L1不同的是，L2很难使某些参数达到0，它只能是参数接近0。<br>5）针对DNN，采用batch normalization：即BN，既能提高泛化能力，又大大提高训练速度，现被广泛应用于DNN的激活层之前。主要优势：减少了梯度对参数大小和初始值的依赖，将参数值（特征）缩放在[0,1]区间（若针对Relu还限制了输出的范围），这样反向传播时梯度控制在1左右，使得网络在较高的学习率之下也不易发生梯度爆炸或弥散（也防止了在使用sigmoid作为激活函数时训练容易陷入梯度极小饱和或极大的极端情况）。<h3 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h3>在上面，我们主要使用逻辑回归解决二分类的问题，那对于多分类的问题，也可以用逻辑回归来解决吗？<h4 id="one-vs-rest"><a href="#one-vs-rest" class="headerlink" title="one vs rest"></a>one vs rest</h4>由于概率函数$h_{\theta}(x)$所表示的是样本标记为某一类型的概率，但可以将一对一（二分类）扩展为一对多(one vs rest)：<br>1）将类型$class_1$看作正样本，其他类型全部看作负样本，然后我们就可以得到样本类型为该类型的概率$p_1$；<br>2）然后再讲另外类型$class_2$看作正样本，其他类型全部看作负样本，同理得到$p_2$；<br>3）以此循环，我们可以得到该待预测样本的标记类型分别为类型$class_i$时的概率$p_i$，最后我们取$p_i$中最大的那个概率对应的样本标记类型为我们的待预测样本类型。<h4 id="softmax函数"><a href="#softmax函数" class="headerlink" title="softmax函数"></a>softmax函数</h4>使用softmax函数构造模型解决多分类问题，与logistic回归不同的是，softmax回归分类模型会有多个的输出，且输出个数与类别个数相等，输出为样本$X$的各个类别的概率，最后对样本进行预测的类型为概率最高的那个类别。<h4 id="选择方案"><a href="#选择方案" class="headerlink" title="选择方案"></a>选择方案</h4>当标签类别之间是互斥时，适合选择softmax回归分类器；当标签类别之间不完全互斥时，适合选择建立多个独立的logistic回归分类器。</li>
</ol>
<h2 id="模型之间的对比"><a href="#模型之间的对比" class="headerlink" title="模型之间的对比"></a>模型之间的对比</h2><h3 id="线性回归与逻辑回归"><a href="#线性回归与逻辑回归" class="headerlink" title="线性回归与逻辑回归"></a>线性回归与逻辑回归</h3><p>逻辑回归和线性回归首先都是广义的线性回归，其次经典线性模型的优化目标函数是最小二乘，二逻辑回归则是似然函数。另外线性回归在整个实数域范围内进行预测，敏感度一致，而分类范围则需要在[0,1]；逻辑回归就是一种减小预测范围，将预测值限定在[0,1]间的一种回归模型，因而对于这类问题来说，逻辑回归的鲁棒性比线性回归好。<br>逻辑回归的模型本质是一个线性回归模型，逻辑回归都是以线性回归为理论支持的。但线性回归模型无法做到sigmoid的非线性形式，sigmoid可以轻松处理0/1分类问题。逻辑回归在线性回归的实数范围输出值上施加sigmoid函数将值收敛到0~1范围，其目标函数也因此从差平方和变为对数损失函数，以提供最优化所需导数（sigmoid函数是softmax函数的二元特例）。注意，逻辑回归玩玩是解决二元0/1分类问题，只是它和线性回归耦合太紧，也被冠以回归的名字。若要求多分类，就要把sigmoid换成softmax。</p>
<h3 id="最大熵与逻辑回归"><a href="#最大熵与逻辑回归" class="headerlink" title="最大熵与逻辑回归"></a>最大熵与逻辑回归</h3><p>最大熵原理是概率模型学习的一个准则，最大熵认为，学习概率模型时，在所有可能分布中，熵最大的模型是最好的模型。<br><a href="https://www.jianshu.com/p/504b8d09c23e" target="_blank" rel="noopener">最大熵推导过程</a><br>最大熵在解决二分类问题时就是逻辑回归，在解决多分类问题时就是多项逻辑回归。此外，最大熵与逻辑回归都称为对数线性模型。</p>
<h3 id="SVM与逻辑回归"><a href="#SVM与逻辑回归" class="headerlink" title="SVM与逻辑回归"></a>SVM与逻辑回归</h3><p>这两个模型应用广泛且有很多相同点，所以把SVM和LR放在一起比较。<br>相同点：<br>1）都是线性分类器，本质上都是求一个最佳分类超平面<br>2）都是监督学习算法。<br>3）都是判别模型。通过决策函数，判别输入特征之间的差别来进行分类。<br>常见的判别模型：KNN、SVM、LR。<br>常见的生成模型：朴素贝叶斯、隐马尔科夫模型。<br>不同点：<br>1）本质上的损失函数不同<br>LR的损失函数是交叉熵：</p>
<script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}\sum_{i=1}^m(y^{(i)}logh_{\theta}(x^{(i)})+(1-y^{(i)})log(1-h_{\theta}(x^{(i)})))</script><p>SVM的目标函数是hinge loss：</p>
<script type="math/tex; mode=display">L(w,b,\alpha)=\frac{1}{2}||w||^2-\sum_{i=1}^n\alpha_i(y_i(w^Tx_i+b)-1)</script><p>逻辑回归基于概率理论，假设样本为正样本的概率可以用sigmoid函数来表示极大似然估计的方法估计出参数的值。支持向量机基于几何间隔最大化原理，认为存在最大间隔的分类面为最优分类面。<br>2）两个模型对数据和参数的敏感程度不同<br>SVM考虑分类边界线附近的样本（决定分类超平面的样本），在支持向量外添加或减少任何样本点对分类决策面没有任何影响。LR受所有数据点的影响，每个样本点都会影响决策面的结果。如果训练数据不同类别严重不平衡，则一般需要先对数据做平衡处理，让不同类别的样本尽量平衡。<br>3）SVM基于距离分类，LR基于概率分类<br>SVM依赖数据表达的距离测度，所以需要先对数据先做normalization；LR不受其影响。<br>4）逻辑回归是处理经验风险最小化，SVM是结构风险最小化。这点体现在SVM自带L2正则化项，而逻辑回归需要在损失函数之外添加正则项。<br>5）逻辑回归通过非线性变换减弱分离平面较远点的影响，SVM则只支持向量从而消去较远点的影响。</p>
<h2 id="支持向量机SVM"><a href="#支持向量机SVM" class="headerlink" title="支持向量机SVM"></a>支持向量机SVM</h2><p>SVM是一种二分类模型，其基本思想是在特征空间中寻找间隔最大的分离超平面使数据得到高效的二分类，具体来讲有三种情况（不加核函数的话就是个线性模型，加了之后会升级为一个非线性模型）：<br>当训练样本线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机；<br>当训练函数近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机；<br>当训练数据线性不可分时，通过使用核技巧及软间隔最大化，学习非线性支持向量机。</p>
<h3 id="一句话介绍SVM"><a href="#一句话介绍SVM" class="headerlink" title="一句话介绍SVM"></a>一句话介绍SVM</h3><p>SVM是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔大使它有别于普通的感知机，通过核技巧隐式的在输入空间直接求解映射空间中特征向量的内积，使其成为一个非线性分类器。SVM的学习策略是间隔最大化，可形式化为一个求解凸二次规划问题。</p>
<h3 id="SVM的几个核心概念"><a href="#SVM的几个核心概念" class="headerlink" title="SVM的几个核心概念"></a>SVM的几个核心概念</h3><h4 id="确定超平面及函数间隔"><a href="#确定超平面及函数间隔" class="headerlink" title="确定超平面及函数间隔"></a>确定超平面及函数间隔</h4><p>由空间上的平面公式确定超平面$wx+b=0$，且$|wx+b|$表示点$x$到平面上的距离。正例负例位于分割平面两侧，因此$y(wx+b)$可同时表示分类正确性以及距离置信度。这也就是函数间隔，其被定义为训练集中所有点到超平面距离的最小值。</p>
<h4 id="几何间隔"><a href="#几何间隔" class="headerlink" title="几何间隔"></a>几何间隔</h4><p>由于成比例地缩放$w$和$b$会使得$|wx+b|$跟着成比例缩放，因此需要对法向量w加上约束，使得间隔是确定的，也就是函数间隔整体除以$||w||$，也就得到了几何间隔。</p>
<h4 id="间隔最大化"><a href="#间隔最大化" class="headerlink" title="间隔最大化"></a>间隔最大化</h4><p>分为硬间隔最大和软间隔最大<br>SVM的基本思想就是求解可以正确划分数据集并且几何间隔最大的分离超平面，其原因是线性可分超平面有无数个，但是间隔最大超平面使唯一的。</p>
<h4 id="支持向量"><a href="#支持向量" class="headerlink" title="支持向量"></a>支持向量</h4><p>与超平面最近的点被称为支持向量，也就是使得原始问题约束项成立的点。</p>
<h4 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h4><p>核函数本质不是将特征映射到高维空间，而是找到一种直接在低维空间对高维空间中向量做点积运算的简便方法。</p>
<h3 id="SVM推导"><a href="#SVM推导" class="headerlink" title="SVM推导"></a>SVM推导</h3><p>（重点）<a href="https://zhuanlan.zhihu.com/p/45444502" target="_blank" rel="noopener">SVM算法推导过程</a><br><a href="https://blog.csdn.net/szlcw1/article/details/52259668?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">SVM常考问题</a></p>
<h3 id="SVM为什么采用间隔最大化（与感知机的区别）"><a href="#SVM为什么采用间隔最大化（与感知机的区别）" class="headerlink" title="SVM为什么采用间隔最大化（与感知机的区别）"></a>SVM为什么采用间隔最大化（与感知机的区别）</h3><p>当训练数据线性可分时，存在无穷个分离超平面可以将两类数据正确分开。感知机利用误分类最小策略，求得分离超平面，不过此时的解有无穷多个。线性可分支持向量机利用间隔最大化求得最优分离超平面，这个解是唯一的。另一方面，此时的间隔超平面所产生的分类结果是最鲁棒的，对未知实例的泛化能力最强。</p>
<h3 id="SVM的目标（硬间隔）"><a href="#SVM的目标（硬间隔）" class="headerlink" title="SVM的目标（硬间隔）"></a>SVM的目标（硬间隔）</h3><p>有两个目标：第一是使间隔最大化，第二是使样本正确分类，由此推出目标函数：</p>
<script type="math/tex; mode=display">\mathop{min}\limits_{w,b}\frac{1}{2}||w||^2\quad s.t. y_i(w^Tx_i+b)\ge 1,\forall i</script><p>目标以是从点到面的距离公式简化来的，目标二相当于感知机，只是把大于等于0进行缩放变成了大于等于1，方便后面的推导。</p>
<h3 id="将原始问题转化为对偶问题"><a href="#将原始问题转化为对偶问题" class="headerlink" title="将原始问题转化为对偶问题"></a>将原始问题转化为对偶问题</h3><p>做所以说对偶问题更容易求解，其原因在于降低了算法的计算复杂度。在原问题下，算法的复杂度与样本维度相关，即等于权重w的维度，而在对偶问题下，算法复杂度与样本数量相关，即为拉格朗日算子的个数。<br>因此，如果你是做线性分类，且样本维度低于样本数量的话，在原问题下求解就好了，Liblinear之类的线性SVM默认都是这样的；但如果你是做非线性分类，那就会涉及到升维（比如使用高斯核做核函数，其实是将样本升到无穷维），升维后的样本维度往往会远大于样本数量，此时显然在对偶问题下求解会更好。</p>
<h3 id="软间隔"><a href="#软间隔" class="headerlink" title="软间隔"></a>软间隔</h3><p>不管在原特征空间，还是在映射的高维空间，我们都假设样本是线性可分的。虽然理论上我们总能找到一个高维映射使数据线性可分，但在实际任务中，寻找一个合适的核函数很困难。此外，由于数据通常有噪声存在，一味追求数据线性可分可能会使模型陷入过拟合，因此我们放宽对样本的要求，允许少量样本分类错误。这样的想法就意味着对目标函数的改变，之前推导的目标函数里不允许任何错误，并且让间隔最大，现在给之前的目标函数加上一个误差，就相当于允许原先的目标出错，引入松弛变量，公式变为：</p>
<script type="math/tex; mode=display">\mathop{min}\limits_{w,b,\xi}\frac{1}{2}||w||^2+\sum_{i=1}^n\xi_i</script><p>在松弛变量中引入合页损失(hinge loss):</p>
<script type="math/tex; mode=display">l_{hinge}(z)=max(0,1-z)</script><p>但是这个代价需要一个控制的因子，引入C&gt;0，惩罚参数。C越大说明把错误放的越大，说明对错误地容忍度就小，反之亦然。当C无穷大时，就变成一点错误都不能容忍，即变成硬间隔。实际应用时我们要合理选取C，C越小越容易欠拟合，C越大越容易过拟合。<br>所以软间隔的目标函数为：</p>
<script type="math/tex; mode=display">\mathop{min}\limits_{w,b,\xi}\frac{1}{2}||w||^2+C\sum_{i=1}^n\xi_i</script><script type="math/tex; mode=display">s.t.\ y_i(w_i^Tx+b)\ge 1-\xi_i\quad \xi_i\ge 0, i=1,2,...,n</script><p>其中：$\xi_i=max(0,1-y_i(w^Tx_i+b))$</p>
<h3 id="核函数-1"><a href="#核函数-1" class="headerlink" title="核函数"></a>核函数</h3><p>为什么要引入核函数？<br>当样本在原始空间线性不可分时，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。而引入这样的映射后，所要求解的对偶问题中，无需求解真正的映射函数，而只需要知道其核函数。核函数的定义：$K(x,y)=&lt;(x),(y)&gt;$，即在特征空间的内积等于它们在原始样本空间中通过核函数K计算的结果。一方面数据变成高维空间中线性可分的数据，另一方面不需要求解具体的映射函数，只需要给定具体的核函数即可，这样使得求解的难度大大降低。因为核函数求得的值等于将两个低维空间找那个的向量映射到高维空间后的内积。<br>常用的核函数：<br>1）线性核函数；2）多项式核；3）径向基核（RBF）；4）傅里叶核；5）样条核；6）Sigmoid核函数。<br>其中Gauss径向基函数则是局部性强的核函数，其外推能力随着参数的增大而减弱；多项式形式的核函数具有良好的全局性质，局部性差。<br>如何选择和函数呢？<br>1）当特征维数远远大于样本数的情况下，使用线性核就可以<br>2）当特征维数和样本数都很大，例如文本分类，一般使用线性核<br>3）当特征维数远小于样本数，一般使用RBF。</p>
<h3 id="为什么SVM对缺失数据敏感？"><a href="#为什么SVM对缺失数据敏感？" class="headerlink" title="为什么SVM对缺失数据敏感？"></a>为什么SVM对缺失数据敏感？</h3><p>这里说的缺失数据是指缺失某些特征数据，向量数据不完整。SVM没有处理缺失值的策略。而SVM希望样本在特征空间中线性可分，所以特征空间的好坏对SVM的性能很重要，缺失特征数据将影响训练结果的好坏。</p>
<h3 id="SVM的优缺点"><a href="#SVM的优缺点" class="headerlink" title="SVM的优缺点"></a>SVM的优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>1）由于SVM是一个凸优化问题，所以求得的解一定是全局最优而不是局部最优。<br>2）不仅适用于线性问题还适用于非线性问题（用核技巧）<br>3）同游高维样本空间的数据也能用SVM，这是因为数据集的复杂度只取决于支持向量而不是数据集的维度，这在某种意义上避免了“维数灾难”。<br>4）理论基础比较完善</p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>1）二次规划问题求解将涉及m阶矩阵的计算（m为样本的个数），因此SVM不适用于超大数据集。（SMO算法可以缓解这个问题）<br>2）只适用于二分类问题。（SVM的退岗SVR也适用于回归问题；可以通过多个SVM的组合来解决多分类问题）</p>
<h2 id="常用的距离公式"><a href="#常用的距离公式" class="headerlink" title="常用的距离公式"></a>常用的距离公式</h2><h3 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h3><p>点$P_1(x_1,y_1)$和点$P_2(x_2,y_2)$的距离为：</p>
<script type="math/tex; mode=display">distance(P_1,P_2)=|x_2-x_1|+|y_2-y_1|</script><h3 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h3><p>欧式空间中两点的距离。点$P_1(x_1,x_2,…,x_n)$和点$P_2(y_1,y_2,…,y_n)$的距离如下：</p>
<script type="math/tex; mode=display">distance=\sqrt{\sum_1^n(x_i-y_i)^2}</script><h3 id="切比雪夫距离"><a href="#切比雪夫距离" class="headerlink" title="切比雪夫距离"></a>切比雪夫距离</h3><p>两点之间的距离定义为其各坐标数值差的最大值。点$P_1(x_1,x_2,…,x_n)$和点$P_2(y_1,y_2,…,y_n)$的距离如下：</p>
<script type="math/tex; mode=display">distance=(P_1,P_2)=max(|x_1-y_1|,|x_2-y_2|,...,|x_n-y_n|)</script><h3 id="余弦相似度"><a href="#余弦相似度" class="headerlink" title="余弦相似度"></a>余弦相似度</h3><p>余弦相似度是通过测量两个向量夹角的度数来度量他们之间的相似度。对于A和B的距离是：</p>
<script type="math/tex; mode=display">cos(\theta)=\frac{A\cdot B}{||A||\cdot||B||}=\frac{\sum_1^n(A_i\times B_i)}{\sqrt{\sum_i^n(A_i)^2}\times\sqrt{\sum_i^n(B_i)^2}}</script><h2 id="数据降维"><a href="#数据降维" class="headerlink" title="数据降维"></a>数据降维</h2><h3 id="数据降维原理"><a href="#数据降维原理" class="headerlink" title="数据降维原理"></a>数据降维原理</h3><p>降维就是一种对高维度特征数据预处理方法。降维是将高维度的数据保留下最重要的一些特征，去除噪声和不重要的特征，从而实现提升数据处理速度的目的。在实际的生产和应用中，降维在一定的信息损失范围内，可以为我们节省大量的时间和成本。<br>降维具有如下一些优点：<br>1) 使得数据集更易使用。<br>2) 降低算法的计算开销。<br>3) 去除噪声。<br>4) 使得结果容易理解。<br>降维的算法有很多，比如奇异值分解(SVD)、主成分分析(PCA)、因子分析(FA)、独立成分分析(ICA)。</p>
<h3 id="线性判别分析LDA"><a href="#线性判别分析LDA" class="headerlink" title="线性判别分析LDA"></a>线性判别分析LDA</h3><p>LDA是一种监督学习的降维技术，也就是说它的数据集的每个样本是有类别输出的。这点和PCA不同，PCA是不考虑样本类别输出的无监督降维技术。LDA的思想可以用一句话来概括，就是“投影后类内方差最小，类间方差最大”。我们要将数据在低维度上进行投影，投影后希望每一种类别数据的投影点尽可能地接近，而不同类别的数据的类别中心之间的距离尽可能地大。<br>LDA求解方法：<br>1）计算数据集中每个类别样本的均值向量$\mu_j$，及总体均值向量$\mu$。<br>2）计算类内散度矩阵$S_w$，全局散度矩阵$S_t$，并得到类间散度矩阵$S_b=S_t-S_w$。<br>3）对矩阵$S_w^{-1}S_b$进行特征值分解，将特征值从大到小排列。<br>4）取特征值前k大的对应的特征向量组成新的矩阵，将n维样本<br>映射到k维。<br>从目标出发，PCA选择的是投影后数据方差最大的方向。由于它是无监督的，因此PCA假设方差越大，信息量越多，用主成分来表示原始数据可以去除冗余的维度，达到降维。而LDA选择的是投影后类内方差小、 类间方差大的方向。其用到了类别标签信息，为了找到数据中具有判别性的维度，使得原始数据在这些方向上投影后，不同类别尽可能区分开。</p>
<h3 id="PCA原理"><a href="#PCA原理" class="headerlink" title="PCA原理"></a>PCA原理</h3><p><a href="https://blog.csdn.net/program_developer/article/details/80632779?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">PCA介绍</a><br>PCA(Principal Component Analysis)，即主成分分析方法，是一种使用最广泛的数据降维算法。PCA的主要思想是将n维特征映射到k维上，这k维是全新的正交特征也被称为主成分，是在原有n维特征的基础上重新构造出来的k维特征。PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身是密切相关的。其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第1,2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。通过这种方式获得的新的坐标轴，我们发现，大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。于是，我们可以忽略余下的坐标轴，只保留前面k个含有绝大部分方差的坐标轴。事实上，这相当于只保留包含绝大部分方差的维度特征，而忽略包含方差几乎为0的特征维度，实现对数据特征的降维处理。<br>思考：我们如何得到这些包含最大差异性的主成分方向呢？<br>1）对样本数据进行中心化处理。<br>2）求样本协方差矩阵。<br>3）对协方差矩阵进行特征值分解， 将特征值从大到小排列。<br>4）取特征值前k大对应的特征向量ω1,ω2,…,ωk组成新的矩阵，将n维样本映射到k维。<br>由于得到协方差矩阵的特征值特征向量有两种方法：特征值分解协方差矩阵、奇异值分解协方差矩阵，所以PCA算法有两种实现方法：基于特征值分解协方差矩阵实现PCA算法、基于SVD分解协方差矩阵实现PCA算法。<br>PCA算法的主要优点有：<br>1）仅仅需要以方差衡量信息量，不受数据集以外的因素影响。<br>2）各主成分之间正交，可消除原始数据成分间的相互影响的因素。<br>3）计算方法简单，主要运算是特征值分解，易于实现。<br>PCA算法的主要缺点有：<br>1）主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强。<br>2）方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响。</p>
<h3 id="SVD奇异值分解"><a href="#SVD奇异值分解" class="headerlink" title="SVD奇异值分解"></a>SVD奇异值分解</h3><p>SVD是一种矩阵分解方法，相当于因式分解，其目的就是将一个矩阵拆分成多个矩阵相乘的形式。能用小得多的数据集来表示原始数据集，这样可以去除噪声和冗余信息。适用于数值型数据。<br>优点：简化数据，去除噪声，提高算法的结果；<br>缺点：数据的转换可能难以理解，分解出的矩阵解释性往往不强。</p>
<h3 id="LDA、PCA、SVD推导过程"><a href="#LDA、PCA、SVD推导过程" class="headerlink" title="LDA、PCA、SVD推导过程"></a>LDA、PCA、SVD推导过程</h3><p><a href="https://blog.csdn.net/weixin_31866177/article/details/88079612?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">简述LDA、PCA、SVD推导过程</a></p>
<h2 id="K近邻算法（KNN）"><a href="#K近邻算法（KNN）" class="headerlink" title="K近邻算法（KNN）"></a>K近邻算法（KNN）</h2><p>对于新的样本，根据其K个最近邻的训练样本的标签，通过多数表决等方式进行预测。<br>k近邻的三要数：k值选择；距离度量；决策规则。<br>K近邻的优点：第一就就是k近邻算法是一种在线技术，新数据可以直接加入数据集而不必进行重新训练，第二就是k近邻算法理论简单，容易实现。第三就是准确性高，对异常值和噪声有较高的容忍度。第四就是k近邻算法天生就支持多分类，区别与感知机、逻辑回归、SVM。<br>K近邻算法的缺点：基本的 k近邻算法每预测一个“点”的分类都会重新进行一次全局运算，对于样本容量大的数据集计算量比较大。而且K近邻算法容易导致维度灾难，在高维空间中计算距离的时候，就会变得非常远；样本不平衡时，预测偏差比较大，k值大小的选择得依靠经验或者交叉验证得到。k的选择可以使用交叉验证，也可以使用网格搜索。k的值越大，模型的偏差越大，对噪声数据越不敏感，当k的值很大的时候，可能造成模型欠拟合。k的值越小，模型的方差就会越大，当k的值很小的时候，就会造成模型的过拟合。<br>K值的选择：<br>1）K值较小，则模型复杂度较高，容易发生过拟合，学习的估计误差会增大，预测结果对近邻的实例点非常敏感。<br>2）K值较大可以减少学习的估计误差，但是学习的近似误差会增大，与输入实例较远的训练实例也会对预测起作用，使预测发生错误，k值增大模型的复杂度会下降。<br>3）在应用中，k值一般取一个比较小的值，通常采用交叉验证法来选取最优的K值。</p>
<h2 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h2><p>集成学习能够通过训练数据集产生多个学习模型，然后通过一定的结合策略生成强学习模型。<br><img src="/images/集成学习.png" alt="集成学习"></p>
<h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><p>算法流程<br>1）从训练样本集中随机可放回抽样（Bootstrapping )N次，得到与训练集相同大小的训练集，重复抽样K次，得到K个训练集 。<br>2） 每个训练集得到一个最优模型，K个训练集得到K个最优模型。<br>3） 分类问题：对K个模型采用投票的方式得到分类结果；回归问题：对K个模型的值求平均得到分类结果。</p>
<h3 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h3><p>Boosting是一种可将弱学习器提升为强学习器的算法。Boosting的每一次抽样的样本分布是不一样的，每一次迭代，都是根据上一次迭代的结果，增加被错误分类的样本的权重。使模型在之后的迭代中更加注重难以分类的样本。这是一个不断学习的过程，也是一个不断提升的过程，这就是Boosting思想的本质所在。迭代之后，将每次迭代的基分类器进行集成，那么如何进行样本权重的调整和分类器的集成是我们需要考虑的关键问题。<br>1）每一轮如何改变训练数据的权值和概率分布？<br>通过提高那些在前一轮被弱学习器分错样例的权值，减小前一轮正确样例的权值，使学习器重点学习分错的样本，提高学习器的性能。<br>2）通过什么方式来组合弱学习器？<br>通过加法模型将弱学习器进行线性组合，学习器准确率大，则相应的学习器权值大；反之，则学习器的权值小。即给学习器好的模型一个较大的确信度，提高学习器的性能。</p>
<h3 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h3><p>集成学习得到多个学习器后，结合策略得到最终的结果。通常用到最多的是平均法，投票法和学习法。<br>1） 平均法<br>对于数值类的回归预测，通常使用的结合策略是平均法，即对K个学习器的学习结果求平均，得到最终的预测结果。<br>2）投票法<br>对于分类问题的预测，通常使用的结合策略是投票法，也就是我们常说的少数服从多数。即对K个学习器的分类结果作一个统计，出现次数最多的类作为预测类。<br>3） 学习法<br>上面两种结合策略方法比较简单，可能学习误差较大。因此，我们尝试用学习法去预测结果，学习法是将K个学习器的分类结果再次作为输入，将训练集的输出作为输出，重新训练一个学习器来得到最终结果。</p>
<h3 id="Bagging和Boosting的区别："><a href="#Bagging和Boosting的区别：" class="headerlink" title="Bagging和Boosting的区别："></a>Bagging和Boosting的区别：</h3><p>1）样本选择上：<br>Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。<br>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化，而权值是根据上一轮的分类结果进行调整。<br>2）训练样本权重：<br>Bagging：使用均匀取样，每个样例的权重相等。<br>Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。<br>3）预测函数权重：<br>Bagging：所有预测函数的权重相等。<br>Boosting：学习器性能好的分配较大的权重，学习器性能差的分配较小的权重。<br>4）并行计算：<br>Bagging：各个预测函数可以并行生成。<br>Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。</p>
<h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p>决策树是一种自上而下，对样本数据进行树形分类的过程，由节点和有向边组成。 节点分为内部节点和叶节点，其中每个内部节点表示一个特征或属性，叶节点表示类别。 从顶部节点开始，所有样本聚在一起，经过根节点的划分，样本被分到不同的子节点中，再根据子节点的特征进一步划分，直至所有样本都被归到某个类别。</p>
<h3 id="决策树的实现-ID3、C4-5、CART"><a href="#决策树的实现-ID3、C4-5、CART" class="headerlink" title="决策树的实现 ID3、C4.5、CART"></a>决策树的实现 ID3、C4.5、CART</h3><p>ID3使用信息增益来指导树的分裂：<br><img src="/images/ID3.jpg" alt="ID3"><br>C4.5通过信息增益比来指导树的分裂：<br><img src="/images/C45.jpg" alt="C4.5"><br>CART的话既可以是分类树，也可以是回归树。当是分类树时，使用基尼系数来指导树的分裂：<br><img src="/images/CART1.png" alt="CART"><br>当是回归树时，则使用的是平方损失最小：<br><img src="/images/CART2.jpg" alt="CART"></p>
<h3 id="CART分类树和ID3以及C4-5的区别"><a href="#CART分类树和ID3以及C4-5的区别" class="headerlink" title="CART分类树和ID3以及C4.5的区别"></a>CART分类树和ID3以及C4.5的区别</h3><p>1）首先是决策规则的区别，CART分类树使用基尼系数、ID3使用的是信息增益，而C4.5使用的是信息增益比。ID3采用信息增益作为评价标准，模型的泛化能力非常弱。C4.5通过引入信息增益比，一定程度上对取值比较多的特征进行惩罚， 避免ID3出现过拟合的特性，提升决策树的泛化能力。<br>2）ID3和C4.5可以是多叉树，但是CART分类树只能是二叉树。<br>3）从样本类型的角度，ID3只能处理离散型变量，而C4.5和CART都可以处理连续型变量。C4.5处理连续型变量时，通过对数据排序之后找到类别不同的分割线作为切分点，根据切分点把连续属性转换为布尔型，从而将连续型变量转换多个取值区间的离散型变量。而对于CART，由于其构建时每次都会对特征进行二值划分，因此可以很好地适用于连续性变量。</p>
<h3 id="决策树剪枝"><a href="#决策树剪枝" class="headerlink" title="决策树剪枝"></a>决策树剪枝</h3><p>决策树剪枝可分为前剪枝和后剪枝，剪枝可防止过拟合。前剪枝本质就是早停止，后剪枝通常是通过衡量剪枝后损失函数变化来决定是否剪枝。<br>为什么要对决策树进行减枝？ 如何进行减枝？<br>剪枝是决策树解决过拟合问题的方法。 在决策树学习过程中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，于是可能将训练样本学得太好，以至于把训练集自身的一些特点当作所有数据共有的一般特点而导致测试集预测效果不好，出现了过拟合现象。 因此，可以通过剪枝来去掉一些分支来降低过拟合的风险。<br>决策树剪枝的基本策略有“预剪枝”和“后剪枝”。 预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点； 后剪枝则是先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。<br>前剪枝的几种停止条件：<br>1）当树到达一定深度的时候，停止树的生长。<br>2）当到达当前结点的样本数量小于某个阈值的时候，停止树的生长。<br>3）计算每次分裂对测试集的准确度提升，当小于某个阈值的时候，不再继续扩展。<br>常见的后剪枝方法包括错误率降低剪枝（Reduced Error Pruning，REP）、悲观剪枝（Pessimistic Error Pruning，PEP）、代价复杂度剪枝（Cost Complexity Pruning，CCP）、最小误差剪枝（Minimum Error Pruning， MEP）、CVP（Critical Value Pruning）、OPP（Optimal Pruning）等方法。</p>
<h3 id="随机森林的随机体现在哪些方面"><a href="#随机森林的随机体现在哪些方面" class="headerlink" title="随机森林的随机体现在哪些方面"></a>随机森林的随机体现在哪些方面</h3><p>随机森林的随机主要体现在两个方面：一个是建立每棵树时所选择的特征是随机选择的；二是生成每棵树的样本也是通过有放回抽样产生的。</p>
<h3 id="GDBT-Xgboost-lightGBM的区别"><a href="#GDBT-Xgboost-lightGBM的区别" class="headerlink" title="GDBT,Xgboost,lightGBM的区别"></a>GDBT,Xgboost,lightGBM的区别</h3><p>1）传统 GBDT 以 CART 作为基分类器，xgboost 还支持线性分类器，这个时候 xgboost 相当于带 L1 和 L2 正则化项的逻辑回归(分类问题)或者线性回归(回归问题)。<br>2）传统 GBDT 在优化时只用到一阶导数信息，xgboost 则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。<br>3）xgboost 在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的 score 的 L2 模的平方和。从 Bias-variance tradeoff 角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是 xgboost 优于传统GBDT 的一个特性。<br>4）Shrinkage(缩减)，相当于学习速率(xgboost 中的eta)。xgboost 在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把 eta 设置得小一点，然后迭代次数设置得大一点。(补充:传统 GBDT 的实现也有学习速率)<br>5）列抽样(column subsampling)。xgboost 借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是 xgboost异于传统gbdt 的一个特性。<br>6）对缺失值的处理。对于特征的值有缺失的样本，xgboost 可以自动学习出它的分裂方向。<br>7）xgboost 工具支持并行。boosting 不是一种串行的结构吗?怎么并行的? 注意 xgboost 的并行不是 tree 粒度的并行，xgboost 也是一次迭代完才能进行下一次迭代的(第t次迭代的代价函数里包含了前面 t-1 次迭代的预测值)。xgboost 的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序(因为要确定最佳分割点)，xgboost在训练之前，预先对数据进行了排序，然后保存为 block 结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。<br>8）可并行的近似直方图算法。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以 xgboost 还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。<br>Xgboost和LightGBM，二者的区别如下：<br>1）由于在决策树在每一次选择节点特征的过程中，要遍历所有的属性的所有取 值并选择一个较好的。XGBoost 使用的是近似算法算法，先对特征值进行排序 Pre-sort，然后根据二阶梯度进行分桶，能够更精确的找到数据分隔点;但是 复杂度较高。LightGBM 使用的是 histogram 算法，这种只需要将数据分割成不同的段即可，不需要进行预先的排序。占用的内存更低，数据分隔的复杂度更低。<br>2）决策树生长策略，我们刚才介绍过了，XGBoost采用的是 Level-wise 的树 生长策略，LightGBM 采用的是 leaf-wise 的生长策略。<br>3）并行策略对比，XGBoost 的并行主要集中在特征并行上，而 LightGBM 的并 行策略分特征并行，数据并行以及投票并行。</p>
<h2 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h2><p>​ 聚类就是按照某个特定标准把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不在同一个簇中的数据对象的差异性也尽可能地大。主要的聚类算法可以划分为如下几类：划分方法、层次方法、基于密度的方法、基于网格的方法以及基于模型的方法。</p>
<h3 id="聚类和降维有什么区别和联系"><a href="#聚类和降维有什么区别和联系" class="headerlink" title="聚类和降维有什么区别和联系"></a>聚类和降维有什么区别和联系</h3><p>​ 聚类用于找寻数据内在的分布结构，既可以作为一个单独的过程，也可作为分类等其他学习任务的前驱过程。聚类是标准的无监督学习。在一些推荐系统中需确定新用户的类型，但定义“用户类型”却可能不太容易，此时往往可先对原有的用户数据进行聚类，根据聚类结果将每个簇定义为一个类,然后再基于这些类训练分类模型,用于判别新用户的类型。<br>降维则是为了缓解维数灾难的一个重要方法，就是通过某种数学变换将原始高维属性空间转变为一个低维“子空间”。从而通过最主要的几个特征维度就可以实现对数据的描述，对于后续的分类很有帮助。<br>聚类和降维都可以作为分类等问题的预处理步骤。虽然他们都能实现对数据的约减，但二者适用的对象不同，聚类针对的是数据点，而降维则是对于数据的特征。</p>
<h3 id="k-means聚类算法"><a href="#k-means聚类算法" class="headerlink" title="k-means聚类算法"></a>k-means聚类算法</h3><p>k-means算法以k为参数，把n个对象分成k个簇，使簇内具有较高的相似度，而簇间的相似度较低。k-means算法的处理过程如下：首先，随机地选择k个对象，每个对象初始地代表了一个簇的平均值或中心;对剩余的每个对象，根据其与各簇中心的距离，将它赋给最近的簇;然后重新计算每个簇的平均值。这个过程不断重复，直到准则函数收敛。通常，采用平方误差准则，其定义如下：</p>
<script type="math/tex; mode=display">E=\sum_{i=1}^k\sum_{p\in C_i}||p-m_i||^2</script><h4 id="k-means-算法"><a href="#k-means-算法" class="headerlink" title="k-means++算法"></a>k-means++算法</h4><p>k个初始化的质心的位置选择对最后的聚类结果和运行时间都有很大的影响，因此需要选择合适的k个质心。如果仅仅是完全随机的选择，有可能导致算法收敛很慢。K-Means++算法就是对K-Means随机初始化质心的方法的优化。<br>K-Means++的对于初始化质心的优化策略也很简单，如下：<br>a)从输入的数据点集合中随机选择一个点作为第一个聚类中心μ1<br>b)对于数据集中的每一个点$x_i$，计算它与已选择的聚类中心中最近聚类中心的距离$D(x_i)=arg min||x_i−μ_r||_2^2, r=1,2,…kselected$。<br>c)选择一个新的数据点作为新的聚类中心，选择的原则是：D(x)较大的点，被选取作为聚类中心的概率较大<br>d) 重复b和c直到选择出k个聚类质心<br>e) 利用这k个质心来作为初始化质心去运行标准的K-Means算法</p>
<h4 id="ISODATA算法"><a href="#ISODATA算法" class="headerlink" title="ISODATA算法"></a>ISODATA算法</h4><p>当K值的大小不确定时，可以使用ISODATA算法。ISODATA的全称是迭代自组织数据分析法。在K均值算法中，聚类个数K的值需要预先人为地确定，并且在整个算法过程中无法更改。而当遇到高维度、海量的数据集时，人们往往很难准确地估计出K的大小。ISODATA算法就是针对这个问题进行了改进，它的思想也很直观。当属于某个类别的样本数过少时，把该类别去除；当属于某个类别的样本数过多、分散程度较大时，把该类别分为两个子类别。ISODATA算法在K均值算法的基础之上增加了两个操作，一是分裂操作，对应着增加聚类中心数；二是合并操作，对应着减少聚类中心数。ISODATA算法是一个比较常见的算法，其缺点是需要指定的参数比较多，不仅仅需要一个参考的聚类数量$K_o$，还需要制定3个阈值。<br>1） 预期的聚类中心数目$K_o$。在ISODATA运行过程中聚类中心数可以变化，$K_o$是一个用户指定的参考值，该算法的聚类中心数目变动范围也由其决定。具体地，最终输出的聚类中心数目常见范围是从$K_o$的一半，到两倍$K_o$。<br>2）每个类所要求的最少样本数目$N_{min}$。如果分裂后会导致某个子类别所包含样本数目小于该阈值，就不会对该类别进行分裂操作。<br>3）最大方差Sigma。用于控制某个类别中样本的分散程度。当样本的分散程度超过这个阈值时，且分裂后满足（1），进行分裂操作。<br>4） 两个聚类中心之间所允许最小距离$D_{min}$。如果两个类靠得非常近（即这两个类别对应聚类中心之间的距离非常小），小于该阈值时，则对这两个类进行合并操作。</p>
<h4 id="K-Means与KNN的区别"><a href="#K-Means与KNN的区别" class="headerlink" title="K-Means与KNN的区别"></a>K-Means与KNN的区别</h4><p>K-Means是无监督学习的聚类算法，没有样本输出；而KNN是监督学习的分类算法，有对应的类别输出。KNN基本不需要训练，对测试集里面的点，只需要找到在训练集中最近的k个点，用这最近的k个点的类别来决定测试点的类别。而K-Means则有明显的训练过程，找到k个类别的最佳质心，从而决定样本的簇类别。<br>当然，两者也有一些相似点，两个算法都包含一个过程，即找出和某一个点最近的点。两者都利用了最近邻(nearest neighbors)的思想。</p>
<h4 id="k-means的优缺点"><a href="#k-means的优缺点" class="headerlink" title="k-means的优缺点"></a>k-means的优缺点</h4><p>K-Means的主要优点有：<br>1）原理比较简单，实现也是很容易，收敛速度快。<br>2）聚类效果较优。<br>3）算法的可解释度比较强。<br>4）主要需要调参的参数仅仅是簇数k。</p>
<p>K-Means的主要缺点有：<br>1）K值的选取不好把握<br>2）对于不是凸的数据集比较难收敛<br>3）如果各隐含类别的数据不平衡，比如各隐含类别的数据量严重失衡，或者各隐含类别的方差不同，则聚类效果不佳。<br>4）采用迭代方法，得到的结果只是局部最优。<br>5）对噪音和异常点比较的敏感。</p>
<h3 id="层次聚类算法"><a href="#层次聚类算法" class="headerlink" title="层次聚类算法"></a>层次聚类算法</h3><p>根据层次分解的顺序是自底向上的还是自上向下的，层次聚类算法分为凝聚的层次聚类算法和分裂的层次聚类算法。凝聚型层次聚类的策略是先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到所有对象都在一个簇中，或者某个终结条件被满足。<br>算法流程：<br>以采用最小距离的凝聚层次聚类算法为例：<br>(1) 将每个对象看作一类，计算两两之间的最小距离；<br>(2) 将距离最小的两个类合并成一个新类；<br>(3) 重新计算新类与所有类之间的距离；<br>(4) 重复(2)、(3)，直到所有类最后合并成一类。</p>
<h2 id="当机器学习性能不是很好时，你会如何优化？"><a href="#当机器学习性能不是很好时，你会如何优化？" class="headerlink" title="当机器学习性能不是很好时，你会如何优化？"></a>当机器学习性能不是很好时，你会如何优化？</h2><p><a href="https://mp.weixin.qq.com/s/jO-r2gsQkl6WzVcVvIl-Cg" target="_blank" rel="noopener">参考答案</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/12/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/12/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">简历项目介绍</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-12 16:02:14" itemprop="dateCreated datePublished" datetime="2020-02-12T16:02:14+08:00">2020-02-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-04-20 10:14:43" itemprop="dateModified" datetime="2020-04-20T10:14:43+08:00">2020-04-20</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="智能辅助健身锻炼系统"><a href="#智能辅助健身锻炼系统" class="headerlink" title="智能辅助健身锻炼系统"></a>智能辅助健身锻炼系统</h1><h2 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>本项目（是和深圳趣感科技公司委托下）搭建的一个远程的在线辅助健身锻炼系统，类似于keep软件，但项目核心通过评分机制促进用户的锻炼效果。项目针对的是需要在家完成健身锻炼的人群，通过2D摄像头采集用户的锻炼视频，实时上传到系统的业务后台，利用服务器端提供的姿态估计和行为识别算法，评估用户的锻炼效果，辅助用户在家完成健身锻炼。</p>
<h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>深圳趣感科技公司是开发一款穿戴式跑步训练指导系统，通过传感器采集人体运动数据，对跑步姿态进行科学评估，根据评估结果生成个性化的力量训练和跑姿改善计划，并实时监测训练完成度和质量。<br>深圳趣感科技提供了的一系列标准5-6分钟的锻炼视频，作为锻炼动作的模板。每个动作持续时间是3-5s，</p>
<h2 id="项目架构"><a href="#项目架构" class="headerlink" title="项目架构"></a>项目架构</h2><p>本项目是分模块设计的，前端是网页版智能健身指导平台，结合摄像头采集用户的锻炼视频及标准的锻炼视频和用户锻炼效果的展示。中间是系统的业务后台，负责对视频流数据和姿态数据的处理、封装和转发。最后是服务器端，主要运行姿态估计和行为识别等算法，通过人体关键点评估用户的锻炼效果。</p>
<h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><p>项目的前端是基于vue.js的Element框架搭建，业务后台是基于java的SpringBoot+Mybatis框架；算法层大多基于python实现，主要完成2D的人体姿态估计和基于关键点的行为识别算法。利用openpose获取人体关键点，然后将17个关键点坐标输入HCN网络进行行为分类。在三次准备动作中，若两次动作类别正确，则判断用户开始锻炼。最后采用DTW算法对该段时间内用户锻炼的关键点和正确指导视频的关键点进行匹配，判断用户锻炼的效果。<br>HCN网络一种端到端的共现特征学习框架，其使用了 CNN 来自动地从骨架序列中学习分层的共现特征。我们首先使用核大小为 n×1 的卷积层独立地为每个关节学习了点层面的特征。然后我们再将该卷积层的输出转置，以将关节的维度作为通道。如果一个骨架的每个关节都被当作是一个通道，那么卷积层就可以轻松地学习所有关节的共现。在这个转置运算之后，后续的层分层地聚合来自所有关节的全局特征。通过构建这种结构，在使用7层的网络就能获得较高的行为识别的准确率。<br>共现性：人的某个行为动作常常和骨架的一些特定关节点构成的集合，以及这个集合中节点的交互密切相关。如要判别是否在打电话，关节点“手腕”、“手肘”、“肩膀”和“头”的动作最为关键。我们将这种几个关节点同时影响和决定判别的特性称为共现性。</p>
<h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><p>（1）结合openpose和基于骨骼的行为识别算法，实现了真实场景下具有较高鲁棒性的动作分类及评估。（2）算法层与平台之间的视频通信采用redis的消息中间件，采用发布/订阅模式为不同的任务订阅不同channel，实行并行的任务处理。（3）算法模块中行为识别算法创新主要体现在论文中，我可以给你详细介绍一下我的论文。</p>
<h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2><p>遇到的最大的问题是什么？怎么解决的？学到了什么？<br>项目遇到的最大问题是系统方案的设计，针对项目的需求，实时的姿态估计前后端、服务器间的通信机制的实现，单一动作样本实现动作评估的算法模型选择等等，都花费大量的时间进行前期的项目调研，查询相关的资料文献、咨询有开发经验的师兄们后才最终明确系统的设计方案。<br>系统后台和服务器端间的通信，为了满足项目的实时性需求，采用redis做二者的消息中间件，利用redis的发布/订阅模式，完成图像信息的传输。<br>在这次的项目中，培养了我对现有资料的总结和应用能力，对系统方案宏观考虑和设计的能力，以及在团队合作时成员间协作配合的能力。</p>
<h2 id="项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？"><a href="#项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？" class="headerlink" title="项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？"></a>项目负责人带领多少人的团队？从哪些维度规划项目？项目时间节点把握？</h2><p>项目是四个人的团队。主要从功能模块和时间线规划项目。功能模块分为三个部分，主要是前端、后台和算法模块。前端和后台各安排一位同学完成，还有两个同学专注于算法模块的设计，分别负责姿态估计和行为识别算法。在时间上主要是半个月的调研以及和客户的沟通、方案的设计。然后是两个月的系统框架的初步搭建，以及最后三个月的界面调整和算法优化。</p>
<h2 id="项目最大的收获是什么？"><a href="#项目最大的收获是什么？" class="headerlink" title="项目最大的收获是什么？"></a>项目最大的收获是什么？</h2><p>在完整负责了一个项目设计和开发过程后，培养了我对现有资料的学习、总结和应用能力，对系统方案宏观考虑和设计的能力，以及在团队合作时成员间任务分配和协作配合能力。</p>
<h2 id="项目的后期扩展有哪些？"><a href="#项目的后期扩展有哪些？" class="headerlink" title="项目的后期扩展有哪些？"></a>项目的后期扩展有哪些？</h2><p>项目后期扩展可以从功能角度考虑，比如和专业健身教练合作为每个用户定制个性化的健身计划，通过系统评分有效促进健身锻炼。从算法层面考虑，通过更细粒度的标注信息，如动作锻炼的次数，关节角度等，提高动作评估的多样性和科学性。</p>
<h2 id="选取openpose的指标？为什么采用openpose"><a href="#选取openpose的指标？为什么采用openpose" class="headerlink" title="选取openpose的指标？为什么采用openpose?"></a>选取openpose的指标？为什么采用openpose?</h2><p>使用姿态估计算法时，主要考虑了openpose和alphapose两种技术，在准确率和速度上，openpose达到60mAP和10FPS，alphapose达到71mAP和20FPS，二者性能差距不大，但从系统的后期扩展性考虑，使用openpose可以估计半身或局部的人体姿态，便于系统功能扩展。<br>采用openpose的最大原因是视频数据单一，只有单人的标准健身视频，在通过深度学习判断动作类别时存在大量的背景干扰，采用姿态估计获得人体的关键点进行动作评估，可以有效减低背景干扰，增强系统的鲁棒性。</p>
<h2 id="动作相似度是怎么判断的？动作时间规划在项目中如何实现？"><a href="#动作相似度是怎么判断的？动作时间规划在项目中如何实现？" class="headerlink" title="动作相似度是怎么判断的？动作时间规划在项目中如何实现？"></a>动作相似度是怎么判断的？动作时间规划在项目中如何实现？</h2><p>DTW动态时间规划，可以计算两个时间序列的相似度，尤其适合用于不同长度、不同节奏的时间序列。DTW将自动对时间序列进行缩放，使得两个序列的形态尽可能一致，得到最大可能的相似度。<br>我们假设用户的动作序列为Q和标准的锻炼动作序列为C，其中Q和C分别代表动作开始到结束期间人体的关键点坐标序列，即序列中的每一时刻都是由人体的17个关键点的坐标构成，标准动作序列事先通过openpose采集存放在数据库，根据行为识别判断的人体动作类别来获取，所有的人体关键点的空间坐标转换为相对人体的重心位置的相对坐标。动作匹配就转化为比较在动作发生时间内用户动作的关键点序列与标准模板的关键点序列的相似度进行评分。我们需要构造一个nxm的矩阵网格，n和m分别表征两段动作序列的长度。矩阵元素(i, j)表示两段动作序列qi和cj两帧的空间距离d(qi, cj)（每一帧都是在计算17个对应的人体关键点空间距离，也就是序列Q的每一个点和序列C的每一个点之间的相似度，距离越小则相似度越高。）。从开始时间匹配这两个动作序列Q和C，每经过一帧，之前所计算的空间距离都会累加。到达终点(n, m)后，这个累积距离就是我们上面说的最后的总的距离，也就是序列Q和C的相似度。通过使累积的距离最小，来判断两动作序列的最大可能相似度。</p>
<h2 id="常见的消息队列有哪些及其功能是什么？"><a href="#常见的消息队列有哪些及其功能是什么？" class="headerlink" title="常见的消息队列有哪些及其功能是什么？"></a>常见的消息队列有哪些及其功能是什么？</h2><p>当前使用较多的消息队列有RabbitMQ、RocketMQ、ActiveMQ、Kafka、ZeroMQ、MetaMQ等，而部分数据库如Redis、MySQL以及phxsql也可以实现消息队列的功能。<br>消息队列是指利用高效可靠的消息传递机制进行平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息排队模型，它可以在分布式环境下提供应用解耦、弹性伸缩、冗余存储、流量削峰、异步通信、数据同步等等功能，其作为分布式系统架构中的一个重要组件，有着举足轻重的地位。<br>消息队列的特点：<br>1）采用异步处理模式<br>消息发送者 可以发送一个消息而无须等待响应。消息发送者 将消息发送到一条 虚拟的通道（主题 或 队列）上，消息接收者 则 订阅 或是 监听 该通道。一条信息可能最终转发给 一个或多个 消息接收者，这些接收者都无需对 消息发送者 做出 同步回应。整个过程都是异步的。<br>2）应用系统之间解耦合<br>发送者和接受者不必了解对方、只需要 确认消息；发送者和接受者 不必同时在线。</p>
<h1 id="电信亿迅智慧安防系统"><a href="#电信亿迅智慧安防系统" class="headerlink" title="电信亿迅智慧安防系统"></a>电信亿迅智慧安防系统</h1><h2 id="项目介绍-1"><a href="#项目介绍-1" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>北邮和电信集团亿迅公司合作的智慧安防系统，系统采用基于深度学习的目标检测算法，对场景中的人脸和人体进行结构化分析和特征提取，分析人员的头部特征和穿着特征以及运动特征。</p>
<h2 id="主要工作"><a href="#主要工作" class="headerlink" title="主要工作"></a>主要工作</h2><p>主要负责多目标跟踪模块，采用YoloV3算法检测出人体位置，利用deepsort算法进行在线的多目标追踪。</p>
<h1 id="国家电网能力开放平台（项目核心成员）"><a href="#国家电网能力开放平台（项目核心成员）" class="headerlink" title="国家电网能力开放平台（项目核心成员）"></a>国家电网能力开放平台（项目核心成员）</h1><h2 id="项目介绍-2"><a href="#项目介绍-2" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>北邮与国家电网电车公司合作的，面向服务提供方ISP和应用开发方ISV设计开发的能力开放平台，能有效整合服务资源，通过能力开放的形式吸引服务提供商在平台完成注册、发布API，并与应用开发方建立商业联系。平台则需完成对ISP、ISV的服务监管和计量计费。</p>
<h2 id="项目架构-1"><a href="#项目架构-1" class="headerlink" title="项目架构"></a>项目架构</h2><p>基于微服务架构设计，分为协议转换模块、控制接入模块和平台管理模块。</p>
<h2 id="主要工作-1"><a href="#主要工作-1" class="headerlink" title="主要工作"></a>主要工作</h2><p>主要负责与国家电网南瑞子公司进行需求对接，并且主导了整体架构微服务的设计，完成了“协议转换模块”、“流量控制模块”、“权限管理模块”和“计费管理模块”的设计与实现。<br>1）协议转换模块：因为系统之间通信使用的基于阿里的HSF通信协议，所以需要将http接口转换为hsf需要的接口样式，对于用户的http调用，采用Spring AOP做了一个拦截，具体采用的Around方法，在调用之前，调用之中，调用之后分别对请求做了一些操作。<br>2）接入控制模块：对应协议控制模块中的拦截之前，对用户请求做了：鉴权、流控。在请求之后，做了计量计费操作。<br>鉴权：用户表，角色表，权限表，可见的菜单表，页面元素、文件表。<br>限流：基于Redis+Lua脚本，实现了基于固定时间分片的分布式限流。（1）通过spring AOP方法拦截的用户请求中获得用户调用的appid和apiid。根据appid和apiid组合的key值，在redis缓存中查找用户的流量控制策略。 （2）将appid、apiid和当前时间戳组合作为key值，将最大访问次数作为value值存入redis中，用户调用一次接口，将value值加一，在限制时间内达到最大次数，返回-1，否则返回+1，根据返回的状态对请求进行放行或拒绝。（3）Redis中不存在该流控策略，根据apiid从数据库中查找对应的流量控制策略，并将appid和apiid作为key值，流控策略作为value值存入redis中，并执行一次方法（2）。<br>计费：采用是工厂模式，产生三种计费方式：“按照时间计费（包年包月）”、“按照流量计费”、“按照次数计费”。</p>
<h2 id="亮点："><a href="#亮点：" class="headerlink" title="亮点："></a>亮点：</h2><p>设计模式：<br>1）代理模式：协议转换和访问控制模块之间采用了代理模式，整个协议控制模块都相当于中介。使用了AOP对原始方法做了处理，AOP本身利用反射对目标方法使用了动态代理模式。<br>2）策略模式：定义一系列控制算法，并且使得他们之间可以互换。访问控制模块使用该设计模式，分为“正常状态下的访问”和“测试状态下的访问”，这两种不同的状态，包含了不同的控制策略。“正常状态下的访问”：鉴权、流控、计费，“测试状态下的访问”：鉴权、流控，不包计费。利用Spring将这些策略注入到不同的List中，然后依次进行调用。<br>3）工厂模式：将“包年包月计费”、“按照流量计费”、“按照次数计费”实现同一个接口，并用工厂类，利用反射来调用这些计费方式。<br>微服务：<br>多个模块独立部署：对于不同的模块，进行不同方向上的拓展。项目中：协议转换模块承载最大的用户接入，需要做X轴拓展，通过负载均衡，对请求进行分发。而访问控制模块则分为不同的小模块，可以做数据库的Y轴上业务的拓展（功能性拆分）。可以按照服务队硬件资源不同的需求进行升级！<br>模块解耦，本项目是采用基于RPC的HSF协议进行模块之间的通信，面向连接。HSF是阿里内部使用的模块间通信方式。在调通分布式模块之间通信的遇到过一个比较大的问题，后来通过分析Edas平台各个服务器IP地址和服务端口以及redis日志文件，判断到最后是因为一个模块之间的redis地址出错导致没有启动redis，引发的后续通信的问题，体现了排错能力和自主解决问题的能力。</p>
<h1 id="2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别"><a href="#2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别" class="headerlink" title="2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别"></a>2018广东工业智造大数据创新大赛—铝型材表面瑕疵识别</h1><h2 id="项目介绍-3"><a href="#项目介绍-3" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>在铝型材的实际生产过程中，由于各方面的影响，铝型材表面会产生<br>裂纹、起皮、划伤等瑕疵，影响铝型材的质量。为保证产品质量，需要人工进行肉眼目测。然而，铝型材的表面自身会含有纹路，与瑕疵的区分度不高。传统人工肉眼检查十分费力，不能及时准确的判断出表面瑕疵，质检的效率难以把控。铝型材制造商迫切希望采用最新的AI技术来革新现有质检流程，自动完成质检任务，减少漏检发生率，提高产品的质量。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>瑕疵类型：不导电、檫花、角位漏底、桔皮、漏底、喷流、漆泡、起坑、杂色和脏点10类。训练时加上“正常”类别和“其他”类别一共12类。<br>初赛数据量：3000张图片，包含所有的瑕疵类型。初赛的图片结果为单标签的，即一张图片只有一种瑕疵。“其他”的类别文件夹中瑕疵初赛不要求细分，只是统一划分为一类。<br>初赛是分类任务，初赛提交的文件是csv文件，只需要提交测试集中图片名称和对应的类别标签。<br>分辨率统一为2056x1920<br>训练集：guangdong_round1_train1_20180903，约240M，约250张图片<br>guangdong_round1_train2_20180916，约1G。<br>分为无瑕疵图片1018张，和有瑕疵图片1120张<br>测试集：a榜：guangdong_round1_test_a_20180916，约384兆，440张图片<br>b榜：guangdong_round1_test_b_20181009，约825兆，1000张图片。<br>复赛图片大约有4356张图片，包含单瑕疵图片、多瑕疵图片和无瑕疵图片。单瑕疵图片指所含瑕疵类型只有一种的图片，但图片中可能出现多处相同类型的瑕疵；多瑕疵图片指所含瑕疵类型多于一种的图片；无瑕疵图片指瑕疵可忽略不计的图片，这些图片不需要标注。<br>复赛是检测任务，需要检测测试集中每幅图像所有瑕疵的位置和类型，瑕疵的位置通过矩形检测框进行标记，需给出各个矩形检测框的置信度，并将检测结果保存为utf-8编码的json文件。<br>训练集：guangdong_round1_train2_20181011，约6G，分为单瑕疵图片2776张，多瑕疵图片229张和无瑕疵图片1351张。<br>测试集：a榜：guangdong_round2_test_a_20181011，约420M，500张图片<br>b榜：guangdong_round2_test_b_20181106，约841M，1000张图片</p>
<h2 id="比赛内容"><a href="#比赛内容" class="headerlink" title="比赛内容"></a>比赛内容</h2><p>在给定的生产线上铝型材监测影像上标注出瑕疵的位置并判断瑕疵类型。在前期的数据统计中，我们发现瑕疵的IOU占比小于0.1的样本数量占总体的63%左右，但还有5%的数据IOU占比达到0.7-0.8左右。样本数据存在瑕疵的尺寸大小变化大，两极分化严重，且微小瑕疵的样本数量多等问题。针对瑕疵的长宽比例不均匀，我们首先采用faster R-CNN来适应更多的长宽比，并采用resnet101作为骨干网络减少漏检的概率。针对微小瑕疵样本数量多的问题，我们采用特征金字塔网络（FPN）来对网络进行改进，并进一步采用ROIAlign替换ROIPooling，来提高小目标的检测效果。在训练过程中，我们使用数据增强和多尺度训练的方法，提高了模型的泛化能力及稳定性。在测试阶段，我们采用soft NMS替换NMS，实现更精细的回归框，提高检测结果。</p>
<h2 id="方案设计"><a href="#方案设计" class="headerlink" title="方案设计"></a>方案设计</h2><p>在前期的数据统计过程中，我们发现瑕疵的IOU占比小于0.1的数量占到总体的60%，但还有5%左右的数据主要是IOU占比达到0.7-0.8左右。瑕疵的矩形框尺寸大小变化大，两极分化严重，而且微小瑕疵的样本数量多。针对瑕疵的长宽比例不均匀，我们采用faster R-CNN两阶段来适应更多的长宽比。在单模的网络中我们首先会将图片缩小两倍之后才作为网络的输入。主干网络选取的是Resnet-101，在整个卷积的过程中，提取到特征的大小相对于输入图片是缩小了16倍。也就是说，从原图到最后一层的卷积特征，空间大小一共下降了32倍。 由于之后每一个候选框特征会被缩放到7x7的大小，如果说本身缩放前的特征就非常的小，那么缩放之后的特征是不具有判别力的。我们统计了一下数据集中边长&lt;=64的样本，发现这类小样本占了整个数据集的10%，这会严重地影响性能。为了解决这个问题，我们采用了特征金字塔结构(FPN)来对网络进行改进。把高层特征做2倍上采样（最近邻上采样），然后将其和对应的前一层特征结合（前一层要经过$1\times 1$的卷积核才能用，目的是改变channels,使之和后一层的channels相同），结合方式就是element-wise相加的操作。最后，使用$3\times 3$的卷积核去处理已经融合的特征图（为了消除上采样的混叠效应），以生成最后需要的特征图。我们总结了一下，特征金字塔在这个任务中具有两个优点：第一，在卷积神经网络中，高层的特征具有强的语义信息，低层的特征具有结构信息，因此 将高低层的信息进行结合，是可以增强特征的表达能力的。第二，我们将候选框产生和提取特征的位置分散到了特征金字塔的每一层，这样可以增加小目标的特征映射分辨率，对最后的预测也是有好处的。<br><img src="/images/faster rcnn+fpn.png" alt="Faster RCNN+FPN网络"><br>考虑到模型训练时间，实际的资源消耗以及网络的性能，采用多尺度训练，一方面增强了网络在多个尺度上的表现能力，另一方面提升了模型的泛化能力及稳定性。预先定义几个固定的尺度[(960,1024),(720,960),(640,800)]，每个epoch随机选择一个尺度进行训练。<br>考虑到小瑕疵的定位不准确导致误检，采用RoiAlign替代RoiPooling，取消量化误差，即遍历每一个候选区域，保持浮点数边界不做量化；将候选区域分割成$k\times k$个单元，每个单元的边界也不做量化；从而将整个特征聚集过程转化为一个连续的操作来细化检测框。<br>在测试阶段采用soft NMS替换NMS精细化检测框。<br>NMS：候选框的得分进行排序，选取得分最高的那个框，接下来计算其他框与当前框的重合程度(IOU)，如果重合程度大于一定的阈值就删除，这样不停的迭代下去就会得到所有想要找到的目标物体的区域。<br>而soft nms只是将重叠度大于一定的阈值进行抑制，最后再按分数过滤，从而使得重叠的物体被更大程度的保留下来。</p>
<h2 id="比赛的评价指标是什么？如何计算的？"><a href="#比赛的评价指标是什么？如何计算的？" class="headerlink" title="比赛的评价指标是什么？如何计算的？"></a>比赛的评价指标是什么？如何计算的？</h2><p>比赛的评价指标是参照PASCALVOC的评估标准IOU=0.5，计算10类瑕疵的mAP值作为最终的分数。本次大赛计算mAP时，对同一个ground-truth框，重复预测n次，取置信度(confidence)最高的预测框作为TP（true positive）样本，其余的n-1个框都作为FP(False positive)样本进行处理。大赛参照2010年之后的PASCAL VOC评分标准，检测框和真实框的交并比(IOU)阈值设定为0.5，同时，采用Interpolating all points方法插值获得PR曲线，并在此基础上计算mAP的值。<br>mAP计算过程：<br>1）mAP是对各目标类计算得到的AP取平均值<br>2）某类目标（假设为car）的AP可以理解为car类PR曲线（Precision-Recall）下的面积。<br>3）为了画出car的PR曲线，要对测试集上所有预测出的类别为car的bounding box按照置信度降序排列，然后标记每个bounding box是TP（True Positive）还是FP(False Positive)，并分别对TP和FP的数目进行累计，计算相应的Precision和Recall。Precision是指在所有的预测中有多少是正确的, P=TP/(TP+FP)=TP/(all detections)；Recall是指在所有正确的（目标检测中指GT）中有多少被预测出来了，R=TP/(TP+FN)=TP/(all GTs)。<br>4）TP和FP的判断：VOC中对每个类别为car的bounding box,计算该bounding box与其所在的image中所有的GT的IoU（交并比），如果其中最大的IoU&gt;=0.5，则记为TP;否则记为FP(包括IoU都为0的情况）。</p>
<h1 id="论文《基于注意增强的密集图卷积网络的人体行为识别》"><a href="#论文《基于注意增强的密集图卷积网络的人体行为识别》" class="headerlink" title="论文《基于注意增强的密集图卷积网络的人体行为识别》"></a>论文《基于注意增强的密集图卷积网络的人体行为识别》</h1><h2 id="论文介绍"><a href="#论文介绍" class="headerlink" title="论文介绍"></a>论文介绍</h2><p>论文的研究方向是基于骨骼关键点的人体行为识别，是对视频中人体动作进行分类。论文的创新点主要有两点，首先现有的分层图卷积网络在聚合节点更宽范围的领域信息时，在长期扩散中弱化了局部邻域的特征，针对这个问题，我们提出了残差图卷积操作，增强局部领域的特征，接着利用密集连接结合通道注意模块重用不同模块间的上下文信息，增强节点的全局和局部特征。其次，在现有的算法认为所有的节点和帧信息对行为的判断具有相同的贡献，但是视频序列中存在大量的冗余的信息干扰模型的判断，带来准确率的下降，因此我们引入注意模块，通过计算不同特征间的相关性，增强有效的特征，抑制无关的特征。</p>
<h2 id="创新点-1"><a href="#创新点-1" class="headerlink" title="创新点"></a>创新点</h2><p>残差图卷积操作，原始的图卷积操作层间传播可简化为$X^{l+1}=\delta(W^lX^lA)$，图中的邻接矩阵是根据拓扑结构预先设置的，我们认为邻接矩阵也是可以通过网络来自动学习的，为邻接矩阵中的每个元素都设置一个权重，我们提出$X^{l+1}=\delta(W^lX^l(A\cdot M)+X^l)$，使网络在学习一般的权重矩阵W外，还要学习一个邻接矩阵的权重矩阵M，使得网络可以学习节点更多的局部领域特征。并且我们将短连接将输入和输出进行逐元素求和，使得网络在聚合更宽范围领域的信息时也能更好的保留局部信息。<br>密集连接，网络的结构类似于densenet模型，和densenet将不同模块的信息在channel通道concate来重用上下文特征不同，在密集连接的图卷积网络中结合通道注意模块将不同模块的上下文信息逐元素求和，来降低图卷积网络层数过深容易梯度消失带来的影响，从而增强了节点的全局和局部特征。<br>注意模块，主要分为channel attention module和spatial-temporal attention module。通道注意模块主要是计算不同特征通道间的相关性，把重要的特征进行增强，结合密集连接可以有效增强上下文的时空特征。时空注意模块是计算不同节点和不同帧间的相关性，和通道注意模块不同，我们认为关节的重要性和时间是耦合关系，因此我们联合关节维度和时间维度来计算模块间的相关性，增强关键帧和关键关节的信息。<br>多流信息融合，通过关节信息计算人体骨架的二阶骨骼信息和运动信息，可以有效的补充单模态信息的不足，促进行为识别的准确率。</p>
<h1 id="基于机器学习的多模态手势识别算法研究与实现"><a href="#基于机器学习的多模态手势识别算法研究与实现" class="headerlink" title="基于机器学习的多模态手势识别算法研究与实现"></a>基于机器学习的多模态手势识别算法研究与实现</h1><h2 id="项目介绍-4"><a href="#项目介绍-4" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>本科毕设项目，选取美国手势语言数据集ASL为研究对象，研究基于卷积神经网络的手势图像处理和识别方法，主要的研究多模态的手势识别方法。基于RGB图像和深度图像的联合使用，能有效提高手势识别的准确率。</p>
<h2 id="项目内容"><a href="#项目内容" class="headerlink" title="项目内容"></a>项目内容</h2><p><a href="http://www.kevinlt.top/2018/10/23/hand_segment/" target="_blank" rel="noopener">手部区域分割</a><br>首先是手部区域的分割，将RGB图像转换到YCrCb颜色空间下，其Y通道表示明亮度，即灰阶值；Cr，Cb通道则表示色度，用于描述色彩及饱和度，其中Cr反映了图像信号红色部分与亮度值之间的差异，而Cb反应信号中蓝色部分与亮度之间的差异。在Cr通道下，手部区域和其他区域有较大差别，利用该特性对手部区域进行分割。采用Ostu阈值分割，将手部的前景区域提取出来。对于存在的一些噪声，通过先腐蚀再膨胀操作，可以去除其中的一些毛边。去除毛边后我们从中挑选出最大的contour，基本可以得到手部的前景区域。其次，上述的算法在存在人脸肤色干扰时，不能得到干净的手部区域，故采用深度图像来去除人脸肤色的干扰。将提取的人体肤色的mask和深度图像相乘，去除背景的干扰，然后利用k-means聚类算法从深度图像中分离出人脸区域的位置，只保留手部的区域。将手部的mask和RGB图像相乘，然后利用VGG16网络进行手势动作的分类，有效提高了手势识别的精确性和鲁棒性。<br>Ostu算法：假定图像包含两类像素（前景像素和背景像素），直方图为双峰直方图，然后计算使得两类像素能分开的最佳阈值（类内方差），或等价的间类间方差最大。</p>
<h1 id="自我介绍"><a href="#自我介绍" class="headerlink" title="自我介绍"></a>自我介绍</h1><p>（一分钟版本）<br>您好，很感谢你在百忙中抽出时间给我这次面试的机会。我叫高信凯，今年25岁，是北京邮电大学信息与通信工程专业2018级硕士研究生，想要应聘的职位是xxx。本科阶段由于我保送到北邮读研究生，在毕设期间参加了实验室关于手势识别方面的项目，坚定了我从事这方面工作的决心。在2018年9月份我和同学组队参加了天池的铝材瑕疵检测比赛，激烈的比赛使我对视觉领域有了更深入的认识和了解。后来我开始负责实验室的智能辅助健身锻炼系统的项目，参与并完成了整个平台的设计和搭建过程，在深入的研究过程中进一步发掘出自己的研究方向，因此我决定将计算机视觉方向作为我未来事业的起点。我非常喜欢贵公司的这个职位，相信它能充分满足我的兴趣并体现自身的价值，我也有信心有能力做好这份工作。非常感谢贵公司给与我这次面试学习的机会，谢谢。<br>（简短版本）<br>您好，我叫高信凯，今年25岁，是北京邮电大学信息与通信工程专业2018级硕士研究生，想要应聘的职位是xxx。我非常喜欢贵公司的这个职位，相信它能充分满足我的兴趣并体现自身的价值，我也有信心有能力做好这份工作。非常感谢贵公司给与我这次面试学习的机会，谢谢。</p>
<h1 id="平常如何学习"><a href="#平常如何学习" class="headerlink" title="平常如何学习"></a>平常如何学习</h1><p>在研究生阶段，除了学科知识的学习外，在课余阶段我通常以问题导向型进行知识的积累。比如在学习视觉算法中分类问题的时候，我先开始了解经典的网络模型，学习不同的网络模型的思路及创新点，然后查阅各种资料论文关注模型的参数设置，损失函数的收敛等等知识，从而是自己能够高效的学习该方面的知识。</p>
<h1 id="上过哪些CV课程"><a href="#上过哪些CV课程" class="headerlink" title="上过哪些CV课程"></a>上过哪些CV课程</h1><p>研究生课程：视频大数据的机器学习、模式识别与机器学习、神经网络与模糊系统、图像分析与机器视觉<br>自学课程：吴恩达教授的CS229网课、李飞飞教授的CS231n网课。</p>
<h1 id="项目中遇到的重大问题"><a href="#项目中遇到的重大问题" class="headerlink" title="项目中遇到的重大问题"></a>项目中遇到的重大问题</h1><p>在完成国家电网能力开发平台时，由于项目是采用的基于RPC的 HSF协议进行模块之间的通信。HSF是阿里内部使用的模块间通信的方式，我之前没有使用过，通过短期的学习能力，调通分布式模块之间通信的问题，在这个项目即将上线部署的时候，我们需要到电网公司内部进行压力测试，我遇到的比较大的一个难题是项目上线部署后各个模块之间无法通信。最后通过分析Edas平台各个服务IP地址和服务端口，以及redis日志文件，判断到最后是因为一个模块之中的redis地址出错导致没有启动redis。引发的后续通信的问题。体现了排错能力和自主解决问题的能力。</p>
<h1 id="项目如何跟别人合作"><a href="#项目如何跟别人合作" class="headerlink" title="项目如何跟别人合作"></a>项目如何跟别人合作</h1><p>在项目合作过程中，小组成员集体讨论项目需求，提出具体的项目方案后，根据每人的研究方向和动手能力分配工作量，并统一使用github进行代码的托管和维护。</p>
<h1 id="有什么想问的（一面、二面、三面分别问什么）"><a href="#有什么想问的（一面、二面、三面分别问什么）" class="headerlink" title="有什么想问的（一面、二面、三面分别问什么）"></a>有什么想问的（一面、二面、三面分别问什么）</h1><p>请问我应聘的这个职位所在团队面对着怎样的问题和挑战？另外，贵公司对这个职务有怎样的期待呢？<br>在刚入职的两三个月里，公司更希望这个岗位的信任把工作重心放在哪个方向呢？<br>公司针对实习生的培养机制是怎样的呢？团队的技术栈是什么样的？在去实习前应该重点学习哪些技术呢？</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/11/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D%EF%BC%88%E8%AF%A6%E7%BB%86%E7%89%88%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/11/%E7%AE%80%E5%8E%86%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D%EF%BC%88%E8%AF%A6%E7%BB%86%E7%89%88%EF%BC%89/" class="post-title-link" itemprop="url">简历项目介绍（详细版）</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-11 09:07:30" itemprop="dateCreated datePublished" datetime="2020-02-11T09:07:30+08:00">2020-02-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-07 09:30:08" itemprop="dateModified" datetime="2020-03-07T09:30:08+08:00">2020-03-07</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="基于姿态估计的康复健身平台"><a href="#基于姿态估计的康复健身平台" class="headerlink" title="基于姿态估计的康复健身平台"></a>基于姿态估计的康复健身平台</h1><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul>
<li>系统架构<ul>
<li>前端设计</li>
<li>后台架构</li>
</ul>
</li>
<li>算法模块<ul>
<li>2D姿态估计</li>
<li>3D姿态估计</li>
<li>动作识别</li>
</ul>
</li>
</ul>
<h2 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>本项目来源是北京邮电大学的创新创业项目，主要目的是为了搭建基于人体姿态估计算法的平台，为用户在家中使用普通的2D摄像头，辅助进行健身和康复训练提供检测和指导。</p>
<h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p><img src="/images/system.jpg" alt="系统架构"><br>摄像头采集图片，每秒采集10帧，将视频帧(600, 400)转为base64编码格式，和用户的user-token、任务的task-id一起封装成Json对象。然后通过stomp通信协议，利用activemq消息中间件进行前端和后台之间的信息传递。前端模拟生产者发送消息，通过设定的topics发送到对应的队列Queues中。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> client, destination, login, passcode;</span><br><span class="line">url = <span class="string">"ws://10.103.238.165:61614"</span>;</span><br><span class="line">destination = <span class="string">"/queue/video"</span>;</span><br><span class="line">login = <span class="string">"admin"</span>;</span><br><span class="line">passcode = <span class="string">"password"</span>;</span><br><span class="line"></span><br><span class="line">client = Stomp.client(url);</span><br><span class="line"><span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">timer = setInterval(</span></span><br><span class="line"><span class="string">            function () &#123;</span></span><br><span class="line"><span class="string">                ctx.drawImage(video, 0, 0, 600, 400);</span></span><br><span class="line"><span class="string">                var data = canvas.toDataURL('</span>image/jpeg<span class="string">', 1.0);    //将获取到的图像转换为base64编码</span></span><br><span class="line"><span class="string">                //newblob = dataURItoBlob(data);</span></span><br><span class="line"><span class="string">                //添加状态判断，当为OPEN时，发送消息</span></span><br><span class="line"><span class="string">                //var message = &#123;&#125;;</span></span><br><span class="line"><span class="string">                client.send(destination, &#123;'</span>user-token<span class="string">': 123, '</span>task<span class="string">': 0x01&#125;, data);//发送消息, 0x02 -&gt; 0000 0010</span></span><br><span class="line"><span class="string">                //接收图片时间</span></span><br><span class="line"><span class="string">                var timestamp = new Date().getTime();</span></span><br><span class="line"><span class="string">            &#125;, 100);</span></span><br></pre></td></tr></table></figure><br>后台是是SpringBoot+Mybatis框架搭建，通过模拟一个消费者，应用监听器监听消息。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@JmsListener</span>(destination = <span class="string">"video"</span>,containerFactory = <span class="string">"jmsListenerContainerQueue"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processImage</span><span class="params">(Message message)</span> </span>&#123;</span><br><span class="line"><span class="comment">//      if (message instanceof BytesMessage) &#123;</span></span><br><span class="line">            BytesMessage bytesMessage = (BytesMessage)message;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 得到一些参数：</span></span><br><span class="line">                String user_token = String.valueOf(bytesMessage.getByteProperty(<span class="string">"user-token"</span>));  <span class="comment">// user-token</span></span><br><span class="line">                String task = String.valueOf(bytesMessage.getByteProperty(<span class="string">"task"</span>));               <span class="comment">// task</span></span><br><span class="line">                String image_base64 =<span class="string">""</span>;                                            <span class="comment">// origin image</span></span><br><span class="line">                UUID uuid= UUID.randomUUID();</span><br><span class="line">                String imageID = uuid.toString();                                   <span class="comment">// imageID</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>*<span class="number">1024</span>];</span><br><span class="line">                <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">while</span>((len=bytesMessage.readBytes(buffer))!=-<span class="number">1</span>)&#123;</span><br><span class="line">                    image_base64 = <span class="keyword">new</span> String(buffer,<span class="number">0</span>,len);</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                Jedis jedis = jedisPool.getResource();</span><br><span class="line">                Map&lt;String,String&gt; imageData = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">                imageData.put(<span class="string">"imageID"</span>,imageID);</span><br><span class="line">                imageData.put(<span class="string">"userToken"</span>,user_token);</span><br><span class="line">                imageData.put(<span class="string">"taskList"</span>,task);</span><br><span class="line">                imageData.put(<span class="string">"image"</span>,image_base64);</span><br><span class="line"></span><br><span class="line">                JSONObject jsonObject = JSONObject.fromObject(imageData);</span><br><span class="line"></span><br><span class="line"><span class="comment">//              比较task列表并分发存入对应的redis的list</span></span><br><span class="line">                <span class="keyword">int</span> taskToDo = Integer.parseInt(task);</span><br><span class="line">                <span class="keyword">if</span>((taskToDo&amp;<span class="number">0x01</span>)&gt;<span class="number">0</span>) &#123; <span class="comment">//pose</span></span><br><span class="line">                    jedis.rpush(<span class="string">"image_queue_to_pose_estimation"</span>, jsonObject.toString());</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>((taskToDo&amp;<span class="number">0x02</span>)&gt;<span class="number">0</span>)&#123; <span class="comment">//face</span></span><br><span class="line">                    jedis.rpush(<span class="string">"image_queue_to_face_recognition"</span>, jsonObject.toString());</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>((taskToDo&amp;<span class="number">0x04</span>)&gt;<span class="number">0</span>)&#123; <span class="comment">//object</span></span><br><span class="line">                    jedis.rpush(<span class="string">"image_queue_to_object_recognition"</span>, jsonObject.toString());</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">//手动释放资源，不然会因为jedisPool里面的maxActive=200的限制，只能创建200个jedis资源。</span></span><br><span class="line">                jedis.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (JMSException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><br>后台将前端发送的Json对象解析出来，为了保证每张图片不重复，使用UUID随机生成图片ID(image_id)，将image_id、user_token、task_id和image_base64放入Hashmap中，转成Json对象存入redis中，通过redis的发布/订阅模式，和服务器算法进行信息传输。算法一直运行在服务器上，订阅redis的频道channel，来监听redis中存储的消息。将消息中的Json对象解析出来后，将base_64编码的图片数据解码转变成numpy矩阵类型，送入深度学习模型，将得到的human对象的list,human对象里包含BodyParts，是每个对象的x,y坐标和置信度值。然后human对象封装成Json对象，通过发布新的通道存储在redis中，业务后台同样订阅该通道，将算法模块返回的结果通过websocket方式提供给前端展示。</p>
<h3 id="消息中间件"><a href="#消息中间件" class="headerlink" title="消息中间件"></a>消息中间件</h3><p>消息中间件事一种夸进程的通信方式，这种方式使得系统之间上下游进行了逻辑和物理解耦合。使用消息中间件，在C/S或B/S模型中，请求可以由服务器端主动发起；消息中间件与上下游相对独立，不关心系统的技术架构，更适用于异构系统之间的通信和数据交互。</p>
<ol>
<li>ActiveMQ<br>ActiveMQ支持两种消息队列模型为点对点（Point To Point）模型和发布-订阅（Publisher To Subscriber）模型。其中，点对点模型以queue作为消息的承载，消息生产者发送消息到queue中，然后消费者获取消息。对于已经被消费过的信息，queue中不再存储，虽然支持多个消费者，但一个消息只能被消费一次。发布-订阅模型，以topic承载消息，生产者发布消息到topic中，订阅该topic的多个消费者能同时接收到该消息。消息的两种传送机制为推送和拉取。推送的方式有消息中间件主动将消息发送给消费者，能处理快速即时的消息，但如果消费者处理消息能力较弱，消息推送不断，则有可能造成缓冲区的溢出；拉取的方式由消费者主动向消息中间件拉取信息，会造成消息的部分延迟。</li>
<li>Redis<br>Redis作为key-value内存型存储系统，一般作为缓存中间件使用，在某些场景下也可以作为消息中间件进行数据的缓存和传输。Redis具有基于内存的高速读写特性，支持String、List、Hash、Set、Zset五种类型的操作，支持原子性事务，还具有较为丰富的特性。将Redis作为消息中间件使用，一般利用其列表的数据结构，生产者通过Ipush来发布消息，消费者通过brpop来获取消息。此种实现方式，在Redis宕机且数据没有持久化的情况下可能造成数据的丢失，对于数据可靠性要求不是太高的场景中适用。</li>
</ol>
<h2 id="算法模块"><a href="#算法模块" class="headerlink" title="算法模块"></a>算法模块</h2><h3 id="2D姿态估计"><a href="#2D姿态估计" class="headerlink" title="2D姿态估计"></a>2D姿态估计</h3><p><a href="https://blog.csdn.net/zziahgf/article/details/79643752" target="_blank" rel="noopener">CPM模型</a><br><a href="https://blog.csdn.net/htt789/article/details/80283370" target="_blank" rel="noopener">openpose姿态估计</a><br><a href="https://zhuanlan.zhihu.com/p/66803058" target="_blank" rel="noopener">openpose</a><br><a href="https://blog.csdn.net/young__fan/article/details/90719285" target="_blank" rel="noopener">匈牙利算法</a><br>使用openpose获得人体的18个关键点坐标，然后输入HCN网络进行动作分类，然后使用动态时间规划进行动作匹配。<br>数据集：公司给的健身动作视频，每个动作是3-5s，每组动作锻炼30次，总共进行8组，每段视频都是是单一的健身指导视频。由于视频中只有单一的参与者指导动作，训练数据背景单一，估考虑采用基于骨骼关键点的行为识别。<br>算法流程：<br>1.从redis中读取图片，将base64编码转为矩阵数据<br>2.输入openpose算法，得到人体的18个关键点。<br>BODY_PARTS = { “Nose”: 0, “Neck”: 1, “RShoulder”: 2, “RElbow”:3, “RWrist”: 4, “LShoulder”: 5, “LElbow”: 6, “LWrist”: 7, “RHip”: 8, “RKnee”: 9, “RAnkle”: 10, “LHip”: 11, “LKnee”: 12, “LAnkle”: 13, “REye”: 14, “LEye”: 15, “REar”: 16, “LEar”: 17, “Background”: 18 }<br>3.将得到的17个关键点输入到HCN网络进行动作分类。<br>关键点：在训练动作分类网络时，可以对关键点信息进行数据增强。<br>1)归一化处理，将其他通道求平均，只保留C和V通道求数据的均值和方差，然后对每一个数据进行归一化处理。<br>2）时间片段选取，在150帧时间序列中选择有效的64帧<br>3）坐标旋转变换，随机设一个角度，对构建旋转矩阵，对关键点进行旋转变换。<br>CNN 模型在提取高层面信息方面能力出色，并且也已经被用于根据骨架学习空间-时间特征。这些基于 CNN 的方法可以通过将时间动态和骨架关节分别编码成行和列而将骨架序列表示成一张图像，然后就像图像分类一样将图像输入 CNN 来识别其中含有的动作。但是，在这种情况下，只有卷积核内的相邻关节才被认为是在学习共现特征。尽管感受野（receptive field）能在之后的卷积层中覆盖骨架的所有关节，但我们很难有效地从所有关节中挖掘共现特征。由于空间维度中的权重共享机制，CNN 模型无法为每个关节都学习自由的参数。这促使我们设计一个能获得所有关节的全局响应的模型，以利用不同关节之间的相关性。<br>着眼于人的行为动作的特点，我们将行为动作中关节点具有的共现性特性引入到网络设计中，将其作为网络参数学习的约束来优化识别性能。人的某个行为动作常常和骨架的一些特定关节点构成的集合，以及这个集合中节点的交互密切相关。如要判别是否在打电话，关节点“手腕”、“手肘”、“肩膀”和“头”的动作最为关键。不同的行为动作与之密切相关的节点集合有所不同。例如对于“走路”的行为动作，“脚腕”、“膝盖”、“臀部”等关节点构成具有判别力的节点集合。我们将这种几个关节点同时影响和决定判别的特性称为共现性（Co-occurrence）。<br>我们提出了一种端到端的共现特征学习框架，其使用了 CNN 来自动地从骨架序列中学习分层的共现特征。我们发现一个卷积层的输出是来自所有输入通道的全局响应。如果一个骨架的每个关节都被当作是一个通道，那么卷积层就可以轻松地学习所有关节的共现。更具体而言，我们将骨架序列表示成了一个形状帧×关节×3（最后一维作为通道）的张量。我们首先使用核大小为 n×1 的卷积层独立地为每个关节学习了点层面的特征。然后我们再将该卷积层的输出转置，以将关节的维度作为通道。在这个转置运算之后，后续的层分层地聚合来自所有关节的全局特征。<br><img src="/images/HCN.jpg" alt=""><br>我们提出的分层式共现网络（HCN：Hierarchical Co-occurrence Network）的概况。绿色模块是卷积层，其中最后一维表示输出通道的数量。后面的「/2」表示卷积之后附带的最大池化层，步幅为 2。转置层是根据顺序参数重新排列输入张量的维度。conv1、conv5、conv6 和 fc7 之后附加了 ReLU 激活函数以引入非线性。<br>4.动作匹配，采用动态时间规划（DTW）算法，判断用户的运动视频和标准动作是否匹配。<br><a href="https://zhuanlan.zhihu.com/p/32849741" target="_blank" rel="noopener">DTW介绍</a><br>比较在该段时间内用户的姿态的(x,y)坐标点与标准模板的相似度进行评分。我们需要构造一个nxm的矩阵网格，矩阵元素(i, j)表示qi和cj两个点的距离d(qi, cj)（也就是序列Q的每一个点和序列C的每一个点之间的相似度，距离越小则相似度越高。）我们定义一个累加距离cumulative distances。从(0, 0)点开始匹配这两个序列Q和C，每到一个点，之前所有的点计算的距离都会累加。到达终点(n, m)后，这个累积距离就是我们上面说的最后的总的距离，也就是序列Q和C的相似度。</p>
<script type="math/tex; mode=display">\gamma(i,j)=d(q_i,c_j)+min(\gamma(i-1,j-1),\gamma(i-1,j),\gamma(i,j-1))</script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bassyess.github.io/2020/02/10/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kay">
      <meta itemprop="description" content="千里之行，始于足下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Home">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/10/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-10 21:46:14" itemprop="dateCreated datePublished" datetime="2020-02-10T21:46:14+08:00">2020-02-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Kay</p>
  <div class="site-description" itemprop="description">千里之行，始于足下</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">28</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kay</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.1
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
